{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84526bc5-cd1a-4fac-a796-57902266c3bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "636876fb-747b-4480-8ea0-8ff0618bd573",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-18 17:59:41.221172: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-18 17:59:41.297448: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-10-18 17:59:41.297465: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-10-18 17:59:41.687064: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-10-18 17:59:41.687111: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-10-18 17:59:41.687117: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nbeats_keras.model import NBeatsNet as NBeatsKeras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "#from nbeats_pytorch.model import NBeatsNet as NBeatsPytorch\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "import time\n",
    "from keras.models import load_model\n",
    "#from target_data_electronic70_7 import target_X, target_y ,test_X, test_y\n",
    "#from m4databasis21_7 import base_domain,zt_in,zt_out,M4Meta,inputsize,train_12,train_12_y\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error,mean_absolute_percentage_error\n",
    "from tensorflow.keras.losses import Loss\n",
    "import tensorflow as tf\n",
    "#from m4databasis35_7_70_7 import train_35,train_35_y,train_70,train_70_y\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, LayerNormalization, MultiHeadAttention, Dropout, Add, Concatenate,Flatten,Reshape\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, TimeDistributed, Lambda\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3850e1af-7ef4-47f2-b130-6732c47014c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'ele'\n",
    "target_X= pd.read_csv(f\"../data/{data}_train_input_7.csv\").iloc[:,1:].values.astype(np.float32) / 10000\n",
    "target_y =pd.read_csv(f\"../data/{data}_train_output_7.csv\").iloc[:,1:].values.astype(np.float32) / 10000\n",
    "\n",
    "X_train = target_X[:-round(target_X.shape[0]*0.2),:].astype(np.float32)\n",
    "y_train = target_y[:-round(target_y.shape[0]*0.2)].astype(np.float32)\n",
    "\n",
    "X_train_val= target_X[-round(target_X.shape[0]*0.2):,:].astype(np.float32)\n",
    "y_train_val =target_y[-round(target_y.shape[0]*0.2):].astype(np.float32)\n",
    "\n",
    "\n",
    "test_X= pd.read_csv(f\"../data/{data}_val_input_7.csv\").iloc[:,1:].values.astype(np.float32) / 10000\n",
    "test_y =pd.read_csv(f\"../data/{data}_val_output_7.csv\").iloc[:,1:].values.astype(np.float32) / 10000\n",
    "\n",
    "#X_train=target_X.astype(np.float32)\n",
    "#y_train=target_y.astype(np.float32)\n",
    "#y_train.astype(np.float32)\n",
    "backcast_length = X_train.shape[1]\n",
    "forecast_length = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3aff672-3e0d-4a08-9d95-0a0eacbdbb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "# loss SMAPE\n",
    "class SMAPE(Loss):\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_pred = tf.reshape(y_pred, tf.shape(y_true))  # 예측 값의 차원을 맞춤\n",
    "       # y_pred=tf.clip_by_value(y_pred, 1e-10, tf.reduce_max(y_pred))\n",
    "       # y_true = tf.clip_by_value(y_true, 1e-10, tf.reduce_max(y_true))\n",
    "        \n",
    "        numerator = 100 * tf.abs(y_true- y_pred )\n",
    "        denominator =  (tf.abs(y_true ) + tf.abs(y_pred))/2\n",
    "        smape =  numerator /  denominator #tf.clip_by_value(denominator, 1e-10, tf.reduce_max(denominator))\n",
    "        return tf.reduce_mean(smape)\n",
    "\n",
    "#################################################################################\n",
    "# loss MASE\n",
    "class MASE(Loss):\n",
    "    def __init__(self, training_data, period, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.scale = self.calculate_scale(training_data, period)\n",
    "    def seasonal_diff(data, period):\n",
    "        return data[period:] - data[:-period]\n",
    "\n",
    "    def calculate_scale(self, training_data, period):\n",
    "        # 주기 차분 계산\n",
    "        diff = seasonal_diff(training_data, period)\n",
    "        scale = np.mean(np.abs(diff))\n",
    "        return scale\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        y_pred = tf.reshape(y_pred, tf.shape(y_true))  # 차원 맞추기\n",
    "        error = tf.abs(y_true - y_pred)\n",
    "        return tf.reduce_mean(error / self.scale)\n",
    "\n",
    "def seasonal_diff(data, period):\n",
    "    return data[period:] - data[:-period]\n",
    "#################################################################################\n",
    "# 하이퍼파라미터 인자 설정\n",
    "def hyperparameter():\n",
    "    # 1 backcast\n",
    "    # 2 forecast\n",
    "    # 3 inputdim\n",
    "    # 4 outputdim\n",
    "    # 5 unit\n",
    "    # 6 bacth size\n",
    "    return X_train.shape[1],1,y_train.shape[1]\n",
    "\n",
    "#################################################################################\n",
    "# nbeats 모델 생성 함수\n",
    "def build_model(input_timesteps,features,output_timesteps):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, return_sequences=True, input_shape=(input_timesteps, features)))\n",
    "    model.add(LSTM(64, return_sequences=True))\n",
    "    #model.add(LSTM(unit, return_sequences=True))\n",
    "    # Use Lambda layer to select the last 'output_timesteps' outputs\n",
    "    model.add(Lambda(lambda x: x[:, -24:, :]))\n",
    "    model.add(TimeDistributed(Dense(1)))\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model.compile(loss='mse', optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "#################################################################################\n",
    "# 부트스트랩 샘플링\n",
    "# 배깅\n",
    "\n",
    "def train_bagging_models(num_models, loss_fn , epochs_, patience_,batch_size_,lr):\n",
    "    models = {}\n",
    "    input_timesteps,features,output_timesteps= hyperparameter()\n",
    "    historys = []\n",
    "    for n in range(num_models):\n",
    "        K.clear_session()\n",
    "        model = build_model(input_timesteps,features,output_timesteps)\n",
    "       # model.set_weights(pretrained_weights)  # 전이 학습 가중치 적용\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "        model.compile(optimizer=optimizer , loss=loss_fn)\n",
    "        \n",
    "        # 부트스트랩 샘플링\n",
    "        #select = np.random.choice(len(X_train), size=len(X_train), replace=True)\n",
    "        #X_bootstrap = X_train[select]\n",
    "        #y_bootstrap = y_train[select]\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience = patience_, verbose = 1, restore_best_weights=True)\n",
    "        history = model.fit(X_train, y_train, batch_size = batch_size_,\n",
    "                  epochs=epochs_, verbose=1, \n",
    "                  callbacks=[early_stop],\n",
    "                validation_data = [X_train_val,y_train_val])\n",
    "        models[f'model_{n+1}'] = model\n",
    "        historys.append(history)\n",
    "        #models.append(model)\n",
    "        print(f\"'########################################################Model{n}\")\n",
    "    return models,historys\n",
    "\n",
    "#################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#################################################################################\n",
    "\n",
    "def bagging_predict(models, X):\n",
    "    predictions = np.array([model.predict(X) for model in models.values()])\n",
    "    return np.median(predictions, axis=0)\n",
    "\n",
    "def bagging_predict2(models, X):\n",
    "    predictions = np.array([model.predict(X) for model in models.values()])\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27d56b6-6ab8-4a68-894a-11912352091e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce9eb03-7500-4d76-af24-72f76cc67df4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-18 17:59:48.235914: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-10-18 17:59:48.235956: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ymlee2-desktop): /proc/driver/nvidia/version does not exist\n",
      "2024-10-18 17:59:48.236755: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "73/73 [==============================] - 8s 83ms/step - loss: 4.3294 - val_loss: 1.1657\n",
      "Epoch 2/2000\n",
      "73/73 [==============================] - 6s 78ms/step - loss: 0.9306 - val_loss: 0.9428\n",
      "Epoch 3/2000\n",
      "73/73 [==============================] - 6s 80ms/step - loss: 0.9062 - val_loss: 0.9267\n",
      "Epoch 4/2000\n",
      "73/73 [==============================] - 6s 78ms/step - loss: 0.8852 - val_loss: 0.8952\n",
      "Epoch 5/2000\n",
      "73/73 [==============================] - 6s 78ms/step - loss: 0.8567 - val_loss: 0.8504\n",
      "Epoch 6/2000\n",
      "73/73 [==============================] - 6s 78ms/step - loss: 0.8241 - val_loss: 0.8197\n",
      "Epoch 7/2000\n",
      "73/73 [==============================] - 6s 79ms/step - loss: 0.7942 - val_loss: 0.7820\n",
      "Epoch 8/2000\n",
      "73/73 [==============================] - 6s 80ms/step - loss: 0.7597 - val_loss: 0.7974\n",
      "Epoch 9/2000\n",
      "73/73 [==============================] - 6s 78ms/step - loss: 0.7123 - val_loss: 0.6918\n",
      "Epoch 10/2000\n",
      "73/73 [==============================] - 6s 80ms/step - loss: 0.6669 - val_loss: 0.6244\n",
      "Epoch 11/2000\n",
      "73/73 [==============================] - 6s 79ms/step - loss: 0.6409 - val_loss: 0.6077\n",
      "Epoch 12/2000\n",
      "73/73 [==============================] - 6s 80ms/step - loss: 0.6259 - val_loss: 0.6482\n",
      "Epoch 13/2000\n",
      "73/73 [==============================] - 6s 80ms/step - loss: 0.6093 - val_loss: 0.5776\n",
      "Epoch 14/2000\n",
      "73/73 [==============================] - 6s 79ms/step - loss: 0.5984 - val_loss: 0.6460\n",
      "Epoch 15/2000\n",
      "73/73 [==============================] - 6s 81ms/step - loss: 0.5907 - val_loss: 0.5637\n",
      "Epoch 16/2000\n",
      "73/73 [==============================] - 6s 79ms/step - loss: 0.5785 - val_loss: 0.5536\n",
      "Epoch 17/2000\n",
      "73/73 [==============================] - 6s 80ms/step - loss: 0.5769 - val_loss: 0.5528\n",
      "Epoch 18/2000\n",
      "73/73 [==============================] - 6s 80ms/step - loss: 0.5546 - val_loss: 0.5460\n",
      "Epoch 19/2000\n",
      "73/73 [==============================] - 6s 81ms/step - loss: 0.5453 - val_loss: 0.5412\n",
      "Epoch 20/2000\n",
      "73/73 [==============================] - 6s 80ms/step - loss: 0.5383 - val_loss: 0.5313\n",
      "Epoch 21/2000\n",
      "73/73 [==============================] - 6s 81ms/step - loss: 0.5339 - val_loss: 0.5237\n",
      "Epoch 22/2000\n",
      "73/73 [==============================] - 6s 81ms/step - loss: 0.5123 - val_loss: 0.5151\n",
      "Epoch 23/2000\n",
      "73/73 [==============================] - 6s 82ms/step - loss: 0.5209 - val_loss: 0.4984\n",
      "Epoch 24/2000\n",
      "73/73 [==============================] - 6s 82ms/step - loss: 0.4958 - val_loss: 0.5205\n",
      "Epoch 25/2000\n",
      "73/73 [==============================] - 6s 79ms/step - loss: 0.4893 - val_loss: 0.4923\n",
      "Epoch 26/2000\n",
      "73/73 [==============================] - 6s 81ms/step - loss: 0.4475 - val_loss: 0.4707\n",
      "Epoch 27/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 0.4426 - val_loss: 0.4904\n",
      "Epoch 28/2000\n",
      "73/73 [==============================] - 6s 82ms/step - loss: 0.4299 - val_loss: 0.4847\n",
      "Epoch 29/2000\n",
      "73/73 [==============================] - 6s 82ms/step - loss: 0.4186 - val_loss: 0.4434\n",
      "Epoch 30/2000\n",
      "73/73 [==============================] - 6s 81ms/step - loss: 0.4031 - val_loss: 0.4242\n",
      "Epoch 31/2000\n",
      "73/73 [==============================] - 6s 82ms/step - loss: 0.3840 - val_loss: 0.4118\n",
      "Epoch 32/2000\n",
      "73/73 [==============================] - 6s 82ms/step - loss: 0.3715 - val_loss: 0.4080\n",
      "Epoch 33/2000\n",
      "73/73 [==============================] - 6s 81ms/step - loss: 0.3575 - val_loss: 0.4050\n",
      "Epoch 34/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 0.3621 - val_loss: 0.4034\n",
      "Epoch 35/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 0.3572 - val_loss: 0.3767\n",
      "Epoch 36/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 0.3502 - val_loss: 0.4028\n",
      "Epoch 37/2000\n",
      "73/73 [==============================] - 6s 82ms/step - loss: 0.3557 - val_loss: 0.3913\n",
      "Epoch 38/2000\n",
      "73/73 [==============================] - 6s 82ms/step - loss: 0.3512 - val_loss: 0.4004\n",
      "Epoch 39/2000\n",
      "73/73 [==============================] - 6s 82ms/step - loss: 0.3403 - val_loss: 0.3437\n",
      "Epoch 40/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 0.3373 - val_loss: 0.3605\n",
      "Epoch 41/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 0.3281 - val_loss: 0.3801\n",
      "Epoch 42/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 0.3330 - val_loss: 0.3779\n",
      "Epoch 43/2000\n",
      "73/73 [==============================] - 6s 82ms/step - loss: 0.3287 - val_loss: 0.3640\n",
      "Epoch 44/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 0.3228 - val_loss: 0.3666\n",
      "Epoch 45/2000\n",
      "73/73 [==============================] - 6s 80ms/step - loss: 0.3361 - val_loss: 0.3402\n",
      "Epoch 46/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 0.3351 - val_loss: 0.3543\n",
      "Epoch 47/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 0.3240 - val_loss: 0.3436\n",
      "Epoch 48/2000\n",
      "73/73 [==============================] - 6s 82ms/step - loss: 0.3075 - val_loss: 0.3532\n",
      "Epoch 49/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 0.3125 - val_loss: 0.3512\n",
      "Epoch 50/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 0.3046 - val_loss: 0.3320\n",
      "Epoch 51/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 0.2965 - val_loss: 0.3301\n",
      "Epoch 52/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 0.3025 - val_loss: 0.3298\n",
      "Epoch 53/2000\n",
      "73/73 [==============================] - 6s 82ms/step - loss: 0.3095 - val_loss: 0.3190\n",
      "Epoch 54/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 0.2949 - val_loss: 0.3383\n",
      "Epoch 55/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 0.2971 - val_loss: 0.3317\n",
      "Epoch 56/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 0.2967 - val_loss: 0.3463\n",
      "Epoch 57/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 0.3043 - val_loss: 0.3321\n",
      "Epoch 58/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 0.2977 - val_loss: 0.3122\n",
      "Epoch 59/2000\n",
      "73/73 [==============================] - 6s 82ms/step - loss: 0.3028 - val_loss: 0.3083\n",
      "Epoch 60/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.2949 - val_loss: 0.3401\n",
      "Epoch 61/2000\n",
      "73/73 [==============================] - 6s 82ms/step - loss: 0.2889 - val_loss: 0.3097\n",
      "Epoch 62/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 0.2896 - val_loss: 0.3029\n",
      "Epoch 63/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 0.2976 - val_loss: 0.3093\n",
      "Epoch 64/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 0.2883 - val_loss: 0.3253\n",
      "Epoch 65/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 0.2865 - val_loss: 0.3234\n",
      "Epoch 66/2000\n",
      "73/73 [==============================] - 6s 82ms/step - loss: 0.2912 - val_loss: 0.2859\n",
      "Epoch 67/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 0.2800 - val_loss: 0.3367\n",
      "Epoch 68/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 0.2958 - val_loss: 0.2947\n",
      "Epoch 69/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 0.2814 - val_loss: 0.3079\n",
      "Epoch 70/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 0.2746 - val_loss: 0.3031\n",
      "Epoch 71/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 0.2753 - val_loss: 0.3058\n",
      "Epoch 72/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 0.2829 - val_loss: 0.2930\n",
      "Epoch 73/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 0.2788 - val_loss: 0.3013\n",
      "Epoch 74/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 0.2856 - val_loss: 0.2834\n",
      "Epoch 75/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.2733 - val_loss: 0.2859\n",
      "Epoch 76/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.2776 - val_loss: 0.3374\n",
      "Epoch 77/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.2708 - val_loss: 0.2907\n",
      "Epoch 78/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.2648 - val_loss: 0.3092\n",
      "Epoch 79/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 0.2716 - val_loss: 0.3132\n",
      "Epoch 80/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 0.2668 - val_loss: 0.2839\n",
      "Epoch 81/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 0.2767 - val_loss: 0.2826\n",
      "Epoch 82/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.2687 - val_loss: 0.2893\n",
      "Epoch 83/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 0.2654 - val_loss: 0.2812\n",
      "Epoch 84/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 0.2753 - val_loss: 0.3436\n",
      "Epoch 85/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 0.2663 - val_loss: 0.2886\n",
      "Epoch 86/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.2627 - val_loss: 0.2693\n",
      "Epoch 87/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 0.2679 - val_loss: 0.2734\n",
      "Epoch 88/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.2683 - val_loss: 0.2692\n",
      "Epoch 89/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.2604 - val_loss: 0.2897\n",
      "Epoch 90/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.2612 - val_loss: 0.2935\n",
      "Epoch 91/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.2682 - val_loss: 0.2683\n",
      "Epoch 92/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 0.2559 - val_loss: 0.2951\n",
      "Epoch 93/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.2639 - val_loss: 0.2673\n",
      "Epoch 94/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.2648 - val_loss: 0.2872\n",
      "Epoch 95/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.2539 - val_loss: 0.2827\n",
      "Epoch 96/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.2522 - val_loss: 0.2675\n",
      "Epoch 97/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.2575 - val_loss: 0.2796\n",
      "Epoch 98/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.2567 - val_loss: 0.2638\n",
      "Epoch 99/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.2577 - val_loss: 0.2758\n",
      "Epoch 100/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.2589 - val_loss: 0.2674\n",
      "Epoch 101/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.2515 - val_loss: 0.2732\n",
      "Epoch 102/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.2606 - val_loss: 0.2904\n",
      "Epoch 103/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.2598 - val_loss: 0.2678\n",
      "Epoch 104/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 0.2451 - val_loss: 0.2642\n",
      "Epoch 105/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.2523 - val_loss: 0.2600\n",
      "Epoch 106/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.2453 - val_loss: 0.2737\n",
      "Epoch 107/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.2418 - val_loss: 0.2813\n",
      "Epoch 108/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.2522 - val_loss: 0.2565\n",
      "Epoch 109/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.2475 - val_loss: 0.2690\n",
      "Epoch 110/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 0.2581 - val_loss: 0.2720\n",
      "Epoch 111/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.2506 - val_loss: 0.2794\n",
      "Epoch 112/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.2602 - val_loss: 0.2625\n",
      "Epoch 113/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.2446 - val_loss: 0.2743\n",
      "Epoch 114/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.2461 - val_loss: 0.2800\n",
      "Epoch 115/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 0.2504 - val_loss: 0.2544\n",
      "Epoch 116/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.2391 - val_loss: 0.2685\n",
      "Epoch 117/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.2496 - val_loss: 0.2757\n",
      "Epoch 118/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.2501 - val_loss: 0.2765\n",
      "Epoch 119/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.2431 - val_loss: 0.2690\n",
      "Epoch 120/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.2505 - val_loss: 0.2691\n",
      "Epoch 121/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.2475 - val_loss: 0.2521\n",
      "Epoch 122/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.2452 - val_loss: 0.2759\n",
      "Epoch 123/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 0.2437 - val_loss: 0.2526\n",
      "Epoch 124/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.2345 - val_loss: 0.2615\n",
      "Epoch 125/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.2440 - val_loss: 0.2683\n",
      "Epoch 126/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.2423 - val_loss: 0.2606\n",
      "Epoch 127/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.2355 - val_loss: 0.2551\n",
      "Epoch 128/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.2297 - val_loss: 0.2833\n",
      "Epoch 129/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.2438 - val_loss: 0.2538\n",
      "Epoch 130/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.2397 - val_loss: 0.2611\n",
      "Epoch 131/2000\n",
      "73/73 [==============================] - ETA: 0s - loss: 0.2379Restoring model weights from the end of the best epoch: 121.\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.2379 - val_loss: 0.2686\n",
      "Epoch 131: early stopping\n",
      "'########################################################Model0\n",
      "Epoch 1/2000\n",
      "73/73 [==============================] - 8s 93ms/step - loss: 5.0087 - val_loss: 2.1150\n",
      "Epoch 2/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 1.0826 - val_loss: 0.9579\n",
      "Epoch 3/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.9225 - val_loss: 0.9490\n",
      "Epoch 4/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.9035 - val_loss: 0.9031\n",
      "Epoch 5/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.8782 - val_loss: 0.9494\n",
      "Epoch 6/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.8897 - val_loss: 0.9066\n",
      "Epoch 7/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.8708 - val_loss: 0.8761\n",
      "Epoch 8/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.8470 - val_loss: 0.8469\n",
      "Epoch 9/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.8275 - val_loss: 0.8261\n",
      "Epoch 10/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.8164 - val_loss: 0.8242\n",
      "Epoch 11/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.7931 - val_loss: 0.8235\n",
      "Epoch 12/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.7881 - val_loss: 0.7650\n",
      "Epoch 13/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.7509 - val_loss: 0.7318\n",
      "Epoch 14/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.7124 - val_loss: 0.6948\n",
      "Epoch 15/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.6870 - val_loss: 0.6497\n",
      "Epoch 16/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.6404 - val_loss: 0.6215\n",
      "Epoch 17/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.6181 - val_loss: 0.6255\n",
      "Epoch 18/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.6034 - val_loss: 0.5750\n",
      "Epoch 19/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.5913 - val_loss: 0.5845\n",
      "Epoch 20/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.5797 - val_loss: 0.5565\n",
      "Epoch 21/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.5842 - val_loss: 0.5478\n",
      "Epoch 22/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.5578 - val_loss: 0.5407\n",
      "Epoch 23/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.5528 - val_loss: 0.5311\n",
      "Epoch 24/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.5414 - val_loss: 0.5326\n",
      "Epoch 25/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.5379 - val_loss: 0.5453\n",
      "Epoch 26/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.5397 - val_loss: 0.5289\n",
      "Epoch 27/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.5294 - val_loss: 0.5374\n",
      "Epoch 28/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.5287 - val_loss: 0.5113\n",
      "Epoch 29/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.5223 - val_loss: 0.5133\n",
      "Epoch 30/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.5283 - val_loss: 0.5401\n",
      "Epoch 31/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.5231 - val_loss: 0.4960\n",
      "Epoch 32/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.5081 - val_loss: 0.4901\n",
      "Epoch 33/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.5065 - val_loss: 0.4807\n",
      "Epoch 34/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.4978 - val_loss: 0.4777\n",
      "Epoch 35/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.5001 - val_loss: 0.4743\n",
      "Epoch 36/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.4961 - val_loss: 0.4724\n",
      "Epoch 37/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.4929 - val_loss: 0.4945\n",
      "Epoch 38/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.4954 - val_loss: 0.4752\n",
      "Epoch 39/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.4857 - val_loss: 0.4713\n",
      "Epoch 40/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.4861 - val_loss: 0.4844\n",
      "Epoch 41/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.4918 - val_loss: 0.4597\n",
      "Epoch 42/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.4862 - val_loss: 0.4733\n",
      "Epoch 43/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.4735 - val_loss: 0.4489\n",
      "Epoch 44/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.4661 - val_loss: 0.4455\n",
      "Epoch 45/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.4652 - val_loss: 0.4332\n",
      "Epoch 46/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.4720 - val_loss: 0.4545\n",
      "Epoch 47/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.4433 - val_loss: 0.4318\n",
      "Epoch 48/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.4232 - val_loss: 0.4000\n",
      "Epoch 49/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.4094 - val_loss: 0.3996\n",
      "Epoch 50/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.4007 - val_loss: 0.4060\n",
      "Epoch 51/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.3960 - val_loss: 0.4250\n",
      "Epoch 52/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.3984 - val_loss: 0.3680\n",
      "Epoch 53/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3751 - val_loss: 0.3977\n",
      "Epoch 54/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.3792 - val_loss: 0.4015\n",
      "Epoch 55/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.3717 - val_loss: 0.3527\n",
      "Epoch 56/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.3585 - val_loss: 0.3703\n",
      "Epoch 57/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.3479 - val_loss: 0.3401\n",
      "Epoch 58/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3458 - val_loss: 0.3392\n",
      "Epoch 59/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.3439 - val_loss: 0.3454\n",
      "Epoch 60/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3379 - val_loss: 0.3475\n",
      "Epoch 61/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.3375 - val_loss: 0.3158\n",
      "Epoch 62/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.3344 - val_loss: 0.3811\n",
      "Epoch 63/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.3369 - val_loss: 0.3594\n",
      "Epoch 64/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3316 - val_loss: 0.3220\n",
      "Epoch 65/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3241 - val_loss: 0.3069\n",
      "Epoch 66/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.3271 - val_loss: 0.3260\n",
      "Epoch 67/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.3263 - val_loss: 0.3333\n",
      "Epoch 68/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3133 - val_loss: 0.3303\n",
      "Epoch 69/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.3125 - val_loss: 0.3100\n",
      "Epoch 70/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.3096 - val_loss: 0.3021\n",
      "Epoch 71/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.3126 - val_loss: 0.3885\n",
      "Epoch 72/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.3123 - val_loss: 0.2980\n",
      "Epoch 73/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.3063 - val_loss: 0.3287\n",
      "Epoch 74/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3120 - val_loss: 0.3046\n",
      "Epoch 75/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.3083 - val_loss: 0.3308\n",
      "Epoch 76/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.3174 - val_loss: 0.2948\n",
      "Epoch 77/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.2996 - val_loss: 0.3098\n",
      "Epoch 78/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.3066 - val_loss: 0.3045\n",
      "Epoch 79/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.2978 - val_loss: 0.2861\n",
      "Epoch 80/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.2947 - val_loss: 0.3140\n",
      "Epoch 81/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.3120 - val_loss: 0.3122\n",
      "Epoch 82/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3013 - val_loss: 0.3314\n",
      "Epoch 83/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2930 - val_loss: 0.3036\n",
      "Epoch 84/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.2929 - val_loss: 0.2786\n",
      "Epoch 85/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.2902 - val_loss: 0.3062\n",
      "Epoch 86/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.2848 - val_loss: 0.2996\n",
      "Epoch 87/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.2888 - val_loss: 0.2877\n",
      "Epoch 88/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.2955 - val_loss: 0.3657\n",
      "Epoch 89/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.2982 - val_loss: 0.2895\n",
      "Epoch 90/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2928 - val_loss: 0.2801\n",
      "Epoch 91/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2868 - val_loss: 0.2865\n",
      "Epoch 92/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.2805 - val_loss: 0.2897\n",
      "Epoch 93/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.2811 - val_loss: 0.2945\n",
      "Epoch 94/2000\n",
      "73/73 [==============================] - ETA: 0s - loss: 0.2821Restoring model weights from the end of the best epoch: 84.\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.2821 - val_loss: 0.2866\n",
      "Epoch 94: early stopping\n",
      "'########################################################Model1\n",
      "Epoch 1/2000\n",
      "73/73 [==============================] - 8s 93ms/step - loss: 4.3730 - val_loss: 1.4096\n",
      "Epoch 2/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.9640 - val_loss: 0.9588\n",
      "Epoch 3/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.9162 - val_loss: 0.9392\n",
      "Epoch 4/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.9049 - val_loss: 0.9258\n",
      "Epoch 5/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.8824 - val_loss: 0.8853\n",
      "Epoch 6/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.8487 - val_loss: 0.8584\n",
      "Epoch 7/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.8227 - val_loss: 0.8166\n",
      "Epoch 8/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.7945 - val_loss: 0.7708\n",
      "Epoch 9/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.7613 - val_loss: 0.7635\n",
      "Epoch 10/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.7177 - val_loss: 0.6669\n",
      "Epoch 11/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.6403 - val_loss: 0.6047\n",
      "Epoch 12/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.6107 - val_loss: 0.5929\n",
      "Epoch 13/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.5948 - val_loss: 0.5795\n",
      "Epoch 14/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.5793 - val_loss: 0.5675\n",
      "Epoch 15/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.5740 - val_loss: 0.5969\n",
      "Epoch 16/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.5766 - val_loss: 0.5648\n",
      "Epoch 17/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.5700 - val_loss: 0.5462\n",
      "Epoch 18/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.5514 - val_loss: 0.5381\n",
      "Epoch 19/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.5402 - val_loss: 0.5425\n",
      "Epoch 20/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.5285 - val_loss: 0.5543\n",
      "Epoch 21/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.5310 - val_loss: 0.5070\n",
      "Epoch 22/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.5086 - val_loss: 0.5330\n",
      "Epoch 23/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.5067 - val_loss: 0.5449\n",
      "Epoch 24/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.4928 - val_loss: 0.4746\n",
      "Epoch 25/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.4833 - val_loss: 0.4721\n",
      "Epoch 26/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.4830 - val_loss: 0.4733\n",
      "Epoch 27/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.4751 - val_loss: 0.4728\n",
      "Epoch 28/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.4562 - val_loss: 0.4611\n",
      "Epoch 29/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.4434 - val_loss: 0.4511\n",
      "Epoch 30/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.4172 - val_loss: 0.4717\n",
      "Epoch 31/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.4282 - val_loss: 0.4259\n",
      "Epoch 32/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.3926 - val_loss: 0.4113\n",
      "Epoch 33/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.3768 - val_loss: 0.4000\n",
      "Epoch 34/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3789 - val_loss: 0.4038\n",
      "Epoch 35/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.3732 - val_loss: 0.3979\n",
      "Epoch 36/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.3704 - val_loss: 0.4089\n",
      "Epoch 37/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.3627 - val_loss: 0.3730\n",
      "Epoch 38/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3501 - val_loss: 0.3850\n",
      "Epoch 39/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.3438 - val_loss: 0.4184\n",
      "Epoch 40/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3445 - val_loss: 0.4073\n",
      "Epoch 41/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.3378 - val_loss: 0.4010\n",
      "Epoch 42/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.3360 - val_loss: 0.3519\n",
      "Epoch 43/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.3402 - val_loss: 0.3522\n",
      "Epoch 44/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.3276 - val_loss: 0.3713\n",
      "Epoch 45/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.3251 - val_loss: 0.3352\n",
      "Epoch 46/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3259 - val_loss: 0.3351\n",
      "Epoch 47/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.3163 - val_loss: 0.3405\n",
      "Epoch 48/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.3126 - val_loss: 0.3274\n",
      "Epoch 49/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.3186 - val_loss: 0.3625\n",
      "Epoch 50/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.3153 - val_loss: 0.3545\n",
      "Epoch 51/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.3226 - val_loss: 0.3315\n",
      "Epoch 52/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.3168 - val_loss: 0.3227\n",
      "Epoch 53/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.3009 - val_loss: 0.3221\n",
      "Epoch 54/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.2966 - val_loss: 0.3270\n",
      "Epoch 55/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2987 - val_loss: 0.3424\n",
      "Epoch 56/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3000 - val_loss: 0.3368\n",
      "Epoch 57/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.3006 - val_loss: 0.3080\n",
      "Epoch 58/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2919 - val_loss: 0.3135\n",
      "Epoch 59/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.2899 - val_loss: 0.3200\n",
      "Epoch 60/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.2860 - val_loss: 0.3040\n",
      "Epoch 61/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.3115 - val_loss: 0.3225\n",
      "Epoch 62/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.3109 - val_loss: 0.3147\n",
      "Epoch 63/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2882 - val_loss: 0.3128\n",
      "Epoch 64/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.2848 - val_loss: 0.3196\n",
      "Epoch 65/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2782 - val_loss: 0.3494\n",
      "Epoch 66/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.2920 - val_loss: 0.2988\n",
      "Epoch 67/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2808 - val_loss: 0.3034\n",
      "Epoch 68/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.2767 - val_loss: 0.3064\n",
      "Epoch 69/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2854 - val_loss: 0.2985\n",
      "Epoch 70/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.2891 - val_loss: 0.2950\n",
      "Epoch 71/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2836 - val_loss: 0.2968\n",
      "Epoch 72/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.2718 - val_loss: 0.2965\n",
      "Epoch 73/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.2788 - val_loss: 0.3230\n",
      "Epoch 74/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.2744 - val_loss: 0.3027\n",
      "Epoch 75/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.2767 - val_loss: 0.3054\n",
      "Epoch 76/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.2686 - val_loss: 0.2942\n",
      "Epoch 77/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.2679 - val_loss: 0.3084\n",
      "Epoch 78/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2671 - val_loss: 0.2900\n",
      "Epoch 79/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.2674 - val_loss: 0.2869\n",
      "Epoch 80/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.2757 - val_loss: 0.3173\n",
      "Epoch 81/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2684 - val_loss: 0.2865\n",
      "Epoch 82/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.2653 - val_loss: 0.2976\n",
      "Epoch 83/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.2702 - val_loss: 0.3033\n",
      "Epoch 84/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.2666 - val_loss: 0.2862\n",
      "Epoch 85/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2653 - val_loss: 0.2964\n",
      "Epoch 86/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2742 - val_loss: 0.2909\n",
      "Epoch 87/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.2696 - val_loss: 0.3287\n",
      "Epoch 88/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2618 - val_loss: 0.2927\n",
      "Epoch 89/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.2631 - val_loss: 0.2992\n",
      "Epoch 90/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2546 - val_loss: 0.2801\n",
      "Epoch 91/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2539 - val_loss: 0.2981\n",
      "Epoch 92/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2618 - val_loss: 0.2771\n",
      "Epoch 93/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2690 - val_loss: 0.3005\n",
      "Epoch 94/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.2538 - val_loss: 0.2794\n",
      "Epoch 95/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.2546 - val_loss: 0.2863\n",
      "Epoch 96/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.2656 - val_loss: 0.2876\n",
      "Epoch 97/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.2688 - val_loss: 0.3001\n",
      "Epoch 98/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.2567 - val_loss: 0.2772\n",
      "Epoch 99/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.2642 - val_loss: 0.2978\n",
      "Epoch 100/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2488 - val_loss: 0.2807\n",
      "Epoch 101/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2502 - val_loss: 0.3029\n",
      "Epoch 102/2000\n",
      "73/73 [==============================] - ETA: 0s - loss: 0.2579Restoring model weights from the end of the best epoch: 92.\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2579 - val_loss: 0.2816\n",
      "Epoch 102: early stopping\n",
      "'########################################################Model2\n",
      "Epoch 1/2000\n",
      "73/73 [==============================] - 8s 97ms/step - loss: 5.2089 - val_loss: 2.0259\n",
      "Epoch 2/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 1.0482 - val_loss: 0.9593\n",
      "Epoch 3/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.9240 - val_loss: 0.9548\n",
      "Epoch 4/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.9175 - val_loss: 0.9399\n",
      "Epoch 5/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.9062 - val_loss: 0.9195\n",
      "Epoch 6/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.8771 - val_loss: 0.8737\n",
      "Epoch 7/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.8274 - val_loss: 0.8156\n",
      "Epoch 8/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.7930 - val_loss: 0.7910\n",
      "Epoch 9/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.7482 - val_loss: 0.7256\n",
      "Epoch 10/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.6908 - val_loss: 0.6850\n",
      "Epoch 11/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.6464 - val_loss: 0.6372\n",
      "Epoch 12/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.6165 - val_loss: 0.5954\n",
      "Epoch 13/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.6083 - val_loss: 0.5931\n",
      "Epoch 14/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.5853 - val_loss: 0.5709\n",
      "Epoch 15/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.5793 - val_loss: 0.5813\n",
      "Epoch 16/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.5640 - val_loss: 0.5441\n",
      "Epoch 17/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.5558 - val_loss: 0.5416\n",
      "Epoch 18/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.5452 - val_loss: 0.5593\n",
      "Epoch 19/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.5509 - val_loss: 0.5497\n",
      "Epoch 20/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.5213 - val_loss: 0.5043\n",
      "Epoch 21/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.5076 - val_loss: 0.5227\n",
      "Epoch 22/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.4995 - val_loss: 0.4743\n",
      "Epoch 23/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.4782 - val_loss: 0.5060\n",
      "Epoch 24/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.4702 - val_loss: 0.4609\n",
      "Epoch 25/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.4391 - val_loss: 0.4592\n",
      "Epoch 26/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.4205 - val_loss: 0.4268\n",
      "Epoch 27/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.4038 - val_loss: 0.4300\n",
      "Epoch 28/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3981 - val_loss: 0.4233\n",
      "Epoch 29/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3870 - val_loss: 0.4139\n",
      "Epoch 30/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3793 - val_loss: 0.4064\n",
      "Epoch 31/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3968 - val_loss: 0.4270\n",
      "Epoch 32/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3722 - val_loss: 0.4056\n",
      "Epoch 33/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3664 - val_loss: 0.3981\n",
      "Epoch 34/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3532 - val_loss: 0.3756\n",
      "Epoch 35/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3501 - val_loss: 0.3912\n",
      "Epoch 36/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3473 - val_loss: 0.3631\n",
      "Epoch 37/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.3284 - val_loss: 0.3622\n",
      "Epoch 38/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3274 - val_loss: 0.3716\n",
      "Epoch 39/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3351 - val_loss: 0.3381\n",
      "Epoch 40/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.3187 - val_loss: 0.3486\n",
      "Epoch 41/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3391 - val_loss: 0.3714\n",
      "Epoch 42/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3218 - val_loss: 0.3336\n",
      "Epoch 43/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.3171 - val_loss: 0.3467\n",
      "Epoch 44/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3186 - val_loss: 0.3489\n",
      "Epoch 45/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3102 - val_loss: 0.3144\n",
      "Epoch 46/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3041 - val_loss: 0.3237\n",
      "Epoch 47/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2980 - val_loss: 0.3348\n",
      "Epoch 48/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2980 - val_loss: 0.3633\n",
      "Epoch 49/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3022 - val_loss: 0.3152\n",
      "Epoch 50/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2897 - val_loss: 0.3185\n",
      "Epoch 51/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3144 - val_loss: 0.3362\n",
      "Epoch 52/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2949 - val_loss: 0.3262\n",
      "Epoch 53/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2911 - val_loss: 0.3103\n",
      "Epoch 54/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.2830 - val_loss: 0.3029\n",
      "Epoch 55/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.2967 - val_loss: 0.2941\n",
      "Epoch 56/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.2920 - val_loss: 0.3212\n",
      "Epoch 57/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2800 - val_loss: 0.3085\n",
      "Epoch 58/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2824 - val_loss: 0.3065\n",
      "Epoch 59/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2741 - val_loss: 0.3092\n",
      "Epoch 60/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.2851 - val_loss: 0.3104\n",
      "Epoch 61/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2736 - val_loss: 0.3540\n",
      "Epoch 62/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2778 - val_loss: 0.3188\n",
      "Epoch 63/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2718 - val_loss: 0.2954\n",
      "Epoch 64/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2811 - val_loss: 0.2966\n",
      "Epoch 65/2000\n",
      "73/73 [==============================] - ETA: 0s - loss: 0.2724Restoring model weights from the end of the best epoch: 55.\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2724 - val_loss: 0.3031\n",
      "Epoch 65: early stopping\n",
      "'########################################################Model3\n",
      "Epoch 1/2000\n",
      "73/73 [==============================] - 8s 95ms/step - loss: 5.1077 - val_loss: 1.9468\n",
      "Epoch 2/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 1.0359 - val_loss: 0.9614\n",
      "Epoch 3/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.9244 - val_loss: 0.9562\n",
      "Epoch 4/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.9026 - val_loss: 0.9059\n",
      "Epoch 5/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.8603 - val_loss: 0.8500\n",
      "Epoch 6/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.8333 - val_loss: 0.8214\n",
      "Epoch 7/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.8044 - val_loss: 0.8183\n",
      "Epoch 8/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.7820 - val_loss: 0.7614\n",
      "Epoch 9/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.7446 - val_loss: 0.7196\n",
      "Epoch 10/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.6903 - val_loss: 0.6668\n",
      "Epoch 11/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.6453 - val_loss: 0.6174\n",
      "Epoch 12/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.6264 - val_loss: 0.6506\n",
      "Epoch 13/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.6178 - val_loss: 0.5911\n",
      "Epoch 14/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.5982 - val_loss: 0.5791\n",
      "Epoch 15/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.5781 - val_loss: 0.5812\n",
      "Epoch 16/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.5788 - val_loss: 0.5591\n",
      "Epoch 17/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.5653 - val_loss: 0.5710\n",
      "Epoch 18/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.5554 - val_loss: 0.5494\n",
      "Epoch 19/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.5498 - val_loss: 0.5626\n",
      "Epoch 20/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.5511 - val_loss: 0.5380\n",
      "Epoch 21/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.5308 - val_loss: 0.5340\n",
      "Epoch 22/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.5167 - val_loss: 0.5285\n",
      "Epoch 23/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.4961 - val_loss: 0.4850\n",
      "Epoch 24/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.4892 - val_loss: 0.4692\n",
      "Epoch 25/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.4685 - val_loss: 0.5058\n",
      "Epoch 26/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.4654 - val_loss: 0.4668\n",
      "Epoch 27/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.4719 - val_loss: 0.4455\n",
      "Epoch 28/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.4591 - val_loss: 0.4332\n",
      "Epoch 29/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.4283 - val_loss: 0.4235\n",
      "Epoch 30/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.4349 - val_loss: 0.4159\n",
      "Epoch 31/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.4078 - val_loss: 0.4067\n",
      "Epoch 32/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.4017 - val_loss: 0.3904\n",
      "Epoch 33/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.4195 - val_loss: 0.4061\n",
      "Epoch 34/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3965 - val_loss: 0.3964\n",
      "Epoch 35/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.3843 - val_loss: 0.3689\n",
      "Epoch 36/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3801 - val_loss: 0.4213\n",
      "Epoch 37/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3993 - val_loss: 0.4097\n",
      "Epoch 38/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3634 - val_loss: 0.3752\n",
      "Epoch 39/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3687 - val_loss: 0.3661\n",
      "Epoch 40/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.3788 - val_loss: 0.3795\n",
      "Epoch 41/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3758 - val_loss: 0.3716\n",
      "Epoch 42/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3749 - val_loss: 0.3694\n",
      "Epoch 43/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3532 - val_loss: 0.3529\n",
      "Epoch 44/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3473 - val_loss: 0.3631\n",
      "Epoch 45/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3428 - val_loss: 0.3610\n",
      "Epoch 46/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.3431 - val_loss: 0.3815\n",
      "Epoch 47/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3359 - val_loss: 0.3298\n",
      "Epoch 48/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.3430 - val_loss: 0.3570\n",
      "Epoch 49/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.3341 - val_loss: 0.3370\n",
      "Epoch 50/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3145 - val_loss: 0.3175\n",
      "Epoch 51/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3348 - val_loss: 0.3279\n",
      "Epoch 52/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.3139 - val_loss: 0.3315\n",
      "Epoch 53/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3083 - val_loss: 0.3015\n",
      "Epoch 54/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3316 - val_loss: 0.3284\n",
      "Epoch 55/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3081 - val_loss: 0.3037\n",
      "Epoch 56/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.2992 - val_loss: 0.3169\n",
      "Epoch 57/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2982 - val_loss: 0.3162\n",
      "Epoch 58/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3027 - val_loss: 0.3006\n",
      "Epoch 59/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2883 - val_loss: 0.2904\n",
      "Epoch 60/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.3041 - val_loss: 0.3110\n",
      "Epoch 61/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2940 - val_loss: 0.3052\n",
      "Epoch 62/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3001 - val_loss: 0.3148\n",
      "Epoch 63/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.2889 - val_loss: 0.2758\n",
      "Epoch 64/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.2842 - val_loss: 0.2966\n",
      "Epoch 65/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2880 - val_loss: 0.2942\n",
      "Epoch 66/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2858 - val_loss: 0.2972\n",
      "Epoch 67/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2884 - val_loss: 0.3039\n",
      "Epoch 68/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2796 - val_loss: 0.2912\n",
      "Epoch 69/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.3287 - val_loss: 0.3833\n",
      "Epoch 70/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3300 - val_loss: 0.3109\n",
      "Epoch 71/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2911 - val_loss: 0.3120\n",
      "Epoch 72/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2884 - val_loss: 0.3201\n",
      "Epoch 73/2000\n",
      "73/73 [==============================] - ETA: 0s - loss: 0.2819Restoring model weights from the end of the best epoch: 63.\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2819 - val_loss: 0.3337\n",
      "Epoch 73: early stopping\n",
      "'########################################################Model4\n",
      "Epoch 1/2000\n",
      "73/73 [==============================] - 8s 94ms/step - loss: 4.2012 - val_loss: 1.2655\n",
      "Epoch 2/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.9445 - val_loss: 0.9560\n",
      "Epoch 3/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.9173 - val_loss: 0.9534\n",
      "Epoch 4/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.9022 - val_loss: 0.9027\n",
      "Epoch 5/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.8661 - val_loss: 0.8634\n",
      "Epoch 6/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.8371 - val_loss: 0.8307\n",
      "Epoch 7/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.8081 - val_loss: 0.8192\n",
      "Epoch 8/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.7832 - val_loss: 0.8380\n",
      "Epoch 9/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.7630 - val_loss: 0.7260\n",
      "Epoch 10/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.7037 - val_loss: 0.6673\n",
      "Epoch 11/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.6547 - val_loss: 0.6250\n",
      "Epoch 12/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.6240 - val_loss: 0.6086\n",
      "Epoch 13/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.6313 - val_loss: 0.6228\n",
      "Epoch 14/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.6040 - val_loss: 0.5743\n",
      "Epoch 15/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.5817 - val_loss: 0.5661\n",
      "Epoch 16/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.5762 - val_loss: 0.5654\n",
      "Epoch 17/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.5700 - val_loss: 0.5813\n",
      "Epoch 18/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.5610 - val_loss: 0.5508\n",
      "Epoch 19/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.5621 - val_loss: 0.5427\n",
      "Epoch 20/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.5456 - val_loss: 0.5379\n",
      "Epoch 21/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.5422 - val_loss: 0.5332\n",
      "Epoch 22/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.5321 - val_loss: 0.5107\n",
      "Epoch 23/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.5213 - val_loss: 0.5054\n",
      "Epoch 24/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.5079 - val_loss: 0.5059\n",
      "Epoch 25/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.5014 - val_loss: 0.5170\n",
      "Epoch 26/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.4954 - val_loss: 0.4853\n",
      "Epoch 27/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.4902 - val_loss: 0.4618\n",
      "Epoch 28/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.4354 - val_loss: 0.4669\n",
      "Epoch 29/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.4705 - val_loss: 0.4482\n",
      "Epoch 30/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.4088 - val_loss: 0.4172\n",
      "Epoch 31/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3938 - val_loss: 0.4581\n",
      "Epoch 32/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.4207 - val_loss: 0.4047\n",
      "Epoch 33/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.3938 - val_loss: 0.4359\n",
      "Epoch 34/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.3830 - val_loss: 0.4141\n",
      "Epoch 35/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3810 - val_loss: 0.4062\n",
      "Epoch 36/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.3616 - val_loss: 0.3776\n",
      "Epoch 37/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.3547 - val_loss: 0.3763\n",
      "Epoch 38/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.3544 - val_loss: 0.3726\n",
      "Epoch 39/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.3541 - val_loss: 0.3738\n",
      "Epoch 40/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.3517 - val_loss: 0.4314\n",
      "Epoch 41/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.3586 - val_loss: 0.3960\n",
      "Epoch 42/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.3578 - val_loss: 0.3565\n",
      "Epoch 43/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.3403 - val_loss: 0.3925\n",
      "Epoch 44/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.3524 - val_loss: 0.4690\n",
      "Epoch 45/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.3349 - val_loss: 0.3619\n",
      "Epoch 46/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.3257 - val_loss: 0.3931\n",
      "Epoch 47/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.3315 - val_loss: 0.3419\n",
      "Epoch 48/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3220 - val_loss: 0.3501\n",
      "Epoch 49/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3163 - val_loss: 0.3451\n",
      "Epoch 50/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.3247 - val_loss: 0.3426\n",
      "Epoch 51/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3299 - val_loss: 0.3823\n",
      "Epoch 52/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3206 - val_loss: 0.3478\n",
      "Epoch 53/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.3226 - val_loss: 0.3630\n",
      "Epoch 54/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.3093 - val_loss: 0.3285\n",
      "Epoch 55/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3130 - val_loss: 0.3177\n",
      "Epoch 56/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3104 - val_loss: 0.3228\n",
      "Epoch 57/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.3060 - val_loss: 0.3178\n",
      "Epoch 58/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3149 - val_loss: 0.3288\n",
      "Epoch 59/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.2973 - val_loss: 0.3415\n",
      "Epoch 60/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.3124 - val_loss: 0.3127\n",
      "Epoch 61/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3039 - val_loss: 0.3292\n",
      "Epoch 62/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3046 - val_loss: 0.3709\n",
      "Epoch 63/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3091 - val_loss: 0.3350\n",
      "Epoch 64/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3019 - val_loss: 0.3146\n",
      "Epoch 65/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.2950 - val_loss: 0.3370\n",
      "Epoch 66/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.3046 - val_loss: 0.3099\n",
      "Epoch 67/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2926 - val_loss: 0.3222\n",
      "Epoch 68/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3020 - val_loss: 0.3068\n",
      "Epoch 69/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3064 - val_loss: 0.3852\n",
      "Epoch 70/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.3099 - val_loss: 0.3281\n",
      "Epoch 71/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.2970 - val_loss: 0.3256\n",
      "Epoch 72/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.3052 - val_loss: 0.3141\n",
      "Epoch 73/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.2917 - val_loss: 0.3367\n",
      "Epoch 74/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.3363 - val_loss: 0.3317\n",
      "Epoch 75/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.3005 - val_loss: 0.4652\n",
      "Epoch 76/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.3114 - val_loss: 0.3026\n",
      "Epoch 77/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.2930 - val_loss: 0.2955\n",
      "Epoch 78/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.2817 - val_loss: 0.3049\n",
      "Epoch 79/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.2816 - val_loss: 0.3046\n",
      "Epoch 80/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.2733 - val_loss: 0.2901\n",
      "Epoch 81/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.2770 - val_loss: 0.2897\n",
      "Epoch 82/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2766 - val_loss: 0.2897\n",
      "Epoch 83/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2823 - val_loss: 0.2962\n",
      "Epoch 84/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.2835 - val_loss: 0.2900\n",
      "Epoch 85/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.2795 - val_loss: 0.3058\n",
      "Epoch 86/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.2786 - val_loss: 0.3053\n",
      "Epoch 87/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.2741 - val_loss: 0.3177\n",
      "Epoch 88/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.2796 - val_loss: 0.2894\n",
      "Epoch 89/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2714 - val_loss: 0.2925\n",
      "Epoch 90/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.2675 - val_loss: 0.3124\n",
      "Epoch 91/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.2733 - val_loss: 0.2831\n",
      "Epoch 92/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.2730 - val_loss: 0.2876\n",
      "Epoch 93/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.2717 - val_loss: 0.3546\n",
      "Epoch 94/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2788 - val_loss: 0.3004\n",
      "Epoch 95/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.2787 - val_loss: 0.2783\n",
      "Epoch 96/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2688 - val_loss: 0.2936\n",
      "Epoch 97/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.2703 - val_loss: 0.2849\n",
      "Epoch 98/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2644 - val_loss: 0.3047\n",
      "Epoch 99/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.2697 - val_loss: 0.3032\n",
      "Epoch 100/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2725 - val_loss: 0.2763\n",
      "Epoch 101/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.2655 - val_loss: 0.3185\n",
      "Epoch 102/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.2669 - val_loss: 0.2851\n",
      "Epoch 103/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.2673 - val_loss: 0.2850\n",
      "Epoch 104/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.2737 - val_loss: 0.2874\n",
      "Epoch 105/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2847 - val_loss: 0.2821\n",
      "Epoch 106/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.2638 - val_loss: 0.2845\n",
      "Epoch 107/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.2694 - val_loss: 0.2959\n",
      "Epoch 108/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2666 - val_loss: 0.2961\n",
      "Epoch 109/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2648 - val_loss: 0.2853\n",
      "Epoch 110/2000\n",
      "73/73 [==============================] - ETA: 0s - loss: 0.2753Restoring model weights from the end of the best epoch: 100.\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.2753 - val_loss: 0.3148\n",
      "Epoch 110: early stopping\n",
      "'########################################################Model5\n",
      "Epoch 1/2000\n",
      "73/73 [==============================] - 8s 89ms/step - loss: 4.7809 - val_loss: 1.3025\n",
      "Epoch 2/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.9381 - val_loss: 0.9422\n",
      "Epoch 3/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.8983 - val_loss: 0.9355\n",
      "Epoch 4/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.8670 - val_loss: 0.8608\n",
      "Epoch 5/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.8339 - val_loss: 0.8287\n",
      "Epoch 6/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.8128 - val_loss: 0.7999\n",
      "Epoch 7/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.7937 - val_loss: 0.7831\n",
      "Epoch 8/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.7644 - val_loss: 0.7404\n",
      "Epoch 9/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.7274 - val_loss: 0.7084\n",
      "Epoch 10/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.6723 - val_loss: 0.6454\n",
      "Epoch 11/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.6513 - val_loss: 0.6487\n",
      "Epoch 12/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.6201 - val_loss: 0.6012\n",
      "Epoch 13/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.6005 - val_loss: 0.5878\n",
      "Epoch 14/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.5963 - val_loss: 0.6008\n",
      "Epoch 15/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 0.5856 - val_loss: 0.5915\n",
      "Epoch 16/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.5827 - val_loss: 0.5624\n",
      "Epoch 17/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.5735 - val_loss: 0.5617\n",
      "Epoch 18/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.5574 - val_loss: 0.5418\n",
      "Epoch 19/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.5537 - val_loss: 0.5342\n",
      "Epoch 20/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.5454 - val_loss: 0.5325\n",
      "Epoch 21/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.5491 - val_loss: 0.5396\n",
      "Epoch 22/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.5385 - val_loss: 0.5198\n",
      "Epoch 23/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.5264 - val_loss: 0.5149\n",
      "Epoch 24/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.5343 - val_loss: 0.5388\n",
      "Epoch 25/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.5195 - val_loss: 0.4992\n",
      "Epoch 26/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.5113 - val_loss: 0.5057\n",
      "Epoch 27/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.5086 - val_loss: 0.4825\n",
      "Epoch 28/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.5019 - val_loss: 0.5550\n",
      "Epoch 29/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.4922 - val_loss: 0.4814\n",
      "Epoch 30/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.4883 - val_loss: 0.5254\n",
      "Epoch 31/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.4878 - val_loss: 0.5288\n",
      "Epoch 32/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.4769 - val_loss: 0.4747\n",
      "Epoch 33/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.4701 - val_loss: 0.4953\n",
      "Epoch 34/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 0.4880 - val_loss: 0.4528\n",
      "Epoch 35/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.4543 - val_loss: 0.4473\n",
      "Epoch 36/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.4355 - val_loss: 0.4657\n",
      "Epoch 37/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.4466 - val_loss: 0.4403\n",
      "Epoch 38/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.4493 - val_loss: 0.4405\n",
      "Epoch 39/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.4363 - val_loss: 0.4163\n",
      "Epoch 40/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 0.4243 - val_loss: 0.4102\n",
      "Epoch 41/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.4117 - val_loss: 0.5245\n",
      "Epoch 42/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.5250 - val_loss: 0.4564\n",
      "Epoch 43/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.4662 - val_loss: 0.5052\n",
      "Epoch 44/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.4612 - val_loss: 0.4583\n",
      "Epoch 45/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.4367 - val_loss: 0.4263\n",
      "Epoch 46/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.4867 - val_loss: 0.4894\n",
      "Epoch 47/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.5003 - val_loss: 0.4740\n",
      "Epoch 48/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.4616 - val_loss: 0.5074\n",
      "Epoch 49/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.4808 - val_loss: 0.4607\n",
      "Epoch 50/2000\n",
      "73/73 [==============================] - ETA: 0s - loss: 0.4697Restoring model weights from the end of the best epoch: 40.\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.4697 - val_loss: 0.4402\n",
      "Epoch 50: early stopping\n",
      "'########################################################Model6\n",
      "Epoch 1/2000\n",
      "73/73 [==============================] - 8s 98ms/step - loss: 4.7565 - val_loss: 1.7197\n",
      "Epoch 2/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 1.0274 - val_loss: 0.9660\n",
      "Epoch 3/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.9266 - val_loss: 0.9591\n",
      "Epoch 4/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.9157 - val_loss: 0.9507\n",
      "Epoch 5/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.8988 - val_loss: 0.9135\n",
      "Epoch 6/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.8689 - val_loss: 0.8696\n",
      "Epoch 7/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.8402 - val_loss: 0.8424\n",
      "Epoch 8/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 0.8248 - val_loss: 0.8174\n",
      "Epoch 9/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.7882 - val_loss: 0.7842\n",
      "Epoch 10/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.7620 - val_loss: 0.7232\n",
      "Epoch 11/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.6804 - val_loss: 0.6483\n",
      "Epoch 12/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.6424 - val_loss: 0.6219\n",
      "Epoch 13/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 0.6200 - val_loss: 0.6016\n",
      "Epoch 14/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.5966 - val_loss: 0.5830\n",
      "Epoch 15/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.5921 - val_loss: 0.5730\n",
      "Epoch 16/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.5837 - val_loss: 0.5727\n",
      "Epoch 17/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.5693 - val_loss: 0.5742\n",
      "Epoch 18/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.5393 - val_loss: 0.5343\n",
      "Epoch 19/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.5385 - val_loss: 0.5697\n",
      "Epoch 20/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.5272 - val_loss: 0.5413\n",
      "Epoch 21/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.5374 - val_loss: 0.5383\n",
      "Epoch 22/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.5135 - val_loss: 0.5380\n",
      "Epoch 23/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.5369 - val_loss: 0.4905\n",
      "Epoch 24/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.4743 - val_loss: 0.5008\n",
      "Epoch 25/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.4604 - val_loss: 0.4674\n",
      "Epoch 26/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.4649 - val_loss: 0.4804\n",
      "Epoch 27/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.4481 - val_loss: 0.4569\n",
      "Epoch 28/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.4399 - val_loss: 0.4472\n",
      "Epoch 29/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.4188 - val_loss: 0.4399\n",
      "Epoch 30/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.4225 - val_loss: 0.4483\n",
      "Epoch 31/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 0.4031 - val_loss: 0.4271\n",
      "Epoch 32/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3911 - val_loss: 0.4153\n",
      "Epoch 33/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3920 - val_loss: 0.4082\n",
      "Epoch 34/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3889 - val_loss: 0.4013\n",
      "Epoch 35/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3865 - val_loss: 0.4240\n",
      "Epoch 36/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3607 - val_loss: 0.3747\n",
      "Epoch 37/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3573 - val_loss: 0.3812\n",
      "Epoch 38/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3488 - val_loss: 0.3565\n",
      "Epoch 39/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3535 - val_loss: 0.4188\n",
      "Epoch 40/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3315 - val_loss: 0.3584\n",
      "Epoch 41/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3194 - val_loss: 0.3622\n",
      "Epoch 42/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3304 - val_loss: 0.3658\n",
      "Epoch 43/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3161 - val_loss: 0.3774\n",
      "Epoch 44/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3187 - val_loss: 0.3598\n",
      "Epoch 45/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 0.3173 - val_loss: 0.3385\n",
      "Epoch 46/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3194 - val_loss: 0.3465\n",
      "Epoch 47/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3173 - val_loss: 0.3377\n",
      "Epoch 48/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3184 - val_loss: 0.3370\n",
      "Epoch 49/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3054 - val_loss: 0.3348\n",
      "Epoch 50/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 0.3059 - val_loss: 0.3355\n",
      "Epoch 51/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3033 - val_loss: 0.3151\n",
      "Epoch 52/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2963 - val_loss: 0.3099\n",
      "Epoch 53/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3027 - val_loss: 0.3266\n",
      "Epoch 54/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3105 - val_loss: 0.3305\n",
      "Epoch 55/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2948 - val_loss: 0.3184\n",
      "Epoch 56/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2967 - val_loss: 0.3335\n",
      "Epoch 57/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2962 - val_loss: 0.3145\n",
      "Epoch 58/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2898 - val_loss: 0.3257\n",
      "Epoch 59/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2948 - val_loss: 0.3278\n",
      "Epoch 60/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2922 - val_loss: 0.3409\n",
      "Epoch 61/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2872 - val_loss: 0.2991\n",
      "Epoch 62/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2832 - val_loss: 0.3071\n",
      "Epoch 63/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2881 - val_loss: 0.3244\n",
      "Epoch 64/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.2845 - val_loss: 0.3146\n",
      "Epoch 65/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2795 - val_loss: 0.3113\n",
      "Epoch 66/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2822 - val_loss: 0.3030\n",
      "Epoch 67/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2798 - val_loss: 0.2975\n",
      "Epoch 68/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 0.2817 - val_loss: 0.3296\n",
      "Epoch 69/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2802 - val_loss: 0.3125\n",
      "Epoch 70/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2788 - val_loss: 0.3040\n",
      "Epoch 71/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2748 - val_loss: 0.3021\n",
      "Epoch 72/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2752 - val_loss: 0.2912\n",
      "Epoch 73/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2838 - val_loss: 0.3181\n",
      "Epoch 74/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2801 - val_loss: 0.2962\n",
      "Epoch 75/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2826 - val_loss: 0.3074\n",
      "Epoch 76/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2706 - val_loss: 0.3039\n",
      "Epoch 77/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2727 - val_loss: 0.2979\n",
      "Epoch 78/2000\n",
      "73/73 [==============================] - 6s 82ms/step - loss: 0.2678 - val_loss: 0.3086\n",
      "Epoch 79/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2740 - val_loss: 0.3102\n",
      "Epoch 80/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2713 - val_loss: 0.3145\n",
      "Epoch 81/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2648 - val_loss: 0.2971\n",
      "Epoch 82/2000\n",
      "73/73 [==============================] - ETA: 0s - loss: 0.2645Restoring model weights from the end of the best epoch: 72.\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 0.2645 - val_loss: 0.2999\n",
      "Epoch 82: early stopping\n",
      "'########################################################Model7\n",
      "Epoch 1/2000\n",
      "73/73 [==============================] - 8s 94ms/step - loss: 4.6870 - val_loss: 1.2190\n",
      "Epoch 2/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.9358 - val_loss: 0.9479\n",
      "Epoch 3/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.9088 - val_loss: 0.9290\n",
      "Epoch 4/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.8928 - val_loss: 0.9141\n",
      "Epoch 5/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.8661 - val_loss: 0.8871\n",
      "Epoch 6/2000\n",
      "73/73 [==============================] - 6s 81ms/step - loss: 0.8356 - val_loss: 0.8210\n",
      "Epoch 7/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.8139 - val_loss: 0.7940\n",
      "Epoch 8/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.7754 - val_loss: 0.7648\n",
      "Epoch 9/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.7349 - val_loss: 0.7203\n",
      "Epoch 10/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.6651 - val_loss: 0.6280\n",
      "Epoch 11/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.6479 - val_loss: 0.6182\n",
      "Epoch 12/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.6115 - val_loss: 0.5934\n",
      "Epoch 13/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.5954 - val_loss: 0.5776\n",
      "Epoch 14/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.5932 - val_loss: 0.5744\n",
      "Epoch 15/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.5807 - val_loss: 0.5617\n",
      "Epoch 16/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.5659 - val_loss: 0.5574\n",
      "Epoch 17/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.5616 - val_loss: 0.5546\n",
      "Epoch 18/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.5609 - val_loss: 0.5433\n",
      "Epoch 19/2000\n",
      "73/73 [==============================] - 6s 82ms/step - loss: 0.5482 - val_loss: 0.5415\n",
      "Epoch 20/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.5424 - val_loss: 0.5277\n",
      "Epoch 21/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.5468 - val_loss: 0.5309\n",
      "Epoch 22/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.5223 - val_loss: 0.5054\n",
      "Epoch 23/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.5049 - val_loss: 0.4970\n",
      "Epoch 24/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.5105 - val_loss: 0.4869\n",
      "Epoch 25/2000\n",
      "73/73 [==============================] - 6s 81ms/step - loss: 0.4946 - val_loss: 0.5105\n",
      "Epoch 26/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.4934 - val_loss: 0.4528\n",
      "Epoch 27/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.4646 - val_loss: 0.4834\n",
      "Epoch 28/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.4473 - val_loss: 0.4420\n",
      "Epoch 29/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.4782 - val_loss: 0.4312\n",
      "Epoch 30/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.4522 - val_loss: 0.4723\n",
      "Epoch 31/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.4785 - val_loss: 0.4600\n",
      "Epoch 32/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.4354 - val_loss: 0.4319\n",
      "Epoch 33/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.4292 - val_loss: 0.4261\n",
      "Epoch 34/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.4220 - val_loss: 0.3944\n",
      "Epoch 35/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.4022 - val_loss: 0.4111\n",
      "Epoch 36/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.4088 - val_loss: 0.3733\n",
      "Epoch 37/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.3977 - val_loss: 0.3679\n",
      "Epoch 38/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.3782 - val_loss: 0.3978\n",
      "Epoch 39/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.3720 - val_loss: 0.3539\n",
      "Epoch 40/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.3557 - val_loss: 0.3567\n",
      "Epoch 41/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.3842 - val_loss: 0.5713\n",
      "Epoch 42/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.5222 - val_loss: 0.4852\n",
      "Epoch 43/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.4880 - val_loss: 0.4538\n",
      "Epoch 44/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.4614 - val_loss: 0.4250\n",
      "Epoch 45/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 0.4001 - val_loss: 0.3805\n",
      "Epoch 46/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.3736 - val_loss: 0.4435\n",
      "Epoch 47/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.3924 - val_loss: 0.3771\n",
      "Epoch 48/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.5108 - val_loss: 0.4843\n",
      "Epoch 49/2000\n",
      "73/73 [==============================] - ETA: 0s - loss: 0.4916Restoring model weights from the end of the best epoch: 39.\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.4916 - val_loss: 0.4624\n",
      "Epoch 49: early stopping\n",
      "'########################################################Model8\n",
      "Epoch 1/2000\n",
      "73/73 [==============================] - 9s 96ms/step - loss: 5.1445 - val_loss: 1.8135\n",
      "Epoch 2/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.9996 - val_loss: 0.9572\n",
      "Epoch 3/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.9130 - val_loss: 0.9355\n",
      "Epoch 4/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.8947 - val_loss: 0.9076\n",
      "Epoch 5/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.8576 - val_loss: 0.8489\n",
      "Epoch 6/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.8256 - val_loss: 0.8438\n",
      "Epoch 7/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.7955 - val_loss: 0.7751\n",
      "Epoch 8/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.7533 - val_loss: 0.7289\n",
      "Epoch 9/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.7090 - val_loss: 0.6662\n",
      "Epoch 10/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.6600 - val_loss: 0.6289\n",
      "Epoch 11/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.6248 - val_loss: 0.5984\n",
      "Epoch 12/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.6001 - val_loss: 0.5917\n",
      "Epoch 13/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.5960 - val_loss: 0.5837\n",
      "Epoch 14/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 0.5905 - val_loss: 0.5865\n",
      "Epoch 15/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.5739 - val_loss: 0.6034\n",
      "Epoch 16/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.5656 - val_loss: 0.5577\n",
      "Epoch 17/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.5703 - val_loss: 0.5523\n",
      "Epoch 18/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.5447 - val_loss: 0.5331\n",
      "Epoch 19/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.5442 - val_loss: 0.5482\n",
      "Epoch 20/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.5249 - val_loss: 0.5209\n",
      "Epoch 21/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.5245 - val_loss: 0.5102\n",
      "Epoch 22/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.5091 - val_loss: 0.5103\n",
      "Epoch 23/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.5127 - val_loss: 0.5032\n",
      "Epoch 24/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.5069 - val_loss: 0.4980\n",
      "Epoch 25/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.4935 - val_loss: 0.4696\n",
      "Epoch 26/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.4673 - val_loss: 0.4906\n",
      "Epoch 27/2000\n",
      "73/73 [==============================] - 6s 82ms/step - loss: 0.4505 - val_loss: 0.4465\n",
      "Epoch 28/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.4466 - val_loss: 0.4149\n",
      "Epoch 29/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.4250 - val_loss: 0.4189\n",
      "Epoch 30/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.4170 - val_loss: 0.4004\n",
      "Epoch 31/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3990 - val_loss: 0.4044\n",
      "Epoch 32/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.3975 - val_loss: 0.4225\n",
      "Epoch 33/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 0.3861 - val_loss: 0.3656\n",
      "Epoch 34/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3725 - val_loss: 0.3616\n",
      "Epoch 35/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3521 - val_loss: 0.4044\n",
      "Epoch 36/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3719 - val_loss: 0.3348\n",
      "Epoch 37/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3611 - val_loss: 0.4141\n",
      "Epoch 38/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3656 - val_loss: 0.3972\n",
      "Epoch 39/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3638 - val_loss: 0.3484\n",
      "Epoch 40/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3542 - val_loss: 0.3609\n",
      "Epoch 41/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3343 - val_loss: 0.3485\n",
      "Epoch 42/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3301 - val_loss: 0.3127\n",
      "Epoch 43/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3204 - val_loss: 0.3390\n",
      "Epoch 44/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3185 - val_loss: 0.3161\n",
      "Epoch 45/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.3041 - val_loss: 0.3249\n",
      "Epoch 46/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.3205 - val_loss: 0.3962\n",
      "Epoch 47/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3678 - val_loss: 0.3982\n",
      "Epoch 48/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3595 - val_loss: 0.3161\n",
      "Epoch 49/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2955 - val_loss: 0.2940\n",
      "Epoch 50/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2995 - val_loss: 0.3055\n",
      "Epoch 51/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.2961 - val_loss: 0.2961\n",
      "Epoch 52/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.2917 - val_loss: 0.2993\n",
      "Epoch 53/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2885 - val_loss: 0.2887\n",
      "Epoch 54/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2887 - val_loss: 0.3007\n",
      "Epoch 55/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2865 - val_loss: 0.2903\n",
      "Epoch 56/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2936 - val_loss: 0.3301\n",
      "Epoch 57/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2901 - val_loss: 0.3038\n",
      "Epoch 58/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2868 - val_loss: 0.3036\n",
      "Epoch 59/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2831 - val_loss: 0.2923\n",
      "Epoch 60/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2789 - val_loss: 0.3178\n",
      "Epoch 61/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2909 - val_loss: 0.2797\n",
      "Epoch 62/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2815 - val_loss: 0.2891\n",
      "Epoch 63/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2720 - val_loss: 0.2784\n",
      "Epoch 64/2000\n",
      "73/73 [==============================] - 6s 82ms/step - loss: 0.2718 - val_loss: 0.2714\n",
      "Epoch 65/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2686 - val_loss: 0.2697\n",
      "Epoch 66/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2675 - val_loss: 0.2653\n",
      "Epoch 67/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2715 - val_loss: 0.2748\n",
      "Epoch 68/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2662 - val_loss: 0.2675\n",
      "Epoch 69/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2688 - val_loss: 0.2746\n",
      "Epoch 70/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 0.2745 - val_loss: 0.2682\n",
      "Epoch 71/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2677 - val_loss: 0.2642\n",
      "Epoch 72/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2763 - val_loss: 0.2756\n",
      "Epoch 73/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2688 - val_loss: 0.2915\n",
      "Epoch 74/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2970 - val_loss: 0.4073\n",
      "Epoch 75/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3647 - val_loss: 0.3295\n",
      "Epoch 76/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3022 - val_loss: 0.3213\n",
      "Epoch 77/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.4229 - val_loss: 0.3923\n",
      "Epoch 78/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3809 - val_loss: 0.3475\n",
      "Epoch 79/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2917 - val_loss: 0.2936\n",
      "Epoch 80/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2674 - val_loss: 0.2720\n",
      "Epoch 81/2000\n",
      "73/73 [==============================] - ETA: 0s - loss: 0.2683Restoring model weights from the end of the best epoch: 71.\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2683 - val_loss: 0.2753\n",
      "Epoch 81: early stopping\n",
      "'########################################################Model9\n",
      "Epoch 1/2000\n",
      "73/73 [==============================] - 8s 92ms/step - loss: 57.7223 - val_loss: 16.5606\n",
      "Epoch 2/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 12.0724 - val_loss: 11.9613\n",
      "Epoch 3/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 11.4423 - val_loss: 11.6888\n",
      "Epoch 4/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 11.1605 - val_loss: 11.1371\n",
      "Epoch 5/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 10.7050 - val_loss: 10.4700\n",
      "Epoch 6/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 10.3598 - val_loss: 10.0625\n",
      "Epoch 7/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 9.9624 - val_loss: 9.6962\n",
      "Epoch 8/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 9.6629 - val_loss: 9.4397\n",
      "Epoch 9/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 9.3819 - val_loss: 8.9074\n",
      "Epoch 10/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 8.8217 - val_loss: 8.3451\n",
      "Epoch 11/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 8.3035 - val_loss: 7.8054\n",
      "Epoch 12/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 8.0051 - val_loss: 7.5281\n",
      "Epoch 13/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 7.7176 - val_loss: 7.3037\n",
      "Epoch 14/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 7.5137 - val_loss: 7.1949\n",
      "Epoch 15/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 7.4064 - val_loss: 7.4769\n",
      "Epoch 16/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 7.1880 - val_loss: 6.8424\n",
      "Epoch 17/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 7.2932 - val_loss: 7.1386\n",
      "Epoch 18/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 6.9225 - val_loss: 6.6063\n",
      "Epoch 19/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 6.7890 - val_loss: 6.5547\n",
      "Epoch 20/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 6.6387 - val_loss: 6.3184\n",
      "Epoch 21/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 6.7983 - val_loss: 6.4893\n",
      "Epoch 22/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 6.5113 - val_loss: 6.2766\n",
      "Epoch 23/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 6.5245 - val_loss: 6.2039\n",
      "Epoch 24/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 6.4707 - val_loss: 6.3701\n",
      "Epoch 25/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 6.3113 - val_loss: 6.0244\n",
      "Epoch 26/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 6.2161 - val_loss: 5.9134\n",
      "Epoch 27/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 6.2238 - val_loss: 6.2739\n",
      "Epoch 28/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 6.2750 - val_loss: 5.8703\n",
      "Epoch 29/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 6.1071 - val_loss: 6.3777\n",
      "Epoch 30/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 5.9901 - val_loss: 5.9610\n",
      "Epoch 31/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 5.9457 - val_loss: 5.7037\n",
      "Epoch 32/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 5.8867 - val_loss: 5.7764\n",
      "Epoch 33/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 6.0194 - val_loss: 5.6395\n",
      "Epoch 34/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 5.9151 - val_loss: 5.5915\n",
      "Epoch 35/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 5.8267 - val_loss: 5.6908\n",
      "Epoch 36/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 5.8430 - val_loss: 5.6721\n",
      "Epoch 37/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 5.7503 - val_loss: 5.4854\n",
      "Epoch 38/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 5.6495 - val_loss: 5.7692\n",
      "Epoch 39/2000\n",
      "73/73 [==============================] - 6s 82ms/step - loss: 5.8475 - val_loss: 5.6698\n",
      "Epoch 40/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 5.7234 - val_loss: 5.3918\n",
      "Epoch 41/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 5.4893 - val_loss: 5.1239\n",
      "Epoch 42/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 5.6424 - val_loss: 5.3202\n",
      "Epoch 43/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 5.3863 - val_loss: 5.0216\n",
      "Epoch 44/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 5.1269 - val_loss: 4.9883\n",
      "Epoch 45/2000\n",
      "73/73 [==============================] - 6s 82ms/step - loss: 5.2866 - val_loss: 5.4521\n",
      "Epoch 46/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 5.5655 - val_loss: 4.8760\n",
      "Epoch 47/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 5.0614 - val_loss: 4.4990\n",
      "Epoch 48/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 4.8455 - val_loss: 4.6380\n",
      "Epoch 49/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 4.8963 - val_loss: 5.0414\n",
      "Epoch 50/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 4.7523 - val_loss: 4.6907\n",
      "Epoch 51/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 4.8048 - val_loss: 4.6238\n",
      "Epoch 52/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 4.5973 - val_loss: 4.6449\n",
      "Epoch 53/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 4.5494 - val_loss: 4.8552\n",
      "Epoch 54/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 4.4864 - val_loss: 4.4222\n",
      "Epoch 55/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 4.4409 - val_loss: 4.0947\n",
      "Epoch 56/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 4.2198 - val_loss: 4.3024\n",
      "Epoch 57/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 4.1561 - val_loss: 4.0671\n",
      "Epoch 58/2000\n",
      "73/73 [==============================] - 6s 82ms/step - loss: 4.0725 - val_loss: 4.0289\n",
      "Epoch 59/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.9009 - val_loss: 4.1743\n",
      "Epoch 60/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 4.1302 - val_loss: 3.9285\n",
      "Epoch 61/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.9532 - val_loss: 4.1598\n",
      "Epoch 62/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 3.8425 - val_loss: 3.6477\n",
      "Epoch 63/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.9088 - val_loss: 3.5176\n",
      "Epoch 64/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 3.7067 - val_loss: 3.6464\n",
      "Epoch 65/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.6982 - val_loss: 3.8748\n",
      "Epoch 66/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.6608 - val_loss: 4.2741\n",
      "Epoch 67/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.9117 - val_loss: 4.1246\n",
      "Epoch 68/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.7272 - val_loss: 3.8259\n",
      "Epoch 69/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.4962 - val_loss: 3.5731\n",
      "Epoch 70/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.6000 - val_loss: 3.6071\n",
      "Epoch 71/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.4269 - val_loss: 3.3384\n",
      "Epoch 72/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.4127 - val_loss: 3.7512\n",
      "Epoch 73/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.3886 - val_loss: 3.6690\n",
      "Epoch 74/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.4464 - val_loss: 3.3980\n",
      "Epoch 75/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.4004 - val_loss: 3.4762\n",
      "Epoch 76/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.3868 - val_loss: 3.4635\n",
      "Epoch 77/2000\n",
      "73/73 [==============================] - 6s 82ms/step - loss: 3.4185 - val_loss: 3.4963\n",
      "Epoch 78/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.3613 - val_loss: 3.3303\n",
      "Epoch 79/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.2653 - val_loss: 3.2753\n",
      "Epoch 80/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.3290 - val_loss: 3.3969\n",
      "Epoch 81/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.3136 - val_loss: 3.2367\n",
      "Epoch 82/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.2762 - val_loss: 3.4156\n",
      "Epoch 83/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 3.2507 - val_loss: 3.4378\n",
      "Epoch 84/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.2235 - val_loss: 3.2042\n",
      "Epoch 85/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.3122 - val_loss: 3.3939\n",
      "Epoch 86/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.2823 - val_loss: 3.3748\n",
      "Epoch 87/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.2288 - val_loss: 3.4531\n",
      "Epoch 88/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 3.2807 - val_loss: 3.3105\n",
      "Epoch 89/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.1983 - val_loss: 3.3217\n",
      "Epoch 90/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.2047 - val_loss: 3.3601\n",
      "Epoch 91/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.2547 - val_loss: 3.1464\n",
      "Epoch 92/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.1096 - val_loss: 3.2626\n",
      "Epoch 93/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 3.1392 - val_loss: 3.2277\n",
      "Epoch 94/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.1022 - val_loss: 3.4850\n",
      "Epoch 95/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 3.1561 - val_loss: 3.1625\n",
      "Epoch 96/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 3.1701 - val_loss: 3.2470\n",
      "Epoch 97/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 3.2198 - val_loss: 3.5431\n",
      "Epoch 98/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.1240 - val_loss: 3.3470\n",
      "Epoch 99/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.1601 - val_loss: 3.3547\n",
      "Epoch 100/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.1327 - val_loss: 3.3022\n",
      "Epoch 101/2000\n",
      "73/73 [==============================] - ETA: 0s - loss: 3.1297Restoring model weights from the end of the best epoch: 91.\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 3.1297 - val_loss: 3.2196\n",
      "Epoch 101: early stopping\n",
      "'########################################################Model0\n",
      "Epoch 1/2000\n",
      "73/73 [==============================] - 8s 97ms/step - loss: 56.0187 - val_loss: 14.7594\n",
      "Epoch 2/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 11.7681 - val_loss: 11.8697\n",
      "Epoch 3/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 11.4705 - val_loss: 11.6263\n",
      "Epoch 4/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 11.2312 - val_loss: 11.3234\n",
      "Epoch 5/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 10.8973 - val_loss: 10.8365\n",
      "Epoch 6/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 10.2858 - val_loss: 9.9024\n",
      "Epoch 7/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 9.7662 - val_loss: 9.3866\n",
      "Epoch 8/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 9.2410 - val_loss: 8.8075\n",
      "Epoch 9/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 8.6522 - val_loss: 8.1607\n",
      "Epoch 10/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 8.0617 - val_loss: 7.5186\n",
      "Epoch 11/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 7.8915 - val_loss: 7.3455\n",
      "Epoch 12/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 7.6090 - val_loss: 7.2077\n",
      "Epoch 13/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 7.4227 - val_loss: 7.2949\n",
      "Epoch 14/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 7.3108 - val_loss: 7.1751\n",
      "Epoch 15/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 7.1579 - val_loss: 7.0048\n",
      "Epoch 16/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 7.1577 - val_loss: 6.7826\n",
      "Epoch 17/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 6.9803 - val_loss: 6.6792\n",
      "Epoch 18/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 6.9200 - val_loss: 6.7199\n",
      "Epoch 19/2000\n",
      "73/73 [==============================] - 6s 82ms/step - loss: 6.7373 - val_loss: 6.7146\n",
      "Epoch 20/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 6.6202 - val_loss: 6.3592\n",
      "Epoch 21/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 6.5112 - val_loss: 6.5828\n",
      "Epoch 22/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 6.5313 - val_loss: 6.6193\n",
      "Epoch 23/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 6.5501 - val_loss: 6.0901\n",
      "Epoch 24/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 6.2966 - val_loss: 5.9537\n",
      "Epoch 25/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 6.5242 - val_loss: 6.4109\n",
      "Epoch 26/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 6.6187 - val_loss: 6.1470\n",
      "Epoch 27/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 5.8789 - val_loss: 6.3077\n",
      "Epoch 28/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 6.4003 - val_loss: 6.1568\n",
      "Epoch 29/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 6.0430 - val_loss: 5.8015\n",
      "Epoch 30/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 5.8072 - val_loss: 5.9351\n",
      "Epoch 31/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 6.3086 - val_loss: 5.8524\n",
      "Epoch 32/2000\n",
      "73/73 [==============================] - 6s 82ms/step - loss: 6.1539 - val_loss: 5.6665\n",
      "Epoch 33/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 5.6820 - val_loss: 5.9273\n",
      "Epoch 34/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 6.0094 - val_loss: 5.1849\n",
      "Epoch 35/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 5.4527 - val_loss: 5.4213\n",
      "Epoch 36/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 6.3291 - val_loss: 6.4814\n",
      "Epoch 37/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 6.2130 - val_loss: 5.6963\n",
      "Epoch 38/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 6.5840 - val_loss: 5.7049\n",
      "Epoch 39/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 5.8527 - val_loss: 5.3899\n",
      "Epoch 40/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 5.2681 - val_loss: 5.2115\n",
      "Epoch 41/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 5.2368 - val_loss: 4.7282\n",
      "Epoch 42/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 4.9832 - val_loss: 4.8066\n",
      "Epoch 43/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 5.0151 - val_loss: 4.8179\n",
      "Epoch 44/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 5.0008 - val_loss: 5.5513\n",
      "Epoch 45/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 5.0399 - val_loss: 5.0522\n",
      "Epoch 46/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 4.7713 - val_loss: 5.1724\n",
      "Epoch 47/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 4.9152 - val_loss: 4.9222\n",
      "Epoch 48/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 4.7266 - val_loss: 4.5614\n",
      "Epoch 49/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 4.4829 - val_loss: 4.3090\n",
      "Epoch 50/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 4.8879 - val_loss: 4.1814\n",
      "Epoch 51/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 4.5363 - val_loss: 4.3912\n",
      "Epoch 52/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 4.4279 - val_loss: 4.3765\n",
      "Epoch 53/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 4.5212 - val_loss: 4.1075\n",
      "Epoch 54/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 4.3783 - val_loss: 4.2735\n",
      "Epoch 55/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 4.2459 - val_loss: 4.2233\n",
      "Epoch 56/2000\n",
      "73/73 [==============================] - 6s 82ms/step - loss: 4.2392 - val_loss: 4.6962\n",
      "Epoch 57/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 4.2396 - val_loss: 4.2270\n",
      "Epoch 58/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 4.0911 - val_loss: 3.9767\n",
      "Epoch 59/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 5.7665 - val_loss: 5.3159\n",
      "Epoch 60/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 4.9945 - val_loss: 5.6186\n",
      "Epoch 61/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 4.9507 - val_loss: 4.7753\n",
      "Epoch 62/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 4.4780 - val_loss: 4.0982\n",
      "Epoch 63/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 4.1919 - val_loss: 4.1922\n",
      "Epoch 64/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 4.3041 - val_loss: 4.4481\n",
      "Epoch 65/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 4.0497 - val_loss: 4.1057\n",
      "Epoch 66/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.9767 - val_loss: 3.8040\n",
      "Epoch 67/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.9150 - val_loss: 3.8754\n",
      "Epoch 68/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.8291 - val_loss: 4.2823\n",
      "Epoch 69/2000\n",
      "73/73 [==============================] - 6s 82ms/step - loss: 3.8728 - val_loss: 4.1133\n",
      "Epoch 70/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 4.0411 - val_loss: 4.1315\n",
      "Epoch 71/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.8534 - val_loss: 3.8262\n",
      "Epoch 72/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.8779 - val_loss: 4.1598\n",
      "Epoch 73/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 4.2029 - val_loss: 3.9558\n",
      "Epoch 74/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 3.8378 - val_loss: 3.7021\n",
      "Epoch 75/2000\n",
      "73/73 [==============================] - 6s 82ms/step - loss: 3.6769 - val_loss: 3.6921\n",
      "Epoch 76/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.6981 - val_loss: 3.8828\n",
      "Epoch 77/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.8422 - val_loss: 3.7757\n",
      "Epoch 78/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.7515 - val_loss: 3.8336\n",
      "Epoch 79/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 4.4668 - val_loss: 3.9427\n",
      "Epoch 80/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.8639 - val_loss: 3.9848\n",
      "Epoch 81/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.6081 - val_loss: 3.8448\n",
      "Epoch 82/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.5231 - val_loss: 3.6868\n",
      "Epoch 83/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.5638 - val_loss: 3.6453\n",
      "Epoch 84/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.5390 - val_loss: 3.8131\n",
      "Epoch 85/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.5477 - val_loss: 4.1889\n",
      "Epoch 86/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.4334 - val_loss: 3.8657\n",
      "Epoch 87/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 3.5233 - val_loss: 3.4024\n",
      "Epoch 88/2000\n",
      "73/73 [==============================] - 6s 81ms/step - loss: 3.5725 - val_loss: 3.5233\n",
      "Epoch 89/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.4796 - val_loss: 3.6797\n",
      "Epoch 90/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.5537 - val_loss: 3.4830\n",
      "Epoch 91/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.5334 - val_loss: 3.3769\n",
      "Epoch 92/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.4665 - val_loss: 3.5032\n",
      "Epoch 93/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 3.4224 - val_loss: 3.4347\n",
      "Epoch 94/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 3.3666 - val_loss: 3.4398\n",
      "Epoch 95/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.4287 - val_loss: 3.5630\n",
      "Epoch 96/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.3884 - val_loss: 3.4136\n",
      "Epoch 97/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.3141 - val_loss: 3.5837\n",
      "Epoch 98/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.3427 - val_loss: 3.7147\n",
      "Epoch 99/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.2585 - val_loss: 3.6726\n",
      "Epoch 100/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.5098 - val_loss: 3.3893\n",
      "Epoch 101/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 3.2653 - val_loss: 3.2363\n",
      "Epoch 102/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.2314 - val_loss: 3.4726\n",
      "Epoch 103/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.2916 - val_loss: 3.2556\n",
      "Epoch 104/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.4252 - val_loss: 3.2955\n",
      "Epoch 105/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 3.3933 - val_loss: 3.6292\n",
      "Epoch 106/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 3.6532 - val_loss: 3.6010\n",
      "Epoch 107/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 3.3993 - val_loss: 4.1294\n",
      "Epoch 108/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.3868 - val_loss: 3.2709\n",
      "Epoch 109/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.2579 - val_loss: 3.3528\n",
      "Epoch 110/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.2962 - val_loss: 3.3645\n",
      "Epoch 111/2000\n",
      "73/73 [==============================] - ETA: 0s - loss: 3.2364Restoring model weights from the end of the best epoch: 101.\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.2364 - val_loss: 3.2891\n",
      "Epoch 111: early stopping\n",
      "'########################################################Model1\n",
      "Epoch 1/2000\n",
      "73/73 [==============================] - 8s 87ms/step - loss: 65.0114 - val_loss: 26.4121\n",
      "Epoch 2/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 13.6058 - val_loss: 11.8652\n",
      "Epoch 3/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 11.4919 - val_loss: 11.7808\n",
      "Epoch 4/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 11.3564 - val_loss: 11.5146\n",
      "Epoch 5/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 10.9916 - val_loss: 10.9183\n",
      "Epoch 6/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 10.6812 - val_loss: 10.4657\n",
      "Epoch 7/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 10.3389 - val_loss: 10.5433\n",
      "Epoch 8/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 9.9746 - val_loss: 9.7596\n",
      "Epoch 9/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 9.5646 - val_loss: 9.1643\n",
      "Epoch 10/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 9.0052 - val_loss: 9.0789\n",
      "Epoch 11/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 8.4841 - val_loss: 8.0646\n",
      "Epoch 12/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 8.2480 - val_loss: 7.6974\n",
      "Epoch 13/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 7.8180 - val_loss: 7.6696\n",
      "Epoch 14/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 7.6571 - val_loss: 7.6788\n",
      "Epoch 15/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 7.4810 - val_loss: 7.2162\n",
      "Epoch 16/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 7.3785 - val_loss: 7.2353\n",
      "Epoch 17/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 7.3321 - val_loss: 7.0231\n",
      "Epoch 18/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 7.2196 - val_loss: 6.9582\n",
      "Epoch 19/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 7.1760 - val_loss: 6.8355\n",
      "Epoch 20/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 7.0325 - val_loss: 7.1118\n",
      "Epoch 21/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 6.9065 - val_loss: 6.6526\n",
      "Epoch 22/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 6.6735 - val_loss: 6.3751\n",
      "Epoch 23/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 6.6646 - val_loss: 6.2024\n",
      "Epoch 24/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 6.4659 - val_loss: 6.3821\n",
      "Epoch 25/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 6.2118 - val_loss: 6.1805\n",
      "Epoch 26/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 6.2783 - val_loss: 6.0203\n",
      "Epoch 27/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 5.8052 - val_loss: 5.6519\n",
      "Epoch 28/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 5.4319 - val_loss: 5.1891\n",
      "Epoch 29/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 5.2252 - val_loss: 4.9624\n",
      "Epoch 30/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 5.0044 - val_loss: 5.0806\n",
      "Epoch 31/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 5.0518 - val_loss: 5.0866\n",
      "Epoch 32/2000\n",
      "73/73 [==============================] - 6s 82ms/step - loss: 4.8839 - val_loss: 4.6379\n",
      "Epoch 33/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 4.7584 - val_loss: 4.6113\n",
      "Epoch 34/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 4.7404 - val_loss: 4.5181\n",
      "Epoch 35/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 4.5375 - val_loss: 4.5324\n",
      "Epoch 36/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 4.4735 - val_loss: 5.0504\n",
      "Epoch 37/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 4.6072 - val_loss: 4.2829\n",
      "Epoch 38/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 4.3127 - val_loss: 4.3661\n",
      "Epoch 39/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 4.2542 - val_loss: 4.1186\n",
      "Epoch 40/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 4.1794 - val_loss: 3.8722\n",
      "Epoch 41/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 4.0453 - val_loss: 4.1685\n",
      "Epoch 42/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 4.1383 - val_loss: 3.9467\n",
      "Epoch 43/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 4.1064 - val_loss: 3.8214\n",
      "Epoch 44/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.9206 - val_loss: 3.6649\n",
      "Epoch 45/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.9292 - val_loss: 3.9875\n",
      "Epoch 46/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.9991 - val_loss: 3.8258\n",
      "Epoch 47/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 4.0175 - val_loss: 4.3451\n",
      "Epoch 48/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.8062 - val_loss: 3.8361\n",
      "Epoch 49/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.7704 - val_loss: 3.6441\n",
      "Epoch 50/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 3.7651 - val_loss: 3.6363\n",
      "Epoch 51/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.6496 - val_loss: 3.5845\n",
      "Epoch 52/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 3.5814 - val_loss: 3.8694\n",
      "Epoch 53/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 3.6183 - val_loss: 3.6207\n",
      "Epoch 54/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 3.5474 - val_loss: 3.6518\n",
      "Epoch 55/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 3.4868 - val_loss: 3.3997\n",
      "Epoch 56/2000\n",
      "73/73 [==============================] - 6s 82ms/step - loss: 3.4113 - val_loss: 3.4918\n",
      "Epoch 57/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 3.4534 - val_loss: 3.8383\n",
      "Epoch 58/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 3.5796 - val_loss: 3.4324\n",
      "Epoch 59/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 3.4150 - val_loss: 4.5825\n",
      "Epoch 60/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 3.7389 - val_loss: 3.5058\n",
      "Epoch 61/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 3.3477 - val_loss: 3.3269\n",
      "Epoch 62/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.3759 - val_loss: 3.8547\n",
      "Epoch 63/2000\n",
      "73/73 [==============================] - 7s 100ms/step - loss: 3.3524 - val_loss: 3.6207\n",
      "Epoch 64/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 3.3677 - val_loss: 3.4068\n",
      "Epoch 65/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 3.3578 - val_loss: 3.3287\n",
      "Epoch 66/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 3.4343 - val_loss: 3.2938\n",
      "Epoch 67/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 3.2504 - val_loss: 3.2898\n",
      "Epoch 68/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 3.3336 - val_loss: 3.1543\n",
      "Epoch 69/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 3.2691 - val_loss: 3.5965\n",
      "Epoch 70/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 3.3156 - val_loss: 3.1918\n",
      "Epoch 71/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 3.4407 - val_loss: 3.3389\n",
      "Epoch 72/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 3.2487 - val_loss: 3.1260\n",
      "Epoch 73/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 3.2224 - val_loss: 3.2592\n",
      "Epoch 74/2000\n",
      "73/73 [==============================] - 6s 82ms/step - loss: 3.2298 - val_loss: 3.5464\n",
      "Epoch 75/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.2448 - val_loss: 3.1884\n",
      "Epoch 76/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 3.1496 - val_loss: 3.3530\n",
      "Epoch 77/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 4.0958 - val_loss: 3.2954\n",
      "Epoch 78/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 3.2454 - val_loss: 3.2344\n",
      "Epoch 79/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.1084 - val_loss: 3.3163\n",
      "Epoch 80/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 3.1384 - val_loss: 3.2734\n",
      "Epoch 81/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 3.0924 - val_loss: 3.3448\n",
      "Epoch 82/2000\n",
      "73/73 [==============================] - ETA: 0s - loss: 3.2015Restoring model weights from the end of the best epoch: 72.\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.2015 - val_loss: 3.3757\n",
      "Epoch 82: early stopping\n",
      "'########################################################Model2\n",
      "Epoch 1/2000\n",
      "73/73 [==============================] - 8s 94ms/step - loss: 61.3845 - val_loss: 23.9635\n",
      "Epoch 2/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 13.1397 - val_loss: 11.9476\n",
      "Epoch 3/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 11.5644 - val_loss: 11.8382\n",
      "Epoch 4/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 11.4108 - val_loss: 11.6042\n",
      "Epoch 5/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 11.1308 - val_loss: 11.3722\n",
      "Epoch 6/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 10.7840 - val_loss: 10.5862\n",
      "Epoch 7/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 10.3789 - val_loss: 10.2058\n",
      "Epoch 8/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 10.0488 - val_loss: 10.1546\n",
      "Epoch 9/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 9.6590 - val_loss: 9.2724\n",
      "Epoch 10/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 9.1197 - val_loss: 8.9182\n",
      "Epoch 11/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 8.5756 - val_loss: 8.0990\n",
      "Epoch 12/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 8.1529 - val_loss: 7.8762\n",
      "Epoch 13/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 7.9143 - val_loss: 7.4702\n",
      "Epoch 14/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 7.8336 - val_loss: 7.3654\n",
      "Epoch 15/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 7.5111 - val_loss: 7.2060\n",
      "Epoch 16/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 7.3810 - val_loss: 7.3180\n",
      "Epoch 17/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 7.3738 - val_loss: 7.5125\n",
      "Epoch 18/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 7.1408 - val_loss: 6.7707\n",
      "Epoch 19/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 6.9537 - val_loss: 6.7260\n",
      "Epoch 20/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 6.9822 - val_loss: 6.7562\n",
      "Epoch 21/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 6.8121 - val_loss: 6.7344\n",
      "Epoch 22/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 6.7083 - val_loss: 6.7418\n",
      "Epoch 23/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 6.4084 - val_loss: 6.1363\n",
      "Epoch 24/2000\n",
      "73/73 [==============================] - 6s 80ms/step - loss: 6.8708 - val_loss: 6.6279\n",
      "Epoch 25/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 6.4031 - val_loss: 6.3324\n",
      "Epoch 26/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 6.1228 - val_loss: 6.6495\n",
      "Epoch 27/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 5.8295 - val_loss: 6.0462\n",
      "Epoch 28/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 5.6981 - val_loss: 5.6838\n",
      "Epoch 29/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 5.3561 - val_loss: 5.5310\n",
      "Epoch 30/2000\n",
      "73/73 [==============================] - 6s 79ms/step - loss: 5.3940 - val_loss: 5.8622\n",
      "Epoch 31/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 5.3551 - val_loss: 5.7898\n",
      "Epoch 32/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 5.2742 - val_loss: 5.6774\n",
      "Epoch 33/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 5.0821 - val_loss: 5.6669\n",
      "Epoch 34/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 5.2490 - val_loss: 5.4949\n",
      "Epoch 35/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 5.0255 - val_loss: 5.1026\n",
      "Epoch 36/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 4.8567 - val_loss: 5.0274\n",
      "Epoch 37/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 4.8619 - val_loss: 5.2965\n",
      "Epoch 38/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 4.7492 - val_loss: 5.5682\n",
      "Epoch 39/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 4.7783 - val_loss: 5.2476\n",
      "Epoch 40/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 4.5742 - val_loss: 4.7111\n",
      "Epoch 41/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 4.6455 - val_loss: 4.8955\n",
      "Epoch 42/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 4.5493 - val_loss: 5.2425\n",
      "Epoch 43/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 4.4887 - val_loss: 4.7971\n",
      "Epoch 44/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 4.6338 - val_loss: 4.8780\n",
      "Epoch 45/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 4.7266 - val_loss: 4.7769\n",
      "Epoch 46/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 4.5364 - val_loss: 5.0305\n",
      "Epoch 47/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 4.4075 - val_loss: 4.6380\n",
      "Epoch 48/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 4.4611 - val_loss: 4.7894\n",
      "Epoch 49/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 4.2131 - val_loss: 4.4787\n",
      "Epoch 50/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 4.2523 - val_loss: 4.5118\n",
      "Epoch 51/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 4.3202 - val_loss: 4.7134\n",
      "Epoch 52/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 4.1060 - val_loss: 4.6330\n",
      "Epoch 53/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 4.2330 - val_loss: 4.3320\n",
      "Epoch 54/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 4.1341 - val_loss: 4.5505\n",
      "Epoch 55/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 4.0986 - val_loss: 4.5553\n",
      "Epoch 56/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 4.1491 - val_loss: 4.3468\n",
      "Epoch 57/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 3.9807 - val_loss: 4.3990\n",
      "Epoch 58/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 3.9646 - val_loss: 4.4014\n",
      "Epoch 59/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 4.2515 - val_loss: 4.5669\n",
      "Epoch 60/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 4.1029 - val_loss: 4.2083\n",
      "Epoch 61/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 4.0345 - val_loss: 4.2851\n",
      "Epoch 62/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 3.9496 - val_loss: 4.1258\n",
      "Epoch 63/2000\n",
      "73/73 [==============================] - 6s 81ms/step - loss: 4.0474 - val_loss: 4.4819\n",
      "Epoch 64/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 4.0068 - val_loss: 4.2271\n",
      "Epoch 65/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 3.9704 - val_loss: 4.3055\n",
      "Epoch 66/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 3.8120 - val_loss: 4.3587\n",
      "Epoch 67/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 3.8595 - val_loss: 4.1617\n",
      "Epoch 68/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 3.8661 - val_loss: 4.2462\n",
      "Epoch 69/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 3.7993 - val_loss: 4.1579\n",
      "Epoch 70/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 3.8138 - val_loss: 4.1630\n",
      "Epoch 71/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 3.7395 - val_loss: 4.3226\n",
      "Epoch 72/2000\n",
      "73/73 [==============================] - ETA: 0s - loss: 3.7956Restoring model weights from the end of the best epoch: 62.\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 3.7956 - val_loss: 4.3063\n",
      "Epoch 72: early stopping\n",
      "'########################################################Model3\n",
      "Epoch 1/2000\n",
      "73/73 [==============================] - 8s 97ms/step - loss: 48.4629 - val_loss: 11.7442\n",
      "Epoch 2/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 11.4558 - val_loss: 11.6351\n",
      "Epoch 3/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 11.1688 - val_loss: 11.2329\n",
      "Epoch 4/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 10.8688 - val_loss: 11.0741\n",
      "Epoch 5/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 10.5680 - val_loss: 10.2453\n",
      "Epoch 6/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 10.0250 - val_loss: 9.7638\n",
      "Epoch 7/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 9.6977 - val_loss: 9.2311\n",
      "Epoch 8/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 9.1449 - val_loss: 8.7529\n",
      "Epoch 9/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 8.5870 - val_loss: 8.0748\n",
      "Epoch 10/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 8.1473 - val_loss: 8.8017\n",
      "Epoch 11/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 8.1329 - val_loss: 7.6050\n",
      "Epoch 12/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 7.6577 - val_loss: 7.7623\n",
      "Epoch 13/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 7.5116 - val_loss: 7.2816\n",
      "Epoch 14/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 7.4924 - val_loss: 7.0024\n",
      "Epoch 15/2000\n",
      "73/73 [==============================] - 6s 81ms/step - loss: 7.3348 - val_loss: 6.8693\n",
      "Epoch 16/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 7.0479 - val_loss: 6.7378\n",
      "Epoch 17/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 6.9538 - val_loss: 7.5754\n",
      "Epoch 18/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 6.9083 - val_loss: 6.4844\n",
      "Epoch 19/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 6.7687 - val_loss: 7.1226\n",
      "Epoch 20/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 6.6805 - val_loss: 6.5071\n",
      "Epoch 21/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 6.4337 - val_loss: 6.1945\n",
      "Epoch 22/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 6.4541 - val_loss: 6.0434\n",
      "Epoch 23/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 6.2072 - val_loss: 6.1742\n",
      "Epoch 24/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 6.6490 - val_loss: 6.3413\n",
      "Epoch 25/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 6.4264 - val_loss: 5.8692\n",
      "Epoch 26/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 6.0437 - val_loss: 5.9874\n",
      "Epoch 27/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 5.8331 - val_loss: 5.9149\n",
      "Epoch 28/2000\n",
      "73/73 [==============================] - 6s 80ms/step - loss: 5.6729 - val_loss: 5.6211\n",
      "Epoch 29/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 5.5977 - val_loss: 6.0068\n",
      "Epoch 30/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 5.5257 - val_loss: 5.5525\n",
      "Epoch 31/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 5.2338 - val_loss: 5.1063\n",
      "Epoch 32/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 5.2689 - val_loss: 6.8037\n",
      "Epoch 33/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 5.6627 - val_loss: 5.1999\n",
      "Epoch 34/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 5.0434 - val_loss: 4.9149\n",
      "Epoch 35/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 4.9177 - val_loss: 5.1665\n",
      "Epoch 36/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 4.7602 - val_loss: 4.7565\n",
      "Epoch 37/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 4.6769 - val_loss: 4.9293\n",
      "Epoch 38/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 4.5159 - val_loss: 4.8130\n",
      "Epoch 39/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 4.7640 - val_loss: 5.2187\n",
      "Epoch 40/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 4.5283 - val_loss: 4.5655\n",
      "Epoch 41/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 4.3387 - val_loss: 4.5126\n",
      "Epoch 42/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 4.5813 - val_loss: 4.7250\n",
      "Epoch 43/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 4.3944 - val_loss: 4.2659\n",
      "Epoch 44/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 4.1234 - val_loss: 4.5614\n",
      "Epoch 45/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 4.2445 - val_loss: 4.3154\n",
      "Epoch 46/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 4.1292 - val_loss: 4.9921\n",
      "Epoch 47/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 4.2409 - val_loss: 4.0879\n",
      "Epoch 48/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 4.0076 - val_loss: 3.9928\n",
      "Epoch 49/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.9217 - val_loss: 4.1782\n",
      "Epoch 50/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 4.1275 - val_loss: 4.2045\n",
      "Epoch 51/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.9449 - val_loss: 3.8515\n",
      "Epoch 52/2000\n",
      "73/73 [==============================] - 6s 80ms/step - loss: 3.8396 - val_loss: 4.0596\n",
      "Epoch 53/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 4.3029 - val_loss: 4.0494\n",
      "Epoch 54/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.8807 - val_loss: 4.0906\n",
      "Epoch 55/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.8604 - val_loss: 3.7344\n",
      "Epoch 56/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.9105 - val_loss: 3.8115\n",
      "Epoch 57/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.6465 - val_loss: 4.1180\n",
      "Epoch 58/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.9158 - val_loss: 3.6201\n",
      "Epoch 59/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.6850 - val_loss: 3.5896\n",
      "Epoch 60/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.7145 - val_loss: 3.7164\n",
      "Epoch 61/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 3.6940 - val_loss: 3.5685\n",
      "Epoch 62/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 3.6794 - val_loss: 3.6144\n",
      "Epoch 63/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.5738 - val_loss: 3.5241\n",
      "Epoch 64/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 3.7124 - val_loss: 3.6030\n",
      "Epoch 65/2000\n",
      "73/73 [==============================] - 6s 81ms/step - loss: 3.4700 - val_loss: 3.5325\n",
      "Epoch 66/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 3.5486 - val_loss: 3.9060\n",
      "Epoch 67/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 3.4872 - val_loss: 3.6925\n",
      "Epoch 68/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.4016 - val_loss: 3.3802\n",
      "Epoch 69/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 3.4371 - val_loss: 3.6623\n",
      "Epoch 70/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 3.4491 - val_loss: 3.5355\n",
      "Epoch 71/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 3.4954 - val_loss: 3.6278\n",
      "Epoch 72/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 4.1578 - val_loss: 4.1942\n",
      "Epoch 73/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.7666 - val_loss: 3.8774\n",
      "Epoch 74/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.4974 - val_loss: 3.3584\n",
      "Epoch 75/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.4190 - val_loss: 3.9389\n",
      "Epoch 76/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.5510 - val_loss: 3.7356\n",
      "Epoch 77/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.3858 - val_loss: 3.5118\n",
      "Epoch 78/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.4083 - val_loss: 3.5809\n",
      "Epoch 79/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.4089 - val_loss: 3.4694\n",
      "Epoch 80/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.3512 - val_loss: 3.9216\n",
      "Epoch 81/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.5892 - val_loss: 3.5734\n",
      "Epoch 82/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.2680 - val_loss: 3.5701\n",
      "Epoch 83/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 3.3076 - val_loss: 4.0824\n",
      "Epoch 84/2000\n",
      "73/73 [==============================] - ETA: 0s - loss: 3.3473Restoring model weights from the end of the best epoch: 74.\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 3.3473 - val_loss: 3.5576\n",
      "Epoch 84: early stopping\n",
      "'########################################################Model4\n",
      "Epoch 1/2000\n",
      "73/73 [==============================] - 9s 98ms/step - loss: 58.1698 - val_loss: 23.4774\n",
      "Epoch 2/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 13.3140 - val_loss: 11.8799\n",
      "Epoch 3/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 11.5439 - val_loss: 11.7494\n",
      "Epoch 4/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 11.3435 - val_loss: 11.6153\n",
      "Epoch 5/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 11.1110 - val_loss: 11.0751\n",
      "Epoch 6/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 10.6950 - val_loss: 10.5731\n",
      "Epoch 7/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 10.5338 - val_loss: 10.3027\n",
      "Epoch 8/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 10.1531 - val_loss: 10.1630\n",
      "Epoch 9/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 9.9832 - val_loss: 9.6487\n",
      "Epoch 10/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 9.4425 - val_loss: 9.4141\n",
      "Epoch 11/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 8.8639 - val_loss: 8.2041\n",
      "Epoch 12/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 8.3989 - val_loss: 7.8890\n",
      "Epoch 13/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 8.1088 - val_loss: 7.7587\n",
      "Epoch 14/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 7.8035 - val_loss: 7.3559\n",
      "Epoch 15/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 7.5499 - val_loss: 7.2123\n",
      "Epoch 16/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 7.4121 - val_loss: 7.0947\n",
      "Epoch 17/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 7.2163 - val_loss: 6.8260\n",
      "Epoch 18/2000\n",
      "73/73 [==============================] - 6s 82ms/step - loss: 7.0943 - val_loss: 6.6306\n",
      "Epoch 19/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 6.9699 - val_loss: 6.7023\n",
      "Epoch 20/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 6.7049 - val_loss: 6.4604\n",
      "Epoch 21/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 6.2109 - val_loss: 5.9767\n",
      "Epoch 22/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 5.6158 - val_loss: 5.8208\n",
      "Epoch 23/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 5.3082 - val_loss: 6.2198\n",
      "Epoch 24/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 5.1929 - val_loss: 5.5897\n",
      "Epoch 25/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 5.3126 - val_loss: 5.3303\n",
      "Epoch 26/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 4.9009 - val_loss: 4.8834\n",
      "Epoch 27/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 4.7549 - val_loss: 4.9148\n",
      "Epoch 28/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 4.6443 - val_loss: 5.0891\n",
      "Epoch 29/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 4.6191 - val_loss: 4.9836\n",
      "Epoch 30/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 4.4963 - val_loss: 5.0248\n",
      "Epoch 31/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 4.5168 - val_loss: 4.6116\n",
      "Epoch 32/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 4.5080 - val_loss: 4.7545\n",
      "Epoch 33/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 4.3206 - val_loss: 5.1426\n",
      "Epoch 34/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 4.4603 - val_loss: 4.7408\n",
      "Epoch 35/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 4.2041 - val_loss: 4.4686\n",
      "Epoch 36/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 4.2032 - val_loss: 4.5575\n",
      "Epoch 37/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 4.2003 - val_loss: 4.3310\n",
      "Epoch 38/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 4.3248 - val_loss: 4.7907\n",
      "Epoch 39/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 4.1368 - val_loss: 4.4328\n",
      "Epoch 40/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 4.0240 - val_loss: 4.6585\n",
      "Epoch 41/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 4.1564 - val_loss: 4.3533\n",
      "Epoch 42/2000\n",
      "73/73 [==============================] - 6s 80ms/step - loss: 4.0934 - val_loss: 4.5495\n",
      "Epoch 43/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.9926 - val_loss: 4.4963\n",
      "Epoch 44/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.9841 - val_loss: 4.1677\n",
      "Epoch 45/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 4.0374 - val_loss: 4.4642\n",
      "Epoch 46/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 4.1002 - val_loss: 4.0579\n",
      "Epoch 47/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.8971 - val_loss: 4.8605\n",
      "Epoch 48/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.8435 - val_loss: 3.8548\n",
      "Epoch 49/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.8662 - val_loss: 4.0963\n",
      "Epoch 50/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.7714 - val_loss: 4.1234\n",
      "Epoch 51/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.7947 - val_loss: 4.0902\n",
      "Epoch 52/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.6728 - val_loss: 4.1265\n",
      "Epoch 53/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.8373 - val_loss: 3.9738\n",
      "Epoch 54/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.6903 - val_loss: 3.8115\n",
      "Epoch 55/2000\n",
      "73/73 [==============================] - 6s 80ms/step - loss: 3.5969 - val_loss: 4.0507\n",
      "Epoch 56/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.6294 - val_loss: 4.1374\n",
      "Epoch 57/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.7532 - val_loss: 3.9183\n",
      "Epoch 58/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.6005 - val_loss: 3.9342\n",
      "Epoch 59/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.5011 - val_loss: 3.8113\n",
      "Epoch 60/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 3.6353 - val_loss: 3.9298\n",
      "Epoch 61/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 3.5619 - val_loss: 3.8230\n",
      "Epoch 62/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.5557 - val_loss: 3.7954\n",
      "Epoch 63/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.5351 - val_loss: 4.0998\n",
      "Epoch 64/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.5394 - val_loss: 3.7970\n",
      "Epoch 65/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.5231 - val_loss: 3.7117\n",
      "Epoch 66/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.4545 - val_loss: 3.9891\n",
      "Epoch 67/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.3734 - val_loss: 3.7557\n",
      "Epoch 68/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.4357 - val_loss: 3.7589\n",
      "Epoch 69/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.3108 - val_loss: 3.7472\n",
      "Epoch 70/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.3989 - val_loss: 3.8045\n",
      "Epoch 71/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 3.4650 - val_loss: 3.5685\n",
      "Epoch 72/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.3389 - val_loss: 3.7860\n",
      "Epoch 73/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 3.3290 - val_loss: 3.5795\n",
      "Epoch 74/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 3.4635 - val_loss: 3.4678\n",
      "Epoch 75/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.2614 - val_loss: 3.7714\n",
      "Epoch 76/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.4039 - val_loss: 3.7778\n",
      "Epoch 77/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.3357 - val_loss: 3.5639\n",
      "Epoch 78/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.2818 - val_loss: 3.6306\n",
      "Epoch 79/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 3.2362 - val_loss: 3.9566\n",
      "Epoch 80/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 3.3862 - val_loss: 3.6816\n",
      "Epoch 81/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.3450 - val_loss: 3.5063\n",
      "Epoch 82/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.3373 - val_loss: 3.4558\n",
      "Epoch 83/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.1795 - val_loss: 3.8284\n",
      "Epoch 84/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.2092 - val_loss: 3.5611\n",
      "Epoch 85/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.1906 - val_loss: 3.3710\n",
      "Epoch 86/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.1495 - val_loss: 3.4648\n",
      "Epoch 87/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.2195 - val_loss: 3.4623\n",
      "Epoch 88/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.1175 - val_loss: 3.4943\n",
      "Epoch 89/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.0874 - val_loss: 3.8260\n",
      "Epoch 90/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.0702 - val_loss: 3.5433\n",
      "Epoch 91/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.0699 - val_loss: 3.4378\n",
      "Epoch 92/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 3.0899 - val_loss: 3.5374\n",
      "Epoch 93/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.1184 - val_loss: 3.4177\n",
      "Epoch 94/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.0460 - val_loss: 3.4968\n",
      "Epoch 95/2000\n",
      "73/73 [==============================] - ETA: 0s - loss: 3.0506Restoring model weights from the end of the best epoch: 85.\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.0506 - val_loss: 3.3832\n",
      "Epoch 95: early stopping\n",
      "'########################################################Model5\n",
      "Epoch 1/2000\n",
      "73/73 [==============================] - 9s 103ms/step - loss: 60.7284 - val_loss: 23.1310\n",
      "Epoch 2/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 12.9771 - val_loss: 11.9521\n",
      "Epoch 3/2000\n",
      "73/73 [==============================] - 6s 82ms/step - loss: 11.5034 - val_loss: 11.7511\n",
      "Epoch 4/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 11.4249 - val_loss: 11.5262\n",
      "Epoch 5/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 11.1458 - val_loss: 11.1246\n",
      "Epoch 6/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 10.8005 - val_loss: 10.7192\n",
      "Epoch 7/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 10.4409 - val_loss: 10.2248\n",
      "Epoch 8/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 10.0994 - val_loss: 9.9126\n",
      "Epoch 9/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 9.9226 - val_loss: 9.6428\n",
      "Epoch 10/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 9.6719 - val_loss: 9.1040\n",
      "Epoch 11/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 9.0206 - val_loss: 8.4340\n",
      "Epoch 12/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 8.4397 - val_loss: 7.8583\n",
      "Epoch 13/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 7.9968 - val_loss: 7.8139\n",
      "Epoch 14/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 7.7778 - val_loss: 7.5125\n",
      "Epoch 15/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 7.6126 - val_loss: 7.3090\n",
      "Epoch 16/2000\n",
      "73/73 [==============================] - 6s 79ms/step - loss: 7.3428 - val_loss: 7.1718\n",
      "Epoch 17/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 7.3892 - val_loss: 6.9492\n",
      "Epoch 18/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 7.1296 - val_loss: 6.6935\n",
      "Epoch 19/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 6.9157 - val_loss: 7.5863\n",
      "Epoch 20/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 7.0429 - val_loss: 6.6029\n",
      "Epoch 21/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 6.7136 - val_loss: 6.3100\n",
      "Epoch 22/2000\n",
      "73/73 [==============================] - 6s 81ms/step - loss: 6.6132 - val_loss: 6.2138\n",
      "Epoch 23/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 6.4374 - val_loss: 6.2495\n",
      "Epoch 24/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 6.2870 - val_loss: 6.0449\n",
      "Epoch 25/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 6.4384 - val_loss: 5.9683\n",
      "Epoch 26/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 6.3251 - val_loss: 5.8302\n",
      "Epoch 27/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 6.2242 - val_loss: 6.0258\n",
      "Epoch 28/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 5.9796 - val_loss: 5.6137\n",
      "Epoch 29/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 5.9239 - val_loss: 5.4215\n",
      "Epoch 30/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 5.6733 - val_loss: 5.3695\n",
      "Epoch 31/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 6.0052 - val_loss: 5.4066\n",
      "Epoch 32/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 5.4621 - val_loss: 5.6931\n",
      "Epoch 33/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 5.5883 - val_loss: 5.3327\n",
      "Epoch 34/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 5.4605 - val_loss: 5.6964\n",
      "Epoch 35/2000\n",
      "73/73 [==============================] - 6s 79ms/step - loss: 5.2765 - val_loss: 5.0723\n",
      "Epoch 36/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 5.0550 - val_loss: 4.7819\n",
      "Epoch 37/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 4.8861 - val_loss: 4.8382\n",
      "Epoch 38/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 4.6718 - val_loss: 4.6006\n",
      "Epoch 39/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 4.5567 - val_loss: 5.2962\n",
      "Epoch 40/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 4.4804 - val_loss: 4.6075\n",
      "Epoch 41/2000\n",
      "73/73 [==============================] - 6s 79ms/step - loss: 4.2977 - val_loss: 4.2836\n",
      "Epoch 42/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 4.5925 - val_loss: 4.4735\n",
      "Epoch 43/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 4.2129 - val_loss: 4.2694\n",
      "Epoch 44/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.9222 - val_loss: 4.2183\n",
      "Epoch 45/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.8649 - val_loss: 4.0454\n",
      "Epoch 46/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.9209 - val_loss: 3.9473\n",
      "Epoch 47/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.8699 - val_loss: 4.4081\n",
      "Epoch 48/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.8442 - val_loss: 4.8633\n",
      "Epoch 49/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.9268 - val_loss: 3.8921\n",
      "Epoch 50/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 3.6945 - val_loss: 3.8546\n",
      "Epoch 51/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 3.7880 - val_loss: 3.8453\n",
      "Epoch 52/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.7057 - val_loss: 3.9183\n",
      "Epoch 53/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.6038 - val_loss: 3.7887\n",
      "Epoch 54/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.5818 - val_loss: 3.6808\n",
      "Epoch 55/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 3.5934 - val_loss: 3.5901\n",
      "Epoch 56/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.4939 - val_loss: 3.8282\n",
      "Epoch 57/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.6163 - val_loss: 3.7386\n",
      "Epoch 58/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.5186 - val_loss: 3.5244\n",
      "Epoch 59/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 3.6686 - val_loss: 3.5651\n",
      "Epoch 60/2000\n",
      "73/73 [==============================] - 6s 79ms/step - loss: 3.5158 - val_loss: 3.6618\n",
      "Epoch 61/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.4231 - val_loss: 3.6176\n",
      "Epoch 62/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.4539 - val_loss: 3.6118\n",
      "Epoch 63/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.4198 - val_loss: 3.4465\n",
      "Epoch 64/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.4480 - val_loss: 3.4943\n",
      "Epoch 65/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.3582 - val_loss: 3.6815\n",
      "Epoch 66/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.2803 - val_loss: 3.7060\n",
      "Epoch 67/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.3876 - val_loss: 3.5972\n",
      "Epoch 68/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.2688 - val_loss: 3.5580\n",
      "Epoch 69/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 3.3106 - val_loss: 3.4277\n",
      "Epoch 70/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 3.3676 - val_loss: 3.4855\n",
      "Epoch 71/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 3.2344 - val_loss: 3.3447\n",
      "Epoch 72/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.2959 - val_loss: 3.7121\n",
      "Epoch 73/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.2453 - val_loss: 3.4841\n",
      "Epoch 74/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.1717 - val_loss: 3.5457\n",
      "Epoch 75/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.1994 - val_loss: 3.5612\n",
      "Epoch 76/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.3734 - val_loss: 3.4027\n",
      "Epoch 77/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 3.1926 - val_loss: 3.7521\n",
      "Epoch 78/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.4288 - val_loss: 3.3531\n",
      "Epoch 79/2000\n",
      "73/73 [==============================] - 6s 81ms/step - loss: 3.6560 - val_loss: 3.2707\n",
      "Epoch 80/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.1908 - val_loss: 3.2190\n",
      "Epoch 81/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.1377 - val_loss: 3.2837\n",
      "Epoch 82/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.0856 - val_loss: 3.3937\n",
      "Epoch 83/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.1983 - val_loss: 3.2870\n",
      "Epoch 84/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.2237 - val_loss: 3.4252\n",
      "Epoch 85/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.0763 - val_loss: 3.5315\n",
      "Epoch 86/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.1852 - val_loss: 3.3311\n",
      "Epoch 87/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.0500 - val_loss: 3.7329\n",
      "Epoch 88/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 3.0535 - val_loss: 3.2696\n",
      "Epoch 89/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 3.0067 - val_loss: 3.7397\n",
      "Epoch 90/2000\n",
      "73/73 [==============================] - ETA: 0s - loss: 3.0336Restoring model weights from the end of the best epoch: 80.\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.0336 - val_loss: 3.4011\n",
      "Epoch 90: early stopping\n",
      "'########################################################Model6\n",
      "Epoch 1/2000\n",
      "73/73 [==============================] - 8s 96ms/step - loss: 63.3881 - val_loss: 19.4028\n",
      "Epoch 2/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 12.2186 - val_loss: 11.8988\n",
      "Epoch 3/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 11.5023 - val_loss: 11.7530\n",
      "Epoch 4/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 11.3600 - val_loss: 11.5109\n",
      "Epoch 5/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 11.1010 - val_loss: 11.0831\n",
      "Epoch 6/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 10.6833 - val_loss: 10.5392\n",
      "Epoch 7/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 10.2032 - val_loss: 9.9494\n",
      "Epoch 8/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 9.8196 - val_loss: 9.4213\n",
      "Epoch 9/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 9.2244 - val_loss: 8.8537\n",
      "Epoch 10/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 8.6723 - val_loss: 8.0675\n",
      "Epoch 11/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 8.2644 - val_loss: 8.2269\n",
      "Epoch 12/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 7.9429 - val_loss: 7.5104\n",
      "Epoch 13/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 7.6754 - val_loss: 7.4024\n",
      "Epoch 14/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 7.5269 - val_loss: 7.0991\n",
      "Epoch 15/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 7.2535 - val_loss: 7.1468\n",
      "Epoch 16/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 7.2079 - val_loss: 6.8340\n",
      "Epoch 17/2000\n",
      "73/73 [==============================] - 6s 82ms/step - loss: 7.1570 - val_loss: 6.6868\n",
      "Epoch 18/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 6.9939 - val_loss: 7.0699\n",
      "Epoch 19/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 6.8872 - val_loss: 6.4479\n",
      "Epoch 20/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 6.7018 - val_loss: 6.3979\n",
      "Epoch 21/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 6.6998 - val_loss: 6.3300\n",
      "Epoch 22/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 6.7529 - val_loss: 6.2637\n",
      "Epoch 23/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 6.5144 - val_loss: 6.2288\n",
      "Epoch 24/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 6.4360 - val_loss: 6.1125\n",
      "Epoch 25/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 6.3879 - val_loss: 6.1279\n",
      "Epoch 26/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 6.3078 - val_loss: 5.9187\n",
      "Epoch 27/2000\n",
      "73/73 [==============================] - 6s 79ms/step - loss: 6.3686 - val_loss: 6.4704\n",
      "Epoch 28/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 6.2893 - val_loss: 5.9616\n",
      "Epoch 29/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 6.1497 - val_loss: 5.7252\n",
      "Epoch 30/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 6.1220 - val_loss: 5.8579\n",
      "Epoch 31/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 5.9887 - val_loss: 5.6474\n",
      "Epoch 32/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 5.9898 - val_loss: 6.0355\n",
      "Epoch 33/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 5.9523 - val_loss: 6.2059\n",
      "Epoch 34/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 5.9219 - val_loss: 5.6062\n",
      "Epoch 35/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 5.8480 - val_loss: 5.6450\n",
      "Epoch 36/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 5.7545 - val_loss: 5.3635\n",
      "Epoch 37/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 5.8457 - val_loss: 5.4405\n",
      "Epoch 38/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 5.6662 - val_loss: 5.5045\n",
      "Epoch 39/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 5.9568 - val_loss: 5.9778\n",
      "Epoch 40/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 6.3728 - val_loss: 5.7412\n",
      "Epoch 41/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 5.8073 - val_loss: 5.7966\n",
      "Epoch 42/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 5.5243 - val_loss: 5.5526\n",
      "Epoch 43/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 5.7201 - val_loss: 5.1681\n",
      "Epoch 44/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 5.3277 - val_loss: 5.2970\n",
      "Epoch 45/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 5.3312 - val_loss: 6.0914\n",
      "Epoch 46/2000\n",
      "73/73 [==============================] - 6s 78ms/step - loss: 5.5040 - val_loss: 4.9063\n",
      "Epoch 47/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 5.0947 - val_loss: 4.7183\n",
      "Epoch 48/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 5.1879 - val_loss: 5.2939\n",
      "Epoch 49/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 5.1090 - val_loss: 5.5917\n",
      "Epoch 50/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 5.9039 - val_loss: 5.2958\n",
      "Epoch 51/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 5.6998 - val_loss: 5.0510\n",
      "Epoch 52/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 5.0387 - val_loss: 4.8630\n",
      "Epoch 53/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 4.8002 - val_loss: 4.3015\n",
      "Epoch 54/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 4.7030 - val_loss: 4.1390\n",
      "Epoch 55/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 4.9505 - val_loss: 5.2153\n",
      "Epoch 56/2000\n",
      "73/73 [==============================] - 6s 82ms/step - loss: 4.7011 - val_loss: 4.4251\n",
      "Epoch 57/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 4.5533 - val_loss: 4.7253\n",
      "Epoch 58/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 4.6387 - val_loss: 4.6532\n",
      "Epoch 59/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 4.5922 - val_loss: 4.3552\n",
      "Epoch 60/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 4.1979 - val_loss: 3.9994\n",
      "Epoch 61/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 4.6487 - val_loss: 4.6097\n",
      "Epoch 62/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 4.5315 - val_loss: 3.8793\n",
      "Epoch 63/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 4.3094 - val_loss: 4.1764\n",
      "Epoch 64/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 4.2076 - val_loss: 4.1039\n",
      "Epoch 65/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 4.5854 - val_loss: 5.7376\n",
      "Epoch 66/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 4.9377 - val_loss: 4.1841\n",
      "Epoch 67/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 4.2425 - val_loss: 4.1991\n",
      "Epoch 68/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 4.0730 - val_loss: 3.9606\n",
      "Epoch 69/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 4.0312 - val_loss: 4.0686\n",
      "Epoch 70/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 4.0652 - val_loss: 3.8930\n",
      "Epoch 71/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 3.9570 - val_loss: 3.9104\n",
      "Epoch 72/2000\n",
      "73/73 [==============================] - ETA: 0s - loss: 3.8686Restoring model weights from the end of the best epoch: 62.\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.8686 - val_loss: 4.0596\n",
      "Epoch 72: early stopping\n",
      "'########################################################Model7\n",
      "Epoch 1/2000\n",
      "73/73 [==============================] - 8s 94ms/step - loss: 50.3516 - val_loss: 13.6753\n",
      "Epoch 2/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 11.5440 - val_loss: 11.7255\n",
      "Epoch 3/2000\n",
      "73/73 [==============================] - 6s 82ms/step - loss: 11.3129 - val_loss: 11.4660\n",
      "Epoch 4/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 10.9994 - val_loss: 11.0135\n",
      "Epoch 5/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 10.5527 - val_loss: 10.2960\n",
      "Epoch 6/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 10.0238 - val_loss: 9.7027\n",
      "Epoch 7/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 9.6910 - val_loss: 9.2120\n",
      "Epoch 8/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 9.0008 - val_loss: 8.4806\n",
      "Epoch 9/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 8.2795 - val_loss: 8.8204\n",
      "Epoch 10/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 8.0442 - val_loss: 8.1182\n",
      "Epoch 11/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 7.7828 - val_loss: 7.5417\n",
      "Epoch 12/2000\n",
      "73/73 [==============================] - 6s 82ms/step - loss: 7.7877 - val_loss: 7.3464\n",
      "Epoch 13/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 7.5279 - val_loss: 7.1458\n",
      "Epoch 14/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 7.3645 - val_loss: 7.0216\n",
      "Epoch 15/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 7.2522 - val_loss: 6.9288\n",
      "Epoch 16/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 6.9358 - val_loss: 6.8814\n",
      "Epoch 17/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 7.0971 - val_loss: 6.8282\n",
      "Epoch 18/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 6.7657 - val_loss: 6.2206\n",
      "Epoch 19/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 5.9621 - val_loss: 7.1334\n",
      "Epoch 20/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 6.3818 - val_loss: 6.4521\n",
      "Epoch 21/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 5.6494 - val_loss: 5.5879\n",
      "Epoch 22/2000\n",
      "73/73 [==============================] - 6s 80ms/step - loss: 5.2575 - val_loss: 5.9414\n",
      "Epoch 23/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 5.1556 - val_loss: 5.4406\n",
      "Epoch 24/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 4.9646 - val_loss: 5.4099\n",
      "Epoch 25/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 4.8368 - val_loss: 5.0868\n",
      "Epoch 26/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 4.7047 - val_loss: 5.0459\n",
      "Epoch 27/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 4.7533 - val_loss: 5.0881\n",
      "Epoch 28/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 4.6818 - val_loss: 4.8670\n",
      "Epoch 29/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 4.5222 - val_loss: 4.9219\n",
      "Epoch 30/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 4.6492 - val_loss: 5.1282\n",
      "Epoch 31/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 4.4003 - val_loss: 4.7688\n",
      "Epoch 32/2000\n",
      "73/73 [==============================] - 6s 78ms/step - loss: 4.4333 - val_loss: 4.7620\n",
      "Epoch 33/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 4.2963 - val_loss: 4.5846\n",
      "Epoch 34/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 4.2873 - val_loss: 4.5221\n",
      "Epoch 35/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 4.1759 - val_loss: 4.3601\n",
      "Epoch 36/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 4.1574 - val_loss: 4.6653\n",
      "Epoch 37/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 4.3289 - val_loss: 4.4044\n",
      "Epoch 38/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 4.1237 - val_loss: 4.6948\n",
      "Epoch 39/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 4.0915 - val_loss: 4.2109\n",
      "Epoch 40/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 4.4030 - val_loss: 4.3933\n",
      "Epoch 41/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 4.0350 - val_loss: 4.5987\n",
      "Epoch 42/2000\n",
      "73/73 [==============================] - 6s 79ms/step - loss: 4.0277 - val_loss: 4.3806\n",
      "Epoch 43/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 3.9361 - val_loss: 4.0745\n",
      "Epoch 44/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 3.9860 - val_loss: 4.2919\n",
      "Epoch 45/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 4.0564 - val_loss: 4.3017\n",
      "Epoch 46/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 4.0644 - val_loss: 4.4353\n",
      "Epoch 47/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 4.1331 - val_loss: 4.2153\n",
      "Epoch 48/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 3.9898 - val_loss: 4.6020\n",
      "Epoch 49/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 3.8823 - val_loss: 3.8915\n",
      "Epoch 50/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 3.7829 - val_loss: 3.8718\n",
      "Epoch 51/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 3.7722 - val_loss: 4.1842\n",
      "Epoch 52/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 3.8901 - val_loss: 4.0943\n",
      "Epoch 53/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 3.8866 - val_loss: 3.9285\n",
      "Epoch 54/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 3.7406 - val_loss: 3.8968\n",
      "Epoch 55/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 3.6333 - val_loss: 4.4160\n",
      "Epoch 56/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 3.7637 - val_loss: 4.0471\n",
      "Epoch 57/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 3.6369 - val_loss: 3.8645\n",
      "Epoch 58/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 3.6128 - val_loss: 3.9261\n",
      "Epoch 59/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 3.6389 - val_loss: 4.2611\n",
      "Epoch 60/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 3.6030 - val_loss: 3.6644\n",
      "Epoch 61/2000\n",
      "73/73 [==============================] - 6s 81ms/step - loss: 3.5149 - val_loss: 3.9430\n",
      "Epoch 62/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 3.5583 - val_loss: 3.6103\n",
      "Epoch 63/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 3.5555 - val_loss: 3.8994\n",
      "Epoch 64/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 3.5948 - val_loss: 3.6660\n",
      "Epoch 65/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 3.5230 - val_loss: 3.9193\n",
      "Epoch 66/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 3.5826 - val_loss: 3.7484\n",
      "Epoch 67/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 3.5450 - val_loss: 3.8033\n",
      "Epoch 68/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 3.5277 - val_loss: 3.6022\n",
      "Epoch 69/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 3.4429 - val_loss: 3.6089\n",
      "Epoch 70/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 3.4308 - val_loss: 3.7077\n",
      "Epoch 71/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 3.4854 - val_loss: 3.5051\n",
      "Epoch 72/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 3.4097 - val_loss: 4.1437\n",
      "Epoch 73/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 3.3966 - val_loss: 3.6178\n",
      "Epoch 74/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 3.3956 - val_loss: 3.6270\n",
      "Epoch 75/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 3.4757 - val_loss: 3.8763\n",
      "Epoch 76/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 3.3681 - val_loss: 3.6395\n",
      "Epoch 77/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 3.4268 - val_loss: 3.7413\n",
      "Epoch 78/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 3.3736 - val_loss: 3.7709\n",
      "Epoch 79/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 3.3383 - val_loss: 3.5565\n",
      "Epoch 80/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 3.3047 - val_loss: 3.5637\n",
      "Epoch 81/2000\n",
      "73/73 [==============================] - 6s 79ms/step - loss: 3.4410 - val_loss: 3.3930\n",
      "Epoch 82/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 3.3453 - val_loss: 3.6882\n",
      "Epoch 83/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 3.2371 - val_loss: 3.5519\n",
      "Epoch 84/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 3.2962 - val_loss: 3.5003\n",
      "Epoch 85/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 3.3041 - val_loss: 3.7340\n",
      "Epoch 86/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 3.2885 - val_loss: 3.4753\n",
      "Epoch 87/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 3.2605 - val_loss: 3.4584\n",
      "Epoch 88/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 3.2578 - val_loss: 3.7648\n",
      "Epoch 89/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 3.3876 - val_loss: 4.0162\n",
      "Epoch 90/2000\n",
      "73/73 [==============================] - 6s 78ms/step - loss: 3.3084 - val_loss: 3.3913\n",
      "Epoch 91/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.2067 - val_loss: 3.4584\n",
      "Epoch 92/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 3.1668 - val_loss: 3.5575\n",
      "Epoch 93/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 3.1437 - val_loss: 3.5166\n",
      "Epoch 94/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 3.2729 - val_loss: 3.7238\n",
      "Epoch 95/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 3.2868 - val_loss: 3.3937\n",
      "Epoch 96/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 3.2123 - val_loss: 3.3487\n",
      "Epoch 97/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 3.1586 - val_loss: 3.5554\n",
      "Epoch 98/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 3.2952 - val_loss: 4.4277\n",
      "Epoch 99/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 3.4445 - val_loss: 3.6490\n",
      "Epoch 100/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 3.3790 - val_loss: 3.6850\n",
      "Epoch 101/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 3.3396 - val_loss: 4.0101\n",
      "Epoch 102/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 3.1250 - val_loss: 3.6042\n",
      "Epoch 103/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 3.1061 - val_loss: 3.3317\n",
      "Epoch 104/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 3.1463 - val_loss: 3.3423\n",
      "Epoch 105/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 3.1345 - val_loss: 3.3474\n",
      "Epoch 106/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 3.0806 - val_loss: 3.5207\n",
      "Epoch 107/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 3.1179 - val_loss: 3.3453\n",
      "Epoch 108/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 3.1677 - val_loss: 4.6290\n",
      "Epoch 109/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 3.4524 - val_loss: 3.4024\n",
      "Epoch 110/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 3.0589 - val_loss: 3.3900\n",
      "Epoch 111/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 3.0495 - val_loss: 3.5459\n",
      "Epoch 112/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 3.1329 - val_loss: 3.5064\n",
      "Epoch 113/2000\n",
      "73/73 [==============================] - ETA: 0s - loss: 3.1618Restoring model weights from the end of the best epoch: 103.\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 3.1618 - val_loss: 3.3346\n",
      "Epoch 113: early stopping\n",
      "'########################################################Model8\n",
      "Epoch 1/2000\n",
      "73/73 [==============================] - 9s 98ms/step - loss: 54.1893 - val_loss: 13.5345\n",
      "Epoch 2/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 11.6362 - val_loss: 11.8271\n",
      "Epoch 3/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 11.3835 - val_loss: 11.5747\n",
      "Epoch 4/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 11.1039 - val_loss: 11.2373\n",
      "Epoch 5/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 10.7508 - val_loss: 10.5337\n",
      "Epoch 6/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 10.3367 - val_loss: 10.0191\n",
      "Epoch 7/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 9.9134 - val_loss: 9.8179\n",
      "Epoch 8/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 9.5063 - val_loss: 8.8995\n",
      "Epoch 9/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 8.6628 - val_loss: 8.1367\n",
      "Epoch 10/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 8.2145 - val_loss: 7.8316\n",
      "Epoch 11/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 7.9683 - val_loss: 7.7865\n",
      "Epoch 12/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 7.7299 - val_loss: 7.3762\n",
      "Epoch 13/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 7.5675 - val_loss: 7.0765\n",
      "Epoch 14/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 7.3495 - val_loss: 7.4139\n",
      "Epoch 15/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 7.3007 - val_loss: 6.9093\n",
      "Epoch 16/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 7.1204 - val_loss: 6.8559\n",
      "Epoch 17/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 6.9180 - val_loss: 6.9253\n",
      "Epoch 18/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 6.8484 - val_loss: 6.5546\n",
      "Epoch 19/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 6.7412 - val_loss: 6.7117\n",
      "Epoch 20/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 6.6654 - val_loss: 6.1966\n",
      "Epoch 21/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 6.5846 - val_loss: 6.2774\n",
      "Epoch 22/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 6.3576 - val_loss: 6.2265\n",
      "Epoch 23/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 5.9141 - val_loss: 5.9552\n",
      "Epoch 24/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 5.6669 - val_loss: 5.7960\n",
      "Epoch 25/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 5.5195 - val_loss: 5.5496\n",
      "Epoch 26/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 6.0992 - val_loss: 5.7219\n",
      "Epoch 27/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 5.3459 - val_loss: 5.7061\n",
      "Epoch 28/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 5.2763 - val_loss: 5.2719\n",
      "Epoch 29/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 5.1839 - val_loss: 5.2419\n",
      "Epoch 30/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 4.8927 - val_loss: 4.9900\n",
      "Epoch 31/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 4.6920 - val_loss: 4.7223\n",
      "Epoch 32/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 4.5230 - val_loss: 4.7715\n",
      "Epoch 33/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 4.5169 - val_loss: 4.7484\n",
      "Epoch 34/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 4.5554 - val_loss: 5.0334\n",
      "Epoch 35/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 4.4280 - val_loss: 4.8835\n",
      "Epoch 36/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 4.3098 - val_loss: 4.6203\n",
      "Epoch 37/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 4.2124 - val_loss: 4.5240\n",
      "Epoch 38/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 4.3627 - val_loss: 4.6556\n",
      "Epoch 39/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 4.2932 - val_loss: 4.5021\n",
      "Epoch 40/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 4.0750 - val_loss: 4.2016\n",
      "Epoch 41/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 4.0876 - val_loss: 4.5164\n",
      "Epoch 42/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 4.1156 - val_loss: 4.4086\n",
      "Epoch 43/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 4.0523 - val_loss: 4.3501\n",
      "Epoch 44/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 3.9286 - val_loss: 4.3945\n",
      "Epoch 45/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 3.9565 - val_loss: 4.1923\n",
      "Epoch 46/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.9261 - val_loss: 4.2297\n",
      "Epoch 47/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.8184 - val_loss: 4.6428\n",
      "Epoch 48/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.9824 - val_loss: 4.1944\n",
      "Epoch 49/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.8435 - val_loss: 4.2218\n",
      "Epoch 50/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.7191 - val_loss: 4.0681\n",
      "Epoch 51/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.6328 - val_loss: 3.8996\n",
      "Epoch 52/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 3.6554 - val_loss: 3.9614\n",
      "Epoch 53/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 3.6377 - val_loss: 4.0361\n",
      "Epoch 54/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.6433 - val_loss: 3.9813\n",
      "Epoch 55/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.6458 - val_loss: 4.1127\n",
      "Epoch 56/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.6345 - val_loss: 3.9859\n",
      "Epoch 57/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.5301 - val_loss: 4.2269\n",
      "Epoch 58/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 4.0210 - val_loss: 3.9620\n",
      "Epoch 59/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.6700 - val_loss: 3.8965\n",
      "Epoch 60/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.4884 - val_loss: 3.7965\n",
      "Epoch 61/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.4769 - val_loss: 3.6517\n",
      "Epoch 62/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.4630 - val_loss: 3.6715\n",
      "Epoch 63/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 3.4607 - val_loss: 3.7868\n",
      "Epoch 64/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 3.4840 - val_loss: 3.7851\n",
      "Epoch 65/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.5902 - val_loss: 3.4675\n",
      "Epoch 66/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.4124 - val_loss: 3.5843\n",
      "Epoch 67/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.3928 - val_loss: 3.9648\n",
      "Epoch 68/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.3806 - val_loss: 3.6420\n",
      "Epoch 69/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.3855 - val_loss: 3.5402\n",
      "Epoch 70/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.2752 - val_loss: 3.4325\n",
      "Epoch 71/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 3.3154 - val_loss: 3.6092\n",
      "Epoch 72/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.3542 - val_loss: 3.6552\n",
      "Epoch 73/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.4315 - val_loss: 3.4026\n",
      "Epoch 74/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.3486 - val_loss: 3.5513\n",
      "Epoch 75/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.4174 - val_loss: 3.5673\n",
      "Epoch 76/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.2663 - val_loss: 3.5864\n",
      "Epoch 77/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 3.3185 - val_loss: 3.6439\n",
      "Epoch 78/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.2286 - val_loss: 3.4474\n",
      "Epoch 79/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.2369 - val_loss: 3.2976\n",
      "Epoch 80/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.2742 - val_loss: 3.5734\n",
      "Epoch 81/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.2504 - val_loss: 3.3810\n",
      "Epoch 82/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 3.2836 - val_loss: 3.4733\n",
      "Epoch 83/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 3.1358 - val_loss: 3.6516\n",
      "Epoch 84/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.3026 - val_loss: 3.4239\n",
      "Epoch 85/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.3049 - val_loss: 3.4607\n",
      "Epoch 86/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.1589 - val_loss: 3.5864\n",
      "Epoch 87/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.2489 - val_loss: 3.4904\n",
      "Epoch 88/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.1818 - val_loss: 3.4966\n",
      "Epoch 89/2000\n",
      "73/73 [==============================] - ETA: 0s - loss: 3.1520Restoring model weights from the end of the best epoch: 79.\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.1520 - val_loss: 3.3227\n",
      "Epoch 89: early stopping\n",
      "'########################################################Model9\n",
      "Epoch 1/2000\n",
      "73/73 [==============================] - 8s 87ms/step - loss: 200.0000 - val_loss: 200.0000\n",
      "Epoch 2/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 200.0000 - val_loss: 200.0000\n",
      "Epoch 3/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 200.0000 - val_loss: 200.0000\n",
      "Epoch 4/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 200.0000 - val_loss: 200.0000\n",
      "Epoch 5/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 200.0000 - val_loss: 200.0000\n",
      "Epoch 6/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 200.0000 - val_loss: 200.0000\n",
      "Epoch 7/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 200.0000 - val_loss: 200.0000\n",
      "Epoch 8/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 200.0000 - val_loss: 200.0000\n",
      "Epoch 9/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 200.0000 - val_loss: 200.0000\n",
      "Epoch 10/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 200.0000 - val_loss: 200.0000\n",
      "Epoch 11/2000\n",
      "73/73 [==============================] - ETA: 0s - loss: 200.0000Restoring model weights from the end of the best epoch: 1.\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 200.0000 - val_loss: 200.0000\n",
      "Epoch 11: early stopping\n",
      "'########################################################Model0\n",
      "Epoch 1/2000\n",
      "73/73 [==============================] - 8s 91ms/step - loss: 97.3496 - val_loss: 27.9080\n",
      "Epoch 2/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 13.9786 - val_loss: 11.8867\n",
      "Epoch 3/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 11.5930 - val_loss: 11.8219\n",
      "Epoch 4/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 11.4891 - val_loss: 11.6160\n",
      "Epoch 5/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 11.3341 - val_loss: 11.4345\n",
      "Epoch 6/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 11.0655 - val_loss: 10.9698\n",
      "Epoch 7/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 10.8003 - val_loss: 10.7144\n",
      "Epoch 8/2000\n",
      "73/73 [==============================] - 6s 82ms/step - loss: 10.5478 - val_loss: 10.4514\n",
      "Epoch 9/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 10.4171 - val_loss: 10.2223\n",
      "Epoch 10/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 10.1934 - val_loss: 10.1446\n",
      "Epoch 11/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 10.0395 - val_loss: 9.7194\n",
      "Epoch 12/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 9.6355 - val_loss: 9.2805\n",
      "Epoch 13/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 9.3103 - val_loss: 8.7977\n",
      "Epoch 14/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 8.6366 - val_loss: 8.4850\n",
      "Epoch 15/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 8.3232 - val_loss: 8.3402\n",
      "Epoch 16/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 8.0738 - val_loss: 7.9167\n",
      "Epoch 17/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 8.0425 - val_loss: 8.0070\n",
      "Epoch 18/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 7.8807 - val_loss: 7.5948\n",
      "Epoch 19/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 7.7017 - val_loss: 7.3671\n",
      "Epoch 20/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 7.6331 - val_loss: 7.3773\n",
      "Epoch 21/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 7.4509 - val_loss: 7.1380\n",
      "Epoch 22/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 7.3056 - val_loss: 7.4774\n",
      "Epoch 23/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 7.2693 - val_loss: 7.0579\n",
      "Epoch 24/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 7.3697 - val_loss: 7.0305\n",
      "Epoch 25/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 7.2229 - val_loss: 6.8859\n",
      "Epoch 26/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 7.0234 - val_loss: 6.7292\n",
      "Epoch 27/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 6.9209 - val_loss: 6.6289\n",
      "Epoch 28/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 6.7866 - val_loss: 6.4162\n",
      "Epoch 29/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 6.6176 - val_loss: 6.2508\n",
      "Epoch 30/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 6.3728 - val_loss: 6.5353\n",
      "Epoch 31/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 6.4090 - val_loss: 5.9644\n",
      "Epoch 32/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 6.0374 - val_loss: 6.0445\n",
      "Epoch 33/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 5.7812 - val_loss: 5.6181\n",
      "Epoch 34/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 5.8536 - val_loss: 5.8321\n",
      "Epoch 35/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 5.6360 - val_loss: 5.8632\n",
      "Epoch 36/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 5.3276 - val_loss: 5.4341\n",
      "Epoch 37/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 5.0046 - val_loss: 4.9412\n",
      "Epoch 38/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 4.9082 - val_loss: 5.1032\n",
      "Epoch 39/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 4.9577 - val_loss: 4.6658\n",
      "Epoch 40/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 4.7572 - val_loss: 4.8965\n",
      "Epoch 41/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 4.6312 - val_loss: 4.5592\n",
      "Epoch 42/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 4.4591 - val_loss: 4.5759\n",
      "Epoch 43/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 4.3144 - val_loss: 4.4403\n",
      "Epoch 44/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 4.3029 - val_loss: 4.0687\n",
      "Epoch 45/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 4.0719 - val_loss: 3.9733\n",
      "Epoch 46/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 3.9402 - val_loss: 4.0547\n",
      "Epoch 47/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 4.1950 - val_loss: 4.2535\n",
      "Epoch 48/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 3.9590 - val_loss: 4.1077\n",
      "Epoch 49/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.9000 - val_loss: 3.8971\n",
      "Epoch 50/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 3.9267 - val_loss: 4.3347\n",
      "Epoch 51/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 3.8269 - val_loss: 4.1559\n",
      "Epoch 52/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 3.7342 - val_loss: 3.5756\n",
      "Epoch 53/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.7395 - val_loss: 3.7125\n",
      "Epoch 54/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 3.7140 - val_loss: 3.9177\n",
      "Epoch 55/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.5406 - val_loss: 3.7557\n",
      "Epoch 56/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.5733 - val_loss: 3.8163\n",
      "Epoch 57/2000\n",
      "73/73 [==============================] - 6s 82ms/step - loss: 3.5810 - val_loss: 3.6262\n",
      "Epoch 58/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.5721 - val_loss: 3.6223\n",
      "Epoch 59/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.5225 - val_loss: 3.5511\n",
      "Epoch 60/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.4773 - val_loss: 3.4433\n",
      "Epoch 61/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.4707 - val_loss: 3.4587\n",
      "Epoch 62/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.4216 - val_loss: 3.5734\n",
      "Epoch 63/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.5067 - val_loss: 3.6136\n",
      "Epoch 64/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.4517 - val_loss: 4.0000\n",
      "Epoch 65/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 3.4838 - val_loss: 3.4929\n",
      "Epoch 66/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 3.3640 - val_loss: 3.4709\n",
      "Epoch 67/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.3683 - val_loss: 3.5323\n",
      "Epoch 68/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.5058 - val_loss: 3.3836\n",
      "Epoch 69/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 3.4109 - val_loss: 3.5311\n",
      "Epoch 70/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 3.3762 - val_loss: 3.5208\n",
      "Epoch 71/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.3691 - val_loss: 3.4903\n",
      "Epoch 72/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.4216 - val_loss: 3.4675\n",
      "Epoch 73/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.3662 - val_loss: 3.4521\n",
      "Epoch 74/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.2927 - val_loss: 3.4176\n",
      "Epoch 75/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.2501 - val_loss: 3.4135\n",
      "Epoch 76/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 3.2314 - val_loss: 3.6391\n",
      "Epoch 77/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.3156 - val_loss: 3.5446\n",
      "Epoch 78/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.2169 - val_loss: 3.3636\n",
      "Epoch 79/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.2563 - val_loss: 3.2589\n",
      "Epoch 80/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.2647 - val_loss: 3.6115\n",
      "Epoch 81/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.3265 - val_loss: 3.6719\n",
      "Epoch 82/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.2084 - val_loss: 3.3157\n",
      "Epoch 83/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.2303 - val_loss: 3.2248\n",
      "Epoch 84/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 3.1743 - val_loss: 3.3811\n",
      "Epoch 85/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.2397 - val_loss: 3.5341\n",
      "Epoch 86/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.3444 - val_loss: 3.3604\n",
      "Epoch 87/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.1593 - val_loss: 3.2826\n",
      "Epoch 88/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 3.2163 - val_loss: 3.2255\n",
      "Epoch 89/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.2221 - val_loss: 3.3453\n",
      "Epoch 90/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.2140 - val_loss: 3.2926\n",
      "Epoch 91/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.0955 - val_loss: 3.2468\n",
      "Epoch 92/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.1678 - val_loss: 3.1956\n",
      "Epoch 93/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.1552 - val_loss: 3.2366\n",
      "Epoch 94/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 3.1322 - val_loss: 3.3622\n",
      "Epoch 95/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 3.1350 - val_loss: 3.3752\n",
      "Epoch 96/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.1761 - val_loss: 3.4352\n",
      "Epoch 97/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.1534 - val_loss: 3.2501\n",
      "Epoch 98/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.0993 - val_loss: 3.3484\n",
      "Epoch 99/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.1675 - val_loss: 3.4579\n",
      "Epoch 100/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.0998 - val_loss: 3.1946\n",
      "Epoch 101/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.0827 - val_loss: 3.2920\n",
      "Epoch 102/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.0430 - val_loss: 3.3596\n",
      "Epoch 103/2000\n",
      "73/73 [==============================] - 6s 82ms/step - loss: 3.0481 - val_loss: 3.0523\n",
      "Epoch 104/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.0582 - val_loss: 3.2805\n",
      "Epoch 105/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.1429 - val_loss: 3.3058\n",
      "Epoch 106/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 3.1035 - val_loss: 3.4941\n",
      "Epoch 107/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 2.9870 - val_loss: 3.0716\n",
      "Epoch 108/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.0630 - val_loss: 3.0593\n",
      "Epoch 109/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.0125 - val_loss: 3.1757\n",
      "Epoch 110/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.0631 - val_loss: 3.3148\n",
      "Epoch 111/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.0219 - val_loss: 3.0573\n",
      "Epoch 112/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 2.9603 - val_loss: 3.2480\n",
      "Epoch 113/2000\n",
      "73/73 [==============================] - ETA: 0s - loss: 3.0350Restoring model weights from the end of the best epoch: 103.\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 3.0350 - val_loss: 3.5320\n",
      "Epoch 113: early stopping\n",
      "'########################################################Model1\n",
      "Epoch 1/2000\n",
      "73/73 [==============================] - 9s 100ms/step - loss: 92.3026 - val_loss: 30.2814\n",
      "Epoch 2/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 15.0539 - val_loss: 12.0149\n",
      "Epoch 3/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 11.7202 - val_loss: 11.9786\n",
      "Epoch 4/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 11.6227 - val_loss: 11.8476\n",
      "Epoch 5/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 11.4860 - val_loss: 11.6449\n",
      "Epoch 6/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 11.2713 - val_loss: 11.3584\n",
      "Epoch 7/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 11.0751 - val_loss: 10.9994\n",
      "Epoch 8/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 10.7360 - val_loss: 10.5729\n",
      "Epoch 9/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 10.4932 - val_loss: 10.3199\n",
      "Epoch 10/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 10.2264 - val_loss: 10.0395\n",
      "Epoch 11/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 10.0056 - val_loss: 9.7552\n",
      "Epoch 12/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 9.5901 - val_loss: 9.7358\n",
      "Epoch 13/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 9.0597 - val_loss: 8.4656\n",
      "Epoch 14/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 8.3505 - val_loss: 8.1627\n",
      "Epoch 15/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 8.0016 - val_loss: 7.7763\n",
      "Epoch 16/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 7.8642 - val_loss: 8.7181\n",
      "Epoch 17/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 7.9451 - val_loss: 7.3407\n",
      "Epoch 18/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 7.5011 - val_loss: 7.3075\n",
      "Epoch 19/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 7.4129 - val_loss: 7.1891\n",
      "Epoch 20/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 7.3081 - val_loss: 7.0843\n",
      "Epoch 21/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 7.2600 - val_loss: 6.9496\n",
      "Epoch 22/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 7.1401 - val_loss: 7.0878\n",
      "Epoch 23/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 7.0338 - val_loss: 6.9823\n",
      "Epoch 24/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 7.0897 - val_loss: 6.8149\n",
      "Epoch 25/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 7.0759 - val_loss: 6.7105\n",
      "Epoch 26/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 6.9029 - val_loss: 6.6960\n",
      "Epoch 27/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 6.8185 - val_loss: 6.4861\n",
      "Epoch 28/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 6.9405 - val_loss: 6.8491\n",
      "Epoch 29/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 6.6194 - val_loss: 6.4340\n",
      "Epoch 30/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 6.5015 - val_loss: 6.4519\n",
      "Epoch 31/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 6.3970 - val_loss: 6.1245\n",
      "Epoch 32/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 6.2957 - val_loss: 6.0721\n",
      "Epoch 33/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 6.0207 - val_loss: 5.8030\n",
      "Epoch 34/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 5.9417 - val_loss: 5.9061\n",
      "Epoch 35/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 5.6513 - val_loss: 5.6278\n",
      "Epoch 36/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 5.4546 - val_loss: 5.3742\n",
      "Epoch 37/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 5.4214 - val_loss: 5.3742\n",
      "Epoch 38/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 4.9399 - val_loss: 5.1806\n",
      "Epoch 39/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 4.9662 - val_loss: 6.0445\n",
      "Epoch 40/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 5.0204 - val_loss: 5.1066\n",
      "Epoch 41/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 4.6349 - val_loss: 5.1027\n",
      "Epoch 42/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 4.6504 - val_loss: 5.2778\n",
      "Epoch 43/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 4.7830 - val_loss: 5.1891\n",
      "Epoch 44/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 4.5212 - val_loss: 5.2807\n",
      "Epoch 45/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 4.4616 - val_loss: 5.0253\n",
      "Epoch 46/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 4.3826 - val_loss: 4.9669\n",
      "Epoch 47/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 4.2626 - val_loss: 4.5581\n",
      "Epoch 48/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 4.2013 - val_loss: 4.6418\n",
      "Epoch 49/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 4.1638 - val_loss: 4.3981\n",
      "Epoch 50/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 4.1565 - val_loss: 4.7654\n",
      "Epoch 51/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 4.2142 - val_loss: 4.5315\n",
      "Epoch 52/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 4.1442 - val_loss: 4.2785\n",
      "Epoch 53/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 4.0892 - val_loss: 4.4719\n",
      "Epoch 54/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 4.3583 - val_loss: 4.5558\n",
      "Epoch 55/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 3.9861 - val_loss: 4.4212\n",
      "Epoch 56/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 3.9611 - val_loss: 4.0624\n",
      "Epoch 57/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 3.9023 - val_loss: 4.5608\n",
      "Epoch 58/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 3.9210 - val_loss: 4.2723\n",
      "Epoch 59/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 3.9551 - val_loss: 4.6232\n",
      "Epoch 60/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 4.0070 - val_loss: 4.3356\n",
      "Epoch 61/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 3.8239 - val_loss: 4.2155\n",
      "Epoch 62/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 3.8453 - val_loss: 4.7843\n",
      "Epoch 63/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.7719 - val_loss: 4.3461\n",
      "Epoch 64/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.6939 - val_loss: 4.1140\n",
      "Epoch 65/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.7391 - val_loss: 4.0949\n",
      "Epoch 66/2000\n",
      "73/73 [==============================] - ETA: 0s - loss: 3.7546Restoring model weights from the end of the best epoch: 56.\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 3.7546 - val_loss: 4.4393\n",
      "Epoch 66: early stopping\n",
      "'########################################################Model2\n",
      "Epoch 1/2000\n",
      "73/73 [==============================] - 8s 97ms/step - loss: 200.0000 - val_loss: 200.0000\n",
      "Epoch 2/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 161.3369 - val_loss: 40.9917\n",
      "Epoch 3/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 14.9373 - val_loss: 11.8678\n",
      "Epoch 4/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 11.5512 - val_loss: 11.7606\n",
      "Epoch 5/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 11.4202 - val_loss: 11.6238\n",
      "Epoch 6/2000\n",
      "73/73 [==============================] - 6s 82ms/step - loss: 11.2444 - val_loss: 11.2798\n",
      "Epoch 7/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 10.9271 - val_loss: 10.8614\n",
      "Epoch 8/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 10.5973 - val_loss: 10.3934\n",
      "Epoch 9/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 10.1759 - val_loss: 10.1227\n",
      "Epoch 10/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 9.9504 - val_loss: 9.7306\n",
      "Epoch 11/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 9.6215 - val_loss: 9.2874\n",
      "Epoch 12/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 9.1851 - val_loss: 8.8232\n",
      "Epoch 13/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 8.6486 - val_loss: 8.1889\n",
      "Epoch 14/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 8.1986 - val_loss: 7.9366\n",
      "Epoch 15/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 8.0638 - val_loss: 7.4817\n",
      "Epoch 16/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 7.6853 - val_loss: 7.3657\n",
      "Epoch 17/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 7.6290 - val_loss: 7.3146\n",
      "Epoch 18/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 7.5212 - val_loss: 7.1007\n",
      "Epoch 19/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 7.3474 - val_loss: 6.9902\n",
      "Epoch 20/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 7.2264 - val_loss: 6.9967\n",
      "Epoch 21/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 7.1576 - val_loss: 6.9602\n",
      "Epoch 22/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 7.1701 - val_loss: 6.9284\n",
      "Epoch 23/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 7.0522 - val_loss: 6.9987\n",
      "Epoch 24/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 7.1301 - val_loss: 6.7273\n",
      "Epoch 25/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 6.9954 - val_loss: 6.6764\n",
      "Epoch 26/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 6.8977 - val_loss: 6.5821\n",
      "Epoch 27/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 6.7292 - val_loss: 6.3847\n",
      "Epoch 28/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 6.6244 - val_loss: 6.5378\n",
      "Epoch 29/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 6.5759 - val_loss: 6.1532\n",
      "Epoch 30/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 6.4001 - val_loss: 6.1608\n",
      "Epoch 31/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 6.2463 - val_loss: 6.3471\n",
      "Epoch 32/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 6.2583 - val_loss: 5.9216\n",
      "Epoch 33/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 6.1063 - val_loss: 6.3719\n",
      "Epoch 34/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 6.0812 - val_loss: 5.6498\n",
      "Epoch 35/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 5.7258 - val_loss: 5.5496\n",
      "Epoch 36/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 5.5126 - val_loss: 5.5980\n",
      "Epoch 37/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 5.4553 - val_loss: 5.2100\n",
      "Epoch 38/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 5.4182 - val_loss: 5.1057\n",
      "Epoch 39/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 5.4166 - val_loss: 5.1639\n",
      "Epoch 40/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 5.2274 - val_loss: 5.4146\n",
      "Epoch 41/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 5.1046 - val_loss: 4.9061\n",
      "Epoch 42/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 5.0741 - val_loss: 4.8612\n",
      "Epoch 43/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 4.9077 - val_loss: 5.2312\n",
      "Epoch 44/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 5.5385 - val_loss: 4.5072\n",
      "Epoch 45/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 4.8009 - val_loss: 4.3386\n",
      "Epoch 46/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 4.4895 - val_loss: 4.7670\n",
      "Epoch 47/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 4.5792 - val_loss: 4.5860\n",
      "Epoch 48/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 4.3056 - val_loss: 4.0797\n",
      "Epoch 49/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 4.0940 - val_loss: 4.1372\n",
      "Epoch 50/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.9080 - val_loss: 4.3869\n",
      "Epoch 51/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.9725 - val_loss: 4.0747\n",
      "Epoch 52/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 3.8888 - val_loss: 4.0541\n",
      "Epoch 53/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 3.8481 - val_loss: 4.1676\n",
      "Epoch 54/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.8182 - val_loss: 3.7402\n",
      "Epoch 55/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.7151 - val_loss: 3.9682\n",
      "Epoch 56/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.8913 - val_loss: 3.7394\n",
      "Epoch 57/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.5833 - val_loss: 3.7439\n",
      "Epoch 58/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.6900 - val_loss: 3.9937\n",
      "Epoch 59/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.4876 - val_loss: 3.7047\n",
      "Epoch 60/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.6741 - val_loss: 3.8278\n",
      "Epoch 61/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.6564 - val_loss: 3.6246\n",
      "Epoch 62/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 3.5377 - val_loss: 3.6174\n",
      "Epoch 63/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.6055 - val_loss: 3.6830\n",
      "Epoch 64/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.4261 - val_loss: 3.5513\n",
      "Epoch 65/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.4288 - val_loss: 3.8174\n",
      "Epoch 66/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.3134 - val_loss: 3.6323\n",
      "Epoch 67/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.4805 - val_loss: 3.6081\n",
      "Epoch 68/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.3858 - val_loss: 3.8117\n",
      "Epoch 69/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.4321 - val_loss: 3.7402\n",
      "Epoch 70/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.3166 - val_loss: 3.5015\n",
      "Epoch 71/2000\n",
      "73/73 [==============================] - 6s 80ms/step - loss: 3.4594 - val_loss: 3.8279\n",
      "Epoch 72/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.3595 - val_loss: 3.5466\n",
      "Epoch 73/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.2698 - val_loss: 3.8168\n",
      "Epoch 74/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.2924 - val_loss: 3.5305\n",
      "Epoch 75/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.3303 - val_loss: 3.6876\n",
      "Epoch 76/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.2816 - val_loss: 3.5893\n",
      "Epoch 77/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.3426 - val_loss: 3.2931\n",
      "Epoch 78/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.2300 - val_loss: 3.4773\n",
      "Epoch 79/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.2646 - val_loss: 3.8790\n",
      "Epoch 80/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.2282 - val_loss: 4.1112\n",
      "Epoch 81/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 3.2702 - val_loss: 3.3548\n",
      "Epoch 82/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.1808 - val_loss: 3.4565\n",
      "Epoch 83/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.3348 - val_loss: 3.5380\n",
      "Epoch 84/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.2441 - val_loss: 3.3542\n",
      "Epoch 85/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.1371 - val_loss: 3.5100\n",
      "Epoch 86/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.0956 - val_loss: 3.4875\n",
      "Epoch 87/2000\n",
      "73/73 [==============================] - ETA: 0s - loss: 3.1425Restoring model weights from the end of the best epoch: 77.\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.1425 - val_loss: 3.6840\n",
      "Epoch 87: early stopping\n",
      "'########################################################Model3\n",
      "Epoch 1/2000\n",
      "73/73 [==============================] - 8s 97ms/step - loss: 200.0000 - val_loss: 200.0000\n",
      "Epoch 2/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 200.0000 - val_loss: 200.0000\n",
      "Epoch 3/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 200.0000 - val_loss: 200.0000\n",
      "Epoch 4/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 200.0000 - val_loss: 200.0000\n",
      "Epoch 5/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 200.0000 - val_loss: 200.0000\n",
      "Epoch 6/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 200.0000 - val_loss: 200.0000\n",
      "Epoch 7/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 200.0000 - val_loss: 200.0000\n",
      "Epoch 8/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 200.0000 - val_loss: 200.0000\n",
      "Epoch 9/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 200.0000 - val_loss: 200.0000\n",
      "Epoch 10/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 200.0000 - val_loss: 200.0000\n",
      "Epoch 11/2000\n",
      "73/73 [==============================] - ETA: 0s - loss: 200.0000Restoring model weights from the end of the best epoch: 1.\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 200.0000 - val_loss: 200.0000\n",
      "Epoch 11: early stopping\n",
      "'########################################################Model4\n",
      "Epoch 1/2000\n",
      "73/73 [==============================] - 8s 89ms/step - loss: 200.0000 - val_loss: 200.0000\n",
      "Epoch 2/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 200.0000 - val_loss: 200.0000\n",
      "Epoch 3/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 200.0000 - val_loss: 200.0000\n",
      "Epoch 4/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 200.0000 - val_loss: 200.0000\n",
      "Epoch 5/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 200.0000 - val_loss: 200.0000\n",
      "Epoch 6/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 200.0000 - val_loss: 200.0000\n",
      "Epoch 7/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 200.0000 - val_loss: 200.0000\n",
      "Epoch 8/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 200.0000 - val_loss: 200.0000\n",
      "Epoch 9/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 200.0000 - val_loss: 200.0000\n",
      "Epoch 10/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 200.0000 - val_loss: 200.0000\n",
      "Epoch 11/2000\n",
      "73/73 [==============================] - ETA: 0s - loss: 200.0000Restoring model weights from the end of the best epoch: 1.\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 200.0000 - val_loss: 200.0000\n",
      "Epoch 11: early stopping\n",
      "'########################################################Model5\n",
      "Epoch 1/2000\n",
      "73/73 [==============================] - 8s 98ms/step - loss: 80.3797 - val_loss: 20.6961\n",
      "Epoch 2/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 12.7490 - val_loss: 11.9315\n",
      "Epoch 3/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 11.6336 - val_loss: 11.8654\n",
      "Epoch 4/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 11.4887 - val_loss: 11.6764\n",
      "Epoch 5/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 11.2834 - val_loss: 11.3354\n",
      "Epoch 6/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 11.0340 - val_loss: 11.0221\n",
      "Epoch 7/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 10.7161 - val_loss: 10.6116\n",
      "Epoch 8/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 10.5837 - val_loss: 10.4021\n",
      "Epoch 9/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 10.2872 - val_loss: 10.1468\n",
      "Epoch 10/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 9.9503 - val_loss: 9.6566\n",
      "Epoch 11/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 9.5388 - val_loss: 9.3602\n",
      "Epoch 12/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 9.1020 - val_loss: 8.6273\n",
      "Epoch 13/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 8.6264 - val_loss: 7.9959\n",
      "Epoch 14/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 8.2201 - val_loss: 7.7539\n",
      "Epoch 15/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 7.8735 - val_loss: 7.6827\n",
      "Epoch 16/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 7.9130 - val_loss: 7.8249\n",
      "Epoch 17/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 7.6515 - val_loss: 7.3595\n",
      "Epoch 18/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 7.5840 - val_loss: 7.2680\n",
      "Epoch 19/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 7.3739 - val_loss: 7.1294\n",
      "Epoch 20/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 7.2707 - val_loss: 7.0304\n",
      "Epoch 21/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 7.2135 - val_loss: 6.8960\n",
      "Epoch 22/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 6.9646 - val_loss: 7.1544\n",
      "Epoch 23/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 6.7114 - val_loss: 6.8714\n",
      "Epoch 24/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 6.6600 - val_loss: 6.2255\n",
      "Epoch 25/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 6.3421 - val_loss: 6.2626\n",
      "Epoch 26/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 6.4676 - val_loss: 6.0210\n",
      "Epoch 27/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 6.0663 - val_loss: 6.2815\n",
      "Epoch 28/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 6.1756 - val_loss: 5.5517\n",
      "Epoch 29/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 5.9340 - val_loss: 5.8978\n",
      "Epoch 30/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 5.7614 - val_loss: 5.8808\n",
      "Epoch 31/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 5.7653 - val_loss: 5.1533\n",
      "Epoch 32/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 5.4713 - val_loss: 5.8472\n",
      "Epoch 33/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 5.7469 - val_loss: 5.2340\n",
      "Epoch 34/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 5.2925 - val_loss: 4.6934\n",
      "Epoch 35/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 4.7709 - val_loss: 4.6354\n",
      "Epoch 36/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 4.5509 - val_loss: 4.9073\n",
      "Epoch 37/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 4.4620 - val_loss: 4.4759\n",
      "Epoch 38/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 4.4107 - val_loss: 4.4934\n",
      "Epoch 39/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 4.1624 - val_loss: 4.4051\n",
      "Epoch 40/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.8658 - val_loss: 4.5494\n",
      "Epoch 41/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.9385 - val_loss: 4.0167\n",
      "Epoch 42/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.8458 - val_loss: 3.9226\n",
      "Epoch 43/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.9275 - val_loss: 4.1717\n",
      "Epoch 44/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.9860 - val_loss: 4.0856\n",
      "Epoch 45/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 3.9290 - val_loss: 3.8931\n",
      "Epoch 46/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.7312 - val_loss: 3.9412\n",
      "Epoch 47/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.6867 - val_loss: 3.6095\n",
      "Epoch 48/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.6101 - val_loss: 3.8579\n",
      "Epoch 49/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.6409 - val_loss: 3.8185\n",
      "Epoch 50/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.5415 - val_loss: 3.9514\n",
      "Epoch 51/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.5831 - val_loss: 3.6110\n",
      "Epoch 52/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 3.6397 - val_loss: 3.9162\n",
      "Epoch 53/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.4532 - val_loss: 3.4854\n",
      "Epoch 54/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.5590 - val_loss: 4.0364\n",
      "Epoch 55/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.7724 - val_loss: 4.0268\n",
      "Epoch 56/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.5556 - val_loss: 3.5143\n",
      "Epoch 57/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.4120 - val_loss: 3.3777\n",
      "Epoch 58/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.4599 - val_loss: 3.5493\n",
      "Epoch 59/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.5903 - val_loss: 4.0652\n",
      "Epoch 60/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.4076 - val_loss: 3.3689\n",
      "Epoch 61/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.3284 - val_loss: 3.5430\n",
      "Epoch 62/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.3694 - val_loss: 3.5731\n",
      "Epoch 63/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 3.4856 - val_loss: 3.4558\n",
      "Epoch 64/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 3.4751 - val_loss: 3.2854\n",
      "Epoch 65/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.3934 - val_loss: 4.6030\n",
      "Epoch 66/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.3852 - val_loss: 3.3472\n",
      "Epoch 67/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.6134 - val_loss: 3.5503\n",
      "Epoch 68/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.2671 - val_loss: 3.3784\n",
      "Epoch 69/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.2546 - val_loss: 3.2390\n",
      "Epoch 70/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 3.2843 - val_loss: 3.5227\n",
      "Epoch 71/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.2895 - val_loss: 3.4399\n",
      "Epoch 72/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.1859 - val_loss: 3.1702\n",
      "Epoch 73/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.2231 - val_loss: 3.5600\n",
      "Epoch 74/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.3298 - val_loss: 3.2804\n",
      "Epoch 75/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.1684 - val_loss: 3.4434\n",
      "Epoch 76/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.1163 - val_loss: 3.3264\n",
      "Epoch 77/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.1789 - val_loss: 3.1473\n",
      "Epoch 78/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.1635 - val_loss: 3.8325\n",
      "Epoch 79/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.4158 - val_loss: 3.3149\n",
      "Epoch 80/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.3391 - val_loss: 3.3074\n",
      "Epoch 81/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.2433 - val_loss: 3.2416\n",
      "Epoch 82/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 3.0520 - val_loss: 3.2127\n",
      "Epoch 83/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.1187 - val_loss: 3.1803\n",
      "Epoch 84/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.1843 - val_loss: 3.3239\n",
      "Epoch 85/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.1010 - val_loss: 3.3168\n",
      "Epoch 86/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.0713 - val_loss: 3.2170\n",
      "Epoch 87/2000\n",
      "73/73 [==============================] - ETA: 0s - loss: 3.0414Restoring model weights from the end of the best epoch: 77.\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.0414 - val_loss: 3.3119\n",
      "Epoch 87: early stopping\n",
      "'########################################################Model6\n",
      "Epoch 1/2000\n",
      "73/73 [==============================] - 8s 97ms/step - loss: 97.0131 - val_loss: 29.1481\n",
      "Epoch 2/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 14.1992 - val_loss: 11.9625\n",
      "Epoch 3/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 11.6193 - val_loss: 11.8756\n",
      "Epoch 4/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 11.4914 - val_loss: 11.6626\n",
      "Epoch 5/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 11.3003 - val_loss: 11.4356\n",
      "Epoch 6/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 11.0613 - val_loss: 11.0697\n",
      "Epoch 7/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 10.7395 - val_loss: 10.5593\n",
      "Epoch 8/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 10.4228 - val_loss: 10.2895\n",
      "Epoch 9/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 10.2364 - val_loss: 9.9567\n",
      "Epoch 10/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 9.9906 - val_loss: 9.6438\n",
      "Epoch 11/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 9.6116 - val_loss: 9.5328\n",
      "Epoch 12/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 9.1226 - val_loss: 8.7650\n",
      "Epoch 13/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 8.6026 - val_loss: 8.2303\n",
      "Epoch 14/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 8.1381 - val_loss: 7.9187\n",
      "Epoch 15/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 8.0658 - val_loss: 7.7247\n",
      "Epoch 16/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 7.8196 - val_loss: 7.8995\n",
      "Epoch 17/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 7.8989 - val_loss: 7.3322\n",
      "Epoch 18/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 7.5526 - val_loss: 7.1971\n",
      "Epoch 19/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 7.3984 - val_loss: 7.2562\n",
      "Epoch 20/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 7.3043 - val_loss: 7.0233\n",
      "Epoch 21/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 7.1748 - val_loss: 6.9511\n",
      "Epoch 22/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 7.1406 - val_loss: 7.4155\n",
      "Epoch 23/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 6.9102 - val_loss: 6.7841\n",
      "Epoch 24/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 6.7734 - val_loss: 7.5789\n",
      "Epoch 25/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 7.1854 - val_loss: 6.6770\n",
      "Epoch 26/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 6.6393 - val_loss: 6.5710\n",
      "Epoch 27/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 6.5264 - val_loss: 6.4726\n",
      "Epoch 28/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 6.1866 - val_loss: 6.4998\n",
      "Epoch 29/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 6.2108 - val_loss: 5.8643\n",
      "Epoch 30/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 5.8468 - val_loss: 5.8700\n",
      "Epoch 31/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 5.7249 - val_loss: 5.6096\n",
      "Epoch 32/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 5.3035 - val_loss: 5.3775\n",
      "Epoch 33/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 5.2298 - val_loss: 5.2778\n",
      "Epoch 34/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 5.2338 - val_loss: 6.0757\n",
      "Epoch 35/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 5.1597 - val_loss: 5.0311\n",
      "Epoch 36/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 4.8774 - val_loss: 4.9484\n",
      "Epoch 37/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 4.7336 - val_loss: 5.1422\n",
      "Epoch 38/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 4.7295 - val_loss: 5.1348\n",
      "Epoch 39/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 4.5447 - val_loss: 4.7941\n",
      "Epoch 40/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 4.5971 - val_loss: 4.9448\n",
      "Epoch 41/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 4.5671 - val_loss: 4.7224\n",
      "Epoch 42/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 4.3694 - val_loss: 4.4455\n",
      "Epoch 43/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 4.4192 - val_loss: 5.1325\n",
      "Epoch 44/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 4.2999 - val_loss: 4.8910\n",
      "Epoch 45/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 4.3579 - val_loss: 4.4390\n",
      "Epoch 46/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 4.2479 - val_loss: 4.5003\n",
      "Epoch 47/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 4.2458 - val_loss: 4.4604\n",
      "Epoch 48/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 4.1964 - val_loss: 4.5981\n",
      "Epoch 49/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 4.1713 - val_loss: 4.7690\n",
      "Epoch 50/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 4.1009 - val_loss: 4.5824\n",
      "Epoch 51/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 4.0757 - val_loss: 4.6586\n",
      "Epoch 52/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 4.1393 - val_loss: 4.7515\n",
      "Epoch 53/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 4.0346 - val_loss: 4.2526\n",
      "Epoch 54/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 4.1447 - val_loss: 4.3680\n",
      "Epoch 55/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 4.0460 - val_loss: 4.5406\n",
      "Epoch 56/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.9624 - val_loss: 4.1395\n",
      "Epoch 57/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 4.0445 - val_loss: 4.6976\n",
      "Epoch 58/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 4.0508 - val_loss: 4.1995\n",
      "Epoch 59/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.8542 - val_loss: 4.5184\n",
      "Epoch 60/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.8032 - val_loss: 3.9951\n",
      "Epoch 61/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.8269 - val_loss: 4.3297\n",
      "Epoch 62/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 3.7624 - val_loss: 4.0972\n",
      "Epoch 63/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.8574 - val_loss: 4.4702\n",
      "Epoch 64/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.7778 - val_loss: 4.2251\n",
      "Epoch 65/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 3.6622 - val_loss: 4.1791\n",
      "Epoch 66/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 3.7751 - val_loss: 4.0880\n",
      "Epoch 67/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 3.5901 - val_loss: 3.7899\n",
      "Epoch 68/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 3.7404 - val_loss: 3.8872\n",
      "Epoch 69/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 3.7286 - val_loss: 3.8979\n",
      "Epoch 70/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.7507 - val_loss: 4.3603\n",
      "Epoch 71/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.7093 - val_loss: 3.8704\n",
      "Epoch 72/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.6175 - val_loss: 4.2039\n",
      "Epoch 73/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 3.5449 - val_loss: 3.8926\n",
      "Epoch 74/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.6866 - val_loss: 4.2335\n",
      "Epoch 75/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 3.8698 - val_loss: 4.1278\n",
      "Epoch 76/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 3.6037 - val_loss: 3.8642\n",
      "Epoch 77/2000\n",
      "73/73 [==============================] - ETA: 0s - loss: 3.5936Restoring model weights from the end of the best epoch: 67.\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.5936 - val_loss: 3.8307\n",
      "Epoch 77: early stopping\n",
      "'########################################################Model7\n",
      "Epoch 1/2000\n",
      "73/73 [==============================] - 9s 97ms/step - loss: 92.8702 - val_loss: 26.1520\n",
      "Epoch 2/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 13.7727 - val_loss: 11.9667\n",
      "Epoch 3/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 11.6186 - val_loss: 11.8555\n",
      "Epoch 4/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 11.3168 - val_loss: 11.2963\n",
      "Epoch 5/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 10.9988 - val_loss: 10.8382\n",
      "Epoch 6/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 10.9547 - val_loss: 10.9962\n",
      "Epoch 7/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 10.8156 - val_loss: 11.0399\n",
      "Epoch 8/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 10.6440 - val_loss: 10.6033\n",
      "Epoch 9/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 10.4557 - val_loss: 10.3145\n",
      "Epoch 10/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 10.3351 - val_loss: 10.1294\n",
      "Epoch 11/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 10.1412 - val_loss: 9.9906\n",
      "Epoch 12/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 9.9339 - val_loss: 9.6568\n",
      "Epoch 13/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 9.7957 - val_loss: 9.4484\n",
      "Epoch 14/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 9.3542 - val_loss: 9.0585\n",
      "Epoch 15/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 8.9707 - val_loss: 8.6279\n",
      "Epoch 16/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 8.7505 - val_loss: 8.2471\n",
      "Epoch 17/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 8.1953 - val_loss: 7.8735\n",
      "Epoch 18/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 8.0041 - val_loss: 7.6924\n",
      "Epoch 19/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 7.8666 - val_loss: 7.5040\n",
      "Epoch 20/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 7.7918 - val_loss: 8.0168\n",
      "Epoch 21/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 7.5877 - val_loss: 7.2473\n",
      "Epoch 22/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 7.5410 - val_loss: 7.1675\n",
      "Epoch 23/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 7.2655 - val_loss: 7.2581\n",
      "Epoch 24/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 7.1530 - val_loss: 6.8888\n",
      "Epoch 25/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 7.0322 - val_loss: 6.8195\n",
      "Epoch 26/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 6.9378 - val_loss: 6.8498\n",
      "Epoch 27/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 6.8563 - val_loss: 6.6609\n",
      "Epoch 28/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 6.7939 - val_loss: 6.4214\n",
      "Epoch 29/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 6.7344 - val_loss: 6.6040\n",
      "Epoch 30/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 6.6435 - val_loss: 6.3282\n",
      "Epoch 31/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 6.5076 - val_loss: 6.5251\n",
      "Epoch 32/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 6.3940 - val_loss: 6.1882\n",
      "Epoch 33/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 5.9683 - val_loss: 7.5011\n",
      "Epoch 34/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 6.9026 - val_loss: 6.4340\n",
      "Epoch 35/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 6.4392 - val_loss: 6.2545\n",
      "Epoch 36/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 6.0904 - val_loss: 6.0270\n",
      "Epoch 37/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 6.1022 - val_loss: 5.9930\n",
      "Epoch 38/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 5.8777 - val_loss: 5.9959\n",
      "Epoch 39/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 5.7666 - val_loss: 5.7072\n",
      "Epoch 40/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 5.4452 - val_loss: 5.8365\n",
      "Epoch 41/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 5.4078 - val_loss: 5.5248\n",
      "Epoch 42/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 5.4372 - val_loss: 5.6677\n",
      "Epoch 43/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 5.2430 - val_loss: 5.4019\n",
      "Epoch 44/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 5.1122 - val_loss: 5.6709\n",
      "Epoch 45/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 5.2110 - val_loss: 5.1830\n",
      "Epoch 46/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 5.0916 - val_loss: 5.3646\n",
      "Epoch 47/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 4.9801 - val_loss: 5.5267\n",
      "Epoch 48/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 5.0371 - val_loss: 5.0644\n",
      "Epoch 49/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 4.7391 - val_loss: 5.0057\n",
      "Epoch 50/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 4.8082 - val_loss: 5.2981\n",
      "Epoch 51/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 4.8326 - val_loss: 4.7468\n",
      "Epoch 52/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 4.8252 - val_loss: 4.8853\n",
      "Epoch 53/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 4.6575 - val_loss: 5.0507\n",
      "Epoch 54/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 4.8576 - val_loss: 4.6458\n",
      "Epoch 55/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 4.5805 - val_loss: 4.7409\n",
      "Epoch 56/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 4.7114 - val_loss: 4.5830\n",
      "Epoch 57/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 4.5655 - val_loss: 4.6233\n",
      "Epoch 58/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 4.3734 - val_loss: 4.3920\n",
      "Epoch 59/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 4.3102 - val_loss: 4.3736\n",
      "Epoch 60/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 4.4218 - val_loss: 4.5565\n",
      "Epoch 61/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 4.3259 - val_loss: 4.6652\n",
      "Epoch 62/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 4.2823 - val_loss: 4.8956\n",
      "Epoch 63/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 4.1441 - val_loss: 4.6560\n",
      "Epoch 64/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 4.1474 - val_loss: 4.1240\n",
      "Epoch 65/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 4.0117 - val_loss: 4.2548\n",
      "Epoch 66/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 3.9608 - val_loss: 4.0383\n",
      "Epoch 67/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.9543 - val_loss: 4.0395\n",
      "Epoch 68/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 4.0718 - val_loss: 3.9823\n",
      "Epoch 69/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.8973 - val_loss: 4.2908\n",
      "Epoch 70/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.9587 - val_loss: 5.2406\n",
      "Epoch 71/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.9699 - val_loss: 3.8255\n",
      "Epoch 72/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.7886 - val_loss: 3.8638\n",
      "Epoch 73/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.7118 - val_loss: 3.8964\n",
      "Epoch 74/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.6463 - val_loss: 3.7299\n",
      "Epoch 75/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.5808 - val_loss: 4.3644\n",
      "Epoch 76/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.8691 - val_loss: 3.6604\n",
      "Epoch 77/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.5682 - val_loss: 3.8913\n",
      "Epoch 78/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.7144 - val_loss: 3.8801\n",
      "Epoch 79/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.5702 - val_loss: 3.7242\n",
      "Epoch 80/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.5924 - val_loss: 4.1094\n",
      "Epoch 81/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 3.6070 - val_loss: 3.7379\n",
      "Epoch 82/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.5476 - val_loss: 3.7372\n",
      "Epoch 83/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.5959 - val_loss: 3.9999\n",
      "Epoch 84/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 3.5697 - val_loss: 3.8046\n",
      "Epoch 85/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.6155 - val_loss: 3.6705\n",
      "Epoch 86/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.5833 - val_loss: 3.6191\n",
      "Epoch 87/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.4889 - val_loss: 3.9060\n",
      "Epoch 88/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.5521 - val_loss: 4.2958\n",
      "Epoch 89/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.5342 - val_loss: 3.6120\n",
      "Epoch 90/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.4160 - val_loss: 3.4695\n",
      "Epoch 91/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.4108 - val_loss: 3.9159\n",
      "Epoch 92/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.5095 - val_loss: 3.8110\n",
      "Epoch 93/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.4640 - val_loss: 3.4426\n",
      "Epoch 94/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.4818 - val_loss: 3.4367\n",
      "Epoch 95/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.3584 - val_loss: 3.6342\n",
      "Epoch 96/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.3993 - val_loss: 3.4938\n",
      "Epoch 97/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.4020 - val_loss: 3.6455\n",
      "Epoch 98/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.3980 - val_loss: 3.4821\n",
      "Epoch 99/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.4153 - val_loss: 3.5255\n",
      "Epoch 100/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 3.5379 - val_loss: 3.5134\n",
      "Epoch 101/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.3985 - val_loss: 3.6102\n",
      "Epoch 102/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 3.3370 - val_loss: 3.4602\n",
      "Epoch 103/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.2557 - val_loss: 3.5151\n",
      "Epoch 104/2000\n",
      "73/73 [==============================] - ETA: 0s - loss: 3.3596Restoring model weights from the end of the best epoch: 94.\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 3.3596 - val_loss: 4.0821\n",
      "Epoch 104: early stopping\n",
      "'########################################################Model8\n",
      "Epoch 1/2000\n",
      "73/73 [==============================] - 8s 96ms/step - loss: 86.7486 - val_loss: 20.4165\n",
      "Epoch 2/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 12.2607 - val_loss: 11.8212\n",
      "Epoch 3/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 11.5103 - val_loss: 11.6734\n",
      "Epoch 4/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 11.3208 - val_loss: 11.4947\n",
      "Epoch 5/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 11.2553 - val_loss: 11.4285\n",
      "Epoch 6/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 10.9112 - val_loss: 10.9059\n",
      "Epoch 7/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 10.6129 - val_loss: 10.5968\n",
      "Epoch 8/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 10.3994 - val_loss: 10.1409\n",
      "Epoch 9/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 10.0813 - val_loss: 9.7533\n",
      "Epoch 10/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 9.6858 - val_loss: 9.4965\n",
      "Epoch 11/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 9.2694 - val_loss: 9.1596\n",
      "Epoch 12/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 8.7929 - val_loss: 8.5396\n",
      "Epoch 13/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 8.3454 - val_loss: 7.9278\n",
      "Epoch 14/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 8.0040 - val_loss: 7.7719\n",
      "Epoch 15/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 7.7874 - val_loss: 7.4640\n",
      "Epoch 16/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 7.6601 - val_loss: 7.6741\n",
      "Epoch 17/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 7.5436 - val_loss: 7.2972\n",
      "Epoch 18/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 7.4569 - val_loss: 7.0608\n",
      "Epoch 19/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 7.2460 - val_loss: 6.9208\n",
      "Epoch 20/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 7.1137 - val_loss: 6.9465\n",
      "Epoch 21/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 7.0399 - val_loss: 6.8708\n",
      "Epoch 22/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 6.9465 - val_loss: 6.6481\n",
      "Epoch 23/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 6.8287 - val_loss: 6.7256\n",
      "Epoch 24/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 6.8367 - val_loss: 6.4132\n",
      "Epoch 25/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 6.7273 - val_loss: 6.5134\n",
      "Epoch 26/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 6.6819 - val_loss: 6.2883\n",
      "Epoch 27/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 6.5683 - val_loss: 6.3498\n",
      "Epoch 28/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 6.9720 - val_loss: 6.1868\n",
      "Epoch 29/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 6.4686 - val_loss: 6.4146\n",
      "Epoch 30/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 6.5515 - val_loss: 6.3788\n",
      "Epoch 31/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 6.4092 - val_loss: 6.0293\n",
      "Epoch 32/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 6.4247 - val_loss: 6.1359\n",
      "Epoch 33/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 6.3718 - val_loss: 6.0398\n",
      "Epoch 34/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 6.3287 - val_loss: 5.9216\n",
      "Epoch 35/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 6.2692 - val_loss: 6.1390\n",
      "Epoch 36/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 6.2893 - val_loss: 5.8212\n",
      "Epoch 37/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 6.2063 - val_loss: 6.1572\n",
      "Epoch 38/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 6.1669 - val_loss: 5.9775\n",
      "Epoch 39/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 6.0917 - val_loss: 5.6472\n",
      "Epoch 40/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 5.9930 - val_loss: 5.6884\n",
      "Epoch 41/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 5.8479 - val_loss: 6.3471\n",
      "Epoch 42/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 6.0775 - val_loss: 5.7638\n",
      "Epoch 43/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 5.8084 - val_loss: 5.5581\n",
      "Epoch 44/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 5.9974 - val_loss: 5.5414\n",
      "Epoch 45/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 5.8330 - val_loss: 5.5644\n",
      "Epoch 46/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 5.8308 - val_loss: 5.3980\n",
      "Epoch 47/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 5.6007 - val_loss: 5.3949\n",
      "Epoch 48/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 5.6840 - val_loss: 5.4638\n",
      "Epoch 49/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 5.7101 - val_loss: 5.4068\n",
      "Epoch 50/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 5.5035 - val_loss: 5.2897\n",
      "Epoch 51/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 5.6550 - val_loss: 5.1697\n",
      "Epoch 52/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 5.4992 - val_loss: 5.2786\n",
      "Epoch 53/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 5.4488 - val_loss: 5.3048\n",
      "Epoch 54/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 5.4237 - val_loss: 5.2613\n",
      "Epoch 55/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 5.4323 - val_loss: 5.2762\n",
      "Epoch 56/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 5.4716 - val_loss: 5.0885\n",
      "Epoch 57/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 5.3235 - val_loss: 4.9830\n",
      "Epoch 58/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 5.3006 - val_loss: 5.0723\n",
      "Epoch 59/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 5.1563 - val_loss: 5.3353\n",
      "Epoch 60/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 5.2342 - val_loss: 4.9807\n",
      "Epoch 61/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 5.1946 - val_loss: 5.1525\n",
      "Epoch 62/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 5.0245 - val_loss: 4.6879\n",
      "Epoch 63/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 4.7549 - val_loss: 4.5887\n",
      "Epoch 64/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 4.5802 - val_loss: 4.4219\n",
      "Epoch 65/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 4.4520 - val_loss: 4.4695\n",
      "Epoch 66/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 4.4568 - val_loss: 4.5455\n",
      "Epoch 67/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 4.1926 - val_loss: 4.4787\n",
      "Epoch 68/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 4.1307 - val_loss: 4.3151\n",
      "Epoch 69/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.9974 - val_loss: 3.9938\n",
      "Epoch 70/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 4.0347 - val_loss: 4.0911\n",
      "Epoch 71/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 4.2136 - val_loss: 4.1465\n",
      "Epoch 72/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.8717 - val_loss: 4.0238\n",
      "Epoch 73/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.8166 - val_loss: 3.7689\n",
      "Epoch 74/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.8421 - val_loss: 3.7039\n",
      "Epoch 75/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 3.7523 - val_loss: 3.9419\n",
      "Epoch 76/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.6654 - val_loss: 3.8710\n",
      "Epoch 77/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.6494 - val_loss: 3.7790\n",
      "Epoch 78/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.7649 - val_loss: 3.6355\n",
      "Epoch 79/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.5438 - val_loss: 3.6503\n",
      "Epoch 80/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.4121 - val_loss: 3.5215\n",
      "Epoch 81/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.4715 - val_loss: 3.5355\n",
      "Epoch 82/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.4956 - val_loss: 3.5112\n",
      "Epoch 83/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.4437 - val_loss: 3.8422\n",
      "Epoch 84/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.4479 - val_loss: 3.6194\n",
      "Epoch 85/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 3.3366 - val_loss: 3.6549\n",
      "Epoch 86/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.4985 - val_loss: 3.5839\n",
      "Epoch 87/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.5718 - val_loss: 3.3810\n",
      "Epoch 88/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 3.3610 - val_loss: 3.8285\n",
      "Epoch 89/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 3.4385 - val_loss: 3.6822\n",
      "Epoch 90/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.3856 - val_loss: 3.9283\n",
      "Epoch 91/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.2893 - val_loss: 3.5926\n",
      "Epoch 92/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.3582 - val_loss: 3.5700\n",
      "Epoch 93/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.2710 - val_loss: 3.6050\n",
      "Epoch 94/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.3481 - val_loss: 3.3745\n",
      "Epoch 95/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.2567 - val_loss: 3.3149\n",
      "Epoch 96/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 3.1677 - val_loss: 3.4503\n",
      "Epoch 97/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.2697 - val_loss: 3.4782\n",
      "Epoch 98/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.1813 - val_loss: 3.6747\n",
      "Epoch 99/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.1638 - val_loss: 3.3205\n",
      "Epoch 100/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.2770 - val_loss: 3.3470\n",
      "Epoch 101/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.1517 - val_loss: 3.3095\n",
      "Epoch 102/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.1177 - val_loss: 3.4562\n",
      "Epoch 103/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.1806 - val_loss: 3.3966\n",
      "Epoch 104/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.1142 - val_loss: 3.2925\n",
      "Epoch 105/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.1041 - val_loss: 3.3233\n",
      "Epoch 106/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 3.0504 - val_loss: 3.3252\n",
      "Epoch 107/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 3.1166 - val_loss: 3.4524\n",
      "Epoch 108/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 3.0533 - val_loss: 3.2667\n",
      "Epoch 109/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 3.1353 - val_loss: 3.2134\n",
      "Epoch 110/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.0948 - val_loss: 3.4065\n",
      "Epoch 111/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.0787 - val_loss: 3.3281\n",
      "Epoch 112/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.0911 - val_loss: 3.2994\n",
      "Epoch 113/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.0169 - val_loss: 3.3776\n",
      "Epoch 114/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.1063 - val_loss: 3.4524\n",
      "Epoch 115/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.0319 - val_loss: 3.2182\n",
      "Epoch 116/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 3.0620 - val_loss: 3.2337\n",
      "Epoch 117/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 3.1295 - val_loss: 3.2546\n",
      "Epoch 118/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 2.9857 - val_loss: 3.5278\n",
      "Epoch 119/2000\n",
      "73/73 [==============================] - ETA: 0s - loss: 3.1035Restoring model weights from the end of the best epoch: 109.\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 3.1035 - val_loss: 3.4393\n",
      "Epoch 119: early stopping\n",
      "'########################################################Model9\n",
      "Epoch 1/2000\n",
      "73/73 [==============================] - 9s 100ms/step - loss: 3.1319 - val_loss: 0.8983\n",
      "Epoch 2/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.7563 - val_loss: 0.7723\n",
      "Epoch 3/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.7441 - val_loss: 0.7602\n",
      "Epoch 4/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.7266 - val_loss: 0.7302\n",
      "Epoch 5/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.6978 - val_loss: 0.7389\n",
      "Epoch 6/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.6877 - val_loss: 0.6727\n",
      "Epoch 7/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.6561 - val_loss: 0.6464\n",
      "Epoch 8/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.6306 - val_loss: 0.6173\n",
      "Epoch 9/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.5889 - val_loss: 0.5875\n",
      "Epoch 10/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.5567 - val_loss: 0.5698\n",
      "Epoch 11/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.5141 - val_loss: 0.4876\n",
      "Epoch 12/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.4943 - val_loss: 0.4793\n",
      "Epoch 13/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.4897 - val_loss: 0.4981\n",
      "Epoch 14/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.4804 - val_loss: 0.4955\n",
      "Epoch 15/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.4678 - val_loss: 0.4557\n",
      "Epoch 16/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.4588 - val_loss: 0.4445\n",
      "Epoch 17/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.4544 - val_loss: 0.4412\n",
      "Epoch 18/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.4448 - val_loss: 0.4372\n",
      "Epoch 19/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.4340 - val_loss: 0.4377\n",
      "Epoch 20/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.4387 - val_loss: 0.4247\n",
      "Epoch 21/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.4264 - val_loss: 0.4295\n",
      "Epoch 22/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.4241 - val_loss: 0.4180\n",
      "Epoch 23/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.4154 - val_loss: 0.3957\n",
      "Epoch 24/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.3975 - val_loss: 0.3889\n",
      "Epoch 25/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.4495 - val_loss: 0.4167\n",
      "Epoch 26/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.4211 - val_loss: 0.4036\n",
      "Epoch 27/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.4086 - val_loss: 0.3942\n",
      "Epoch 28/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.4077 - val_loss: 0.4084\n",
      "Epoch 29/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.4041 - val_loss: 0.4083\n",
      "Epoch 30/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3950 - val_loss: 0.3825\n",
      "Epoch 31/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3773 - val_loss: 0.3704\n",
      "Epoch 32/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3665 - val_loss: 0.3872\n",
      "Epoch 33/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3649 - val_loss: 0.3597\n",
      "Epoch 34/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3527 - val_loss: 0.3659\n",
      "Epoch 35/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3534 - val_loss: 0.3557\n",
      "Epoch 36/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3374 - val_loss: 0.3459\n",
      "Epoch 37/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3294 - val_loss: 0.3341\n",
      "Epoch 38/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3294 - val_loss: 0.3498\n",
      "Epoch 39/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.3196 - val_loss: 0.3252\n",
      "Epoch 40/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3099 - val_loss: 0.3417\n",
      "Epoch 41/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3013 - val_loss: 0.3085\n",
      "Epoch 42/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.3014 - val_loss: 0.3591\n",
      "Epoch 43/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2988 - val_loss: 0.2882\n",
      "Epoch 44/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2841 - val_loss: 0.3020\n",
      "Epoch 45/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2857 - val_loss: 0.2917\n",
      "Epoch 46/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2759 - val_loss: 0.3025\n",
      "Epoch 47/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2677 - val_loss: 0.2906\n",
      "Epoch 48/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2817 - val_loss: 0.3007\n",
      "Epoch 49/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2749 - val_loss: 0.2816\n",
      "Epoch 50/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2580 - val_loss: 0.2673\n",
      "Epoch 51/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2490 - val_loss: 0.2586\n",
      "Epoch 52/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2460 - val_loss: 0.2652\n",
      "Epoch 53/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2460 - val_loss: 0.2590\n",
      "Epoch 54/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2427 - val_loss: 0.2702\n",
      "Epoch 55/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2427 - val_loss: 0.2469\n",
      "Epoch 56/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2402 - val_loss: 0.2525\n",
      "Epoch 57/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2372 - val_loss: 0.2846\n",
      "Epoch 58/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2397 - val_loss: 0.2421\n",
      "Epoch 59/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2266 - val_loss: 0.2692\n",
      "Epoch 60/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.2245 - val_loss: 0.2373\n",
      "Epoch 61/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2387 - val_loss: 0.2802\n",
      "Epoch 62/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2265 - val_loss: 0.2438\n",
      "Epoch 63/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2227 - val_loss: 0.2340\n",
      "Epoch 64/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2272 - val_loss: 0.2664\n",
      "Epoch 65/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2144 - val_loss: 0.2517\n",
      "Epoch 66/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2174 - val_loss: 0.2359\n",
      "Epoch 67/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2165 - val_loss: 0.2324\n",
      "Epoch 68/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2125 - val_loss: 0.2572\n",
      "Epoch 69/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2140 - val_loss: 0.2227\n",
      "Epoch 70/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2086 - val_loss: 0.2319\n",
      "Epoch 71/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.2256 - val_loss: 0.2348\n",
      "Epoch 72/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2132 - val_loss: 0.2252\n",
      "Epoch 73/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2036 - val_loss: 0.2241\n",
      "Epoch 74/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2105 - val_loss: 0.2376\n",
      "Epoch 75/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2050 - val_loss: 0.2380\n",
      "Epoch 76/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2051 - val_loss: 0.2299\n",
      "Epoch 77/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2057 - val_loss: 0.2343\n",
      "Epoch 78/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.2055 - val_loss: 0.2332\n",
      "Epoch 79/2000\n",
      "73/73 [==============================] - ETA: 0s - loss: 0.2052Restoring model weights from the end of the best epoch: 69.\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2052 - val_loss: 0.2298\n",
      "Epoch 79: early stopping\n",
      "'########################################################Model0\n",
      "Epoch 1/2000\n",
      "73/73 [==============================] - 8s 95ms/step - loss: 3.8850 - val_loss: 1.3571\n",
      "Epoch 2/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.8073 - val_loss: 0.7770\n",
      "Epoch 3/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.7442 - val_loss: 0.7879\n",
      "Epoch 4/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.7381 - val_loss: 0.7445\n",
      "Epoch 5/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.7085 - val_loss: 0.7123\n",
      "Epoch 6/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.6844 - val_loss: 0.6801\n",
      "Epoch 7/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.6617 - val_loss: 0.6475\n",
      "Epoch 8/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.6382 - val_loss: 0.6177\n",
      "Epoch 9/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.6054 - val_loss: 0.5780\n",
      "Epoch 10/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.5581 - val_loss: 0.5410\n",
      "Epoch 11/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.5331 - val_loss: 0.5281\n",
      "Epoch 12/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.5164 - val_loss: 0.4885\n",
      "Epoch 13/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.4997 - val_loss: 0.4857\n",
      "Epoch 14/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.4835 - val_loss: 0.4805\n",
      "Epoch 15/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.4753 - val_loss: 0.4719\n",
      "Epoch 16/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.4755 - val_loss: 0.4662\n",
      "Epoch 17/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.4602 - val_loss: 0.4535\n",
      "Epoch 18/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.4531 - val_loss: 0.4470\n",
      "Epoch 19/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.4516 - val_loss: 0.4444\n",
      "Epoch 20/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.4395 - val_loss: 0.4306\n",
      "Epoch 21/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.4266 - val_loss: 0.4442\n",
      "Epoch 22/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.4238 - val_loss: 0.4136\n",
      "Epoch 23/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.4227 - val_loss: 0.3920\n",
      "Epoch 24/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.4169 - val_loss: 0.4097\n",
      "Epoch 25/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.4098 - val_loss: 0.4204\n",
      "Epoch 26/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.4098 - val_loss: 0.3951\n",
      "Epoch 27/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3848 - val_loss: 0.3706\n",
      "Epoch 28/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.4241 - val_loss: 0.3864\n",
      "Epoch 29/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3886 - val_loss: 0.3817\n",
      "Epoch 30/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.3846 - val_loss: 0.3674\n",
      "Epoch 31/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3678 - val_loss: 0.4179\n",
      "Epoch 32/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3591 - val_loss: 0.3646\n",
      "Epoch 33/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.3548 - val_loss: 0.3436\n",
      "Epoch 34/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.3376 - val_loss: 0.3494\n",
      "Epoch 35/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3299 - val_loss: 0.3385\n",
      "Epoch 36/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.3167 - val_loss: 0.3368\n",
      "Epoch 37/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.3108 - val_loss: 0.3276\n",
      "Epoch 38/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3076 - val_loss: 0.3412\n",
      "Epoch 39/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.3015 - val_loss: 0.3020\n",
      "Epoch 40/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2913 - val_loss: 0.3083\n",
      "Epoch 41/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2807 - val_loss: 0.2978\n",
      "Epoch 42/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2771 - val_loss: 0.2913\n",
      "Epoch 43/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.2796 - val_loss: 0.3000\n",
      "Epoch 44/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2881 - val_loss: 0.3022\n",
      "Epoch 45/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2807 - val_loss: 0.3072\n",
      "Epoch 46/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2681 - val_loss: 0.2861\n",
      "Epoch 47/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2661 - val_loss: 0.3221\n",
      "Epoch 48/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2678 - val_loss: 0.3281\n",
      "Epoch 49/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2783 - val_loss: 0.2873\n",
      "Epoch 50/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2678 - val_loss: 0.2773\n",
      "Epoch 51/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.2587 - val_loss: 0.2864\n",
      "Epoch 52/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.2567 - val_loss: 0.2900\n",
      "Epoch 53/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2506 - val_loss: 0.3014\n",
      "Epoch 54/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.2718 - val_loss: 0.2863\n",
      "Epoch 55/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.2521 - val_loss: 0.2906\n",
      "Epoch 56/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.2565 - val_loss: 0.2538\n",
      "Epoch 57/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2481 - val_loss: 0.2600\n",
      "Epoch 58/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2436 - val_loss: 0.2815\n",
      "Epoch 59/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.2434 - val_loss: 0.2701\n",
      "Epoch 60/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2472 - val_loss: 0.2682\n",
      "Epoch 61/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2452 - val_loss: 0.2688\n",
      "Epoch 62/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.2396 - val_loss: 0.2598\n",
      "Epoch 63/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2402 - val_loss: 0.2864\n",
      "Epoch 64/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.2480 - val_loss: 0.2633\n",
      "Epoch 65/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2368 - val_loss: 0.2637\n",
      "Epoch 66/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.2318 - val_loss: 0.2532\n",
      "Epoch 67/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.2335 - val_loss: 0.2542\n",
      "Epoch 68/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2307 - val_loss: 0.2553\n",
      "Epoch 69/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2356 - val_loss: 0.2457\n",
      "Epoch 70/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2284 - val_loss: 0.2473\n",
      "Epoch 71/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.2320 - val_loss: 0.2498\n",
      "Epoch 72/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2297 - val_loss: 0.2540\n",
      "Epoch 73/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2309 - val_loss: 0.2470\n",
      "Epoch 74/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 0.2355 - val_loss: 0.2404\n",
      "Epoch 75/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2317 - val_loss: 0.2812\n",
      "Epoch 76/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.2257 - val_loss: 0.2643\n",
      "Epoch 77/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.2305 - val_loss: 0.2574\n",
      "Epoch 78/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2273 - val_loss: 0.2385\n",
      "Epoch 79/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2289 - val_loss: 0.2487\n",
      "Epoch 80/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2271 - val_loss: 0.2633\n",
      "Epoch 81/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2287 - val_loss: 0.2430\n",
      "Epoch 82/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2225 - val_loss: 0.2412\n",
      "Epoch 83/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2260 - val_loss: 0.2320\n",
      "Epoch 84/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2193 - val_loss: 0.2557\n",
      "Epoch 85/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2201 - val_loss: 0.2351\n",
      "Epoch 86/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2260 - val_loss: 0.2509\n",
      "Epoch 87/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2327 - val_loss: 0.2463\n",
      "Epoch 88/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2222 - val_loss: 0.2319\n",
      "Epoch 89/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.2173 - val_loss: 0.2432\n",
      "Epoch 90/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2137 - val_loss: 0.2407\n",
      "Epoch 91/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2206 - val_loss: 0.2343\n",
      "Epoch 92/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2167 - val_loss: 0.2438\n",
      "Epoch 93/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 0.2176 - val_loss: 0.2262\n",
      "Epoch 94/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2193 - val_loss: 0.2508\n",
      "Epoch 95/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2143 - val_loss: 0.2232\n",
      "Epoch 96/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2159 - val_loss: 0.2452\n",
      "Epoch 97/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2154 - val_loss: 0.2356\n",
      "Epoch 98/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2146 - val_loss: 0.2314\n",
      "Epoch 99/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2182 - val_loss: 0.2350\n",
      "Epoch 100/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2152 - val_loss: 0.2284\n",
      "Epoch 101/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2125 - val_loss: 0.2272\n",
      "Epoch 102/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2075 - val_loss: 0.2583\n",
      "Epoch 103/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2219 - val_loss: 0.2370\n",
      "Epoch 104/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2097 - val_loss: 0.2395\n",
      "Epoch 105/2000\n",
      "73/73 [==============================] - ETA: 0s - loss: 0.2124Restoring model weights from the end of the best epoch: 95.\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2124 - val_loss: 0.2291\n",
      "Epoch 105: early stopping\n",
      "'########################################################Model1\n",
      "Epoch 1/2000\n",
      "73/73 [==============================] - 9s 98ms/step - loss: 3.7375 - val_loss: 0.9525\n",
      "Epoch 2/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.7699 - val_loss: 0.7823\n",
      "Epoch 3/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.7474 - val_loss: 0.7650\n",
      "Epoch 4/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.7257 - val_loss: 0.7288\n",
      "Epoch 5/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.7049 - val_loss: 0.6987\n",
      "Epoch 6/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.6834 - val_loss: 0.6897\n",
      "Epoch 7/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.6593 - val_loss: 0.6462\n",
      "Epoch 8/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.6303 - val_loss: 0.6171\n",
      "Epoch 9/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.5981 - val_loss: 0.5760\n",
      "Epoch 10/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.5616 - val_loss: 0.5253\n",
      "Epoch 11/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.5184 - val_loss: 0.5070\n",
      "Epoch 12/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.5045 - val_loss: 0.4883\n",
      "Epoch 13/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.4951 - val_loss: 0.4805\n",
      "Epoch 14/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.4819 - val_loss: 0.4685\n",
      "Epoch 15/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.4756 - val_loss: 0.4621\n",
      "Epoch 16/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.4657 - val_loss: 0.4549\n",
      "Epoch 17/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.4698 - val_loss: 0.4559\n",
      "Epoch 18/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.4516 - val_loss: 0.4412\n",
      "Epoch 19/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.4484 - val_loss: 0.4335\n",
      "Epoch 20/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.4431 - val_loss: 0.4597\n",
      "Epoch 21/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.4380 - val_loss: 0.4251\n",
      "Epoch 22/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.4287 - val_loss: 0.4327\n",
      "Epoch 23/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.4183 - val_loss: 0.4204\n",
      "Epoch 24/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.4074 - val_loss: 0.4142\n",
      "Epoch 25/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.4096 - val_loss: 0.3934\n",
      "Epoch 26/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3853 - val_loss: 0.3849\n",
      "Epoch 27/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3825 - val_loss: 0.3744\n",
      "Epoch 28/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3701 - val_loss: 0.3733\n",
      "Epoch 29/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3654 - val_loss: 0.3622\n",
      "Epoch 30/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3605 - val_loss: 0.3517\n",
      "Epoch 31/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3517 - val_loss: 0.3435\n",
      "Epoch 32/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3465 - val_loss: 0.3550\n",
      "Epoch 33/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3436 - val_loss: 0.3227\n",
      "Epoch 34/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3281 - val_loss: 0.3062\n",
      "Epoch 35/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3197 - val_loss: 0.2939\n",
      "Epoch 36/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3119 - val_loss: 0.3389\n",
      "Epoch 37/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3167 - val_loss: 0.2793\n",
      "Epoch 38/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2791 - val_loss: 0.2750\n",
      "Epoch 39/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2983 - val_loss: 0.2734\n",
      "Epoch 40/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2742 - val_loss: 0.2572\n",
      "Epoch 41/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2893 - val_loss: 0.3109\n",
      "Epoch 42/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.2871 - val_loss: 0.2743\n",
      "Epoch 43/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2638 - val_loss: 0.2670\n",
      "Epoch 44/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2640 - val_loss: 0.2487\n",
      "Epoch 45/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2671 - val_loss: 0.2560\n",
      "Epoch 46/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2518 - val_loss: 0.2613\n",
      "Epoch 47/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2571 - val_loss: 0.3616\n",
      "Epoch 48/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2619 - val_loss: 0.2635\n",
      "Epoch 49/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2464 - val_loss: 0.2384\n",
      "Epoch 50/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2359 - val_loss: 0.2317\n",
      "Epoch 51/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2369 - val_loss: 0.2756\n",
      "Epoch 52/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2445 - val_loss: 0.2519\n",
      "Epoch 53/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2461 - val_loss: 0.2876\n",
      "Epoch 54/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2289 - val_loss: 0.2238\n",
      "Epoch 55/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2259 - val_loss: 0.2340\n",
      "Epoch 56/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2259 - val_loss: 0.2392\n",
      "Epoch 57/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2402 - val_loss: 0.2510\n",
      "Epoch 58/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2253 - val_loss: 0.2313\n",
      "Epoch 59/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2431 - val_loss: 0.2502\n",
      "Epoch 60/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.2186 - val_loss: 0.2351\n",
      "Epoch 61/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2192 - val_loss: 0.2217\n",
      "Epoch 62/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2148 - val_loss: 0.2187\n",
      "Epoch 63/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2457 - val_loss: 0.2233\n",
      "Epoch 64/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2144 - val_loss: 0.2235\n",
      "Epoch 65/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2172 - val_loss: 0.2257\n",
      "Epoch 66/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2216 - val_loss: 0.2223\n",
      "Epoch 67/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2198 - val_loss: 0.2178\n",
      "Epoch 68/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2134 - val_loss: 0.2080\n",
      "Epoch 69/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2082 - val_loss: 0.2115\n",
      "Epoch 70/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2343 - val_loss: 0.2155\n",
      "Epoch 71/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2189 - val_loss: 0.2090\n",
      "Epoch 72/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2261 - val_loss: 0.2167\n",
      "Epoch 73/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2120 - val_loss: 0.2067\n",
      "Epoch 74/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2123 - val_loss: 0.2909\n",
      "Epoch 75/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2189 - val_loss: 0.2501\n",
      "Epoch 76/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2119 - val_loss: 0.2219\n",
      "Epoch 77/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2097 - val_loss: 0.2142\n",
      "Epoch 78/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.2095 - val_loss: 0.2234\n",
      "Epoch 79/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2100 - val_loss: 0.2129\n",
      "Epoch 80/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2072 - val_loss: 0.2098\n",
      "Epoch 81/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2071 - val_loss: 0.2145\n",
      "Epoch 82/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2119 - val_loss: 0.2289\n",
      "Epoch 83/2000\n",
      "73/73 [==============================] - ETA: 0s - loss: 0.2085Restoring model weights from the end of the best epoch: 73.\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2085 - val_loss: 0.2173\n",
      "Epoch 83: early stopping\n",
      "'########################################################Model2\n",
      "Epoch 1/2000\n",
      "73/73 [==============================] - 9s 99ms/step - loss: 3.9433 - val_loss: 1.0746\n",
      "Epoch 2/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.7677 - val_loss: 0.7775\n",
      "Epoch 3/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.7462 - val_loss: 0.7665\n",
      "Epoch 4/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.7336 - val_loss: 0.7441\n",
      "Epoch 5/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.7066 - val_loss: 0.7918\n",
      "Epoch 6/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.6884 - val_loss: 0.6720\n",
      "Epoch 7/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.6607 - val_loss: 0.6566\n",
      "Epoch 8/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.6285 - val_loss: 0.6080\n",
      "Epoch 9/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.5864 - val_loss: 0.5781\n",
      "Epoch 10/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.5341 - val_loss: 0.5132\n",
      "Epoch 11/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.5098 - val_loss: 0.5185\n",
      "Epoch 12/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.4965 - val_loss: 0.5214\n",
      "Epoch 13/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.4886 - val_loss: 0.4985\n",
      "Epoch 14/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.4802 - val_loss: 0.4919\n",
      "Epoch 15/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.4761 - val_loss: 0.4525\n",
      "Epoch 16/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.4608 - val_loss: 0.4803\n",
      "Epoch 17/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.4576 - val_loss: 0.4410\n",
      "Epoch 18/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.4452 - val_loss: 0.4552\n",
      "Epoch 19/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.4407 - val_loss: 0.4302\n",
      "Epoch 20/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.4422 - val_loss: 0.4166\n",
      "Epoch 21/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.4116 - val_loss: 0.4092\n",
      "Epoch 22/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.4128 - val_loss: 0.4052\n",
      "Epoch 23/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3985 - val_loss: 0.4198\n",
      "Epoch 24/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3992 - val_loss: 0.4356\n",
      "Epoch 25/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3834 - val_loss: 0.4195\n",
      "Epoch 26/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3987 - val_loss: 0.3855\n",
      "Epoch 27/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3530 - val_loss: 0.3583\n",
      "Epoch 28/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3367 - val_loss: 0.3657\n",
      "Epoch 29/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3282 - val_loss: 0.3332\n",
      "Epoch 30/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3155 - val_loss: 0.3656\n",
      "Epoch 31/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.3103 - val_loss: 0.3883\n",
      "Epoch 32/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3069 - val_loss: 0.3090\n",
      "Epoch 33/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2969 - val_loss: 0.3101\n",
      "Epoch 34/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2839 - val_loss: 0.3045\n",
      "Epoch 35/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2844 - val_loss: 0.3282\n",
      "Epoch 36/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2862 - val_loss: 0.3036\n",
      "Epoch 37/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2778 - val_loss: 0.3208\n",
      "Epoch 38/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2764 - val_loss: 0.3117\n",
      "Epoch 39/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2809 - val_loss: 0.2905\n",
      "Epoch 40/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2584 - val_loss: 0.2781\n",
      "Epoch 41/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2591 - val_loss: 0.2761\n",
      "Epoch 42/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2633 - val_loss: 0.2856\n",
      "Epoch 43/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2590 - val_loss: 0.2900\n",
      "Epoch 44/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2525 - val_loss: 0.2668\n",
      "Epoch 45/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2484 - val_loss: 0.2762\n",
      "Epoch 46/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2593 - val_loss: 0.2790\n",
      "Epoch 47/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2415 - val_loss: 0.2901\n",
      "Epoch 48/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2468 - val_loss: 0.2581\n",
      "Epoch 49/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.2454 - val_loss: 0.2574\n",
      "Epoch 50/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2496 - val_loss: 0.2686\n",
      "Epoch 51/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2340 - val_loss: 0.2548\n",
      "Epoch 52/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2398 - val_loss: 0.2522\n",
      "Epoch 53/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2346 - val_loss: 0.2565\n",
      "Epoch 54/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2256 - val_loss: 0.2503\n",
      "Epoch 55/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2269 - val_loss: 0.2408\n",
      "Epoch 56/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2255 - val_loss: 0.2418\n",
      "Epoch 57/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2311 - val_loss: 0.2496\n",
      "Epoch 58/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2340 - val_loss: 0.2501\n",
      "Epoch 59/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2327 - val_loss: 0.2576\n",
      "Epoch 60/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2326 - val_loss: 0.2761\n",
      "Epoch 61/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2281 - val_loss: 0.2494\n",
      "Epoch 62/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2290 - val_loss: 0.2383\n",
      "Epoch 63/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2234 - val_loss: 0.2408\n",
      "Epoch 64/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2235 - val_loss: 0.2456\n",
      "Epoch 65/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2194 - val_loss: 0.2322\n",
      "Epoch 66/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2216 - val_loss: 0.2356\n",
      "Epoch 67/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.2270 - val_loss: 0.2634\n",
      "Epoch 68/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2364 - val_loss: 0.2313\n",
      "Epoch 69/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2254 - val_loss: 0.2366\n",
      "Epoch 70/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2177 - val_loss: 0.2477\n",
      "Epoch 71/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2131 - val_loss: 0.2338\n",
      "Epoch 72/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2116 - val_loss: 0.2444\n",
      "Epoch 73/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2099 - val_loss: 0.2466\n",
      "Epoch 74/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2139 - val_loss: 0.2415\n",
      "Epoch 75/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2097 - val_loss: 0.2334\n",
      "Epoch 76/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2183 - val_loss: 0.2404\n",
      "Epoch 77/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2121 - val_loss: 0.2470\n",
      "Epoch 78/2000\n",
      "73/73 [==============================] - ETA: 0s - loss: 0.2602Restoring model weights from the end of the best epoch: 68.\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2602 - val_loss: 0.2382\n",
      "Epoch 78: early stopping\n",
      "'########################################################Model3\n",
      "Epoch 1/2000\n",
      "73/73 [==============================] - 8s 96ms/step - loss: 3.8645 - val_loss: 1.1534\n",
      "Epoch 2/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.7784 - val_loss: 0.7795\n",
      "Epoch 3/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.7494 - val_loss: 0.7690\n",
      "Epoch 4/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.7350 - val_loss: 0.7473\n",
      "Epoch 5/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.7131 - val_loss: 0.7124\n",
      "Epoch 6/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.7030 - val_loss: 0.6997\n",
      "Epoch 7/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 0.6710 - val_loss: 0.6771\n",
      "Epoch 8/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.6507 - val_loss: 0.6348\n",
      "Epoch 9/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.6243 - val_loss: 0.6228\n",
      "Epoch 10/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.5748 - val_loss: 0.5630\n",
      "Epoch 11/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.5281 - val_loss: 0.5020\n",
      "Epoch 12/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.5082 - val_loss: 0.5179\n",
      "Epoch 13/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.4989 - val_loss: 0.4736\n",
      "Epoch 14/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.4796 - val_loss: 0.4767\n",
      "Epoch 15/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.4677 - val_loss: 0.4675\n",
      "Epoch 16/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.4614 - val_loss: 0.4472\n",
      "Epoch 17/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.4486 - val_loss: 0.4438\n",
      "Epoch 18/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.4400 - val_loss: 0.4219\n",
      "Epoch 19/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.4342 - val_loss: 0.4427\n",
      "Epoch 20/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.4143 - val_loss: 0.4520\n",
      "Epoch 21/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.4621 - val_loss: 0.4471\n",
      "Epoch 22/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.4254 - val_loss: 0.4392\n",
      "Epoch 23/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.4301 - val_loss: 0.4196\n",
      "Epoch 24/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.4334 - val_loss: 0.4079\n",
      "Epoch 25/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.4173 - val_loss: 0.4107\n",
      "Epoch 26/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 0.3976 - val_loss: 0.3671\n",
      "Epoch 27/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.4148 - val_loss: 0.3740\n",
      "Epoch 28/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3761 - val_loss: 0.4108\n",
      "Epoch 29/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3975 - val_loss: 0.3735\n",
      "Epoch 30/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3638 - val_loss: 0.4160\n",
      "Epoch 31/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.4298 - val_loss: 0.4003\n",
      "Epoch 32/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.4086 - val_loss: 0.3938\n",
      "Epoch 33/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3985 - val_loss: 0.3708\n",
      "Epoch 34/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3675 - val_loss: 0.3868\n",
      "Epoch 35/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3666 - val_loss: 0.3546\n",
      "Epoch 36/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.3505 - val_loss: 0.3464\n",
      "Epoch 37/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3515 - val_loss: 0.3562\n",
      "Epoch 38/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3407 - val_loss: 0.3278\n",
      "Epoch 39/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3147 - val_loss: 0.3117\n",
      "Epoch 40/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3241 - val_loss: 0.3149\n",
      "Epoch 41/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2986 - val_loss: 0.2926\n",
      "Epoch 42/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3150 - val_loss: 0.2908\n",
      "Epoch 43/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2897 - val_loss: 0.2999\n",
      "Epoch 44/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 0.2849 - val_loss: 0.2949\n",
      "Epoch 45/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2837 - val_loss: 0.3064\n",
      "Epoch 46/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2820 - val_loss: 0.2795\n",
      "Epoch 47/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2679 - val_loss: 0.2756\n",
      "Epoch 48/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2763 - val_loss: 0.2922\n",
      "Epoch 49/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2930 - val_loss: 0.3084\n",
      "Epoch 50/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2650 - val_loss: 0.2613\n",
      "Epoch 51/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2571 - val_loss: 0.2888\n",
      "Epoch 52/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2574 - val_loss: 0.2706\n",
      "Epoch 53/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2515 - val_loss: 0.2504\n",
      "Epoch 54/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.2533 - val_loss: 0.2509\n",
      "Epoch 55/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2656 - val_loss: 0.2563\n",
      "Epoch 56/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2517 - val_loss: 0.2529\n",
      "Epoch 57/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2469 - val_loss: 0.2577\n",
      "Epoch 58/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2419 - val_loss: 0.2555\n",
      "Epoch 59/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2441 - val_loss: 0.2450\n",
      "Epoch 60/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2435 - val_loss: 0.2446\n",
      "Epoch 61/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2379 - val_loss: 0.2454\n",
      "Epoch 62/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2374 - val_loss: 0.2482\n",
      "Epoch 63/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.2419 - val_loss: 0.2511\n",
      "Epoch 64/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2407 - val_loss: 0.2570\n",
      "Epoch 65/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2357 - val_loss: 0.2549\n",
      "Epoch 66/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2330 - val_loss: 0.2420\n",
      "Epoch 67/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2322 - val_loss: 0.2569\n",
      "Epoch 68/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2315 - val_loss: 0.2475\n",
      "Epoch 69/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2271 - val_loss: 0.2319\n",
      "Epoch 70/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2256 - val_loss: 0.2277\n",
      "Epoch 71/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2306 - val_loss: 0.2350\n",
      "Epoch 72/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.2244 - val_loss: 0.2334\n",
      "Epoch 73/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2282 - val_loss: 0.2453\n",
      "Epoch 74/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2333 - val_loss: 0.2201\n",
      "Epoch 75/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2237 - val_loss: 0.2490\n",
      "Epoch 76/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2261 - val_loss: 0.2332\n",
      "Epoch 77/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2356 - val_loss: 0.2299\n",
      "Epoch 78/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2235 - val_loss: 0.2380\n",
      "Epoch 79/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2200 - val_loss: 0.2238\n",
      "Epoch 80/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2183 - val_loss: 0.2333\n",
      "Epoch 81/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.2220 - val_loss: 0.2328\n",
      "Epoch 82/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.2157 - val_loss: 0.2276\n",
      "Epoch 83/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2192 - val_loss: 0.2309\n",
      "Epoch 84/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2211 - val_loss: 0.2143\n",
      "Epoch 85/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2181 - val_loss: 0.2187\n",
      "Epoch 86/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2169 - val_loss: 0.2089\n",
      "Epoch 87/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2173 - val_loss: 0.2356\n",
      "Epoch 88/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2214 - val_loss: 0.2286\n",
      "Epoch 89/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2157 - val_loss: 0.2296\n",
      "Epoch 90/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2107 - val_loss: 0.2149\n",
      "Epoch 91/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2119 - val_loss: 0.2255\n",
      "Epoch 92/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2149 - val_loss: 0.2199\n",
      "Epoch 93/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2089 - val_loss: 0.2304\n",
      "Epoch 94/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2154 - val_loss: 0.2247\n",
      "Epoch 95/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2118 - val_loss: 0.2184\n",
      "Epoch 96/2000\n",
      "73/73 [==============================] - ETA: 0s - loss: 0.2146Restoring model weights from the end of the best epoch: 86.\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2146 - val_loss: 0.2336\n",
      "Epoch 96: early stopping\n",
      "'########################################################Model4\n",
      "Epoch 1/2000\n",
      "73/73 [==============================] - 10s 101ms/step - loss: 3.6155 - val_loss: 1.2488\n",
      "Epoch 2/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.8025 - val_loss: 0.7829\n",
      "Epoch 3/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.7502 - val_loss: 0.7800\n",
      "Epoch 4/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.7306 - val_loss: 0.7442\n",
      "Epoch 5/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.7045 - val_loss: 0.7309\n",
      "Epoch 6/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.6956 - val_loss: 0.6927\n",
      "Epoch 7/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.6815 - val_loss: 0.6907\n",
      "Epoch 8/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.6754 - val_loss: 0.6657\n",
      "Epoch 9/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.6503 - val_loss: 0.6428\n",
      "Epoch 10/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.6324 - val_loss: 0.6106\n",
      "Epoch 11/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.5951 - val_loss: 0.5678\n",
      "Epoch 12/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.5457 - val_loss: 0.5434\n",
      "Epoch 13/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.5175 - val_loss: 0.4950\n",
      "Epoch 14/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.4997 - val_loss: 0.4798\n",
      "Epoch 15/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.5042 - val_loss: 0.4723\n",
      "Epoch 16/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.4778 - val_loss: 0.4665\n",
      "Epoch 17/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.4788 - val_loss: 0.4565\n",
      "Epoch 18/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.4617 - val_loss: 0.4596\n",
      "Epoch 19/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.4629 - val_loss: 0.4551\n",
      "Epoch 20/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.4499 - val_loss: 0.4416\n",
      "Epoch 21/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.4441 - val_loss: 0.4329\n",
      "Epoch 22/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.4409 - val_loss: 0.4299\n",
      "Epoch 23/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.4355 - val_loss: 0.4278\n",
      "Epoch 24/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.4227 - val_loss: 0.4141\n",
      "Epoch 25/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.4079 - val_loss: 0.4019\n",
      "Epoch 26/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.4016 - val_loss: 0.3760\n",
      "Epoch 27/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.4053 - val_loss: 0.3909\n",
      "Epoch 28/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.3931 - val_loss: 0.3782\n",
      "Epoch 29/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3859 - val_loss: 0.3897\n",
      "Epoch 30/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.3828 - val_loss: 0.3809\n",
      "Epoch 31/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.3522 - val_loss: 0.3633\n",
      "Epoch 32/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.3371 - val_loss: 0.3640\n",
      "Epoch 33/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3650 - val_loss: 0.3871\n",
      "Epoch 34/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3363 - val_loss: 0.3235\n",
      "Epoch 35/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3149 - val_loss: 0.3188\n",
      "Epoch 36/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.3093 - val_loss: 0.3442\n",
      "Epoch 37/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3005 - val_loss: 0.3147\n",
      "Epoch 38/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.2865 - val_loss: 0.3007\n",
      "Epoch 39/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.2863 - val_loss: 0.3635\n",
      "Epoch 40/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2759 - val_loss: 0.3061\n",
      "Epoch 41/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2580 - val_loss: 0.3005\n",
      "Epoch 42/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2624 - val_loss: 0.2863\n",
      "Epoch 43/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2607 - val_loss: 0.2891\n",
      "Epoch 44/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2504 - val_loss: 0.2815\n",
      "Epoch 45/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2472 - val_loss: 0.2572\n",
      "Epoch 46/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2550 - val_loss: 0.2650\n",
      "Epoch 47/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2552 - val_loss: 0.2618\n",
      "Epoch 48/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2436 - val_loss: 0.2590\n",
      "Epoch 49/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2424 - val_loss: 0.2658\n",
      "Epoch 50/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2486 - val_loss: 0.2472\n",
      "Epoch 51/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2384 - val_loss: 0.2718\n",
      "Epoch 52/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2352 - val_loss: 0.2588\n",
      "Epoch 53/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2378 - val_loss: 0.2484\n",
      "Epoch 54/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2323 - val_loss: 0.2553\n",
      "Epoch 55/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2297 - val_loss: 0.2484\n",
      "Epoch 56/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2299 - val_loss: 0.2323\n",
      "Epoch 57/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.2252 - val_loss: 0.2556\n",
      "Epoch 58/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2281 - val_loss: 0.2836\n",
      "Epoch 59/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2270 - val_loss: 0.2331\n",
      "Epoch 60/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2183 - val_loss: 0.2342\n",
      "Epoch 61/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2253 - val_loss: 0.2378\n",
      "Epoch 62/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2237 - val_loss: 0.2224\n",
      "Epoch 63/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2203 - val_loss: 0.2308\n",
      "Epoch 64/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2180 - val_loss: 0.2294\n",
      "Epoch 65/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2097 - val_loss: 0.2363\n",
      "Epoch 66/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2327 - val_loss: 0.2261\n",
      "Epoch 67/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2154 - val_loss: 0.2315\n",
      "Epoch 68/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2140 - val_loss: 0.2238\n",
      "Epoch 69/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2093 - val_loss: 0.2275\n",
      "Epoch 70/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2107 - val_loss: 0.2324\n",
      "Epoch 71/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2188 - val_loss: 0.2425\n",
      "Epoch 72/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2136 - val_loss: 0.2192\n",
      "Epoch 73/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2189 - val_loss: 0.2283\n",
      "Epoch 74/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2101 - val_loss: 0.2184\n",
      "Epoch 75/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.2117 - val_loss: 0.2577\n",
      "Epoch 76/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2129 - val_loss: 0.2201\n",
      "Epoch 77/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2065 - val_loss: 0.2168\n",
      "Epoch 78/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.2039 - val_loss: 0.2200\n",
      "Epoch 79/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2183 - val_loss: 0.2194\n",
      "Epoch 80/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2048 - val_loss: 0.2127\n",
      "Epoch 81/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2107 - val_loss: 0.2200\n",
      "Epoch 82/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2046 - val_loss: 0.2193\n",
      "Epoch 83/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2000 - val_loss: 0.2210\n",
      "Epoch 84/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2021 - val_loss: 0.2172\n",
      "Epoch 85/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.2040 - val_loss: 0.2338\n",
      "Epoch 86/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2028 - val_loss: 0.2170\n",
      "Epoch 87/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1973 - val_loss: 0.2309\n",
      "Epoch 88/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1984 - val_loss: 0.2274\n",
      "Epoch 89/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2009 - val_loss: 0.2367\n",
      "Epoch 90/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2052 - val_loss: 0.2119\n",
      "Epoch 91/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2019 - val_loss: 0.2273\n",
      "Epoch 92/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2023 - val_loss: 0.2132\n",
      "Epoch 93/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.1990 - val_loss: 0.2234\n",
      "Epoch 94/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2005 - val_loss: 0.2311\n",
      "Epoch 95/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2052 - val_loss: 0.2279\n",
      "Epoch 96/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.2066 - val_loss: 0.2127\n",
      "Epoch 97/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.1993 - val_loss: 0.2139\n",
      "Epoch 98/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1936 - val_loss: 0.2009\n",
      "Epoch 99/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.1916 - val_loss: 0.2141\n",
      "Epoch 100/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1980 - val_loss: 0.2223\n",
      "Epoch 101/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.2010 - val_loss: 0.2069\n",
      "Epoch 102/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2000 - val_loss: 0.2044\n",
      "Epoch 103/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1968 - val_loss: 0.2034\n",
      "Epoch 104/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.1927 - val_loss: 0.2112\n",
      "Epoch 105/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.1917 - val_loss: 0.2044\n",
      "Epoch 106/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1946 - val_loss: 0.2159\n",
      "Epoch 107/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1930 - val_loss: 0.2200\n",
      "Epoch 108/2000\n",
      "73/73 [==============================] - ETA: 0s - loss: 0.1973Restoring model weights from the end of the best epoch: 98.\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1973 - val_loss: 0.2158\n",
      "Epoch 108: early stopping\n",
      "'########################################################Model5\n",
      "Epoch 1/2000\n",
      "73/73 [==============================] - 9s 99ms/step - loss: 3.1230 - val_loss: 0.7909\n",
      "Epoch 2/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.7485 - val_loss: 0.7735\n",
      "Epoch 3/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.7324 - val_loss: 0.7534\n",
      "Epoch 4/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.7134 - val_loss: 0.7129\n",
      "Epoch 5/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.7001 - val_loss: 0.6918\n",
      "Epoch 6/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.6689 - val_loss: 0.6623\n",
      "Epoch 7/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.6538 - val_loss: 0.6369\n",
      "Epoch 8/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.6255 - val_loss: 0.6246\n",
      "Epoch 9/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.5914 - val_loss: 0.5727\n",
      "Epoch 10/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.5560 - val_loss: 0.5417\n",
      "Epoch 11/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.5331 - val_loss: 0.4990\n",
      "Epoch 12/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.4997 - val_loss: 0.4819\n",
      "Epoch 13/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.4890 - val_loss: 0.4693\n",
      "Epoch 14/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.4898 - val_loss: 0.4633\n",
      "Epoch 15/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.4750 - val_loss: 0.4589\n",
      "Epoch 16/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.4661 - val_loss: 0.4472\n",
      "Epoch 17/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.4600 - val_loss: 0.4392\n",
      "Epoch 18/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.4504 - val_loss: 0.4362\n",
      "Epoch 19/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.4453 - val_loss: 0.4400\n",
      "Epoch 20/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.4492 - val_loss: 0.4421\n",
      "Epoch 21/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.4298 - val_loss: 0.4113\n",
      "Epoch 22/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.4162 - val_loss: 0.4054\n",
      "Epoch 23/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.4179 - val_loss: 0.4021\n",
      "Epoch 24/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.4018 - val_loss: 0.4288\n",
      "Epoch 25/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.4082 - val_loss: 0.3904\n",
      "Epoch 26/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3756 - val_loss: 0.3603\n",
      "Epoch 27/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3732 - val_loss: 0.3461\n",
      "Epoch 28/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3516 - val_loss: 0.3759\n",
      "Epoch 29/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3701 - val_loss: 0.3816\n",
      "Epoch 30/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3985 - val_loss: 0.4152\n",
      "Epoch 31/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3956 - val_loss: 0.3663\n",
      "Epoch 32/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3831 - val_loss: 0.3550\n",
      "Epoch 33/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3686 - val_loss: 0.3415\n",
      "Epoch 34/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3686 - val_loss: 0.3612\n",
      "Epoch 35/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3438 - val_loss: 0.3207\n",
      "Epoch 36/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3877 - val_loss: 0.3619\n",
      "Epoch 37/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3559 - val_loss: 0.3317\n",
      "Epoch 38/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.3377 - val_loss: 0.3403\n",
      "Epoch 39/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3221 - val_loss: 0.3489\n",
      "Epoch 40/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3214 - val_loss: 0.3156\n",
      "Epoch 41/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3276 - val_loss: 0.3494\n",
      "Epoch 42/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3386 - val_loss: 0.3172\n",
      "Epoch 43/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3196 - val_loss: 0.3032\n",
      "Epoch 44/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3222 - val_loss: 0.3089\n",
      "Epoch 45/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3020 - val_loss: 0.2933\n",
      "Epoch 46/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2906 - val_loss: 0.2986\n",
      "Epoch 47/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2897 - val_loss: 0.2850\n",
      "Epoch 48/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2878 - val_loss: 0.3106\n",
      "Epoch 49/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2901 - val_loss: 0.2811\n",
      "Epoch 50/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2771 - val_loss: 0.2745\n",
      "Epoch 51/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2823 - val_loss: 0.3002\n",
      "Epoch 52/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2859 - val_loss: 0.2605\n",
      "Epoch 53/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2754 - val_loss: 0.2845\n",
      "Epoch 54/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2707 - val_loss: 0.2713\n",
      "Epoch 55/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2605 - val_loss: 0.2616\n",
      "Epoch 56/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.2679 - val_loss: 0.2748\n",
      "Epoch 57/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2561 - val_loss: 0.2489\n",
      "Epoch 58/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2473 - val_loss: 0.2406\n",
      "Epoch 59/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2465 - val_loss: 0.2500\n",
      "Epoch 60/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2496 - val_loss: 0.2482\n",
      "Epoch 61/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2398 - val_loss: 0.2532\n",
      "Epoch 62/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2408 - val_loss: 0.2466\n",
      "Epoch 63/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2407 - val_loss: 0.2288\n",
      "Epoch 64/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2404 - val_loss: 0.2342\n",
      "Epoch 65/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2516 - val_loss: 0.2357\n",
      "Epoch 66/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2367 - val_loss: 0.2353\n",
      "Epoch 67/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2345 - val_loss: 0.2427\n",
      "Epoch 68/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2293 - val_loss: 0.2308\n",
      "Epoch 69/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2281 - val_loss: 0.2391\n",
      "Epoch 70/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2352 - val_loss: 0.2492\n",
      "Epoch 71/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2277 - val_loss: 0.2386\n",
      "Epoch 72/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2245 - val_loss: 0.2446\n",
      "Epoch 73/2000\n",
      "73/73 [==============================] - ETA: 0s - loss: 0.2234Restoring model weights from the end of the best epoch: 63.\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2234 - val_loss: 0.2391\n",
      "Epoch 73: early stopping\n",
      "'########################################################Model6\n",
      "Epoch 1/2000\n",
      "73/73 [==============================] - 8s 88ms/step - loss: 4.4908 - val_loss: 1.6014\n",
      "Epoch 2/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.8435 - val_loss: 0.7827\n",
      "Epoch 3/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.7544 - val_loss: 0.7758\n",
      "Epoch 4/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.7469 - val_loss: 0.7667\n",
      "Epoch 5/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.7307 - val_loss: 0.7411\n",
      "Epoch 6/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.7080 - val_loss: 0.7014\n",
      "Epoch 7/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.6849 - val_loss: 0.6787\n",
      "Epoch 8/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.6696 - val_loss: 0.6703\n",
      "Epoch 9/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.6518 - val_loss: 0.6397\n",
      "Epoch 10/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.6279 - val_loss: 0.6115\n",
      "Epoch 11/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.5965 - val_loss: 0.5699\n",
      "Epoch 12/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.5535 - val_loss: 0.5200\n",
      "Epoch 13/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.5302 - val_loss: 0.5396\n",
      "Epoch 14/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.5086 - val_loss: 0.5007\n",
      "Epoch 15/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.5012 - val_loss: 0.4774\n",
      "Epoch 16/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.4894 - val_loss: 0.4857\n",
      "Epoch 17/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.4854 - val_loss: 0.4808\n",
      "Epoch 18/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.4758 - val_loss: 0.4900\n",
      "Epoch 19/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.4680 - val_loss: 0.4556\n",
      "Epoch 20/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.4643 - val_loss: 0.5138\n",
      "Epoch 21/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.4794 - val_loss: 0.4494\n",
      "Epoch 22/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.4508 - val_loss: 0.4630\n",
      "Epoch 23/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.4545 - val_loss: 0.4626\n",
      "Epoch 24/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.4508 - val_loss: 0.4608\n",
      "Epoch 25/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.4476 - val_loss: 0.4362\n",
      "Epoch 26/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.4438 - val_loss: 0.4341\n",
      "Epoch 27/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.4351 - val_loss: 0.4353\n",
      "Epoch 28/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.4354 - val_loss: 0.4253\n",
      "Epoch 29/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.4203 - val_loss: 0.4251\n",
      "Epoch 30/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.4134 - val_loss: 0.4356\n",
      "Epoch 31/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.4138 - val_loss: 0.3966\n",
      "Epoch 32/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.4067 - val_loss: 0.3970\n",
      "Epoch 33/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.4020 - val_loss: 0.3974\n",
      "Epoch 34/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3870 - val_loss: 0.3634\n",
      "Epoch 35/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3861 - val_loss: 0.3752\n",
      "Epoch 36/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3770 - val_loss: 0.4023\n",
      "Epoch 37/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3803 - val_loss: 0.3622\n",
      "Epoch 38/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 0.3745 - val_loss: 0.3895\n",
      "Epoch 39/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3846 - val_loss: 0.3643\n",
      "Epoch 40/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3663 - val_loss: 0.3779\n",
      "Epoch 41/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3576 - val_loss: 0.3394\n",
      "Epoch 42/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3451 - val_loss: 0.3561\n",
      "Epoch 43/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3437 - val_loss: 0.3352\n",
      "Epoch 44/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3919 - val_loss: 0.3689\n",
      "Epoch 45/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3392 - val_loss: 0.3393\n",
      "Epoch 46/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3304 - val_loss: 0.3459\n",
      "Epoch 47/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3189 - val_loss: 0.3312\n",
      "Epoch 48/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3066 - val_loss: 0.3082\n",
      "Epoch 49/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3076 - val_loss: 0.3242\n",
      "Epoch 50/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2820 - val_loss: 0.3075\n",
      "Epoch 51/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2805 - val_loss: 0.2730\n",
      "Epoch 52/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2700 - val_loss: 0.2855\n",
      "Epoch 53/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2875 - val_loss: 0.2880\n",
      "Epoch 54/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2643 - val_loss: 0.2778\n",
      "Epoch 55/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2627 - val_loss: 0.2492\n",
      "Epoch 56/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2593 - val_loss: 0.3036\n",
      "Epoch 57/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.2513 - val_loss: 0.2916\n",
      "Epoch 58/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2602 - val_loss: 0.2765\n",
      "Epoch 59/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2609 - val_loss: 0.2759\n",
      "Epoch 60/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2525 - val_loss: 0.2461\n",
      "Epoch 61/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.2424 - val_loss: 0.2612\n",
      "Epoch 62/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2457 - val_loss: 0.2324\n",
      "Epoch 63/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2399 - val_loss: 0.2387\n",
      "Epoch 64/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2283 - val_loss: 0.2299\n",
      "Epoch 65/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2307 - val_loss: 0.2435\n",
      "Epoch 66/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2267 - val_loss: 0.2650\n",
      "Epoch 67/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2262 - val_loss: 0.2360\n",
      "Epoch 68/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2216 - val_loss: 0.2353\n",
      "Epoch 69/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2221 - val_loss: 0.2236\n",
      "Epoch 70/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2252 - val_loss: 0.2285\n",
      "Epoch 71/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2199 - val_loss: 0.2250\n",
      "Epoch 72/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2239 - val_loss: 0.2356\n",
      "Epoch 73/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2185 - val_loss: 0.2278\n",
      "Epoch 74/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2210 - val_loss: 0.2380\n",
      "Epoch 75/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.2196 - val_loss: 0.2139\n",
      "Epoch 76/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2139 - val_loss: 0.2175\n",
      "Epoch 77/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2164 - val_loss: 0.2169\n",
      "Epoch 78/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2219 - val_loss: 0.2196\n",
      "Epoch 79/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.2210 - val_loss: 0.2302\n",
      "Epoch 80/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2121 - val_loss: 0.2467\n",
      "Epoch 81/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2128 - val_loss: 0.2238\n",
      "Epoch 82/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2100 - val_loss: 0.2217\n",
      "Epoch 83/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2103 - val_loss: 0.2146\n",
      "Epoch 84/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2075 - val_loss: 0.2122\n",
      "Epoch 85/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2082 - val_loss: 0.2108\n",
      "Epoch 86/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2036 - val_loss: 0.2595\n",
      "Epoch 87/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2117 - val_loss: 0.2358\n",
      "Epoch 88/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2048 - val_loss: 0.2149\n",
      "Epoch 89/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2084 - val_loss: 0.2197\n",
      "Epoch 90/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2005 - val_loss: 0.2146\n",
      "Epoch 91/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2089 - val_loss: 0.2213\n",
      "Epoch 92/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2103 - val_loss: 0.2046\n",
      "Epoch 93/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2018 - val_loss: 0.2302\n",
      "Epoch 94/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 0.2050 - val_loss: 0.2073\n",
      "Epoch 95/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2115 - val_loss: 0.2176\n",
      "Epoch 96/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2050 - val_loss: 0.2110\n",
      "Epoch 97/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.1991 - val_loss: 0.2143\n",
      "Epoch 98/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.1975 - val_loss: 0.2066\n",
      "Epoch 99/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.1975 - val_loss: 0.2159\n",
      "Epoch 100/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2049 - val_loss: 0.2032\n",
      "Epoch 101/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2032 - val_loss: 0.2091\n",
      "Epoch 102/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2023 - val_loss: 0.2244\n",
      "Epoch 103/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.1989 - val_loss: 0.2099\n",
      "Epoch 104/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.1948 - val_loss: 0.2102\n",
      "Epoch 105/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.1980 - val_loss: 0.2139\n",
      "Epoch 106/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.1942 - val_loss: 0.2153\n",
      "Epoch 107/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.1984 - val_loss: 0.2302\n",
      "Epoch 108/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2016 - val_loss: 0.2128\n",
      "Epoch 109/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.1934 - val_loss: 0.2105\n",
      "Epoch 110/2000\n",
      "73/73 [==============================] - ETA: 0s - loss: 0.1943Restoring model weights from the end of the best epoch: 100.\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.1943 - val_loss: 0.2144\n",
      "Epoch 110: early stopping\n",
      "'########################################################Model7\n",
      "Epoch 1/2000\n",
      "73/73 [==============================] - 9s 100ms/step - loss: 3.5739 - val_loss: 1.0168\n",
      "Epoch 2/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.7707 - val_loss: 0.7753\n",
      "Epoch 3/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.7428 - val_loss: 0.7547\n",
      "Epoch 4/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.7189 - val_loss: 0.7166\n",
      "Epoch 5/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.6970 - val_loss: 0.7108\n",
      "Epoch 6/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.6838 - val_loss: 0.6750\n",
      "Epoch 7/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.6644 - val_loss: 0.6730\n",
      "Epoch 8/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.6380 - val_loss: 0.6295\n",
      "Epoch 9/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.6056 - val_loss: 0.5830\n",
      "Epoch 10/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.5625 - val_loss: 0.5470\n",
      "Epoch 11/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.5282 - val_loss: 0.5033\n",
      "Epoch 12/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.5025 - val_loss: 0.4890\n",
      "Epoch 13/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.5130 - val_loss: 0.5007\n",
      "Epoch 14/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.4914 - val_loss: 0.4834\n",
      "Epoch 15/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.4872 - val_loss: 0.4636\n",
      "Epoch 16/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.4697 - val_loss: 0.4624\n",
      "Epoch 17/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.4651 - val_loss: 0.4547\n",
      "Epoch 18/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.4572 - val_loss: 0.4435\n",
      "Epoch 19/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.4530 - val_loss: 0.4417\n",
      "Epoch 20/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.4393 - val_loss: 0.4278\n",
      "Epoch 21/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.4348 - val_loss: 0.4168\n",
      "Epoch 22/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.4214 - val_loss: 0.4114\n",
      "Epoch 23/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.4071 - val_loss: 0.4135\n",
      "Epoch 24/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.4269 - val_loss: 0.4033\n",
      "Epoch 25/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3954 - val_loss: 0.3939\n",
      "Epoch 26/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3973 - val_loss: 0.3752\n",
      "Epoch 27/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3764 - val_loss: 0.3513\n",
      "Epoch 28/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.3755 - val_loss: 0.3645\n",
      "Epoch 29/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3931 - val_loss: 0.3976\n",
      "Epoch 30/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3744 - val_loss: 0.3339\n",
      "Epoch 31/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.3447 - val_loss: 0.3500\n",
      "Epoch 32/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.3428 - val_loss: 0.3220\n",
      "Epoch 33/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.3340 - val_loss: 0.3481\n",
      "Epoch 34/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3282 - val_loss: 0.3155\n",
      "Epoch 35/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3117 - val_loss: 0.2850\n",
      "Epoch 36/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2835 - val_loss: 0.2891\n",
      "Epoch 37/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2852 - val_loss: 0.2775\n",
      "Epoch 38/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.2701 - val_loss: 0.2649\n",
      "Epoch 39/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2700 - val_loss: 0.3291\n",
      "Epoch 40/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3337 - val_loss: 0.3844\n",
      "Epoch 41/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3393 - val_loss: 0.3537\n",
      "Epoch 42/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2964 - val_loss: 0.2826\n",
      "Epoch 43/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2664 - val_loss: 0.2922\n",
      "Epoch 44/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2463 - val_loss: 0.2418\n",
      "Epoch 45/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2402 - val_loss: 0.2418\n",
      "Epoch 46/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2487 - val_loss: 0.2612\n",
      "Epoch 47/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2309 - val_loss: 0.2331\n",
      "Epoch 48/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2279 - val_loss: 0.2353\n",
      "Epoch 49/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2262 - val_loss: 0.2390\n",
      "Epoch 50/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2240 - val_loss: 0.2439\n",
      "Epoch 51/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2247 - val_loss: 0.2229\n",
      "Epoch 52/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2294 - val_loss: 0.2306\n",
      "Epoch 53/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2248 - val_loss: 0.2424\n",
      "Epoch 54/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2167 - val_loss: 0.2264\n",
      "Epoch 55/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2129 - val_loss: 0.2255\n",
      "Epoch 56/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.2152 - val_loss: 0.2638\n",
      "Epoch 57/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2298 - val_loss: 0.2181\n",
      "Epoch 58/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2149 - val_loss: 0.2292\n",
      "Epoch 59/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2176 - val_loss: 0.2296\n",
      "Epoch 60/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2184 - val_loss: 0.2091\n",
      "Epoch 61/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2245 - val_loss: 0.2337\n",
      "Epoch 62/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2090 - val_loss: 0.2166\n",
      "Epoch 63/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2107 - val_loss: 0.2284\n",
      "Epoch 64/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2128 - val_loss: 0.2160\n",
      "Epoch 65/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2058 - val_loss: 0.2153\n",
      "Epoch 66/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2056 - val_loss: 0.2105\n",
      "Epoch 67/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2076 - val_loss: 0.2274\n",
      "Epoch 68/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2042 - val_loss: 0.2080\n",
      "Epoch 69/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2115 - val_loss: 0.2078\n",
      "Epoch 70/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2041 - val_loss: 0.2133\n",
      "Epoch 71/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2084 - val_loss: 0.2126\n",
      "Epoch 72/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2064 - val_loss: 0.2147\n",
      "Epoch 73/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2072 - val_loss: 0.2422\n",
      "Epoch 74/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.2359 - val_loss: 0.2357\n",
      "Epoch 75/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2143 - val_loss: 0.2073\n",
      "Epoch 76/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2081 - val_loss: 0.2047\n",
      "Epoch 77/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2104 - val_loss: 0.2341\n",
      "Epoch 78/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2067 - val_loss: 0.2373\n",
      "Epoch 79/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2035 - val_loss: 0.2057\n",
      "Epoch 80/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1980 - val_loss: 0.2116\n",
      "Epoch 81/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1991 - val_loss: 0.2197\n",
      "Epoch 82/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1979 - val_loss: 0.2291\n",
      "Epoch 83/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2045 - val_loss: 0.2130\n",
      "Epoch 84/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1974 - val_loss: 0.2333\n",
      "Epoch 85/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2031 - val_loss: 0.2208\n",
      "Epoch 86/2000\n",
      "73/73 [==============================] - ETA: 0s - loss: 0.1939Restoring model weights from the end of the best epoch: 76.\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1939 - val_loss: 0.2295\n",
      "Epoch 86: early stopping\n",
      "'########################################################Model8\n",
      "Epoch 1/2000\n",
      "73/73 [==============================] - 9s 100ms/step - loss: 4.1051 - val_loss: 1.6062\n",
      "Epoch 2/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.8702 - val_loss: 0.7835\n",
      "Epoch 3/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.7524 - val_loss: 0.7781\n",
      "Epoch 4/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.7457 - val_loss: 0.7651\n",
      "Epoch 5/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.7353 - val_loss: 0.7492\n",
      "Epoch 6/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.7127 - val_loss: 0.7125\n",
      "Epoch 7/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.6869 - val_loss: 0.6801\n",
      "Epoch 8/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.6621 - val_loss: 0.6516\n",
      "Epoch 9/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.6327 - val_loss: 0.6179\n",
      "Epoch 10/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.6002 - val_loss: 0.5650\n",
      "Epoch 11/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.5427 - val_loss: 0.5121\n",
      "Epoch 12/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.5166 - val_loss: 0.4941\n",
      "Epoch 13/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.5005 - val_loss: 0.4866\n",
      "Epoch 14/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.4855 - val_loss: 0.5004\n",
      "Epoch 15/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.4920 - val_loss: 0.4718\n",
      "Epoch 16/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.4743 - val_loss: 0.4586\n",
      "Epoch 17/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.4702 - val_loss: 0.4625\n",
      "Epoch 18/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.4670 - val_loss: 0.4556\n",
      "Epoch 19/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.4628 - val_loss: 0.4569\n",
      "Epoch 20/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.4590 - val_loss: 0.4426\n",
      "Epoch 21/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.4525 - val_loss: 0.4821\n",
      "Epoch 22/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.4495 - val_loss: 0.4372\n",
      "Epoch 23/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.4333 - val_loss: 0.4309\n",
      "Epoch 24/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.4310 - val_loss: 0.4405\n",
      "Epoch 25/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.4118 - val_loss: 0.4177\n",
      "Epoch 26/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.3906 - val_loss: 0.3809\n",
      "Epoch 27/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.4277 - val_loss: 0.4227\n",
      "Epoch 28/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.3777 - val_loss: 0.3940\n",
      "Epoch 29/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.3348 - val_loss: 0.3472\n",
      "Epoch 30/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.3318 - val_loss: 0.3600\n",
      "Epoch 31/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.3516 - val_loss: 0.3621\n",
      "Epoch 32/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.3033 - val_loss: 0.3426\n",
      "Epoch 33/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2961 - val_loss: 0.3077\n",
      "Epoch 34/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.3007 - val_loss: 0.3129\n",
      "Epoch 35/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2876 - val_loss: 0.3241\n",
      "Epoch 36/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2879 - val_loss: 0.3108\n",
      "Epoch 37/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.2829 - val_loss: 0.3132\n",
      "Epoch 38/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2746 - val_loss: 0.2966\n",
      "Epoch 39/2000\n",
      "73/73 [==============================] - 7s 98ms/step - loss: 0.2676 - val_loss: 0.3146\n",
      "Epoch 40/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2775 - val_loss: 0.3113\n",
      "Epoch 41/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 0.2678 - val_loss: 0.3016\n",
      "Epoch 42/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2631 - val_loss: 0.3118\n",
      "Epoch 43/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2650 - val_loss: 0.2715\n",
      "Epoch 44/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.2598 - val_loss: 0.2779\n",
      "Epoch 45/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2558 - val_loss: 0.2836\n",
      "Epoch 46/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.2601 - val_loss: 0.2782\n",
      "Epoch 47/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2508 - val_loss: 0.2714\n",
      "Epoch 48/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2487 - val_loss: 0.2730\n",
      "Epoch 49/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2543 - val_loss: 0.2644\n",
      "Epoch 50/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2444 - val_loss: 0.2950\n",
      "Epoch 51/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2469 - val_loss: 0.2828\n",
      "Epoch 52/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2476 - val_loss: 0.2741\n",
      "Epoch 53/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.2395 - val_loss: 0.2594\n",
      "Epoch 54/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2475 - val_loss: 0.2931\n",
      "Epoch 55/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2438 - val_loss: 0.2676\n",
      "Epoch 56/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2368 - val_loss: 0.2567\n",
      "Epoch 57/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2357 - val_loss: 0.2631\n",
      "Epoch 58/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2343 - val_loss: 0.2669\n",
      "Epoch 59/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.2337 - val_loss: 0.2533\n",
      "Epoch 60/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2350 - val_loss: 0.2714\n",
      "Epoch 61/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2391 - val_loss: 0.2790\n",
      "Epoch 62/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2441 - val_loss: 0.2632\n",
      "Epoch 63/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.2342 - val_loss: 0.2654\n",
      "Epoch 64/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2392 - val_loss: 0.2593\n",
      "Epoch 65/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2298 - val_loss: 0.2489\n",
      "Epoch 66/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2317 - val_loss: 0.2950\n",
      "Epoch 67/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2531 - val_loss: 0.2732\n",
      "Epoch 68/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.2364 - val_loss: 0.2657\n",
      "Epoch 69/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.2243 - val_loss: 0.2473\n",
      "Epoch 70/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.2291 - val_loss: 0.2730\n",
      "Epoch 71/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.2272 - val_loss: 0.2465\n",
      "Epoch 72/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2375 - val_loss: 0.2581\n",
      "Epoch 73/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.2285 - val_loss: 0.2544\n",
      "Epoch 74/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2261 - val_loss: 0.2635\n",
      "Epoch 75/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.2284 - val_loss: 0.2504\n",
      "Epoch 76/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.2203 - val_loss: 0.2496\n",
      "Epoch 77/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2218 - val_loss: 0.2671\n",
      "Epoch 78/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.2272 - val_loss: 0.2735\n",
      "Epoch 79/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2216 - val_loss: 0.2578\n",
      "Epoch 80/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2228 - val_loss: 0.2532\n",
      "Epoch 81/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2405 - val_loss: 0.2427\n",
      "Epoch 82/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2238 - val_loss: 0.2564\n",
      "Epoch 83/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.2216 - val_loss: 0.2707\n",
      "Epoch 84/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.2405 - val_loss: 0.2634\n",
      "Epoch 85/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2317 - val_loss: 0.2541\n",
      "Epoch 86/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.2183 - val_loss: 0.2707\n",
      "Epoch 87/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2227 - val_loss: 0.2510\n",
      "Epoch 88/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.2176 - val_loss: 0.2434\n",
      "Epoch 89/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.2187 - val_loss: 0.2488\n",
      "Epoch 90/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2143 - val_loss: 0.2570\n",
      "Epoch 91/2000\n",
      "73/73 [==============================] - ETA: 0s - loss: 0.2150Restoring model weights from the end of the best epoch: 81.\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.2150 - val_loss: 0.2478\n",
      "Epoch 91: early stopping\n",
      "'########################################################Model9\n",
      "Epoch 1/2000\n",
      "73/73 [==============================] - 8s 97ms/step - loss: 14.5783 - val_loss: 1.9413\n",
      "Epoch 2/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.9792 - val_loss: 0.9291\n",
      "Epoch 3/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.8513 - val_loss: 0.9100\n",
      "Epoch 4/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.8368 - val_loss: 0.8869\n",
      "Epoch 5/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.8022 - val_loss: 0.8300\n",
      "Epoch 6/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.7589 - val_loss: 0.7724\n",
      "Epoch 7/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.7376 - val_loss: 0.7534\n",
      "Epoch 8/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.7068 - val_loss: 0.7207\n",
      "Epoch 9/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.6903 - val_loss: 0.7699\n",
      "Epoch 10/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.6810 - val_loss: 0.6856\n",
      "Epoch 11/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.6739 - val_loss: 0.6710\n",
      "Epoch 12/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.6517 - val_loss: 0.6537\n",
      "Epoch 13/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.6368 - val_loss: 0.6361\n",
      "Epoch 14/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.6222 - val_loss: 0.6204\n",
      "Epoch 15/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.6053 - val_loss: 0.6030\n",
      "Epoch 16/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.5928 - val_loss: 0.5809\n",
      "Epoch 17/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.5658 - val_loss: 0.5560\n",
      "Epoch 18/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.5388 - val_loss: 0.5830\n",
      "Epoch 19/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.5168 - val_loss: 0.4930\n",
      "Epoch 20/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.4828 - val_loss: 0.4591\n",
      "Epoch 21/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.4561 - val_loss: 0.4413\n",
      "Epoch 22/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.4434 - val_loss: 0.4479\n",
      "Epoch 23/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.4669 - val_loss: 0.4353\n",
      "Epoch 24/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.4384 - val_loss: 0.4233\n",
      "Epoch 25/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.4313 - val_loss: 0.4492\n",
      "Epoch 26/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.4272 - val_loss: 0.4097\n",
      "Epoch 27/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.4104 - val_loss: 0.4305\n",
      "Epoch 28/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.4065 - val_loss: 0.4048\n",
      "Epoch 29/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.4053 - val_loss: 0.3951\n",
      "Epoch 30/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.4013 - val_loss: 0.3995\n",
      "Epoch 31/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3847 - val_loss: 0.3752\n",
      "Epoch 32/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3708 - val_loss: 0.3677\n",
      "Epoch 33/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3494 - val_loss: 0.3651\n",
      "Epoch 34/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3901 - val_loss: 0.3863\n",
      "Epoch 35/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3693 - val_loss: 0.3350\n",
      "Epoch 36/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3227 - val_loss: 0.3223\n",
      "Epoch 37/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3462 - val_loss: 0.3699\n",
      "Epoch 38/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.3272 - val_loss: 0.2885\n",
      "Epoch 39/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2872 - val_loss: 0.2696\n",
      "Epoch 40/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.3006 - val_loss: 0.3259\n",
      "Epoch 41/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3040 - val_loss: 0.2829\n",
      "Epoch 42/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2665 - val_loss: 0.3156\n",
      "Epoch 43/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2565 - val_loss: 0.2405\n",
      "Epoch 44/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2412 - val_loss: 0.2349\n",
      "Epoch 45/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2365 - val_loss: 0.2213\n",
      "Epoch 46/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2283 - val_loss: 0.3280\n",
      "Epoch 47/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2705 - val_loss: 0.2068\n",
      "Epoch 48/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2302 - val_loss: 0.1883\n",
      "Epoch 49/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2046 - val_loss: 0.1927\n",
      "Epoch 50/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.1981 - val_loss: 0.1948\n",
      "Epoch 51/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.1923 - val_loss: 0.2097\n",
      "Epoch 52/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.1673 - val_loss: 0.1771\n",
      "Epoch 53/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.1615 - val_loss: 0.2057\n",
      "Epoch 54/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.1777 - val_loss: 0.2068\n",
      "Epoch 55/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.1588 - val_loss: 0.1550\n",
      "Epoch 56/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.1538 - val_loss: 0.1497\n",
      "Epoch 57/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.1452 - val_loss: 0.1555\n",
      "Epoch 58/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.1427 - val_loss: 0.1526\n",
      "Epoch 59/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.1534 - val_loss: 0.1438\n",
      "Epoch 60/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.1598 - val_loss: 0.1429\n",
      "Epoch 61/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.1344 - val_loss: 0.1537\n",
      "Epoch 62/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.1370 - val_loss: 0.1561\n",
      "Epoch 63/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.1346 - val_loss: 0.1287\n",
      "Epoch 64/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.1313 - val_loss: 0.1380\n",
      "Epoch 65/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.1326 - val_loss: 0.1429\n",
      "Epoch 66/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.1260 - val_loss: 0.1349\n",
      "Epoch 67/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.1377 - val_loss: 0.1510\n",
      "Epoch 68/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.1318 - val_loss: 0.1226\n",
      "Epoch 69/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.1235 - val_loss: 0.1508\n",
      "Epoch 70/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.1251 - val_loss: 0.1266\n",
      "Epoch 71/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.1215 - val_loss: 0.1244\n",
      "Epoch 72/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.1237 - val_loss: 0.1455\n",
      "Epoch 73/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.1229 - val_loss: 0.1267\n",
      "Epoch 74/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.1183 - val_loss: 0.1396\n",
      "Epoch 75/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.1185 - val_loss: 0.1215\n",
      "Epoch 76/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.1188 - val_loss: 0.1403\n",
      "Epoch 77/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.1276 - val_loss: 0.1593\n",
      "Epoch 78/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.1262 - val_loss: 0.1296\n",
      "Epoch 79/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.1239 - val_loss: 0.1133\n",
      "Epoch 80/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.1164 - val_loss: 0.1156\n",
      "Epoch 81/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.1075 - val_loss: 0.1175\n",
      "Epoch 82/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.1067 - val_loss: 0.1524\n",
      "Epoch 83/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.1135 - val_loss: 0.1312\n",
      "Epoch 84/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.1077 - val_loss: 0.1362\n",
      "Epoch 85/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.1074 - val_loss: 0.1515\n",
      "Epoch 86/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.1154 - val_loss: 0.1131\n",
      "Epoch 87/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.1225 - val_loss: 0.1248\n",
      "Epoch 88/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.1235 - val_loss: 0.1229\n",
      "Epoch 89/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.1093 - val_loss: 0.1098\n",
      "Epoch 90/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.1098 - val_loss: 0.1301\n",
      "Epoch 91/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.1159 - val_loss: 0.1626\n",
      "Epoch 92/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.1138 - val_loss: 0.1253\n",
      "Epoch 93/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.1015 - val_loss: 0.1225\n",
      "Epoch 94/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.0996 - val_loss: 0.1193\n",
      "Epoch 95/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 0.1087 - val_loss: 0.1189\n",
      "Epoch 96/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.1017 - val_loss: 0.1331\n",
      "Epoch 97/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.1001 - val_loss: 0.1180\n",
      "Epoch 98/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.0972 - val_loss: 0.1435\n",
      "Epoch 99/2000\n",
      "73/73 [==============================] - ETA: 0s - loss: 0.1009Restoring model weights from the end of the best epoch: 89.\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.1009 - val_loss: 0.1471\n",
      "Epoch 99: early stopping\n",
      "'########################################################Model0\n",
      "Epoch 1/2000\n",
      "73/73 [==============================] - 8s 96ms/step - loss: 17.3883 - val_loss: 3.2876\n",
      "Epoch 2/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 1.2433 - val_loss: 0.9410\n",
      "Epoch 3/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.8625 - val_loss: 0.9340\n",
      "Epoch 4/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.8520 - val_loss: 0.9135\n",
      "Epoch 5/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.8291 - val_loss: 0.8837\n",
      "Epoch 6/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.7869 - val_loss: 0.8136\n",
      "Epoch 7/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.7349 - val_loss: 0.7522\n",
      "Epoch 8/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.7108 - val_loss: 0.7024\n",
      "Epoch 9/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.6832 - val_loss: 0.6642\n",
      "Epoch 10/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.6624 - val_loss: 0.7167\n",
      "Epoch 11/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.6784 - val_loss: 0.6801\n",
      "Epoch 12/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.6602 - val_loss: 0.6696\n",
      "Epoch 13/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.6430 - val_loss: 0.6334\n",
      "Epoch 14/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.6345 - val_loss: 0.6545\n",
      "Epoch 15/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.6005 - val_loss: 0.5863\n",
      "Epoch 16/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.5695 - val_loss: 0.5927\n",
      "Epoch 17/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.5613 - val_loss: 0.5245\n",
      "Epoch 18/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.5674 - val_loss: 0.5758\n",
      "Epoch 19/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.5324 - val_loss: 0.5223\n",
      "Epoch 20/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.4980 - val_loss: 0.4841\n",
      "Epoch 21/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.4642 - val_loss: 0.4772\n",
      "Epoch 22/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.4793 - val_loss: 0.4650\n",
      "Epoch 23/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.4537 - val_loss: 0.4610\n",
      "Epoch 24/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.4469 - val_loss: 0.4554\n",
      "Epoch 25/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.4389 - val_loss: 0.4379\n",
      "Epoch 26/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.4420 - val_loss: 0.4487\n",
      "Epoch 27/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.4193 - val_loss: 0.4125\n",
      "Epoch 28/2000\n",
      "73/73 [==============================] - 6s 82ms/step - loss: 0.4392 - val_loss: 0.5045\n",
      "Epoch 29/2000\n",
      "73/73 [==============================] - 6s 81ms/step - loss: 0.4616 - val_loss: 0.4556\n",
      "Epoch 30/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.4391 - val_loss: 0.4332\n",
      "Epoch 31/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.4309 - val_loss: 0.4368\n",
      "Epoch 32/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.4292 - val_loss: 0.4207\n",
      "Epoch 33/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 0.4267 - val_loss: 0.4152\n",
      "Epoch 34/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.4229 - val_loss: 0.4369\n",
      "Epoch 35/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.4155 - val_loss: 0.4058\n",
      "Epoch 36/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.4069 - val_loss: 0.4086\n",
      "Epoch 37/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.4051 - val_loss: 0.3969\n",
      "Epoch 38/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3985 - val_loss: 0.4078\n",
      "Epoch 39/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.4034 - val_loss: 0.3933\n",
      "Epoch 40/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3945 - val_loss: 0.3880\n",
      "Epoch 41/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3919 - val_loss: 0.3830\n",
      "Epoch 42/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3873 - val_loss: 0.3891\n",
      "Epoch 43/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3821 - val_loss: 0.3822\n",
      "Epoch 44/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3838 - val_loss: 0.3960\n",
      "Epoch 45/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3815 - val_loss: 0.3716\n",
      "Epoch 46/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3789 - val_loss: 0.3707\n",
      "Epoch 47/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3745 - val_loss: 0.3747\n",
      "Epoch 48/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.3706 - val_loss: 0.3717\n",
      "Epoch 49/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3681 - val_loss: 0.3596\n",
      "Epoch 50/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3617 - val_loss: 0.3551\n",
      "Epoch 51/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3643 - val_loss: 0.3547\n",
      "Epoch 52/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 0.3688 - val_loss: 0.3670\n",
      "Epoch 53/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3608 - val_loss: 0.3505\n",
      "Epoch 54/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3575 - val_loss: 0.3574\n",
      "Epoch 55/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3570 - val_loss: 0.3483\n",
      "Epoch 56/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3555 - val_loss: 0.3430\n",
      "Epoch 57/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3559 - val_loss: 0.3419\n",
      "Epoch 58/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3524 - val_loss: 0.3433\n",
      "Epoch 59/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3490 - val_loss: 0.3475\n",
      "Epoch 60/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3434 - val_loss: 0.3235\n",
      "Epoch 61/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3395 - val_loss: 0.3337\n",
      "Epoch 62/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3456 - val_loss: 0.3311\n",
      "Epoch 63/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3225 - val_loss: 0.3057\n",
      "Epoch 64/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2994 - val_loss: 0.3029\n",
      "Epoch 65/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3005 - val_loss: 0.3154\n",
      "Epoch 66/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.2928 - val_loss: 0.3085\n",
      "Epoch 67/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2908 - val_loss: 0.2944\n",
      "Epoch 68/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2793 - val_loss: 0.2677\n",
      "Epoch 69/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2625 - val_loss: 0.3075\n",
      "Epoch 70/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2820 - val_loss: 0.2677\n",
      "Epoch 71/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 0.2685 - val_loss: 0.2654\n",
      "Epoch 72/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2428 - val_loss: 0.2629\n",
      "Epoch 73/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2473 - val_loss: 0.2868\n",
      "Epoch 74/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2707 - val_loss: 0.3015\n",
      "Epoch 75/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2576 - val_loss: 0.2378\n",
      "Epoch 76/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2483 - val_loss: 0.2461\n",
      "Epoch 77/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2393 - val_loss: 0.2316\n",
      "Epoch 78/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2313 - val_loss: 0.2462\n",
      "Epoch 79/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2320 - val_loss: 0.2227\n",
      "Epoch 80/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2214 - val_loss: 0.2232\n",
      "Epoch 81/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2207 - val_loss: 0.2309\n",
      "Epoch 82/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2187 - val_loss: 0.2821\n",
      "Epoch 83/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2246 - val_loss: 0.2702\n",
      "Epoch 84/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2979 - val_loss: 0.2806\n",
      "Epoch 85/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.2902 - val_loss: 0.2730\n",
      "Epoch 86/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2542 - val_loss: 0.2702\n",
      "Epoch 87/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2568 - val_loss: 0.3067\n",
      "Epoch 88/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2689 - val_loss: 0.2360\n",
      "Epoch 89/2000\n",
      "73/73 [==============================] - ETA: 0s - loss: 0.2463Restoring model weights from the end of the best epoch: 79.\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.2463 - val_loss: 0.2769\n",
      "Epoch 89: early stopping\n",
      "'########################################################Model1\n",
      "Epoch 1/2000\n",
      "73/73 [==============================] - 9s 100ms/step - loss: 21.5798 - val_loss: 6.2750\n",
      "Epoch 2/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 2.1255 - val_loss: 1.0108\n",
      "Epoch 3/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.8819 - val_loss: 0.9527\n",
      "Epoch 4/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.8705 - val_loss: 0.9506\n",
      "Epoch 5/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.8632 - val_loss: 0.9320\n",
      "Epoch 6/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.8526 - val_loss: 0.9104\n",
      "Epoch 7/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.8333 - val_loss: 0.8820\n",
      "Epoch 8/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.8026 - val_loss: 0.8380\n",
      "Epoch 9/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.7544 - val_loss: 0.7823\n",
      "Epoch 10/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.6919 - val_loss: 0.7944\n",
      "Epoch 11/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.7530 - val_loss: 0.7468\n",
      "Epoch 12/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.6912 - val_loss: 0.7886\n",
      "Epoch 13/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.6837 - val_loss: 0.7018\n",
      "Epoch 14/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.6616 - val_loss: 0.6492\n",
      "Epoch 15/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.6522 - val_loss: 0.7354\n",
      "Epoch 16/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.6683 - val_loss: 0.6662\n",
      "Epoch 17/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.6333 - val_loss: 0.6546\n",
      "Epoch 18/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.6225 - val_loss: 0.6352\n",
      "Epoch 19/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.6087 - val_loss: 0.6144\n",
      "Epoch 20/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.5810 - val_loss: 0.5826\n",
      "Epoch 21/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.5618 - val_loss: 0.5709\n",
      "Epoch 22/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.5395 - val_loss: 0.5333\n",
      "Epoch 23/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.5112 - val_loss: 0.5104\n",
      "Epoch 24/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.4852 - val_loss: 0.5134\n",
      "Epoch 25/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.4763 - val_loss: 0.4694\n",
      "Epoch 26/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.4517 - val_loss: 0.4469\n",
      "Epoch 27/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.4447 - val_loss: 0.4513\n",
      "Epoch 28/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.4354 - val_loss: 0.4283\n",
      "Epoch 29/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.4283 - val_loss: 0.4210\n",
      "Epoch 30/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.4408 - val_loss: 0.4199\n",
      "Epoch 31/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.4180 - val_loss: 0.4136\n",
      "Epoch 32/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.4218 - val_loss: 0.4161\n",
      "Epoch 33/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.4090 - val_loss: 0.3990\n",
      "Epoch 34/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.4027 - val_loss: 0.3990\n",
      "Epoch 35/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3969 - val_loss: 0.3901\n",
      "Epoch 36/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.3950 - val_loss: 0.3876\n",
      "Epoch 37/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3923 - val_loss: 0.3881\n",
      "Epoch 38/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.3844 - val_loss: 0.3971\n",
      "Epoch 39/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3940 - val_loss: 0.4012\n",
      "Epoch 40/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3801 - val_loss: 0.3681\n",
      "Epoch 41/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3790 - val_loss: 0.3749\n",
      "Epoch 42/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.3838 - val_loss: 0.3800\n",
      "Epoch 43/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3713 - val_loss: 0.3592\n",
      "Epoch 44/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3656 - val_loss: 0.3820\n",
      "Epoch 45/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3636 - val_loss: 0.3576\n",
      "Epoch 46/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.3620 - val_loss: 0.3516\n",
      "Epoch 47/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3581 - val_loss: 0.3507\n",
      "Epoch 48/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3530 - val_loss: 0.3530\n",
      "Epoch 49/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3533 - val_loss: 0.3365\n",
      "Epoch 50/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3471 - val_loss: 0.3278\n",
      "Epoch 51/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3431 - val_loss: 0.3601\n",
      "Epoch 52/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3393 - val_loss: 0.3334\n",
      "Epoch 53/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3153 - val_loss: 0.3171\n",
      "Epoch 54/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.2939 - val_loss: 0.3914\n",
      "Epoch 55/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2584 - val_loss: 0.2506\n",
      "Epoch 56/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2615 - val_loss: 0.3063\n",
      "Epoch 57/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2407 - val_loss: 0.2907\n",
      "Epoch 58/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2760 - val_loss: 0.2917\n",
      "Epoch 59/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2086 - val_loss: 0.2191\n",
      "Epoch 60/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2080 - val_loss: 0.2510\n",
      "Epoch 61/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1841 - val_loss: 0.2067\n",
      "Epoch 62/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1916 - val_loss: 0.2343\n",
      "Epoch 63/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1866 - val_loss: 0.2311\n",
      "Epoch 64/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1871 - val_loss: 0.2423\n",
      "Epoch 65/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1802 - val_loss: 0.1764\n",
      "Epoch 66/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.1706 - val_loss: 0.1962\n",
      "Epoch 67/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1610 - val_loss: 0.2186\n",
      "Epoch 68/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.1786 - val_loss: 0.1763\n",
      "Epoch 69/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1595 - val_loss: 0.2200\n",
      "Epoch 70/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1598 - val_loss: 0.1720\n",
      "Epoch 71/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1652 - val_loss: 0.1725\n",
      "Epoch 72/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.1638 - val_loss: 0.1674\n",
      "Epoch 73/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.1564 - val_loss: 0.1795\n",
      "Epoch 74/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1474 - val_loss: 0.1801\n",
      "Epoch 75/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.1528 - val_loss: 0.1716\n",
      "Epoch 76/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.1534 - val_loss: 0.1594\n",
      "Epoch 77/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1515 - val_loss: 0.1573\n",
      "Epoch 78/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1414 - val_loss: 0.1706\n",
      "Epoch 79/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1436 - val_loss: 0.1553\n",
      "Epoch 80/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1420 - val_loss: 0.1477\n",
      "Epoch 81/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1671 - val_loss: 0.1763\n",
      "Epoch 82/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1426 - val_loss: 0.1744\n",
      "Epoch 83/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.1389 - val_loss: 0.1523\n",
      "Epoch 84/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1330 - val_loss: 0.1607\n",
      "Epoch 85/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.1354 - val_loss: 0.1506\n",
      "Epoch 86/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1295 - val_loss: 0.1662\n",
      "Epoch 87/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1394 - val_loss: 0.1464\n",
      "Epoch 88/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1362 - val_loss: 0.1671\n",
      "Epoch 89/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.1299 - val_loss: 0.1312\n",
      "Epoch 90/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.1269 - val_loss: 0.1380\n",
      "Epoch 91/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1297 - val_loss: 0.1505\n",
      "Epoch 92/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.1296 - val_loss: 0.1324\n",
      "Epoch 93/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1277 - val_loss: 0.1469\n",
      "Epoch 94/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1294 - val_loss: 0.1442\n",
      "Epoch 95/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1279 - val_loss: 0.1670\n",
      "Epoch 96/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1304 - val_loss: 0.1562\n",
      "Epoch 97/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1276 - val_loss: 0.1217\n",
      "Epoch 98/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1244 - val_loss: 0.1347\n",
      "Epoch 99/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1313 - val_loss: 0.1518\n",
      "Epoch 100/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1209 - val_loss: 0.1207\n",
      "Epoch 101/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.1219 - val_loss: 0.1254\n",
      "Epoch 102/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1215 - val_loss: 0.1436\n",
      "Epoch 103/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1188 - val_loss: 0.1160\n",
      "Epoch 104/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1297 - val_loss: 0.1264\n",
      "Epoch 105/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1270 - val_loss: 0.1209\n",
      "Epoch 106/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1177 - val_loss: 0.1253\n",
      "Epoch 107/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.1143 - val_loss: 0.1257\n",
      "Epoch 108/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.1170 - val_loss: 0.1347\n",
      "Epoch 109/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1172 - val_loss: 0.1223\n",
      "Epoch 110/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1152 - val_loss: 0.1236\n",
      "Epoch 111/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.1102 - val_loss: 0.1201\n",
      "Epoch 112/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.1132 - val_loss: 0.1104\n",
      "Epoch 113/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1124 - val_loss: 0.1334\n",
      "Epoch 114/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1097 - val_loss: 0.1183\n",
      "Epoch 115/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1115 - val_loss: 0.1156\n",
      "Epoch 116/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1100 - val_loss: 0.1237\n",
      "Epoch 117/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1065 - val_loss: 0.1282\n",
      "Epoch 118/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.1139 - val_loss: 0.1292\n",
      "Epoch 119/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.1088 - val_loss: 0.1196\n",
      "Epoch 120/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1080 - val_loss: 0.1263\n",
      "Epoch 121/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.1060 - val_loss: 0.1385\n",
      "Epoch 122/2000\n",
      "73/73 [==============================] - ETA: 0s - loss: 0.1107Restoring model weights from the end of the best epoch: 112.\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1107 - val_loss: 0.1146\n",
      "Epoch 122: early stopping\n",
      "'########################################################Model2\n",
      "Epoch 1/2000\n",
      "73/73 [==============================] - 9s 100ms/step - loss: 17.9714 - val_loss: 3.4003\n",
      "Epoch 2/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 1.2656 - val_loss: 0.9347\n",
      "Epoch 3/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.8568 - val_loss: 0.9194\n",
      "Epoch 4/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.8420 - val_loss: 0.8998\n",
      "Epoch 5/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.8118 - val_loss: 0.8390\n",
      "Epoch 6/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.7164 - val_loss: 0.8459\n",
      "Epoch 7/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.7780 - val_loss: 0.7718\n",
      "Epoch 8/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.7268 - val_loss: 0.7364\n",
      "Epoch 9/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.7152 - val_loss: 0.7094\n",
      "Epoch 10/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.7005 - val_loss: 0.7169\n",
      "Epoch 11/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.6951 - val_loss: 0.6925\n",
      "Epoch 12/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.6723 - val_loss: 0.6658\n",
      "Epoch 13/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.6606 - val_loss: 0.6570\n",
      "Epoch 14/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.6370 - val_loss: 0.6163\n",
      "Epoch 15/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.6075 - val_loss: 0.6416\n",
      "Epoch 16/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.6596 - val_loss: 0.6442\n",
      "Epoch 17/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.6016 - val_loss: 0.5895\n",
      "Epoch 18/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.5658 - val_loss: 0.5523\n",
      "Epoch 19/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.5092 - val_loss: 0.5119\n",
      "Epoch 20/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.5242 - val_loss: 0.5225\n",
      "Epoch 21/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.4942 - val_loss: 0.4853\n",
      "Epoch 22/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.4673 - val_loss: 0.4957\n",
      "Epoch 23/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.4482 - val_loss: 0.4515\n",
      "Epoch 24/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.4437 - val_loss: 0.4484\n",
      "Epoch 25/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.4344 - val_loss: 0.4324\n",
      "Epoch 26/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.4406 - val_loss: 0.4242\n",
      "Epoch 27/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.4244 - val_loss: 0.4281\n",
      "Epoch 28/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.4122 - val_loss: 0.4012\n",
      "Epoch 29/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3908 - val_loss: 0.3836\n",
      "Epoch 30/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3985 - val_loss: 0.4111\n",
      "Epoch 31/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.4037 - val_loss: 0.4660\n",
      "Epoch 32/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.4095 - val_loss: 0.3958\n",
      "Epoch 33/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.4015 - val_loss: 0.3942\n",
      "Epoch 34/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.3967 - val_loss: 0.3925\n",
      "Epoch 35/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3871 - val_loss: 0.3854\n",
      "Epoch 36/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3926 - val_loss: 0.3799\n",
      "Epoch 37/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.3913 - val_loss: 0.3737\n",
      "Epoch 38/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3833 - val_loss: 0.3729\n",
      "Epoch 39/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.3796 - val_loss: 0.3858\n",
      "Epoch 40/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.3707 - val_loss: 0.3632\n",
      "Epoch 41/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3708 - val_loss: 0.3692\n",
      "Epoch 42/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3770 - val_loss: 0.3651\n",
      "Epoch 43/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.3788 - val_loss: 0.3711\n",
      "Epoch 44/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.3637 - val_loss: 0.3549\n",
      "Epoch 45/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.3652 - val_loss: 0.3550\n",
      "Epoch 46/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.3562 - val_loss: 0.3546\n",
      "Epoch 47/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.3612 - val_loss: 0.3943\n",
      "Epoch 48/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3604 - val_loss: 0.3555\n",
      "Epoch 49/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3598 - val_loss: 0.3445\n",
      "Epoch 50/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.3540 - val_loss: 0.3452\n",
      "Epoch 51/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.3543 - val_loss: 0.3452\n",
      "Epoch 52/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3528 - val_loss: 0.3444\n",
      "Epoch 53/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.3471 - val_loss: 0.3396\n",
      "Epoch 54/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.3492 - val_loss: 0.3408\n",
      "Epoch 55/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3450 - val_loss: 0.3424\n",
      "Epoch 56/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3465 - val_loss: 0.3364\n",
      "Epoch 57/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.3486 - val_loss: 0.3402\n",
      "Epoch 58/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.3510 - val_loss: 0.3387\n",
      "Epoch 59/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.3425 - val_loss: 0.3324\n",
      "Epoch 60/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.3434 - val_loss: 0.3316\n",
      "Epoch 61/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.3477 - val_loss: 0.3375\n",
      "Epoch 62/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3504 - val_loss: 0.3325\n",
      "Epoch 63/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.3671 - val_loss: 0.3304\n",
      "Epoch 64/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.3456 - val_loss: 0.3320\n",
      "Epoch 65/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3365 - val_loss: 0.3348\n",
      "Epoch 66/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3420 - val_loss: 0.3276\n",
      "Epoch 67/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.3356 - val_loss: 0.3403\n",
      "Epoch 68/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.3302 - val_loss: 0.3243\n",
      "Epoch 69/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3239 - val_loss: 0.3130\n",
      "Epoch 70/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.3464 - val_loss: 0.3853\n",
      "Epoch 71/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.3593 - val_loss: 0.3347\n",
      "Epoch 72/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3375 - val_loss: 0.3399\n",
      "Epoch 73/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.3398 - val_loss: 0.3296\n",
      "Epoch 74/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3343 - val_loss: 0.3224\n",
      "Epoch 75/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3244 - val_loss: 0.3269\n",
      "Epoch 76/2000\n",
      "73/73 [==============================] - 7s 98ms/step - loss: 0.2991 - val_loss: 0.3296\n",
      "Epoch 77/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.3004 - val_loss: 0.2762\n",
      "Epoch 78/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2565 - val_loss: 0.2665\n",
      "Epoch 79/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.3016 - val_loss: 0.3130\n",
      "Epoch 80/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2684 - val_loss: 0.2445\n",
      "Epoch 81/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2523 - val_loss: 0.2737\n",
      "Epoch 82/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2374 - val_loss: 0.2162\n",
      "Epoch 83/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2311 - val_loss: 0.2159\n",
      "Epoch 84/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2044 - val_loss: 0.2475\n",
      "Epoch 85/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2487 - val_loss: 0.2289\n",
      "Epoch 86/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.2156 - val_loss: 0.2008\n",
      "Epoch 87/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1997 - val_loss: 0.1999\n",
      "Epoch 88/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1889 - val_loss: 0.2076\n",
      "Epoch 89/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1871 - val_loss: 0.1823\n",
      "Epoch 90/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1802 - val_loss: 0.1948\n",
      "Epoch 91/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1724 - val_loss: 0.1938\n",
      "Epoch 92/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.1820 - val_loss: 0.1863\n",
      "Epoch 93/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1686 - val_loss: 0.1831\n",
      "Epoch 94/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1633 - val_loss: 0.1748\n",
      "Epoch 95/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1694 - val_loss: 0.1891\n",
      "Epoch 96/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1654 - val_loss: 0.2019\n",
      "Epoch 97/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1706 - val_loss: 0.1601\n",
      "Epoch 98/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1619 - val_loss: 0.1688\n",
      "Epoch 99/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1583 - val_loss: 0.1501\n",
      "Epoch 100/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1515 - val_loss: 0.1646\n",
      "Epoch 101/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.1487 - val_loss: 0.1605\n",
      "Epoch 102/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1523 - val_loss: 0.1495\n",
      "Epoch 103/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1508 - val_loss: 0.1556\n",
      "Epoch 104/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1666 - val_loss: 0.1651\n",
      "Epoch 105/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.1451 - val_loss: 0.1525\n",
      "Epoch 106/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1524 - val_loss: 0.1552\n",
      "Epoch 107/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.1459 - val_loss: 0.1526\n",
      "Epoch 108/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1416 - val_loss: 0.1541\n",
      "Epoch 109/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1439 - val_loss: 0.1524\n",
      "Epoch 110/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.1471 - val_loss: 0.1954\n",
      "Epoch 111/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1396 - val_loss: 0.1377\n",
      "Epoch 112/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1308 - val_loss: 0.1343\n",
      "Epoch 113/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1341 - val_loss: 0.1473\n",
      "Epoch 114/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.1248 - val_loss: 0.1685\n",
      "Epoch 115/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.1354 - val_loss: 0.1315\n",
      "Epoch 116/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1261 - val_loss: 0.1416\n",
      "Epoch 117/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1331 - val_loss: 0.1588\n",
      "Epoch 118/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.1273 - val_loss: 0.1300\n",
      "Epoch 119/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1159 - val_loss: 0.1409\n",
      "Epoch 120/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1190 - val_loss: 0.1288\n",
      "Epoch 121/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1217 - val_loss: 0.1304\n",
      "Epoch 122/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1137 - val_loss: 0.1299\n",
      "Epoch 123/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1191 - val_loss: 0.1188\n",
      "Epoch 124/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1191 - val_loss: 0.1242\n",
      "Epoch 125/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1207 - val_loss: 0.1463\n",
      "Epoch 126/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1266 - val_loss: 0.1253\n",
      "Epoch 127/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1138 - val_loss: 0.1280\n",
      "Epoch 128/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.1174 - val_loss: 0.1391\n",
      "Epoch 129/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1202 - val_loss: 0.1324\n",
      "Epoch 130/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1125 - val_loss: 0.1282\n",
      "Epoch 131/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1072 - val_loss: 0.1284\n",
      "Epoch 132/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1117 - val_loss: 0.1235\n",
      "Epoch 133/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1039 - val_loss: 0.1175\n",
      "Epoch 134/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1057 - val_loss: 0.1349\n",
      "Epoch 135/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1085 - val_loss: 0.1194\n",
      "Epoch 136/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.1903 - val_loss: 0.1875\n",
      "Epoch 137/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1406 - val_loss: 0.1259\n",
      "Epoch 138/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1181 - val_loss: 0.1145\n",
      "Epoch 139/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1119 - val_loss: 0.1148\n",
      "Epoch 140/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1076 - val_loss: 0.1158\n",
      "Epoch 141/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1035 - val_loss: 0.1188\n",
      "Epoch 142/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1013 - val_loss: 0.1061\n",
      "Epoch 143/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.1012 - val_loss: 0.1124\n",
      "Epoch 144/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1029 - val_loss: 0.1218\n",
      "Epoch 145/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.0999 - val_loss: 0.1118\n",
      "Epoch 146/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.0973 - val_loss: 0.1106\n",
      "Epoch 147/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1055 - val_loss: 0.1128\n",
      "Epoch 148/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1067 - val_loss: 0.1214\n",
      "Epoch 149/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1007 - val_loss: 0.1144\n",
      "Epoch 150/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.0971 - val_loss: 0.1079\n",
      "Epoch 151/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.0936 - val_loss: 0.0998\n",
      "Epoch 152/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.0956 - val_loss: 0.1249\n",
      "Epoch 153/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.1002 - val_loss: 0.1088\n",
      "Epoch 154/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.0970 - val_loss: 0.1213\n",
      "Epoch 155/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.0961 - val_loss: 0.1096\n",
      "Epoch 156/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.0921 - val_loss: 0.1174\n",
      "Epoch 157/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.0901 - val_loss: 0.1179\n",
      "Epoch 158/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1012 - val_loss: 0.1346\n",
      "Epoch 159/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.0912 - val_loss: 0.1137\n",
      "Epoch 160/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.0920 - val_loss: 0.1109\n",
      "Epoch 161/2000\n",
      "73/73 [==============================] - ETA: 0s - loss: 0.0873Restoring model weights from the end of the best epoch: 151.\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.0873 - val_loss: 0.1168\n",
      "Epoch 161: early stopping\n",
      "'########################################################Model3\n",
      "Epoch 1/2000\n",
      "73/73 [==============================] - 10s 98ms/step - loss: 18.2607 - val_loss: 3.6676\n",
      "Epoch 2/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 1.4447 - val_loss: 0.9707\n",
      "Epoch 3/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.8787 - val_loss: 0.9504\n",
      "Epoch 4/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.8675 - val_loss: 0.9361\n",
      "Epoch 5/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.8507 - val_loss: 0.9036\n",
      "Epoch 6/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.8180 - val_loss: 0.8486\n",
      "Epoch 7/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.7644 - val_loss: 0.7918\n",
      "Epoch 8/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.7353 - val_loss: 0.7097\n",
      "Epoch 9/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.6811 - val_loss: 0.7194\n",
      "Epoch 10/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.7352 - val_loss: 0.8001\n",
      "Epoch 11/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.6807 - val_loss: 0.7629\n",
      "Epoch 12/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.6792 - val_loss: 0.7116\n",
      "Epoch 13/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.6461 - val_loss: 0.6533\n",
      "Epoch 14/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.6165 - val_loss: 0.6318\n",
      "Epoch 15/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.6369 - val_loss: 0.6937\n",
      "Epoch 16/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.6219 - val_loss: 0.6827\n",
      "Epoch 17/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.5887 - val_loss: 0.6082\n",
      "Epoch 18/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.5408 - val_loss: 0.5287\n",
      "Epoch 19/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.5947 - val_loss: 0.5875\n",
      "Epoch 20/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.5515 - val_loss: 0.5406\n",
      "Epoch 21/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.5235 - val_loss: 0.5309\n",
      "Epoch 22/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.5010 - val_loss: 0.4930\n",
      "Epoch 23/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.4814 - val_loss: 0.4690\n",
      "Epoch 24/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.4655 - val_loss: 0.4552\n",
      "Epoch 25/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.4490 - val_loss: 0.4387\n",
      "Epoch 26/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.4408 - val_loss: 0.4383\n",
      "Epoch 27/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.4346 - val_loss: 0.4208\n",
      "Epoch 28/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.4304 - val_loss: 0.4523\n",
      "Epoch 29/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.4203 - val_loss: 0.4122\n",
      "Epoch 30/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.4244 - val_loss: 0.4081\n",
      "Epoch 31/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.4171 - val_loss: 0.4609\n",
      "Epoch 32/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.4000 - val_loss: 0.4147\n",
      "Epoch 33/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.4031 - val_loss: 0.3925\n",
      "Epoch 34/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3985 - val_loss: 0.3853\n",
      "Epoch 35/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3935 - val_loss: 0.3844\n",
      "Epoch 36/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3905 - val_loss: 0.3803\n",
      "Epoch 37/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3865 - val_loss: 0.3750\n",
      "Epoch 38/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.3860 - val_loss: 0.3690\n",
      "Epoch 39/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3746 - val_loss: 0.3713\n",
      "Epoch 40/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3736 - val_loss: 0.3690\n",
      "Epoch 41/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3770 - val_loss: 0.3618\n",
      "Epoch 42/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3804 - val_loss: 0.3910\n",
      "Epoch 43/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3818 - val_loss: 0.3580\n",
      "Epoch 44/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3770 - val_loss: 0.3624\n",
      "Epoch 45/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3680 - val_loss: 0.3531\n",
      "Epoch 46/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3702 - val_loss: 0.3584\n",
      "Epoch 47/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3759 - val_loss: 0.3528\n",
      "Epoch 48/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3585 - val_loss: 0.3773\n",
      "Epoch 49/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3602 - val_loss: 0.3462\n",
      "Epoch 50/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3528 - val_loss: 0.3535\n",
      "Epoch 51/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3589 - val_loss: 0.3492\n",
      "Epoch 52/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3542 - val_loss: 0.3600\n",
      "Epoch 53/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3570 - val_loss: 0.3589\n",
      "Epoch 54/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3510 - val_loss: 0.3373\n",
      "Epoch 55/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3510 - val_loss: 0.3368\n",
      "Epoch 56/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.3463 - val_loss: 0.3439\n",
      "Epoch 57/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3448 - val_loss: 0.3445\n",
      "Epoch 58/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3523 - val_loss: 0.3264\n",
      "Epoch 59/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3210 - val_loss: 0.3135\n",
      "Epoch 60/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3523 - val_loss: 0.3439\n",
      "Epoch 61/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3469 - val_loss: 0.3547\n",
      "Epoch 62/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3503 - val_loss: 0.3381\n",
      "Epoch 63/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3528 - val_loss: 0.3446\n",
      "Epoch 64/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3418 - val_loss: 0.3346\n",
      "Epoch 65/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3453 - val_loss: 0.3310\n",
      "Epoch 66/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3522 - val_loss: 0.3455\n",
      "Epoch 67/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3391 - val_loss: 0.3296\n",
      "Epoch 68/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3366 - val_loss: 0.3180\n",
      "Epoch 69/2000\n",
      "73/73 [==============================] - ETA: 0s - loss: 0.3408Restoring model weights from the end of the best epoch: 59.\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3408 - val_loss: 0.3555\n",
      "Epoch 69: early stopping\n",
      "'########################################################Model4\n",
      "Epoch 1/2000\n",
      "73/73 [==============================] - 8s 96ms/step - loss: 21.3570 - val_loss: 5.1562\n",
      "Epoch 2/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 1.8547 - val_loss: 0.9901\n",
      "Epoch 3/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.8894 - val_loss: 0.9614\n",
      "Epoch 4/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.8739 - val_loss: 0.9463\n",
      "Epoch 5/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.8271 - val_loss: 0.8357\n",
      "Epoch 6/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.7576 - val_loss: 0.8229\n",
      "Epoch 7/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.7348 - val_loss: 0.7708\n",
      "Epoch 8/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.8025 - val_loss: 0.8858\n",
      "Epoch 9/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.7943 - val_loss: 0.8379\n",
      "Epoch 10/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.7512 - val_loss: 0.7618\n",
      "Epoch 11/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.7137 - val_loss: 0.7306\n",
      "Epoch 12/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.7059 - val_loss: 0.7055\n",
      "Epoch 13/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.6697 - val_loss: 0.6818\n",
      "Epoch 14/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.6577 - val_loss: 0.6550\n",
      "Epoch 15/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.6368 - val_loss: 0.6424\n",
      "Epoch 16/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.6229 - val_loss: 0.6491\n",
      "Epoch 17/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.6054 - val_loss: 0.5914\n",
      "Epoch 18/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.5654 - val_loss: 0.5444\n",
      "Epoch 19/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.5468 - val_loss: 0.5563\n",
      "Epoch 20/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.5286 - val_loss: 0.5277\n",
      "Epoch 21/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.4958 - val_loss: 0.4902\n",
      "Epoch 22/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.4745 - val_loss: 0.4679\n",
      "Epoch 23/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.4586 - val_loss: 0.4468\n",
      "Epoch 24/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 0.4506 - val_loss: 0.4414\n",
      "Epoch 25/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.4422 - val_loss: 0.4522\n",
      "Epoch 26/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.4369 - val_loss: 0.4255\n",
      "Epoch 27/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.4264 - val_loss: 0.4195\n",
      "Epoch 28/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.4205 - val_loss: 0.4122\n",
      "Epoch 29/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.4159 - val_loss: 0.4123\n",
      "Epoch 30/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.4111 - val_loss: 0.4031\n",
      "Epoch 31/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.4044 - val_loss: 0.3982\n",
      "Epoch 32/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.4084 - val_loss: 0.3996\n",
      "Epoch 33/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3949 - val_loss: 0.3959\n",
      "Epoch 34/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3931 - val_loss: 0.3830\n",
      "Epoch 35/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3893 - val_loss: 0.3900\n",
      "Epoch 36/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3841 - val_loss: 0.3761\n",
      "Epoch 37/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3838 - val_loss: 0.3839\n",
      "Epoch 38/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3844 - val_loss: 0.3691\n",
      "Epoch 39/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3663 - val_loss: 0.3539\n",
      "Epoch 40/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3597 - val_loss: 0.3873\n",
      "Epoch 41/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3591 - val_loss: 0.3644\n",
      "Epoch 42/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.3414 - val_loss: 0.3476\n",
      "Epoch 43/2000\n",
      "73/73 [==============================] - 6s 87ms/step - loss: 0.3293 - val_loss: 0.3264\n",
      "Epoch 44/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3639 - val_loss: 0.4046\n",
      "Epoch 45/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3899 - val_loss: 0.3573\n",
      "Epoch 46/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3880 - val_loss: 0.3517\n",
      "Epoch 47/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3326 - val_loss: 0.3283\n",
      "Epoch 48/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.3172 - val_loss: 0.2910\n",
      "Epoch 49/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3280 - val_loss: 0.3823\n",
      "Epoch 50/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3898 - val_loss: 0.3832\n",
      "Epoch 51/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3630 - val_loss: 0.3410\n",
      "Epoch 52/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2880 - val_loss: 0.2764\n",
      "Epoch 53/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3491 - val_loss: 0.3522\n",
      "Epoch 54/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3585 - val_loss: 0.3312\n",
      "Epoch 55/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2810 - val_loss: 0.2599\n",
      "Epoch 56/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3497 - val_loss: 0.2912\n",
      "Epoch 57/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2857 - val_loss: 0.2738\n",
      "Epoch 58/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2848 - val_loss: 0.3665\n",
      "Epoch 59/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3402 - val_loss: 0.3179\n",
      "Epoch 60/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2805 - val_loss: 0.2681\n",
      "Epoch 61/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.2723 - val_loss: 0.2766\n",
      "Epoch 62/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2771 - val_loss: 0.2904\n",
      "Epoch 63/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2389 - val_loss: 0.2291\n",
      "Epoch 64/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2774 - val_loss: 0.2914\n",
      "Epoch 65/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2733 - val_loss: 0.2509\n",
      "Epoch 66/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.2418 - val_loss: 0.2904\n",
      "Epoch 67/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2329 - val_loss: 0.2279\n",
      "Epoch 68/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2333 - val_loss: 0.2429\n",
      "Epoch 69/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2245 - val_loss: 0.2063\n",
      "Epoch 70/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2178 - val_loss: 0.2253\n",
      "Epoch 71/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2189 - val_loss: 0.2176\n",
      "Epoch 72/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2123 - val_loss: 0.1967\n",
      "Epoch 73/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2466 - val_loss: 0.2975\n",
      "Epoch 74/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2354 - val_loss: 0.2446\n",
      "Epoch 75/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2128 - val_loss: 0.1924\n",
      "Epoch 76/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2015 - val_loss: 0.2269\n",
      "Epoch 77/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2143 - val_loss: 0.2292\n",
      "Epoch 78/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.1982 - val_loss: 0.2043\n",
      "Epoch 79/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2075 - val_loss: 0.2033\n",
      "Epoch 80/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.2000 - val_loss: 0.2167\n",
      "Epoch 81/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.1982 - val_loss: 0.2182\n",
      "Epoch 82/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.1909 - val_loss: 0.2011\n",
      "Epoch 83/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.1900 - val_loss: 0.1930\n",
      "Epoch 84/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.1962 - val_loss: 0.2390\n",
      "Epoch 85/2000\n",
      "73/73 [==============================] - ETA: 0s - loss: 0.2086Restoring model weights from the end of the best epoch: 75.\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2086 - val_loss: 0.2048\n",
      "Epoch 85: early stopping\n",
      "'########################################################Model5\n",
      "Epoch 1/2000\n",
      "73/73 [==============================] - 8s 97ms/step - loss: 19.3005 - val_loss: 3.6994\n",
      "Epoch 2/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 1.3872 - val_loss: 0.9623\n",
      "Epoch 3/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.8766 - val_loss: 0.9492\n",
      "Epoch 4/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.8653 - val_loss: 0.9277\n",
      "Epoch 5/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.8354 - val_loss: 0.8801\n",
      "Epoch 6/2000\n",
      "73/73 [==============================] - 7s 98ms/step - loss: 0.8071 - val_loss: 0.8262\n",
      "Epoch 7/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.7221 - val_loss: 0.7501\n",
      "Epoch 8/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.6988 - val_loss: 0.7774\n",
      "Epoch 9/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.6709 - val_loss: 0.7062\n",
      "Epoch 10/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.7007 - val_loss: 0.7011\n",
      "Epoch 11/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.6744 - val_loss: 0.7161\n",
      "Epoch 12/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.6627 - val_loss: 0.6974\n",
      "Epoch 13/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.6548 - val_loss: 0.7830\n",
      "Epoch 14/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.6835 - val_loss: 0.6727\n",
      "Epoch 15/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.6118 - val_loss: 0.6568\n",
      "Epoch 16/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.6897 - val_loss: 0.6888\n",
      "Epoch 17/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.6620 - val_loss: 0.6485\n",
      "Epoch 18/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.6435 - val_loss: 0.6306\n",
      "Epoch 19/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.6297 - val_loss: 0.6030\n",
      "Epoch 20/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.5901 - val_loss: 0.6036\n",
      "Epoch 21/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.5928 - val_loss: 0.6208\n",
      "Epoch 22/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.5836 - val_loss: 0.5833\n",
      "Epoch 23/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.5525 - val_loss: 0.5520\n",
      "Epoch 24/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.5326 - val_loss: 0.5347\n",
      "Epoch 25/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.5113 - val_loss: 0.5318\n",
      "Epoch 26/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.4959 - val_loss: 0.4840\n",
      "Epoch 27/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.4697 - val_loss: 0.4617\n",
      "Epoch 28/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.4520 - val_loss: 0.4484\n",
      "Epoch 29/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.4457 - val_loss: 0.4355\n",
      "Epoch 30/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.4316 - val_loss: 0.4226\n",
      "Epoch 31/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.4206 - val_loss: 0.4130\n",
      "Epoch 32/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.4149 - val_loss: 0.4065\n",
      "Epoch 33/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.4073 - val_loss: 0.4010\n",
      "Epoch 34/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.4067 - val_loss: 0.3949\n",
      "Epoch 35/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.4069 - val_loss: 0.3983\n",
      "Epoch 36/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3956 - val_loss: 0.3953\n",
      "Epoch 37/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3893 - val_loss: 0.3832\n",
      "Epoch 38/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3926 - val_loss: 0.3847\n",
      "Epoch 39/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3826 - val_loss: 0.3877\n",
      "Epoch 40/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3785 - val_loss: 0.3736\n",
      "Epoch 41/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3772 - val_loss: 0.3689\n",
      "Epoch 42/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3791 - val_loss: 0.3678\n",
      "Epoch 43/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3698 - val_loss: 0.3684\n",
      "Epoch 44/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3660 - val_loss: 0.3776\n",
      "Epoch 45/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3715 - val_loss: 0.3588\n",
      "Epoch 46/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3664 - val_loss: 0.3577\n",
      "Epoch 47/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3524 - val_loss: 0.3676\n",
      "Epoch 48/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3647 - val_loss: 0.3701\n",
      "Epoch 49/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.3718 - val_loss: 0.3619\n",
      "Epoch 50/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3756 - val_loss: 0.3542\n",
      "Epoch 51/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3596 - val_loss: 0.3567\n",
      "Epoch 52/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3417 - val_loss: 0.3468\n",
      "Epoch 53/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.3211 - val_loss: 0.3345\n",
      "Epoch 54/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3160 - val_loss: 0.3014\n",
      "Epoch 55/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2997 - val_loss: 0.3150\n",
      "Epoch 56/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2849 - val_loss: 0.2886\n",
      "Epoch 57/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2679 - val_loss: 0.2921\n",
      "Epoch 58/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2601 - val_loss: 0.2842\n",
      "Epoch 59/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2619 - val_loss: 0.3142\n",
      "Epoch 60/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2474 - val_loss: 0.2653\n",
      "Epoch 61/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2405 - val_loss: 0.2755\n",
      "Epoch 62/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2343 - val_loss: 0.2479\n",
      "Epoch 63/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2273 - val_loss: 0.2527\n",
      "Epoch 64/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2198 - val_loss: 0.2626\n",
      "Epoch 65/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2382 - val_loss: 0.2483\n",
      "Epoch 66/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2179 - val_loss: 0.2435\n",
      "Epoch 67/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2026 - val_loss: 0.2156\n",
      "Epoch 68/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.2022 - val_loss: 0.2229\n",
      "Epoch 69/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2042 - val_loss: 0.2203\n",
      "Epoch 70/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2069 - val_loss: 0.2474\n",
      "Epoch 71/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.2134 - val_loss: 0.2246\n",
      "Epoch 72/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.1952 - val_loss: 0.2215\n",
      "Epoch 73/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.1911 - val_loss: 0.1830\n",
      "Epoch 74/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2054 - val_loss: 0.2051\n",
      "Epoch 75/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.1780 - val_loss: 0.1794\n",
      "Epoch 76/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.1701 - val_loss: 0.1993\n",
      "Epoch 77/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.1805 - val_loss: 0.1683\n",
      "Epoch 78/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.1841 - val_loss: 0.1724\n",
      "Epoch 79/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.1643 - val_loss: 0.1662\n",
      "Epoch 80/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2393 - val_loss: 0.2076\n",
      "Epoch 81/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.1819 - val_loss: 0.2094\n",
      "Epoch 82/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.1744 - val_loss: 0.1735\n",
      "Epoch 83/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.1623 - val_loss: 0.1902\n",
      "Epoch 84/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.1902 - val_loss: 0.1653\n",
      "Epoch 85/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.1532 - val_loss: 0.1813\n",
      "Epoch 86/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.1698 - val_loss: 0.1810\n",
      "Epoch 87/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.1508 - val_loss: 0.1609\n",
      "Epoch 88/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.1581 - val_loss: 0.1613\n",
      "Epoch 89/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.1605 - val_loss: 0.1847\n",
      "Epoch 90/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.1579 - val_loss: 0.1975\n",
      "Epoch 91/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.1501 - val_loss: 0.1749\n",
      "Epoch 92/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.1590 - val_loss: 0.1591\n",
      "Epoch 93/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.1607 - val_loss: 0.1628\n",
      "Epoch 94/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.1480 - val_loss: 0.1642\n",
      "Epoch 95/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.1751 - val_loss: 0.1632\n",
      "Epoch 96/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.1501 - val_loss: 0.1509\n",
      "Epoch 97/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.1481 - val_loss: 0.1858\n",
      "Epoch 98/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.1569 - val_loss: 0.1759\n",
      "Epoch 99/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.1535 - val_loss: 0.1487\n",
      "Epoch 100/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.1395 - val_loss: 0.1489\n",
      "Epoch 101/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.1473 - val_loss: 0.1600\n",
      "Epoch 102/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.1468 - val_loss: 0.1882\n",
      "Epoch 103/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.1374 - val_loss: 0.1527\n",
      "Epoch 104/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.1436 - val_loss: 0.1715\n",
      "Epoch 105/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.1391 - val_loss: 0.1554\n",
      "Epoch 106/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.1384 - val_loss: 0.1668\n",
      "Epoch 107/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.1554 - val_loss: 0.1678\n",
      "Epoch 108/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.1443 - val_loss: 0.1468\n",
      "Epoch 109/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.1403 - val_loss: 0.1406\n",
      "Epoch 110/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.1447 - val_loss: 0.1438\n",
      "Epoch 111/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.1355 - val_loss: 0.1558\n",
      "Epoch 112/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.1377 - val_loss: 0.1660\n",
      "Epoch 113/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.1406 - val_loss: 0.1597\n",
      "Epoch 114/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.1315 - val_loss: 0.1440\n",
      "Epoch 115/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.1312 - val_loss: 0.1445\n",
      "Epoch 116/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1297 - val_loss: 0.1431\n",
      "Epoch 117/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.1315 - val_loss: 0.1596\n",
      "Epoch 118/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.1530 - val_loss: 0.1511\n",
      "Epoch 119/2000\n",
      "73/73 [==============================] - ETA: 0s - loss: 0.1797Restoring model weights from the end of the best epoch: 109.\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.1797 - val_loss: 0.1902\n",
      "Epoch 119: early stopping\n",
      "'########################################################Model6\n",
      "Epoch 1/2000\n",
      "73/73 [==============================] - 9s 98ms/step - loss: 15.3213 - val_loss: 1.8731\n",
      "Epoch 2/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.9259 - val_loss: 0.9225\n",
      "Epoch 3/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.8410 - val_loss: 0.8961\n",
      "Epoch 4/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.8069 - val_loss: 0.8168\n",
      "Epoch 5/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.7510 - val_loss: 0.7649\n",
      "Epoch 6/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.7206 - val_loss: 0.7449\n",
      "Epoch 7/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.7251 - val_loss: 0.6972\n",
      "Epoch 8/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.6922 - val_loss: 0.6693\n",
      "Epoch 9/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.6750 - val_loss: 0.7147\n",
      "Epoch 10/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.6861 - val_loss: 0.6779\n",
      "Epoch 11/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.6565 - val_loss: 0.6528\n",
      "Epoch 12/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.6276 - val_loss: 0.5981\n",
      "Epoch 13/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.6685 - val_loss: 0.6803\n",
      "Epoch 14/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.6427 - val_loss: 0.6264\n",
      "Epoch 15/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.6063 - val_loss: 0.5952\n",
      "Epoch 16/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.5786 - val_loss: 0.6138\n",
      "Epoch 17/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.5502 - val_loss: 0.5599\n",
      "Epoch 18/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.5262 - val_loss: 0.5051\n",
      "Epoch 19/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.4909 - val_loss: 0.4936\n",
      "Epoch 20/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.4781 - val_loss: 0.4550\n",
      "Epoch 21/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.4471 - val_loss: 0.4398\n",
      "Epoch 22/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.4457 - val_loss: 0.4261\n",
      "Epoch 23/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.4332 - val_loss: 0.4241\n",
      "Epoch 24/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.4509 - val_loss: 0.4424\n",
      "Epoch 25/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.4239 - val_loss: 0.4125\n",
      "Epoch 26/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.4289 - val_loss: 0.4111\n",
      "Epoch 27/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.4120 - val_loss: 0.4043\n",
      "Epoch 28/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.4149 - val_loss: 0.4138\n",
      "Epoch 29/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.4064 - val_loss: 0.4427\n",
      "Epoch 30/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.4069 - val_loss: 0.3934\n",
      "Epoch 31/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.4050 - val_loss: 0.4110\n",
      "Epoch 32/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3929 - val_loss: 0.3902\n",
      "Epoch 33/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.4051 - val_loss: 0.3914\n",
      "Epoch 34/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3870 - val_loss: 0.4111\n",
      "Epoch 35/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3840 - val_loss: 0.3918\n",
      "Epoch 36/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3910 - val_loss: 0.3800\n",
      "Epoch 37/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3840 - val_loss: 0.4050\n",
      "Epoch 38/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3781 - val_loss: 0.3771\n",
      "Epoch 39/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3671 - val_loss: 0.3711\n",
      "Epoch 40/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.3722 - val_loss: 0.3618\n",
      "Epoch 41/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.3610 - val_loss: 0.3637\n",
      "Epoch 42/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3454 - val_loss: 0.3779\n",
      "Epoch 43/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3283 - val_loss: 0.3789\n",
      "Epoch 44/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3244 - val_loss: 0.3187\n",
      "Epoch 45/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2899 - val_loss: 0.2779\n",
      "Epoch 46/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2763 - val_loss: 0.2913\n",
      "Epoch 47/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2973 - val_loss: 0.2645\n",
      "Epoch 48/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2585 - val_loss: 0.2897\n",
      "Epoch 49/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2496 - val_loss: 0.2291\n",
      "Epoch 50/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2412 - val_loss: 0.2496\n",
      "Epoch 51/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2394 - val_loss: 0.2736\n",
      "Epoch 52/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2286 - val_loss: 0.2577\n",
      "Epoch 53/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2099 - val_loss: 0.2353\n",
      "Epoch 54/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2036 - val_loss: 0.2245\n",
      "Epoch 55/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2041 - val_loss: 0.2075\n",
      "Epoch 56/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2020 - val_loss: 0.2552\n",
      "Epoch 57/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2098 - val_loss: 0.2194\n",
      "Epoch 58/2000\n",
      "73/73 [==============================] - 6s 88ms/step - loss: 0.1861 - val_loss: 0.2240\n",
      "Epoch 59/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.2102 - val_loss: 0.2358\n",
      "Epoch 60/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2205 - val_loss: 0.2398\n",
      "Epoch 61/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.1944 - val_loss: 0.2622\n",
      "Epoch 62/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2044 - val_loss: 0.2425\n",
      "Epoch 63/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.1821 - val_loss: 0.2171\n",
      "Epoch 64/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.1717 - val_loss: 0.2159\n",
      "Epoch 65/2000\n",
      "73/73 [==============================] - ETA: 0s - loss: 0.1998Restoring model weights from the end of the best epoch: 55.\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.1998 - val_loss: 0.2172\n",
      "Epoch 65: early stopping\n",
      "'########################################################Model7\n",
      "Epoch 1/2000\n",
      "73/73 [==============================] - 9s 99ms/step - loss: 20.2245 - val_loss: 4.2957\n",
      "Epoch 2/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 1.4676 - val_loss: 0.9456\n",
      "Epoch 3/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.8674 - val_loss: 0.9388\n",
      "Epoch 4/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.8556 - val_loss: 0.9183\n",
      "Epoch 5/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.8426 - val_loss: 0.8998\n",
      "Epoch 6/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.8116 - val_loss: 0.8628\n",
      "Epoch 7/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.7727 - val_loss: 0.7942\n",
      "Epoch 8/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.7372 - val_loss: 0.7527\n",
      "Epoch 9/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.7103 - val_loss: 0.7718\n",
      "Epoch 10/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.6960 - val_loss: 0.7398\n",
      "Epoch 11/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.6756 - val_loss: 0.7088\n",
      "Epoch 12/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.6620 - val_loss: 0.6725\n",
      "Epoch 13/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.6409 - val_loss: 0.6379\n",
      "Epoch 14/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.6319 - val_loss: 0.6324\n",
      "Epoch 15/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.6083 - val_loss: 0.6040\n",
      "Epoch 16/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.5859 - val_loss: 0.5739\n",
      "Epoch 17/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.5713 - val_loss: 0.5652\n",
      "Epoch 18/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.5459 - val_loss: 0.5210\n",
      "Epoch 19/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.5374 - val_loss: 0.5456\n",
      "Epoch 20/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.4949 - val_loss: 0.5089\n",
      "Epoch 21/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.4732 - val_loss: 0.4666\n",
      "Epoch 22/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.4658 - val_loss: 0.4983\n",
      "Epoch 23/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.4581 - val_loss: 0.4237\n",
      "Epoch 24/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.4303 - val_loss: 0.3921\n",
      "Epoch 25/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3954 - val_loss: 0.4502\n",
      "Epoch 26/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.4328 - val_loss: 0.4290\n",
      "Epoch 27/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.4274 - val_loss: 0.4144\n",
      "Epoch 28/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.4096 - val_loss: 0.4013\n",
      "Epoch 29/2000\n",
      "73/73 [==============================] - 6s 84ms/step - loss: 0.3967 - val_loss: 0.4243\n",
      "Epoch 30/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3898 - val_loss: 0.3906\n",
      "Epoch 31/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3892 - val_loss: 0.3917\n",
      "Epoch 32/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.3647 - val_loss: 0.3908\n",
      "Epoch 33/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.3361 - val_loss: 0.3591\n",
      "Epoch 34/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.3341 - val_loss: 0.3501\n",
      "Epoch 35/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.3059 - val_loss: 0.3030\n",
      "Epoch 36/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2738 - val_loss: 0.2893\n",
      "Epoch 37/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2693 - val_loss: 0.3037\n",
      "Epoch 38/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2651 - val_loss: 0.3037\n",
      "Epoch 39/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2640 - val_loss: 0.2811\n",
      "Epoch 40/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2635 - val_loss: 0.2909\n",
      "Epoch 41/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2601 - val_loss: 0.2579\n",
      "Epoch 42/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2478 - val_loss: 0.2701\n",
      "Epoch 43/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2413 - val_loss: 0.2520\n",
      "Epoch 44/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2690 - val_loss: 0.2628\n",
      "Epoch 45/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.2386 - val_loss: 0.2525\n",
      "Epoch 46/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.2294 - val_loss: 0.2384\n",
      "Epoch 47/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 0.2206 - val_loss: 0.2194\n",
      "Epoch 48/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.2149 - val_loss: 0.2379\n",
      "Epoch 49/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.2311 - val_loss: 0.3216\n",
      "Epoch 50/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2196 - val_loss: 0.2326\n",
      "Epoch 51/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.2033 - val_loss: 0.2082\n",
      "Epoch 52/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1968 - val_loss: 0.2265\n",
      "Epoch 53/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1910 - val_loss: 0.2211\n",
      "Epoch 54/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1922 - val_loss: 0.2276\n",
      "Epoch 55/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1814 - val_loss: 0.2215\n",
      "Epoch 56/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1943 - val_loss: 0.1928\n",
      "Epoch 57/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1751 - val_loss: 0.2148\n",
      "Epoch 58/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1808 - val_loss: 0.1892\n",
      "Epoch 59/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.1752 - val_loss: 0.2086\n",
      "Epoch 60/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1703 - val_loss: 0.1806\n",
      "Epoch 61/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1794 - val_loss: 0.1900\n",
      "Epoch 62/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1667 - val_loss: 0.1822\n",
      "Epoch 63/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1672 - val_loss: 0.1918\n",
      "Epoch 64/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.1628 - val_loss: 0.1687\n",
      "Epoch 65/2000\n",
      "73/73 [==============================] - 6s 83ms/step - loss: 0.1603 - val_loss: 0.1712\n",
      "Epoch 66/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1614 - val_loss: 0.1674\n",
      "Epoch 67/2000\n",
      "73/73 [==============================] - 7s 97ms/step - loss: 0.1577 - val_loss: 0.2389\n",
      "Epoch 68/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1680 - val_loss: 0.1636\n",
      "Epoch 69/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1606 - val_loss: 0.1603\n",
      "Epoch 70/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1580 - val_loss: 0.1557\n",
      "Epoch 71/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1622 - val_loss: 0.1612\n",
      "Epoch 72/2000\n",
      "73/73 [==============================] - 7s 95ms/step - loss: 0.1440 - val_loss: 0.1668\n",
      "Epoch 73/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1530 - val_loss: 0.1716\n",
      "Epoch 74/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1451 - val_loss: 0.1802\n",
      "Epoch 75/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1545 - val_loss: 0.2528\n",
      "Epoch 76/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1792 - val_loss: 0.1635\n",
      "Epoch 77/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1438 - val_loss: 0.1683\n",
      "Epoch 78/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1437 - val_loss: 0.1672\n",
      "Epoch 79/2000\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1469 - val_loss: 0.1682\n",
      "Epoch 80/2000\n",
      "73/73 [==============================] - ETA: 0s - loss: 0.1411Restoring model weights from the end of the best epoch: 70.\n",
      "73/73 [==============================] - 7s 96ms/step - loss: 0.1411 - val_loss: 0.1595\n",
      "Epoch 80: early stopping\n",
      "'########################################################Model8\n",
      "Epoch 1/2000\n",
      "73/73 [==============================] - 8s 96ms/step - loss: 20.6773 - val_loss: 4.9264\n",
      "Epoch 2/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 1.6764 - val_loss: 0.9505\n",
      "Epoch 3/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.8655 - val_loss: 0.9343\n",
      "Epoch 4/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.8531 - val_loss: 0.9258\n",
      "Epoch 5/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.8167 - val_loss: 0.8413\n",
      "Epoch 6/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.7569 - val_loss: 0.7386\n",
      "Epoch 7/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.6729 - val_loss: 0.8038\n",
      "Epoch 8/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.7262 - val_loss: 0.7320\n",
      "Epoch 9/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.7098 - val_loss: 0.7043\n",
      "Epoch 10/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.6988 - val_loss: 0.7337\n",
      "Epoch 11/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.6892 - val_loss: 0.6769\n",
      "Epoch 12/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.6829 - val_loss: 0.6722\n",
      "Epoch 13/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.6549 - val_loss: 0.6556\n",
      "Epoch 14/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.6695 - val_loss: 0.6477\n",
      "Epoch 15/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.6327 - val_loss: 0.6318\n",
      "Epoch 16/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.6240 - val_loss: 0.6095\n",
      "Epoch 17/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.6072 - val_loss: 0.6073\n",
      "Epoch 18/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.5903 - val_loss: 0.5674\n",
      "Epoch 19/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.5651 - val_loss: 0.5725\n",
      "Epoch 20/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.5676 - val_loss: 0.6004\n",
      "Epoch 21/2000\n",
      "73/73 [==============================] - 6s 82ms/step - loss: 0.5534 - val_loss: 0.5450\n",
      "Epoch 22/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.5237 - val_loss: 0.5190\n",
      "Epoch 23/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.4994 - val_loss: 0.4998\n",
      "Epoch 24/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.4892 - val_loss: 0.4770\n",
      "Epoch 25/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.4729 - val_loss: 0.4629\n",
      "Epoch 26/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.4527 - val_loss: 0.4446\n",
      "Epoch 27/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.4371 - val_loss: 0.4415\n",
      "Epoch 28/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.4320 - val_loss: 0.4259\n",
      "Epoch 29/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.4218 - val_loss: 0.4292\n",
      "Epoch 30/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.4232 - val_loss: 0.4134\n",
      "Epoch 31/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.4163 - val_loss: 0.4084\n",
      "Epoch 32/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.4081 - val_loss: 0.4467\n",
      "Epoch 33/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.4119 - val_loss: 0.4009\n",
      "Epoch 34/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.4116 - val_loss: 0.3968\n",
      "Epoch 35/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.4006 - val_loss: 0.4003\n",
      "Epoch 36/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3959 - val_loss: 0.4181\n",
      "Epoch 37/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3943 - val_loss: 0.3852\n",
      "Epoch 38/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3884 - val_loss: 0.3829\n",
      "Epoch 39/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.3888 - val_loss: 0.3775\n",
      "Epoch 40/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.3805 - val_loss: 0.3884\n",
      "Epoch 41/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3799 - val_loss: 0.3701\n",
      "Epoch 42/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3803 - val_loss: 0.4090\n",
      "Epoch 43/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3785 - val_loss: 0.3647\n",
      "Epoch 44/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3733 - val_loss: 0.3759\n",
      "Epoch 45/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3725 - val_loss: 0.3602\n",
      "Epoch 46/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3678 - val_loss: 0.3616\n",
      "Epoch 47/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3691 - val_loss: 0.4037\n",
      "Epoch 48/2000\n",
      "73/73 [==============================] - 7s 94ms/step - loss: 0.3673 - val_loss: 0.3581\n",
      "Epoch 49/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3617 - val_loss: 0.3841\n",
      "Epoch 50/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3653 - val_loss: 0.3666\n",
      "Epoch 51/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3489 - val_loss: 0.3471\n",
      "Epoch 52/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3594 - val_loss: 0.3474\n",
      "Epoch 53/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.3500 - val_loss: 0.3578\n",
      "Epoch 54/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.3607 - val_loss: 0.3487\n",
      "Epoch 55/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3400 - val_loss: 0.3396\n",
      "Epoch 56/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.3493 - val_loss: 0.3706\n",
      "Epoch 57/2000\n",
      "73/73 [==============================] - 7s 89ms/step - loss: 0.3407 - val_loss: 0.3388\n",
      "Epoch 58/2000\n",
      "73/73 [==============================] - 6s 85ms/step - loss: 0.2990 - val_loss: 0.3015\n",
      "Epoch 59/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2925 - val_loss: 0.3016\n",
      "Epoch 60/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2638 - val_loss: 0.2899\n",
      "Epoch 61/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2487 - val_loss: 0.2798\n",
      "Epoch 62/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2385 - val_loss: 0.2910\n",
      "Epoch 63/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2469 - val_loss: 0.2679\n",
      "Epoch 64/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2430 - val_loss: 0.2664\n",
      "Epoch 65/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2305 - val_loss: 0.2568\n",
      "Epoch 66/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2301 - val_loss: 0.2351\n",
      "Epoch 67/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2095 - val_loss: 0.2560\n",
      "Epoch 68/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2173 - val_loss: 0.2391\n",
      "Epoch 69/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2057 - val_loss: 0.2308\n",
      "Epoch 70/2000\n",
      "73/73 [==============================] - 7s 91ms/step - loss: 0.2013 - val_loss: 0.2414\n",
      "Epoch 71/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.2878 - val_loss: 0.2613\n",
      "Epoch 72/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.2085 - val_loss: 0.2140\n",
      "Epoch 73/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.1953 - val_loss: 0.2725\n",
      "Epoch 74/2000\n",
      "73/73 [==============================] - 7s 90ms/step - loss: 0.1981 - val_loss: 0.2024\n",
      "Epoch 75/2000\n",
      "73/73 [==============================] - 6s 89ms/step - loss: 0.2024 - val_loss: 0.2125\n",
      "Epoch 76/2000\n",
      "73/73 [==============================] - 6s 86ms/step - loss: 0.1858 - val_loss: 0.1923\n",
      "Epoch 77/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.1958 - val_loss: 0.2273\n",
      "Epoch 78/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.1916 - val_loss: 0.1845\n",
      "Epoch 79/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.1864 - val_loss: 0.1899\n",
      "Epoch 80/2000\n",
      "73/73 [==============================] - 7s 92ms/step - loss: 0.1793 - val_loss: 0.1990\n",
      "Epoch 81/2000\n",
      "73/73 [==============================] - 7s 93ms/step - loss: 0.1731 - val_loss: 0.1889\n",
      "Epoch 82/2000\n",
      " 4/73 [>.............................] - ETA: 6s - loss: 0.2177"
     ]
    }
   ],
   "source": [
    "model_num = 10\n",
    "\n",
    "\n",
    "mase_models = train_bagging_models(model_num, MASE(y_train,24),2000,10,8,0.0001)\n",
    "mape_models = train_bagging_models(model_num,'mape',2000,10,8,0.0001)\n",
    "smape_models = train_bagging_models(model_num, SMAPE(),2000,10,8,0.0001)\n",
    "mae_models = train_bagging_models(model_num, 'mae',2000,10,8,0.0001)\n",
    "mse_models = train_bagging_models(model_num, 'mse',2000,10,8,0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b35de203-07f8-48f9-8ede-0a0bcba1ea27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 29ms/step\n",
      "5/5 [==============================] - 0s 32ms/step\n",
      "5/5 [==============================] - 0s 32ms/step\n",
      "5/5 [==============================] - 0s 32ms/step\n",
      "5/5 [==============================] - 0s 31ms/step\n",
      "5/5 [==============================] - 0s 30ms/step\n",
      "5/5 [==============================] - 0s 31ms/step\n",
      "5/5 [==============================] - 0s 29ms/step\n",
      "5/5 [==============================] - 0s 30ms/step\n",
      "5/5 [==============================] - 0s 30ms/step\n",
      "5/5 [==============================] - 0s 31ms/step\n",
      "5/5 [==============================] - 0s 31ms/step\n",
      "5/5 [==============================] - 0s 32ms/step\n",
      "5/5 [==============================] - 0s 32ms/step\n",
      "5/5 [==============================] - 0s 31ms/step\n",
      "5/5 [==============================] - 0s 30ms/step\n",
      "5/5 [==============================] - 0s 33ms/step\n",
      "5/5 [==============================] - 0s 31ms/step\n",
      "5/5 [==============================] - 0s 32ms/step\n",
      "5/5 [==============================] - 0s 34ms/step\n",
      "5/5 [==============================] - 0s 32ms/step\n",
      "5/5 [==============================] - 0s 32ms/step\n",
      "5/5 [==============================] - 0s 31ms/step\n",
      "5/5 [==============================] - 0s 31ms/step\n",
      "5/5 [==============================] - 0s 31ms/step\n",
      "5/5 [==============================] - 0s 30ms/step\n",
      "5/5 [==============================] - 0s 30ms/step\n",
      "5/5 [==============================] - 0s 32ms/step\n",
      "5/5 [==============================] - 0s 31ms/step\n",
      "5/5 [==============================] - 0s 30ms/step\n",
      "5/5 [==============================] - 0s 31ms/step\n",
      "5/5 [==============================] - 2s 24ms/step\n",
      "5/5 [==============================] - 0s 24ms/step\n",
      "5/5 [==============================] - 0s 31ms/step\n",
      "5/5 [==============================] - 0s 31ms/step\n",
      "5/5 [==============================] - 0s 30ms/step\n",
      "5/5 [==============================] - 0s 30ms/step\n",
      "5/5 [==============================] - 0s 29ms/step\n",
      "5/5 [==============================] - 0s 32ms/step\n",
      "5/5 [==============================] - 0s 31ms/step\n",
      "5/5 [==============================] - 0s 29ms/step\n",
      "5/5 [==============================] - 0s 30ms/step\n",
      "5/5 [==============================] - 0s 28ms/step\n",
      "5/5 [==============================] - 0s 26ms/step\n",
      "5/5 [==============================] - 0s 32ms/step\n",
      "5/5 [==============================] - 0s 30ms/step\n",
      "5/5 [==============================] - 0s 31ms/step\n",
      "5/5 [==============================] - 0s 28ms/step\n",
      "5/5 [==============================] - 0s 31ms/step\n",
      "5/5 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.35106, 0.323, 0.30125, 0.31109, 0.33126)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred1,_=smape_models\n",
    "pred2,_=mase_models\n",
    "pred3,_=mape_models\n",
    "pred4,_=mae_models\n",
    "pred5,_=mse_models\n",
    "\n",
    "smape_predictions = bagging_predict2(pred1, X_train_val)\n",
    "mase_predictions =  bagging_predict2(pred2, X_train_val)\n",
    "mape_predictions =  bagging_predict2(pred3, X_train_val)\n",
    "mae_predictions = bagging_predict2(pred4, X_train_val)\n",
    "mse_predictions =  bagging_predict2(pred5, X_train_val)\n",
    "\n",
    "\n",
    "concat_G = np.concatenate([smape_predictions],axis=0)\n",
    "fin_pred_G = np.median(concat_G,axis=0)\n",
    "#pd.DataFrame(fin_pred).to_csv(\"freezing_I.csv\")\n",
    "sMAPE = np.sqrt(mean_squared_error(y_train_val.flatten(),fin_pred_G.flatten())).round(5)\n",
    "\n",
    "concat_G = np.concatenate([mape_predictions],axis=0)\n",
    "fin_pred_G = np.median(concat_G,axis=0)\n",
    "#pd.DataFrame(fin_pred).to_csv(\"freezing_I.csv\")\n",
    "MAPE= np.sqrt(mean_squared_error(y_train_val.flatten(),fin_pred_G.flatten())).round(5)\n",
    "\n",
    "concat_G = np.concatenate([mase_predictions],axis=0)\n",
    "fin_pred_G = np.median(concat_G,axis=0)\n",
    "#pd.DataFrame(fin_pred).to_csv(\"freezing_I.csv\")\n",
    "MASE = np.sqrt(mean_squared_error(y_train_val.flatten(),fin_pred_G.flatten())).round(5)\n",
    "\n",
    "concat_G = np.concatenate([mae_predictions],axis=0)\n",
    "fin_pred_G = np.median(concat_G,axis=0)\n",
    "#pd.DataFrame(fin_pred).to_csv(\"freezing_I.csv\")\n",
    "MAE = np.sqrt(mean_squared_error(y_train_val.flatten(),fin_pred_G.flatten())).round(5)\n",
    "\n",
    "concat_G = np.concatenate([mse_predictions],axis=0)\n",
    "fin_pred_G = np.median(concat_G,axis=0)\n",
    "#pd.DataFrame(fin_pred).to_csv(\"freezing_I.csv\")\n",
    "MSE = np.sqrt(mean_squared_error(y_train_val.flatten(),fin_pred_G.flatten())).round(5)\n",
    "\n",
    "\n",
    "MSE, MASE, MAE, MAPE, sMAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ed0c7ce-ad6f-47e0-b18a-7e5a1e0a7f80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 31ms/step\n",
      "12/12 [==============================] - 0s 31ms/step\n",
      "12/12 [==============================] - 0s 30ms/step\n",
      "12/12 [==============================] - 0s 32ms/step\n",
      "12/12 [==============================] - 0s 33ms/step\n",
      "12/12 [==============================] - 0s 32ms/step\n",
      "12/12 [==============================] - 0s 30ms/step\n",
      "12/12 [==============================] - 0s 31ms/step\n",
      "12/12 [==============================] - 0s 31ms/step\n",
      "12/12 [==============================] - 0s 31ms/step\n",
      "12/12 [==============================] - 0s 31ms/step\n",
      "12/12 [==============================] - 0s 33ms/step\n",
      "12/12 [==============================] - 0s 31ms/step\n",
      "12/12 [==============================] - 0s 31ms/step\n",
      "12/12 [==============================] - 0s 32ms/step\n",
      "12/12 [==============================] - 0s 30ms/step\n",
      "12/12 [==============================] - 0s 32ms/step\n",
      "12/12 [==============================] - 0s 31ms/step\n",
      "12/12 [==============================] - 0s 30ms/step\n",
      "12/12 [==============================] - 0s 30ms/step\n",
      "12/12 [==============================] - 0s 27ms/step\n",
      "12/12 [==============================] - 0s 25ms/step\n",
      "12/12 [==============================] - 0s 25ms/step\n",
      "12/12 [==============================] - 0s 26ms/step\n",
      "12/12 [==============================] - 0s 32ms/step\n",
      "12/12 [==============================] - 0s 32ms/step\n",
      "12/12 [==============================] - 0s 32ms/step\n",
      "12/12 [==============================] - 0s 30ms/step\n",
      "12/12 [==============================] - 0s 31ms/step\n",
      "12/12 [==============================] - 0s 31ms/step\n",
      "12/12 [==============================] - 0s 31ms/step\n",
      "12/12 [==============================] - 0s 32ms/step\n",
      "12/12 [==============================] - 0s 30ms/step\n",
      "12/12 [==============================] - 0s 31ms/step\n",
      "12/12 [==============================] - 0s 32ms/step\n",
      "12/12 [==============================] - 0s 33ms/step\n",
      "12/12 [==============================] - 0s 32ms/step\n",
      "12/12 [==============================] - 0s 29ms/step\n",
      "12/12 [==============================] - 0s 30ms/step\n",
      "12/12 [==============================] - 0s 32ms/step\n",
      "12/12 [==============================] - 0s 32ms/step\n",
      "12/12 [==============================] - 0s 30ms/step\n",
      "12/12 [==============================] - 0s 30ms/step\n",
      "12/12 [==============================] - 0s 31ms/step\n",
      "12/12 [==============================] - 0s 31ms/step\n",
      "12/12 [==============================] - 0s 32ms/step\n",
      "12/12 [==============================] - 0s 32ms/step\n",
      "12/12 [==============================] - 0s 30ms/step\n",
      "12/12 [==============================] - 0s 31ms/step\n",
      "12/12 [==============================] - 0s 31ms/step\n",
      "############################################################################################\n",
      "############################################################################################\n",
      "exp 0.33852\n"
     ]
    }
   ],
   "source": [
    "pred1,_=smape_models\n",
    "pred2,_=mase_models\n",
    "pred3,_=mape_models\n",
    "pred4,_=mae_models\n",
    "pred5,_=mse_models\n",
    "\n",
    "smape_predictions2 = bagging_predict2(pred1, test_X)\n",
    "smape_predictions2 = np.median(np.concatenate([smape_predictions2],axis=0),axis=0)\n",
    "\n",
    "mase_predictions2 =bagging_predict2(pred2, test_X)\n",
    "mase_predictions2 = np.median(np.concatenate([mase_predictions2],axis=0),axis=0)\n",
    "\n",
    "mape_predictions2 =bagging_predict2(pred3, test_X)\n",
    "mape_predictions2 = np.median(np.concatenate([mape_predictions2],axis=0),axis=0)\n",
    "\n",
    "mae_predictions2 = bagging_predict2(pred4,test_X)\n",
    "mae_predictions2 = np.median(np.concatenate([mae_predictions2],axis=0),axis=0)\n",
    "\n",
    "mse_predictions2 =bagging_predict2(pred5,test_X)\n",
    "mse_predictions2 = np.median(np.concatenate([mse_predictions2],axis=0),axis=0)\n",
    "\n",
    "\n",
    "#concat_mase = np.concatenate([np.nan_to_num(np.array(mase_predictions2), nan=0)])\n",
    "#fin_pred_mase = np.median(concat_mase,axis=1)\n",
    "\n",
    "#concat_mape = np.concatenate([np.nan_to_num(np.array(mape_predictions2), nan=0)])\n",
    "#fin_pred_mape = np.median(concat_mape,axis=1)\n",
    "\n",
    "#concat_smape = np.concatenate([np.nan_to_num(np.array(smape_predictions2), nan=0)])\n",
    "#fin_pred_smape = np.median(concat_smape,axis=1)\n",
    "\n",
    "#concat_mae = np.concatenate([np.nan_to_num(np.array(mae_predictions2), nan=0)])\n",
    "#fin_pred_mae = np.median(concat_mae,axis=1)\n",
    "\n",
    "#concat_mse = np.concatenate([np.nan_to_num(np.array(mse_predictions2), nan=0)])\n",
    "#fin_pred_mse = np.median(concat_mse,axis=1)\n",
    "\n",
    "performance = np.array([MAE, MAPE,sMAPE,MSE,MASE])\n",
    "beta = 3 # 조정 파라미터\n",
    "weights = np.exp(-beta * performance)\n",
    "\n",
    "gd= np.concatenate([mae_predictions2,\n",
    "                    mape_predictions2,\n",
    "                   smape_predictions2,\n",
    "                   mse_predictions2,\n",
    "                   mase_predictions2],axis=0)\n",
    "#gd=np.median(gd,axis=2)\n",
    "normalized_weights = weights / np.sum(weights)\n",
    "\n",
    "# 각 모델의 예측값에 가중치를 부여하여 앙상블 예측 생성\n",
    "ensemble_prediction = np.dot(normalized_weights, gd.reshape(5,-1))\n",
    "print('############################################################################################') \n",
    "print('############################################################################################') \n",
    "pd.DataFrame(ensemble_prediction.flatten()).to_csv('exp7/LSTM.csv')\n",
    "\n",
    "\n",
    "print('exp',np.sqrt(mean_squared_error(test_y.flatten(),ensemble_prediction.flatten())).round(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93fd3e88-6523-4042-a996-ad1f65d9fb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 32ms/step\n",
      "12/12 [==============================] - 0s 31ms/step\n",
      "12/12 [==============================] - 0s 32ms/step\n",
      "12/12 [==============================] - 0s 31ms/step\n",
      "12/12 [==============================] - 0s 33ms/step\n",
      "12/12 [==============================] - 0s 30ms/step\n",
      "12/12 [==============================] - 0s 30ms/step\n",
      "12/12 [==============================] - 0s 31ms/step\n",
      "12/12 [==============================] - 0s 31ms/step\n",
      "12/12 [==============================] - 0s 30ms/step\n",
      "12/12 [==============================] - 0s 32ms/step\n",
      "12/12 [==============================] - 0s 32ms/step\n",
      "12/12 [==============================] - 0s 32ms/step\n",
      "12/12 [==============================] - 0s 31ms/step\n",
      "12/12 [==============================] - 0s 32ms/step\n",
      "12/12 [==============================] - 0s 30ms/step\n",
      "12/12 [==============================] - 0s 32ms/step\n",
      "12/12 [==============================] - 0s 32ms/step\n",
      "12/12 [==============================] - 0s 32ms/step\n",
      "12/12 [==============================] - 0s 30ms/step\n",
      "12/12 [==============================] - 0s 31ms/step\n",
      "12/12 [==============================] - 0s 32ms/step\n",
      "12/12 [==============================] - 0s 31ms/step\n",
      "12/12 [==============================] - 0s 31ms/step\n",
      "12/12 [==============================] - 0s 30ms/step\n",
      "12/12 [==============================] - 0s 32ms/step\n",
      "12/12 [==============================] - 0s 33ms/step\n",
      "12/12 [==============================] - 0s 32ms/step\n",
      "12/12 [==============================] - 0s 30ms/step\n",
      "12/12 [==============================] - 0s 32ms/step\n",
      "12/12 [==============================] - 0s 32ms/step\n",
      "12/12 [==============================] - 0s 31ms/step\n",
      "12/12 [==============================] - 0s 31ms/step\n",
      "12/12 [==============================] - 0s 31ms/step\n",
      "12/12 [==============================] - 0s 32ms/step\n",
      "12/12 [==============================] - 0s 32ms/step\n",
      "12/12 [==============================] - 0s 32ms/step\n",
      "12/12 [==============================] - 0s 32ms/step\n",
      "12/12 [==============================] - 0s 32ms/step\n",
      "12/12 [==============================] - 0s 30ms/step\n",
      "12/12 [==============================] - 0s 31ms/step\n",
      "12/12 [==============================] - 0s 30ms/step\n",
      "12/12 [==============================] - 0s 31ms/step\n",
      "12/12 [==============================] - 0s 32ms/step\n",
      "12/12 [==============================] - 0s 30ms/step\n",
      "12/12 [==============================] - 0s 31ms/step\n",
      "12/12 [==============================] - 0s 31ms/step\n",
      "12/12 [==============================] - 0s 31ms/step\n",
      "12/12 [==============================] - 0s 32ms/step\n",
      "12/12 [==============================] - 0s 32ms/step\n",
      "############################################################################################\n",
      "############################################################################################\n",
      "all 0.3381\n",
      "original 0.33833\n",
      "best 0.34036\n",
      "mse 0.36835\n",
      "mase 0.34271\n",
      "mae 0.33439\n",
      "mape 0.3389\n",
      "smape 0.34982\n"
     ]
    }
   ],
   "source": [
    "pred1,_=smape_models\n",
    "pred2,_=mase_models\n",
    "pred3,_=mape_models\n",
    "pred4,_=mae_models\n",
    "pred5,_=mse_models\n",
    "\n",
    "smape_predictions_G = bagging_predict2(pred1, test_X)\n",
    "mase_predictions_G = bagging_predict2(pred2,test_X)\n",
    "mape_predictions_G = bagging_predict2(pred3,test_X)\n",
    "mae_predictions_G = bagging_predict2(pred4, test_X)\n",
    "mse_predictions_G = bagging_predict2(pred5,test_X)\n",
    "\n",
    "\n",
    "print('############################################################################################') \n",
    "print('############################################################################################') \n",
    "\n",
    "concat_G = np.concatenate([smape_predictions_G, mase_predictions_G,mape_predictions_G,mae_predictions_G,mse_predictions_G],axis=0)\n",
    "fin_pred_G = np.median(concat_G,axis=0)\n",
    "#pd.DataFrame(fin_pred).to_csv(\"freezing_I.csv\")\n",
    "print('all',np.sqrt(mean_squared_error(test_y.flatten(),fin_pred_G.flatten())).round(5)) \n",
    "\n",
    "concat_G = np.concatenate([smape_predictions_G, mase_predictions_G,mape_predictions_G],axis=0)\n",
    "fin_pred_G = np.median(concat_G,axis=0)\n",
    "#pd.DataFrame(fin_pred).to_csv(\"freezing_I.csv\")\n",
    "print('original',np.sqrt(mean_squared_error(test_y.flatten(),fin_pred_G.flatten())).round(5))\n",
    "\n",
    "concat_G = np.concatenate([mse_predictions_G, mase_predictions_G,mae_predictions_G],axis=0)\n",
    "fin_pred_G = np.median(concat_G,axis=0)\n",
    "#pd.DataFrame(fin_pred).to_csv(\"freezing_I.csv\")\n",
    "print('best',np.sqrt(mean_squared_error(test_y.flatten(),fin_pred_G.flatten())).round(5))\n",
    "\n",
    "concat_G = np.concatenate([mse_predictions_G],axis=0)\n",
    "fin_pred_G = np.median(concat_G,axis=0)\n",
    "#pd.DataFrame(fin_pred).to_csv(\"freezing_I.csv\")\n",
    "print('mse',np.sqrt(mean_squared_error(test_y.flatten(),fin_pred_G.flatten())).round(5))\n",
    "\n",
    "\n",
    "concat_G = np.concatenate([mase_predictions_G],axis=0)\n",
    "fin_pred_G = np.median(concat_G,axis=0)\n",
    "#pd.DataFrame(fin_pred).to_csv(\"freezing_I.csv\")\n",
    "print('mase',np.sqrt(mean_squared_error(test_y.flatten(),fin_pred_G.flatten())).round(5))\n",
    "\n",
    "concat_G = np.concatenate([mae_predictions_G],axis=0)\n",
    "fin_pred_G = np.median(concat_G,axis=0)\n",
    "#pd.DataFrame(fin_pred).to_csv(\"freezing_I.csv\")\n",
    "print('mae',np.sqrt(mean_squared_error(test_y.flatten(),fin_pred_G.flatten())).round(5))\n",
    "\n",
    "concat_G = np.concatenate([mape_predictions_G],axis=0)\n",
    "fin_pred_G = np.median(concat_G,axis=0)\n",
    "#pd.DataFrame(fin_pred).to_csv(\"freezing_I.csv\")\n",
    "print('mape',np.sqrt(mean_squared_error(test_y.flatten(),fin_pred_G.flatten())).round(5))\n",
    "\n",
    "concat_G = np.concatenate([smape_predictions_G],axis=0)\n",
    "fin_pred_G = np.median(concat_G,axis=0)\n",
    "#pd.DataFrame(fin_pred).to_csv(\"freezing_I.csv\")\n",
    "print('smape',np.sqrt(mean_squared_error(test_y.flatten(),fin_pred_G.flatten())).round(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ce6054d-bd3d-4981-90dc-91c0ab363196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0.33878228),\n",
       " (2, 0.33865017),\n",
       " (3, 0.33852115),\n",
       " (4, 0.3383954),\n",
       " (5, 0.33827272),\n",
       " (6, 0.33815312),\n",
       " (7, 0.33803657),\n",
       " (8, 0.33792305),\n",
       " (9, 0.3378125),\n",
       " (10, 0.33770493),\n",
       " (11, 0.3376002),\n",
       " (12, 0.3374982),\n",
       " (13, 0.33739907),\n",
       " (14, 0.3373026),\n",
       " (15, 0.337209),\n",
       " (16, 0.33711788),\n",
       " (17, 0.33702937),\n",
       " (18, 0.33694342),\n",
       " (19, 0.33685988)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eee = []\n",
    "for i in range(1,20):\n",
    "    weights = np.exp(-i* performance)\n",
    "    normalized_weights = weights / np.sum(weights)\n",
    "    ensemble_prediction = np.dot(normalized_weights, gd.reshape(5,-1))\n",
    "    eee.append((i,np.sqrt(mean_squared_error(test_y.flatten(),ensemble_prediction.flatten().round(5)))))\n",
    "    #print(f'exp_beta{i}',np.sqrt(mean_squared_error(test_y.flatten(),ensemble_prediction.flatten())).round(5))\n",
    "\n",
    "eee"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
