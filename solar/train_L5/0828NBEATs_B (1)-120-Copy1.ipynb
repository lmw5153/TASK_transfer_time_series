{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e097566-30f2-4f57-b3a2-2ae3b7d02005",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-21 12:59:41.724994: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-21 12:59:41.862345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-09-21 12:59:41.862370: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-09-21 12:59:42.592612: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-09-21 12:59:42.592720: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-09-21 12:59:42.592732: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nbeats_keras.model import NBeatsNet as NBeatsKeras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "#from nbeats_pytorch.model import NBeatsNet as NBeatsPytorch\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "import time\n",
    "from keras.models import load_model\n",
    "#from target_data_electronic70_7 import target_X, target_y ,test_X, test_y\n",
    "#from m4databasis21_7 import base_domain,zt_in,zt_out,M4Meta,inputsize,train_12,train_12_y\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error,mean_absolute_percentage_error\n",
    "plt.rcParams['font.family'] ='Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] =False\n",
    "from tensorflow.keras.losses import Loss\n",
    "import tensorflow as tf\n",
    "#from m4databasis35_7_70_7 import train_35,train_35_y,train_70,train_70_y\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, LayerNormalization, MultiHeadAttention, Dropout, Add, Concatenate,Flatten,Reshape\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31c74fd4-9d10-4b7d-9c83-4da3c7f1871f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 24)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "target_X= pd.read_csv(\"../data/solor_train_input_5.csv\").iloc[:,(1):].values\n",
    "target_y =pd.read_csv(\"../data/solor_train_output_5.csv\").iloc[:,1:].values\n",
    "test_X= pd.read_csv(\"../data/solor_val_input_5.csv\").iloc[:,(1):].values\n",
    "test_y =pd.read_csv(\"../data/solor_val_output_5.csv\").iloc[:,1:].values\n",
    "\n",
    "X_train=target_X\n",
    "y_train=target_y\n",
    "\n",
    "backcast_length = X_train.shape[1]\n",
    "forecast_length = y_train.shape[1]\n",
    "\n",
    "backcast_length,forecast_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475bd839-0f9e-49d3-96a8-f1fe23500d97",
   "metadata": {},
   "source": [
    "# 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "117869af-8623-4129-aa35-bcc7ee3da674",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "# loss SMAPE\n",
    "class SMAPE(Loss):\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_pred = tf.reshape(y_pred, tf.shape(y_true))  # 예측 값의 차원을 맞춤\n",
    "       # y_pred=tf.clip_by_value(y_pred, 1e-10, tf.reduce_max(y_pred))\n",
    "       # y_true = tf.clip_by_value(y_true, 1e-10, tf.reduce_max(y_true))\n",
    "        \n",
    "        numerator = 100 * tf.abs(y_true- y_pred )\n",
    "        denominator =  (tf.abs(y_true ) + tf.abs(y_pred))/2\n",
    "        smape =  numerator /  denominator #tf.clip_by_value(denominator, 1e-10, tf.reduce_max(denominator))\n",
    "        return tf.reduce_mean(smape)\n",
    "\n",
    "#################################################################################\n",
    "# loss MASE\n",
    "class MASE(Loss):\n",
    "    def __init__(self, training_data, period, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.scale = self.calculate_scale(training_data, period)\n",
    "    def seasonal_diff(data, period):\n",
    "        return data[period:] - data[:-period]\n",
    "\n",
    "    def calculate_scale(self, training_data, period):\n",
    "        # 주기 차분 계산\n",
    "        diff = seasonal_diff(training_data, period)\n",
    "        scale = np.mean(np.abs(diff))\n",
    "        return scale\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        y_pred = tf.reshape(y_pred, tf.shape(y_true))  # 차원 맞추기\n",
    "        error = tf.abs(y_true - y_pred)\n",
    "        return tf.reduce_mean(error / self.scale)\n",
    "\n",
    "def seasonal_diff(data, period):\n",
    "    return data[period:] - data[:-period]\n",
    "\n",
    "#################################################################################\n",
    "#################################################################################\n",
    "# 하이퍼파라미터 인자 설정\n",
    "def hyperparameter():\n",
    "    # 1 backcast\n",
    "    # 2 forecast\n",
    "    # 3 inputdim\n",
    "    # 4 outputdim\n",
    "    # 5 unit\n",
    "    # 6 bacth size\n",
    "    return X_train.shape[1],y_train.shape[1],1,1,128\n",
    "\n",
    "#################################################################################\n",
    "# nbeats + I모델 생성 함수\n",
    "def bulid_model(backcast_,forecast_,input_dim,output_dim,unit):\n",
    "    model= NBeatsKeras(backcast_length=backcast_, \n",
    "                       forecast_length=forecast_,\n",
    "                       input_dim=input_dim,\n",
    "                       output_dim=output_dim,\n",
    "                       stack_types=(NBeatsKeras.TREND_BLOCK,\n",
    "                                    NBeatsKeras.TREND_BLOCK,\n",
    "                                    NBeatsKeras.SEASONALITY_BLOCK,\n",
    "                                    NBeatsKeras.SEASONALITY_BLOCK)\n",
    "                   ,nb_blocks_per_stack=1, thetas_dim=(1,2,4,4),\n",
    "                   share_weights_in_stack=True, hidden_layer_units=unit)\n",
    "    return model \n",
    "#################################################################################\n",
    "# nbeats + G모델 생성 함수    \n",
    "def bulid_model_G(backcast_,forecast_,input_dim,output_dim,unit):\n",
    "    model= NBeatsKeras(backcast_length=backcast_, \n",
    "                       forecast_length=forecast_,\n",
    "                       input_dim=input_dim,\n",
    "                       output_dim=output_dim,\n",
    "                       stack_types=(NBeatsKeras.GENERIC_BLOCK,NBeatsKeras.GENERIC_BLOCK)\n",
    "                   ,nb_blocks_per_stack=5, thetas_dim=(2,4),\n",
    "                   share_weights_in_stack=False, hidden_layer_units=unit)\n",
    "    return model \n",
    "#################################################################################\n",
    "# nbeats + I모델 부트스트랩 샘플링 배깅\n",
    "\n",
    "def train_bagging_models(num_models, loss_fn , epochs_, patience_,batch_size_,lr):\n",
    "    models = {}\n",
    "    backcast,forecast,in_dim,out_dim,unit = hyperparameter()\n",
    "    historys = []\n",
    "    for n in range(num_models):\n",
    "        K.clear_session()\n",
    "        model = bulid_model(backcast,forecast,in_dim,out_dim,unit)\n",
    "       # model.set_weights(pretrained_weights)  # 전이 학습 가중치 적용\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "        model.compile(optimizer=optimizer , loss=loss_fn)\n",
    "        \n",
    "        # 부트스트랩 샘플링\n",
    "        #select = np.random.choice(len(X_train), size=len(X_train), replace=True)\n",
    "        #X_bootstrap = X_train[select]\n",
    "        #y_bootstrap = y_train[select]\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience = patience_, verbose = 0, restore_best_weights=True)\n",
    "        history = model.fit(X_train, y_train, batch_size = batch_size_,\n",
    "                  epochs=epochs_, verbose=1, \n",
    "                  callbacks=[early_stop],\n",
    "                 validation_split = 0.2)\n",
    "        models[f'model_{n+1}'] = model\n",
    "        historys.append(history)\n",
    "        #models.append(model)\n",
    "        print(f\"'########################################################Model{n}\")\n",
    "    return models,historys\n",
    "#################################################################################\n",
    "# nbeats + I모델 부트스트랩 샘플링 배깅\n",
    "\n",
    "def train_bagging_models_G(num_models, loss_fn , epochs_, patience_,batch_size_,lr):\n",
    "    models = {}\n",
    "    backcast,forecast,in_dim,out_dim,unit = hyperparameter()\n",
    "    historys = []\n",
    "    for n in range(num_models):\n",
    "        K.clear_session()\n",
    "        model = bulid_model_G(backcast,forecast,in_dim,out_dim,unit)\n",
    "       # model.set_weights(pretrained_weights)  # 전이 학습 가중치 적용\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "        model.compile(optimizer=optimizer , loss=loss_fn)\n",
    "        \n",
    "        # 부트스트랩 샘플링\n",
    "        #select = np.random.choice(len(X_train), size=len(X_train), replace=True)\n",
    "        #X_bootstrap = X_train[select]\n",
    "        #y_bootstrap = y_train[select]\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience = patience_, verbose = 0, restore_best_weights=True)\n",
    "        history = model.fit(X_train, y_train, batch_size = batch_size_,\n",
    "                  epochs=epochs_, verbose=1, \n",
    "                  callbacks=[early_stop],\n",
    "                 validation_split = 0.2)\n",
    "        models[f'model_{n+1}'] = model\n",
    "        historys.append(history)\n",
    "        #models.append(model)\n",
    "        print(f\"'########################################################Model{n}\")\n",
    "    return models,historys\n",
    "\n",
    "#################################################################################\n",
    "# SMAPE 용\n",
    "def train_bagging_models_smape(num_models, loss_fn , epochs_, patience_,batch_size_,lr):\n",
    "    models = {}\n",
    "    backcast,forecast,in_dim,out_dim,unit = hyperparameter()\n",
    "    historys = []\n",
    "    for n in range(num_models):\n",
    "        K.clear_session()\n",
    "        model = bulid_model(backcast,forecast,in_dim,out_dim,unit)\n",
    "       # model.set_weights(pretrained_weights)  # 전이 학습 가중치 적용\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "        model.compile(optimizer=optimizer , loss=loss_fn)\n",
    "        \n",
    "        # 부트스트랩 샘플링\n",
    "        #select = np.random.choice(len(X_train), size=len(X_train), replace=True)\n",
    "        #X_bootstrap = X_train[select]\n",
    "        #y_bootstrap = y_train[select]\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience = patience_, verbose = 0, restore_best_weights=True)\n",
    "        history = model.fit(X_bootstrap, y_bootstrap, batch_size = batch_size_,\n",
    "                  epochs=epochs_, verbose=1, \n",
    "                  callbacks=[early_stop],\n",
    "                 validation_split = 0.2)\n",
    "        models[f'model_{n+1}'] = model\n",
    "        historys.append(history)\n",
    "        #models.append(model)\n",
    "        print(f\"'########################################################Model{n}\")\n",
    "    return models,historys\n",
    "\n",
    "##########################################################################################\n",
    "# 트랜스퍼 레이어\n",
    "class PositionalEncoding(layers.Layer):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = layers.Dropout(rate=dropout)\n",
    "\n",
    "        position = np.arange(max_len)[:, np.newaxis]\n",
    "        div_term = np.exp(np.arange(0, d_model, 2) * (-np.log(10000.0) / d_model))\n",
    "        pe = np.zeros((max_len, d_model))\n",
    "        pe[:, 0::2] = np.sin(position * div_term)\n",
    "        pe[:, 1::2] = np.cos(position * div_term)\n",
    "        pe = pe[np.newaxis, ...]\n",
    "\n",
    "        self.pe = tf.constant(pe, dtype=tf.float32)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = x + self.pe[:, :tf.shape(x)[1], :]\n",
    "        return self.dropout(x)\n",
    "##########################################################################################\n",
    "# 트랜스퍼 레이어\n",
    "def create_model(fn,d_model, nlayers, nhead, dropout, iw, ow,lr):\n",
    "    \n",
    "    \n",
    "    x = layers.Dense(d_model // 2, activation='relu')(pretrained_output_reshaped)\n",
    "    x = layers.Dense(d_model, activation='relu')(x)\n",
    "    \n",
    "    pos_encoding = PositionalEncoding(d_model, dropout)\n",
    "    x = pos_encoding(x)\n",
    "    \n",
    "    for _ in range(nlayers):\n",
    "        attn_output = layers.MultiHeadAttention(num_heads=nhead, key_dim=d_model, dropout=dropout)(x, x)\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x + attn_output)\n",
    "        ffn_output = layers.Dense(d_model, activation='relu')(x)\n",
    "        ffn_output = layers.Dense(d_model)(ffn_output)\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x + ffn_output)\n",
    "    \n",
    "    x = layers.Dense(d_model // 2, activation='relu')(x)\n",
    "    x = layers.Dense(1)(x)\n",
    "    x = tf.squeeze(x, axis=-1)\n",
    "    \n",
    "    outputs = layers.Dense((iw + ow) // 2, activation='relu')(x)\n",
    "    outputs = layers.Dense(ow)(outputs)\n",
    "    \n",
    "    optimizer = Adam(learning_rate=lr)\n",
    "    target_model = Model(inputs=inputs, outputs=outputs)\n",
    "    target_model.compile(optimizer=optimizer, loss=fn)\n",
    "    \n",
    "    return target_model\n",
    "#################################################################################\n",
    "# 예측\n",
    "\n",
    "def bagging_predict(models, X):\n",
    "    predictions = np.array([model.predict(X) for model in models.values()])\n",
    "    return np.median(predictions, axis=0)\n",
    "\n",
    "def bagging_predict2(models, X):\n",
    "    predictions = np.array([model.predict(X) for model in models.values()])\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa4c593-18a3-4fa1-be2e-8894dc7d453f",
   "metadata": {},
   "source": [
    "# 모형적합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f13c2f-9812-460b-9269-22aa352bfc7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-21 13:00:09.320093: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-09-21 13:00:09.320152: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ymlee2-desktop): /proc/driver/nvidia/version does not exist\n",
      "2024-09-21 13:00:09.320665: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 9ms/step - loss: 1.4078 - val_loss: 0.8170\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.9083 - val_loss: 0.7589\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.8423 - val_loss: 0.7344\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.8129 - val_loss: 0.7274\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.7905 - val_loss: 0.7240\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7521 - val_loss: 0.6929\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.7340 - val_loss: 0.6958\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7223 - val_loss: 0.6691\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7021 - val_loss: 0.6762\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6778 - val_loss: 0.6919\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6956 - val_loss: 0.7038\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6562 - val_loss: 0.7013\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6351 - val_loss: 0.6772\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6329 - val_loss: 0.6712\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6185 - val_loss: 0.6797\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5962 - val_loss: 0.6836\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5975 - val_loss: 0.7111\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5582 - val_loss: 0.6877\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.5350 - val_loss: 0.6665\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5218 - val_loss: 0.7218\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5233 - val_loss: 0.6792\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5202 - val_loss: 0.6967\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5066 - val_loss: 0.6984\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4891 - val_loss: 0.6572\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4716 - val_loss: 0.6693\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4562 - val_loss: 0.6980\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4686 - val_loss: 0.6854\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4680 - val_loss: 0.6695\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4367 - val_loss: 0.6759\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.4209 - val_loss: 0.7135\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4366 - val_loss: 0.6691\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4242 - val_loss: 0.6806\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.3993 - val_loss: 0.7166\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.4002 - val_loss: 0.6853\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3837 - val_loss: 0.7059\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3904 - val_loss: 0.6689\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3661 - val_loss: 0.6824\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3688 - val_loss: 0.6867\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3528 - val_loss: 0.7140\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3680 - val_loss: 0.7052\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.3455 - val_loss: 0.6720\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3418 - val_loss: 0.7101\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3488 - val_loss: 0.6942\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3257 - val_loss: 0.6821\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3317 - val_loss: 0.6912\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3429 - val_loss: 0.6716\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3422 - val_loss: 0.6885\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3370 - val_loss: 0.6674\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3212 - val_loss: 0.7029\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3109 - val_loss: 0.6718\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3015 - val_loss: 0.6636\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2872 - val_loss: 0.6941\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2898 - val_loss: 0.6892\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2893 - val_loss: 0.6827\n",
      "'########################################################Model0\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 8ms/step - loss: 1.3081 - val_loss: 0.8328\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.9160 - val_loss: 0.7913\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.8486 - val_loss: 0.7546\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.8261 - val_loss: 0.7531\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.7759 - val_loss: 0.6852\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.7432 - val_loss: 0.6721\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.7236 - val_loss: 0.7425\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.7221 - val_loss: 0.6829\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.7040 - val_loss: 0.6773\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6821 - val_loss: 0.6972\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6618 - val_loss: 0.6645\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6791 - val_loss: 0.7031\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6402 - val_loss: 0.6666\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6196 - val_loss: 0.6643\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5994 - val_loss: 0.6814\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6003 - val_loss: 0.7158\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5791 - val_loss: 0.6596\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5836 - val_loss: 0.6958\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5722 - val_loss: 0.6436\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5433 - val_loss: 0.6941\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5153 - val_loss: 0.6821\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5377 - val_loss: 0.6804\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5030 - val_loss: 0.6789\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5241 - val_loss: 0.6769\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5054 - val_loss: 0.6999\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4714 - val_loss: 0.6783\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4724 - val_loss: 0.6824\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4781 - val_loss: 0.6639\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.4660 - val_loss: 0.7001\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4815 - val_loss: 0.7183\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4359 - val_loss: 0.6961\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4284 - val_loss: 0.6993\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4199 - val_loss: 0.7041\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4087 - val_loss: 0.7164\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3949 - val_loss: 0.6904\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3916 - val_loss: 0.6999\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3920 - val_loss: 0.7207\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3731 - val_loss: 0.7025\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4100 - val_loss: 0.6978\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3576 - val_loss: 0.6846\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3625 - val_loss: 0.6710\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3509 - val_loss: 0.7194\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3379 - val_loss: 0.6654\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.3345 - val_loss: 0.6921\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3278 - val_loss: 0.6700\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.3228 - val_loss: 0.6662\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3138 - val_loss: 0.6878\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3135 - val_loss: 0.6563\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3085 - val_loss: 0.6823\n",
      "'########################################################Model1\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 8ms/step - loss: 1.3352 - val_loss: 0.8154\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.8986 - val_loss: 0.7638\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.8314 - val_loss: 0.7220\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.7943 - val_loss: 0.7253\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.7815 - val_loss: 0.7109\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.7427 - val_loss: 0.6928\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.7456 - val_loss: 0.6713\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7075 - val_loss: 0.6960\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6945 - val_loss: 0.7039\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6804 - val_loss: 0.6878\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6591 - val_loss: 0.6887\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6416 - val_loss: 0.7095\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6315 - val_loss: 0.7292\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6281 - val_loss: 0.6871\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6082 - val_loss: 0.7130\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6010 - val_loss: 0.6695\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5765 - val_loss: 0.6854\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5556 - val_loss: 0.7102\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5633 - val_loss: 0.6668\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5254 - val_loss: 0.6734\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5143 - val_loss: 0.7215\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5038 - val_loss: 0.7053\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5114 - val_loss: 0.6990\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.4811 - val_loss: 0.6889\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.4675 - val_loss: 0.7153\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.4864 - val_loss: 0.6809\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.4701 - val_loss: 0.6727\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.4543 - val_loss: 0.6851\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.4777 - val_loss: 0.6913\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.4346 - val_loss: 0.6640\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.4076 - val_loss: 0.6862\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.3989 - val_loss: 0.6984\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.4079 - val_loss: 0.7253\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.3958 - val_loss: 0.6756\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.3737 - val_loss: 0.6811\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.3664 - val_loss: 0.6694\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.3528 - val_loss: 0.6981\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.3644 - val_loss: 0.6857\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.3447 - val_loss: 0.7173\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3606 - val_loss: 0.6963\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3353 - val_loss: 0.6859\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.3380 - val_loss: 0.6605\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.3278 - val_loss: 0.6968\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.3283 - val_loss: 0.6888\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.3248 - val_loss: 0.7052\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.3093 - val_loss: 0.7114\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2984 - val_loss: 0.6887\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2962 - val_loss: 0.6888\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.2982 - val_loss: 0.7122\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2895 - val_loss: 0.6984\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2873 - val_loss: 0.7055\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2975 - val_loss: 0.6897\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2834 - val_loss: 0.6764\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2770 - val_loss: 0.6953\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2655 - val_loss: 0.6885\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2549 - val_loss: 0.6908\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2668 - val_loss: 0.7103\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2773 - val_loss: 0.7025\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2559 - val_loss: 0.7100\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.2471 - val_loss: 0.6847\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2530 - val_loss: 0.7034\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2393 - val_loss: 0.6661\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2444 - val_loss: 0.7099\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2436 - val_loss: 0.6938\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2370 - val_loss: 0.6967\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2488 - val_loss: 0.6965\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2317 - val_loss: 0.6950\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2357 - val_loss: 0.6845\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2376 - val_loss: 0.6899\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2331 - val_loss: 0.7123\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.2327 - val_loss: 0.6963\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2290 - val_loss: 0.6908\n",
      "'########################################################Model2\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 9ms/step - loss: 1.4071 - val_loss: 0.9109\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.9386 - val_loss: 0.7539\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.8547 - val_loss: 0.7494\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.8147 - val_loss: 0.6956\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7847 - val_loss: 0.7046\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.7594 - val_loss: 0.6950\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7253 - val_loss: 0.6902\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.7384 - val_loss: 0.7142\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.7089 - val_loss: 0.6917\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6812 - val_loss: 0.6823\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6775 - val_loss: 0.6817\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6778 - val_loss: 0.6835\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6419 - val_loss: 0.6665\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6113 - val_loss: 0.6841\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6074 - val_loss: 0.6858\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6060 - val_loss: 0.6734\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6020 - val_loss: 0.6782\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5658 - val_loss: 0.6905\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5668 - val_loss: 0.7070\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.5323 - val_loss: 0.6947\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5147 - val_loss: 0.6638\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5060 - val_loss: 0.7051\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.5482 - val_loss: 0.6877\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.4993 - val_loss: 0.6873\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4799 - val_loss: 0.7253\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4609 - val_loss: 0.7012\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4439 - val_loss: 0.6829\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4363 - val_loss: 0.6869\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4445 - val_loss: 0.7080\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.4393 - val_loss: 0.6621\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4096 - val_loss: 0.6944\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4181 - val_loss: 0.7175\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4058 - val_loss: 0.7284\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4072 - val_loss: 0.6805\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3947 - val_loss: 0.6668\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4002 - val_loss: 0.6792\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.3850 - val_loss: 0.7091\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3771 - val_loss: 0.6953\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3661 - val_loss: 0.6937\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3711 - val_loss: 0.6981\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3510 - val_loss: 0.6753\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3467 - val_loss: 0.6861\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3283 - val_loss: 0.6954\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3174 - val_loss: 0.7078\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3238 - val_loss: 0.6966\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3503 - val_loss: 0.6932\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.3294 - val_loss: 0.6861\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3253 - val_loss: 0.6934\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3034 - val_loss: 0.6813\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2930 - val_loss: 0.6910\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2989 - val_loss: 0.6816\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3019 - val_loss: 0.6753\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.2945 - val_loss: 0.6905\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2854 - val_loss: 0.6995\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2814 - val_loss: 0.6891\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2796 - val_loss: 0.6832\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.2731 - val_loss: 0.6981\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2784 - val_loss: 0.6974\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.2840 - val_loss: 0.7105\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2756 - val_loss: 0.6738\n",
      "'########################################################Model3\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 9ms/step - loss: 1.2778 - val_loss: 0.8472\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.9099 - val_loss: 0.7550\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.8627 - val_loss: 0.7604\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.8128 - val_loss: 0.7575\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7775 - val_loss: 0.7538\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.7603 - val_loss: 0.7011\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.7349 - val_loss: 0.6673\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.7229 - val_loss: 0.6576\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.7165 - val_loss: 0.7010\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6926 - val_loss: 0.6867\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6977 - val_loss: 0.6865\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6639 - val_loss: 0.7151\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6445 - val_loss: 0.6924\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6459 - val_loss: 0.6794\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6332 - val_loss: 0.6667\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6258 - val_loss: 0.7042\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6258 - val_loss: 0.6712\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5890 - val_loss: 0.7088\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5562 - val_loss: 0.6710\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5508 - val_loss: 0.7013\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5420 - val_loss: 0.7011\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5188 - val_loss: 0.7218\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5075 - val_loss: 0.6796\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5248 - val_loss: 0.6978\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4940 - val_loss: 0.6754\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4806 - val_loss: 0.7027\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4605 - val_loss: 0.7572\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.4640 - val_loss: 0.7201\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4575 - val_loss: 0.6939\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4397 - val_loss: 0.6999\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.4311 - val_loss: 0.7610\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4249 - val_loss: 0.7413\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4173 - val_loss: 0.6917\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4006 - val_loss: 0.6926\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4083 - val_loss: 0.7152\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.3945 - val_loss: 0.7144\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.3826 - val_loss: 0.7396\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.3661 - val_loss: 0.7032\n",
      "'########################################################Model4\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6681 - val_loss: 0.6783\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6497 - val_loss: 0.6886\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6459 - val_loss: 0.6898\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6248 - val_loss: 0.6933\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6118 - val_loss: 0.6840\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6050 - val_loss: 0.7003\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.5765 - val_loss: 0.6896\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5808 - val_loss: 0.6870\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5567 - val_loss: 0.6946\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5535 - val_loss: 0.6993\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5145 - val_loss: 0.7100\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5269 - val_loss: 0.7136\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5102 - val_loss: 0.6994\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4842 - val_loss: 0.6905\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4788 - val_loss: 0.7137\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.4743 - val_loss: 0.7339\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4605 - val_loss: 0.7024\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4429 - val_loss: 0.6930\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4514 - val_loss: 0.6874\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4378 - val_loss: 0.7046\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.4338 - val_loss: 0.7268\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 2s 8ms/step - loss: 152386512.0000 - val_loss: 61875156.0000\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 47900252.0000 - val_loss: 41388616.0000\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 35279416.0000 - val_loss: 36345576.0000\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 28505266.0000 - val_loss: 28019916.0000\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 25326676.0000 - val_loss: 25377146.0000\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 20895020.0000 - val_loss: 21641872.0000\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 17943386.0000 - val_loss: 20305530.0000\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 16941424.0000 - val_loss: 18187092.0000\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 15018471.0000 - val_loss: 16107748.0000\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 13200410.0000 - val_loss: 21990472.0000\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 13594789.0000 - val_loss: 15361817.0000\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 12545095.0000 - val_loss: 15257706.0000\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 10638052.0000 - val_loss: 13651784.0000\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 10324301.0000 - val_loss: 12483585.0000\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 9621649.0000 - val_loss: 12565850.0000\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 10041040.0000 - val_loss: 11574614.0000\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 8605845.0000 - val_loss: 10716702.0000\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 8030465.0000 - val_loss: 13665723.0000\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 8722207.0000 - val_loss: 10036932.0000\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 7699116.0000 - val_loss: 9076443.0000\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 6717972.0000 - val_loss: 9270691.0000\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 6536150.0000 - val_loss: 7646074.5000\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 6419823.0000 - val_loss: 8414490.0000\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 5774807.0000 - val_loss: 8260915.0000\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 5671126.0000 - val_loss: 7175335.0000\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 5891304.0000 - val_loss: 7537086.5000\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5690783.5000 - val_loss: 7331619.0000\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5097906.5000 - val_loss: 6590215.0000\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 4556767.0000 - val_loss: 6569033.5000\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4791046.0000 - val_loss: 7322165.0000\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 4882364.5000 - val_loss: 5527926.5000\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4477643.5000 - val_loss: 5952740.5000\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4621934.5000 - val_loss: 5351234.0000\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4143124.7500 - val_loss: 5216134.0000\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3876351.0000 - val_loss: 4958096.0000\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4729158.0000 - val_loss: 8008588.5000\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 4317249.5000 - val_loss: 5150673.5000\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3820591.5000 - val_loss: 4723172.0000\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3233723.5000 - val_loss: 4277174.5000\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3186751.0000 - val_loss: 4691188.0000\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3515937.7500 - val_loss: 3832283.7500\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3171530.5000 - val_loss: 4142977.7500\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3459379.0000 - val_loss: 4241290.5000\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3652598.0000 - val_loss: 5456635.5000\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3103573.2500 - val_loss: 3701185.0000\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2679281.5000 - val_loss: 3705314.5000\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2448533.2500 - val_loss: 3214327.5000\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3090864.0000 - val_loss: 3286672.5000\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2679704.0000 - val_loss: 3379383.0000\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2797493.7500 - val_loss: 3546243.7500\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2281167.7500 - val_loss: 2929891.7500\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2458677.0000 - val_loss: 2850302.7500\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2058314.6250 - val_loss: 3785872.2500\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2096921.8750 - val_loss: 3107222.7500\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1957272.3750 - val_loss: 2782042.0000\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2597328.5000 - val_loss: 2421407.0000\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1868632.3750 - val_loss: 2699902.7500\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1954524.3750 - val_loss: 2444990.2500\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2008004.8750 - val_loss: 3446996.7500\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1730525.0000 - val_loss: 2588619.5000\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1532794.7500 - val_loss: 2293452.2500\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1576690.7500 - val_loss: 1998848.0000\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1668188.6250 - val_loss: 1928702.6250\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1705660.7500 - val_loss: 3118777.5000\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1720385.7500 - val_loss: 2068387.1250\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1355944.0000 - val_loss: 2114961.7500\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1338515.5000 - val_loss: 1952047.6250\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1527141.6250 - val_loss: 1897278.6250\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1432289.1250 - val_loss: 2509492.7500\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1440794.8750 - val_loss: 1731667.6250\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1273056.6250 - val_loss: 2758704.5000\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1325815.7500 - val_loss: 1564177.0000\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1429634.2500 - val_loss: 1571621.1250\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1256562.8750 - val_loss: 1565563.5000\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1185893.8750 - val_loss: 1470184.1250\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1440016.2500 - val_loss: 2010095.2500\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1240549.7500 - val_loss: 1560583.2500\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1416711.2500 - val_loss: 2382101.2500\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1247232.5000 - val_loss: 1588749.7500\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1146909.5000 - val_loss: 1297266.6250\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1033515.6250 - val_loss: 1610729.3750\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1155212.2500 - val_loss: 1471452.7500\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1120931.1250 - val_loss: 1347221.0000\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 937902.6250 - val_loss: 2076447.3750\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 949222.0625 - val_loss: 1228015.2500\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1240997.1250 - val_loss: 1132520.3750\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1026058.5000 - val_loss: 1315461.1250\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1110921.2500 - val_loss: 1549581.7500\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1080476.6250 - val_loss: 1970970.8750\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1003909.0625 - val_loss: 993674.2500\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1128828.1250 - val_loss: 965227.0625\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 756917.1250 - val_loss: 1311922.6250\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 712663.6875 - val_loss: 1177715.2500\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 745115.0000 - val_loss: 801904.6875\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 825422.5000 - val_loss: 1093583.5000\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 780078.9375 - val_loss: 944008.5000\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 769676.7500 - val_loss: 862938.1250\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 867867.8750 - val_loss: 981053.6875\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 901803.3750 - val_loss: 893750.5625\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 766309.1250 - val_loss: 1758088.5000\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 796674.9375 - val_loss: 826714.1250\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 935425.6875 - val_loss: 1059280.6250\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 720726.9375 - val_loss: 942738.7500\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 734775.1250 - val_loss: 756168.6250\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 713365.6250 - val_loss: 1036346.5000\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 669436.7500 - val_loss: 1207725.0000\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 590988.0625 - val_loss: 880330.1875\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 604267.8125 - val_loss: 843998.2500\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 627032.6875 - val_loss: 702722.9375\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 509341.7812 - val_loss: 600995.2500\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 567997.1250 - val_loss: 691687.0625\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 522256.1562 - val_loss: 605118.3750\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 556711.8750 - val_loss: 718490.7500\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 592883.9375 - val_loss: 933859.0000\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 488991.1562 - val_loss: 657409.9375\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 483106.8125 - val_loss: 580669.3750\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 682038.6250 - val_loss: 860040.2500\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 516942.6250 - val_loss: 501790.9375\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 380289.9688 - val_loss: 512613.1250\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 429058.3125 - val_loss: 424496.9688\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 359160.4375 - val_loss: 477561.8125\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 427599.2812 - val_loss: 456264.6250\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 363976.9375 - val_loss: 478684.2500\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 323206.5312 - val_loss: 369924.6250\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 289045.9375 - val_loss: 281166.7188\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 271898.2188 - val_loss: 497235.1875\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 303941.7500 - val_loss: 354448.3750\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 264816.3750 - val_loss: 433331.6562\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 244343.3594 - val_loss: 516195.5938\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 256522.1094 - val_loss: 253138.1719\n",
      "Epoch 131/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 234095.7031 - val_loss: 315351.7500\n",
      "Epoch 132/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 223707.1719 - val_loss: 374154.0000\n",
      "Epoch 133/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 257356.2969 - val_loss: 369253.5000\n",
      "Epoch 134/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 259487.1406 - val_loss: 274922.3125\n",
      "Epoch 135/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 296991.9375 - val_loss: 304096.4375\n",
      "Epoch 136/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 224030.0312 - val_loss: 298179.9375\n",
      "Epoch 137/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 229803.5312 - val_loss: 174686.2812\n",
      "Epoch 138/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 245416.6094 - val_loss: 214799.5156\n",
      "Epoch 139/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 213627.2344 - val_loss: 203312.8750\n",
      "Epoch 140/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 193813.8750 - val_loss: 258814.7031\n",
      "Epoch 141/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 185799.4219 - val_loss: 307199.5000\n",
      "Epoch 142/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 198530.6562 - val_loss: 307228.9375\n",
      "Epoch 143/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 204363.2031 - val_loss: 294712.5625\n",
      "Epoch 144/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 188808.2812 - val_loss: 280291.8125\n",
      "Epoch 145/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 182171.8125 - val_loss: 305254.3750\n",
      "Epoch 146/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 189312.3750 - val_loss: 146954.2812\n",
      "Epoch 147/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 185978.7344 - val_loss: 233277.1875\n",
      "Epoch 148/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 176501.8281 - val_loss: 188448.1719\n",
      "Epoch 149/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 185192.5469 - val_loss: 243598.3750\n",
      "Epoch 150/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 215139.1719 - val_loss: 392113.7188\n",
      "Epoch 151/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 202944.5469 - val_loss: 192416.4375\n",
      "Epoch 152/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 227888.9062 - val_loss: 415222.4688\n",
      "Epoch 153/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 227750.4219 - val_loss: 300792.5938\n",
      "Epoch 154/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 177623.4531 - val_loss: 231193.6562\n",
      "Epoch 155/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 172274.8281 - val_loss: 211363.3750\n",
      "Epoch 156/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 163648.4844 - val_loss: 246192.1719\n",
      "Epoch 157/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 251086.6406 - val_loss: 263132.6250\n",
      "Epoch 158/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 183064.9688 - val_loss: 168535.0312\n",
      "Epoch 159/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 188783.8906 - val_loss: 260521.3750\n",
      "Epoch 160/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 208245.3906 - val_loss: 212981.7969\n",
      "Epoch 161/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 178637.9375 - val_loss: 220466.7656\n",
      "Epoch 162/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 187787.2031 - val_loss: 165143.5312\n",
      "Epoch 163/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 170506.1875 - val_loss: 188733.4844\n",
      "Epoch 164/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 210902.0312 - val_loss: 345893.5938\n",
      "Epoch 165/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 159005.8125 - val_loss: 185310.4062\n",
      "Epoch 166/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 171453.7500 - val_loss: 227357.5938\n",
      "Epoch 167/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 177481.8750 - val_loss: 206186.9375\n",
      "Epoch 168/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 149930.1406 - val_loss: 189651.2500\n",
      "Epoch 169/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 165664.5000 - val_loss: 220187.5625\n",
      "Epoch 170/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 174483.2500 - val_loss: 175590.3906\n",
      "Epoch 171/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 141837.8594 - val_loss: 211336.4688\n",
      "Epoch 172/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 187554.0781 - val_loss: 257720.3594\n",
      "Epoch 173/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 149876.1875 - val_loss: 177823.7031\n",
      "Epoch 174/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 123296.1641 - val_loss: 141903.9375\n",
      "Epoch 175/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 130045.2031 - val_loss: 212851.3125\n",
      "Epoch 176/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 157531.6719 - val_loss: 164915.0312\n",
      "Epoch 177/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 153181.5312 - val_loss: 228183.9688\n",
      "Epoch 178/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 156171.1562 - val_loss: 160244.2500\n",
      "Epoch 179/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 149217.5312 - val_loss: 140493.9375\n",
      "Epoch 180/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 112414.9844 - val_loss: 154929.2812\n",
      "Epoch 181/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 143588.9531 - val_loss: 152315.2344\n",
      "Epoch 182/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 118822.8516 - val_loss: 139515.4219\n",
      "Epoch 183/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 125685.2344 - val_loss: 154619.7031\n",
      "Epoch 184/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 107467.2969 - val_loss: 123849.0469\n",
      "Epoch 185/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 117538.2969 - val_loss: 85976.3984\n",
      "Epoch 186/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 109148.6172 - val_loss: 188675.6406\n",
      "Epoch 187/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 131381.7188 - val_loss: 200780.0625\n",
      "Epoch 188/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 102132.1328 - val_loss: 88077.2031\n",
      "Epoch 189/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 107812.2891 - val_loss: 120727.9297\n",
      "Epoch 190/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 86328.9922 - val_loss: 107316.3125\n",
      "Epoch 191/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 101760.8203 - val_loss: 129966.4688\n",
      "Epoch 192/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 109543.3047 - val_loss: 149253.9531\n",
      "Epoch 193/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 116611.0703 - val_loss: 147535.1250\n",
      "Epoch 194/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 132868.2969 - val_loss: 184401.0625\n",
      "Epoch 195/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 108929.8594 - val_loss: 80778.1172\n",
      "Epoch 196/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 89277.5000 - val_loss: 184864.6406\n",
      "Epoch 197/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 84411.4297 - val_loss: 161050.0625\n",
      "Epoch 198/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 78577.4141 - val_loss: 121356.4141\n",
      "Epoch 199/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 90993.4922 - val_loss: 135021.0938\n",
      "Epoch 200/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 82449.6094 - val_loss: 124537.9297\n",
      "Epoch 201/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 82704.0312 - val_loss: 121404.0547\n",
      "Epoch 202/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 94714.9062 - val_loss: 148803.0469\n",
      "Epoch 203/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 80314.1641 - val_loss: 155103.8438\n",
      "Epoch 204/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 103568.2734 - val_loss: 102700.7969\n",
      "Epoch 205/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 88812.6328 - val_loss: 117867.8203\n",
      "Epoch 206/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 81142.3359 - val_loss: 73305.9531\n",
      "Epoch 207/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 67642.5781 - val_loss: 101980.0938\n",
      "Epoch 208/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 82003.8203 - val_loss: 59964.3047\n",
      "Epoch 209/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 70783.7578 - val_loss: 114041.4453\n",
      "Epoch 210/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 68734.6094 - val_loss: 71958.7578\n",
      "Epoch 211/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 72515.1641 - val_loss: 113373.1484\n",
      "Epoch 212/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 71528.5234 - val_loss: 57882.1016\n",
      "Epoch 213/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 85428.4297 - val_loss: 140824.0781\n",
      "Epoch 214/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 65627.4844 - val_loss: 88986.2031\n",
      "Epoch 215/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 62346.3945 - val_loss: 58395.5156\n",
      "Epoch 216/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 69264.2500 - val_loss: 120078.0156\n",
      "Epoch 217/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 62728.1875 - val_loss: 65898.1172\n",
      "Epoch 218/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 115989.2656 - val_loss: 89081.5312\n",
      "Epoch 219/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 95494.9609 - val_loss: 119649.7109\n",
      "Epoch 220/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 63091.7109 - val_loss: 78002.4688\n",
      "Epoch 221/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 65459.6133 - val_loss: 53111.4258\n",
      "Epoch 222/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 71080.8516 - val_loss: 88980.5625\n",
      "Epoch 223/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 65651.7500 - val_loss: 52001.0664\n",
      "Epoch 224/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 44993.3438 - val_loss: 65353.6055\n",
      "Epoch 225/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 51667.7383 - val_loss: 99266.3438\n",
      "Epoch 226/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 62215.6953 - val_loss: 82816.4688\n",
      "Epoch 227/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 71639.0391 - val_loss: 72820.1172\n",
      "Epoch 228/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 50753.6484 - val_loss: 134244.4688\n",
      "Epoch 229/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 67226.9688 - val_loss: 68878.5859\n",
      "Epoch 230/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 57941.9023 - val_loss: 122526.5391\n",
      "Epoch 231/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 59103.9375 - val_loss: 60236.9805\n",
      "Epoch 232/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 53087.9102 - val_loss: 46861.4766\n",
      "Epoch 233/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 55083.8047 - val_loss: 60894.3945\n",
      "Epoch 234/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 45332.4414 - val_loss: 55955.3711\n",
      "Epoch 235/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 46643.7969 - val_loss: 69811.7188\n",
      "Epoch 236/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 88894.8281 - val_loss: 61045.4141\n",
      "Epoch 237/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 69004.9688 - val_loss: 117245.6562\n",
      "Epoch 238/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 73685.8984 - val_loss: 109680.0156\n",
      "Epoch 239/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 69553.8594 - val_loss: 139842.2344\n",
      "Epoch 240/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 84028.7188 - val_loss: 100858.4219\n",
      "Epoch 241/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 60661.8281 - val_loss: 65300.8828\n",
      "Epoch 242/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 55338.2891 - val_loss: 46531.3047\n",
      "Epoch 243/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 64440.3047 - val_loss: 169152.3750\n",
      "Epoch 244/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 82701.2969 - val_loss: 103370.3438\n",
      "Epoch 245/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 63619.8398 - val_loss: 137513.2031\n",
      "Epoch 246/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 73988.1562 - val_loss: 98110.3906\n",
      "Epoch 247/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 64490.0078 - val_loss: 174894.8125\n",
      "Epoch 248/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 46060.0391 - val_loss: 77432.7344\n",
      "Epoch 249/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 33151.7461 - val_loss: 52694.3008\n",
      "Epoch 250/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 55938.1680 - val_loss: 40516.7695\n",
      "Epoch 251/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 68620.0312 - val_loss: 109505.2031\n",
      "Epoch 252/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 77075.7969 - val_loss: 97071.9609\n",
      "Epoch 253/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 54940.6055 - val_loss: 48232.2188\n",
      "Epoch 254/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 60387.7773 - val_loss: 63078.1602\n",
      "Epoch 255/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 63983.9922 - val_loss: 62930.4570\n",
      "Epoch 256/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 80929.5938 - val_loss: 64632.2891\n",
      "Epoch 257/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 61645.0312 - val_loss: 103335.4609\n",
      "Epoch 258/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 47144.7148 - val_loss: 41064.7422\n",
      "Epoch 259/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 34173.0664 - val_loss: 64651.6016\n",
      "Epoch 260/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 33139.3125 - val_loss: 43178.5000\n",
      "Epoch 261/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 49208.4336 - val_loss: 98772.0312\n",
      "Epoch 262/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 41563.0547 - val_loss: 60127.7656\n",
      "Epoch 263/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 42299.5703 - val_loss: 58605.3789\n",
      "Epoch 264/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 76483.0859 - val_loss: 28029.1719\n",
      "Epoch 265/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 27891.4375 - val_loss: 47235.0898\n",
      "Epoch 266/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 38096.0547 - val_loss: 41412.5469\n",
      "Epoch 267/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 39502.4883 - val_loss: 23064.5801\n",
      "Epoch 268/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 28955.2930 - val_loss: 32197.0684\n",
      "Epoch 269/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 42256.0625 - val_loss: 64951.9570\n",
      "Epoch 270/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 49829.4648 - val_loss: 58271.9570\n",
      "Epoch 271/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 41314.8945 - val_loss: 33885.0117\n",
      "Epoch 272/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 41611.2266 - val_loss: 51267.3086\n",
      "Epoch 273/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 32404.0176 - val_loss: 73212.9609\n",
      "Epoch 274/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 31761.7754 - val_loss: 30551.4043\n",
      "Epoch 275/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 45491.0469 - val_loss: 69140.6016\n",
      "Epoch 276/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 34542.1406 - val_loss: 42884.9336\n",
      "Epoch 277/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 49642.1680 - val_loss: 36744.2734\n",
      "Epoch 278/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 48092.2305 - val_loss: 122445.2578\n",
      "Epoch 279/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 45573.6211 - val_loss: 23562.4297\n",
      "Epoch 280/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 30712.6133 - val_loss: 64698.5117\n",
      "Epoch 281/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 36399.3086 - val_loss: 92677.0938\n",
      "Epoch 282/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 37208.3945 - val_loss: 89160.9766\n",
      "Epoch 283/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 38401.4219 - val_loss: 74545.8984\n",
      "Epoch 284/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 44400.0938 - val_loss: 48745.9297\n",
      "Epoch 285/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 28809.0156 - val_loss: 72851.4531\n",
      "Epoch 286/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 28017.9375 - val_loss: 87823.1016\n",
      "Epoch 287/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 56364.2305 - val_loss: 38950.6797\n",
      "Epoch 288/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 32588.1562 - val_loss: 99495.0469\n",
      "Epoch 289/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 37795.5938 - val_loss: 24862.8066\n",
      "Epoch 290/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 40933.5000 - val_loss: 96298.1719\n",
      "Epoch 291/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 32038.6719 - val_loss: 23319.5918\n",
      "Epoch 292/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 27065.5820 - val_loss: 23007.8535\n",
      "Epoch 293/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 26752.6191 - val_loss: 45945.6758\n",
      "Epoch 294/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 29150.0859 - val_loss: 38915.3008\n",
      "Epoch 295/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 32888.9727 - val_loss: 27076.3613\n",
      "Epoch 296/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 26286.9102 - val_loss: 24965.4766\n",
      "Epoch 297/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 38481.5703 - val_loss: 37817.1328\n",
      "Epoch 298/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 25243.8203 - val_loss: 78308.3828\n",
      "Epoch 299/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 33080.3438 - val_loss: 51485.8555\n",
      "Epoch 300/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 31032.7656 - val_loss: 30959.3906\n",
      "'########################################################Model0\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 9ms/step - loss: 162013248.0000 - val_loss: 63447808.0000\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 51896892.0000 - val_loss: 51357676.0000\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 39987828.0000 - val_loss: 38616056.0000\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 31368780.0000 - val_loss: 29541910.0000\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 25068484.0000 - val_loss: 27899016.0000\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 22477000.0000 - val_loss: 25393570.0000\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 18755886.0000 - val_loss: 20248476.0000\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 17543572.0000 - val_loss: 19917714.0000\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 15227916.0000 - val_loss: 17770112.0000\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 14483878.0000 - val_loss: 17753216.0000\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 12590539.0000 - val_loss: 14588856.0000\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 11834428.0000 - val_loss: 12983029.0000\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 10650903.0000 - val_loss: 13269327.0000\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 10658240.0000 - val_loss: 13660299.0000\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 9822151.0000 - val_loss: 12085926.0000\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 8528451.0000 - val_loss: 11362472.0000\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 8812008.0000 - val_loss: 12245861.0000\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 7782421.5000 - val_loss: 10307870.0000\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 7096469.5000 - val_loss: 9256133.0000\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 6981064.0000 - val_loss: 9504493.0000\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 6218407.0000 - val_loss: 8426304.0000\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5841884.0000 - val_loss: 8952848.0000\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5946136.0000 - val_loss: 8629747.0000\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 5769711.0000 - val_loss: 7527127.5000\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5741811.0000 - val_loss: 7402563.0000\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5057602.0000 - val_loss: 7280591.0000\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5338172.5000 - val_loss: 6531793.5000\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 4736888.0000 - val_loss: 6655345.0000\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4445739.0000 - val_loss: 6340978.5000\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4393792.5000 - val_loss: 5732500.5000\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4268811.0000 - val_loss: 6319339.5000\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3987274.7500 - val_loss: 5429209.0000\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3861983.2500 - val_loss: 5226754.0000\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4072151.7500 - val_loss: 4537044.5000\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3213979.2500 - val_loss: 4319965.5000\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3217888.0000 - val_loss: 4743442.5000\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3631605.0000 - val_loss: 4913371.0000\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3618103.5000 - val_loss: 7461748.5000\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3746041.2500 - val_loss: 6325446.5000\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3368700.7500 - val_loss: 4675843.0000\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2608754.2500 - val_loss: 4047840.2500\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2554759.7500 - val_loss: 3775478.7500\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2541187.2500 - val_loss: 3654277.2500\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2901194.7500 - val_loss: 3748177.2500\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2459115.2500 - val_loss: 3671605.7500\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2174222.7500 - val_loss: 3187400.0000\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2720629.2500 - val_loss: 4516793.0000\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2600884.5000 - val_loss: 2912146.0000\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2105704.2500 - val_loss: 3800653.2500\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2191771.0000 - val_loss: 2946259.7500\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2016600.7500 - val_loss: 2913287.5000\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1987525.5000 - val_loss: 3317250.0000\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2281127.5000 - val_loss: 3063719.7500\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2082152.2500 - val_loss: 2641292.7500\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1794251.5000 - val_loss: 2559158.5000\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2090067.5000 - val_loss: 2804140.2500\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1855410.2500 - val_loss: 4810266.5000\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2156965.5000 - val_loss: 2236175.0000\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1678035.1250 - val_loss: 2443894.0000\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1814022.1250 - val_loss: 3246635.0000\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1775961.3750 - val_loss: 2095085.5000\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1730095.0000 - val_loss: 2793033.5000\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1338960.0000 - val_loss: 2034029.6250\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1467163.8750 - val_loss: 1900157.1250\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1305439.2500 - val_loss: 1813704.5000\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1238360.3750 - val_loss: 1805184.3750\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1347181.2500 - val_loss: 2776270.0000\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1415129.8750 - val_loss: 1803201.7500\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1433488.5000 - val_loss: 2321253.7500\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1401922.0000 - val_loss: 1819384.6250\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1501445.0000 - val_loss: 1946125.2500\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1218388.8750 - val_loss: 1834988.8750\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1421416.1250 - val_loss: 1854870.7500\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1304502.0000 - val_loss: 1672214.8750\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1128385.5000 - val_loss: 1579569.0000\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1214551.3750 - val_loss: 2576313.5000\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1103391.8750 - val_loss: 1622589.3750\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1269586.5000 - val_loss: 1449829.1250\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 968852.5000 - val_loss: 1496958.8750\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 966007.2500 - val_loss: 1332179.0000\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 938484.8125 - val_loss: 1430292.2500\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1034120.0625 - val_loss: 1476138.1250\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 985161.5000 - val_loss: 1282308.3750\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1179318.6250 - val_loss: 1851313.6250\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1075505.7500 - val_loss: 1315403.8750\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 878171.3125 - val_loss: 1294562.0000\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1223981.3750 - val_loss: 1261892.8750\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 941827.8750 - val_loss: 1127752.0000\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 869081.0000 - val_loss: 1618431.5000\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 957062.0000 - val_loss: 1268064.0000\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 976319.3125 - val_loss: 1000181.8750\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 909122.4375 - val_loss: 1105958.2500\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 962880.8750 - val_loss: 1297985.5000\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 854227.8125 - val_loss: 1174816.5000\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 891971.4375 - val_loss: 1237971.1250\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 831609.5625 - val_loss: 1088364.0000\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 700817.5000 - val_loss: 1003133.8750\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 854795.9375 - val_loss: 1084777.2500\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 856308.1250 - val_loss: 992515.5000\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 963408.5000 - val_loss: 1093688.5000\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 778196.1875 - val_loss: 1363597.5000\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 767234.6875 - val_loss: 855063.6875\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 701439.7500 - val_loss: 1037776.2500\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 721121.6875 - val_loss: 834106.5625\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 671603.8750 - val_loss: 1287168.5000\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 702156.3750 - val_loss: 884599.3125\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 650627.1250 - val_loss: 842184.5000\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 686409.3750 - val_loss: 901811.8125\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 719058.0000 - val_loss: 953470.8125\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 788857.7500 - val_loss: 897925.3750\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 641240.3750 - val_loss: 956249.3750\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 638417.8750 - val_loss: 800545.0000\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 796704.1250 - val_loss: 902845.1875\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 673143.1875 - val_loss: 661981.1875\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 625082.0000 - val_loss: 842284.1250\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 621151.2500 - val_loss: 989939.7500\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 522761.9062 - val_loss: 716285.3125\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 558691.1875 - val_loss: 735719.7500\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 657513.8125 - val_loss: 873815.6875\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 535301.6875 - val_loss: 1762859.6250\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 947868.6875 - val_loss: 1021923.4375\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 597349.5000 - val_loss: 890506.5000\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 524937.5625 - val_loss: 792892.1875\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 542409.8750 - val_loss: 696096.3125\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 502825.5625 - val_loss: 925195.5000\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 528039.5625 - val_loss: 605933.3750\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 483456.2188 - val_loss: 639199.9375\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 517727.2812 - val_loss: 670571.4375\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 569490.4375 - val_loss: 635055.7500\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 513009.7188 - val_loss: 599940.0000\n",
      "Epoch 131/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 432418.1875 - val_loss: 618283.8125\n",
      "Epoch 132/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 449972.1562 - val_loss: 627238.5625\n",
      "Epoch 133/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 481182.6250 - val_loss: 539448.3750\n",
      "Epoch 134/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 476427.7812 - val_loss: 1035510.6250\n",
      "Epoch 135/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 450239.8125 - val_loss: 534425.8750\n",
      "Epoch 136/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 482776.4688 - val_loss: 998342.0625\n",
      "Epoch 137/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 555329.6875 - val_loss: 536500.5000\n",
      "Epoch 138/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 442363.7500 - val_loss: 1170001.5000\n",
      "Epoch 139/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 444151.4062 - val_loss: 494791.5625\n",
      "Epoch 140/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 388112.0312 - val_loss: 464989.1250\n",
      "Epoch 141/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 319742.8438 - val_loss: 399879.6250\n",
      "Epoch 142/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 406592.0312 - val_loss: 494167.7188\n",
      "Epoch 143/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 417638.4375 - val_loss: 429316.7812\n",
      "Epoch 144/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 311087.5000 - val_loss: 664376.2500\n",
      "Epoch 145/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 323574.5625 - val_loss: 317402.6250\n",
      "Epoch 146/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 402417.6875 - val_loss: 410269.9375\n",
      "Epoch 147/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 284695.4062 - val_loss: 384347.9375\n",
      "Epoch 148/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 311756.3750 - val_loss: 307387.5000\n",
      "Epoch 149/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 283143.9688 - val_loss: 389721.0000\n",
      "Epoch 150/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 251064.3281 - val_loss: 333632.0000\n",
      "Epoch 151/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 268542.4375 - val_loss: 331046.0000\n",
      "Epoch 152/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 263796.8125 - val_loss: 418191.9062\n",
      "Epoch 153/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 232908.0156 - val_loss: 548420.9375\n",
      "Epoch 154/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 306395.1562 - val_loss: 345078.2500\n",
      "Epoch 155/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 232252.8438 - val_loss: 256548.9688\n",
      "Epoch 156/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 226182.6406 - val_loss: 268857.7500\n",
      "Epoch 157/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 278190.5625 - val_loss: 435089.9062\n",
      "Epoch 158/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 286041.5312 - val_loss: 276347.1875\n",
      "Epoch 159/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 196398.2656 - val_loss: 362802.5938\n",
      "Epoch 160/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 209500.7656 - val_loss: 348850.7500\n",
      "Epoch 161/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 186348.2188 - val_loss: 257440.0781\n",
      "Epoch 162/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 177988.8750 - val_loss: 244819.3438\n",
      "Epoch 163/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 183890.0625 - val_loss: 314542.6562\n",
      "Epoch 164/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 206685.0000 - val_loss: 264544.7188\n",
      "Epoch 165/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 188819.3125 - val_loss: 217312.5781\n",
      "Epoch 166/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 185133.5312 - val_loss: 350029.9375\n",
      "Epoch 167/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 235312.8906 - val_loss: 185189.8281\n",
      "Epoch 168/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 173561.8594 - val_loss: 185639.8125\n",
      "Epoch 169/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 201184.2500 - val_loss: 257429.5469\n",
      "Epoch 170/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 138026.5625 - val_loss: 178455.8281\n",
      "Epoch 171/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 204613.9219 - val_loss: 362145.7188\n",
      "Epoch 172/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 196359.9844 - val_loss: 159859.0000\n",
      "Epoch 173/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 148963.4688 - val_loss: 207102.8281\n",
      "Epoch 174/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 170689.4844 - val_loss: 134081.3594\n",
      "Epoch 175/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 137476.9844 - val_loss: 158394.5469\n",
      "Epoch 176/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 144934.0938 - val_loss: 254612.2969\n",
      "Epoch 177/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 140573.4062 - val_loss: 143432.2812\n",
      "Epoch 178/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 144797.4062 - val_loss: 137180.7656\n",
      "Epoch 179/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 124688.9297 - val_loss: 102095.8516\n",
      "Epoch 180/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 175296.6719 - val_loss: 239848.9375\n",
      "Epoch 181/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 130958.5859 - val_loss: 138503.3750\n",
      "Epoch 182/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 143944.6406 - val_loss: 153677.3906\n",
      "Epoch 183/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 112142.8516 - val_loss: 167615.8906\n",
      "Epoch 184/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 153770.3906 - val_loss: 147505.5781\n",
      "Epoch 185/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 113965.8828 - val_loss: 215024.0000\n",
      "Epoch 186/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 135874.6250 - val_loss: 177772.3281\n",
      "Epoch 187/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 148132.3906 - val_loss: 94278.9453\n",
      "Epoch 188/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 116970.7812 - val_loss: 156559.3125\n",
      "Epoch 189/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 120333.6875 - val_loss: 232846.8125\n",
      "Epoch 190/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 102179.7734 - val_loss: 119025.7656\n",
      "Epoch 191/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 154141.0781 - val_loss: 178934.4688\n",
      "Epoch 192/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 169165.2656 - val_loss: 250738.7812\n",
      "Epoch 193/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 100587.9688 - val_loss: 122445.6562\n",
      "Epoch 194/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 107157.9219 - val_loss: 179345.1719\n",
      "Epoch 195/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 108660.7266 - val_loss: 193329.4375\n",
      "Epoch 196/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 117672.7500 - val_loss: 158999.9844\n",
      "Epoch 197/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 101249.8906 - val_loss: 138518.6094\n",
      "Epoch 198/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 104639.3047 - val_loss: 98606.0938\n",
      "Epoch 199/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 100604.2109 - val_loss: 228752.2812\n",
      "Epoch 200/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 88337.7891 - val_loss: 190948.7969\n",
      "Epoch 201/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 85853.6641 - val_loss: 149790.9844\n",
      "Epoch 202/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 120936.1250 - val_loss: 81628.5469\n",
      "Epoch 203/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 89390.9453 - val_loss: 118947.9062\n",
      "Epoch 204/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 82643.5469 - val_loss: 146513.5938\n",
      "Epoch 205/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 154790.0000 - val_loss: 176201.2656\n",
      "Epoch 206/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 89375.3672 - val_loss: 72373.0859\n",
      "Epoch 207/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 116262.9922 - val_loss: 126543.6406\n",
      "Epoch 208/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 71437.1250 - val_loss: 106813.8281\n",
      "Epoch 209/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 89453.3125 - val_loss: 93903.9453\n",
      "Epoch 210/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 63849.6836 - val_loss: 61014.9023\n",
      "Epoch 211/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 67371.2266 - val_loss: 87184.7266\n",
      "Epoch 212/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 66288.3125 - val_loss: 60740.1523\n",
      "Epoch 213/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 65754.7578 - val_loss: 47994.5508\n",
      "Epoch 214/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 85207.7656 - val_loss: 93723.2188\n",
      "Epoch 215/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 54277.4531 - val_loss: 58625.6953\n",
      "Epoch 216/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 105852.8672 - val_loss: 192838.1562\n",
      "Epoch 217/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 95779.8281 - val_loss: 55023.3594\n",
      "Epoch 218/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 84134.9375 - val_loss: 87909.1484\n",
      "Epoch 219/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 83385.6797 - val_loss: 51070.3516\n",
      "Epoch 220/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 52635.5781 - val_loss: 62493.9922\n",
      "Epoch 221/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 45178.3789 - val_loss: 74954.2734\n",
      "Epoch 222/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 59933.1289 - val_loss: 176682.2656\n",
      "Epoch 223/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 60409.1836 - val_loss: 45961.6172\n",
      "Epoch 224/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 75785.2969 - val_loss: 49613.5352\n",
      "Epoch 225/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 60945.8320 - val_loss: 73267.4531\n",
      "Epoch 226/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 58869.6133 - val_loss: 29310.6348\n",
      "Epoch 227/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 59938.3047 - val_loss: 81779.2891\n",
      "Epoch 228/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 68067.3438 - val_loss: 138902.3281\n",
      "Epoch 229/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 56786.8633 - val_loss: 119188.7578\n",
      "Epoch 230/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 82656.7266 - val_loss: 97693.8281\n",
      "Epoch 231/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 61163.5078 - val_loss: 50797.8086\n",
      "Epoch 232/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 85107.9609 - val_loss: 72218.6094\n",
      "Epoch 233/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 51424.0156 - val_loss: 67973.7422\n",
      "Epoch 234/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 77918.1484 - val_loss: 55263.4375\n",
      "Epoch 235/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 63223.9922 - val_loss: 36282.7695\n",
      "Epoch 236/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 65402.0547 - val_loss: 57104.9141\n",
      "Epoch 237/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 52025.4102 - val_loss: 62902.5508\n",
      "Epoch 238/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 37830.8711 - val_loss: 47089.3867\n",
      "Epoch 239/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 53082.9453 - val_loss: 24464.3535\n",
      "Epoch 240/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 41197.2266 - val_loss: 37525.7852\n",
      "Epoch 241/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 39836.5820 - val_loss: 91577.6797\n",
      "Epoch 242/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 54925.6211 - val_loss: 49083.2500\n",
      "Epoch 243/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 60245.7148 - val_loss: 24422.2480\n",
      "Epoch 244/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 49000.9492 - val_loss: 114942.7969\n",
      "Epoch 245/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 65968.9688 - val_loss: 36663.1055\n",
      "Epoch 246/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 60882.6992 - val_loss: 42492.8867\n",
      "Epoch 247/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 113678.3359 - val_loss: 48457.6289\n",
      "Epoch 248/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 67387.1484 - val_loss: 90497.0078\n",
      "Epoch 249/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 43369.8398 - val_loss: 31915.6992\n",
      "Epoch 250/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 46010.2539 - val_loss: 163384.7656\n",
      "Epoch 251/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 87768.6094 - val_loss: 51131.9609\n",
      "Epoch 252/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 73305.0000 - val_loss: 31677.5723\n",
      "Epoch 253/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 30451.1426 - val_loss: 42089.0156\n",
      "Epoch 254/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 47121.8320 - val_loss: 33368.2695\n",
      "Epoch 255/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 32361.7539 - val_loss: 17759.6230\n",
      "Epoch 256/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 56907.5664 - val_loss: 77910.9453\n",
      "Epoch 257/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 57307.2891 - val_loss: 126092.5000\n",
      "Epoch 258/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 59830.9609 - val_loss: 14559.2539\n",
      "Epoch 259/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 40208.2422 - val_loss: 55903.0859\n",
      "Epoch 260/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 40557.5898 - val_loss: 56761.1055\n",
      "Epoch 261/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 63005.7734 - val_loss: 23460.3164\n",
      "Epoch 262/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 46453.6680 - val_loss: 21629.9941\n",
      "Epoch 263/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 43959.9805 - val_loss: 26966.6289\n",
      "Epoch 264/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 47682.6641 - val_loss: 36439.6055\n",
      "Epoch 265/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 54634.4570 - val_loss: 56701.6484\n",
      "Epoch 266/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 40617.4414 - val_loss: 68566.7422\n",
      "Epoch 267/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 42523.6914 - val_loss: 6901.4414\n",
      "Epoch 268/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 42736.0039 - val_loss: 43779.5039\n",
      "Epoch 269/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 43981.2539 - val_loss: 12829.2754\n",
      "Epoch 270/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 60382.2578 - val_loss: 28238.5293\n",
      "Epoch 271/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 36196.5938 - val_loss: 63619.4883\n",
      "Epoch 272/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 57814.7383 - val_loss: 50340.9727\n",
      "Epoch 273/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 58428.1055 - val_loss: 46670.3984\n",
      "Epoch 274/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 50761.7070 - val_loss: 55759.3750\n",
      "Epoch 275/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 41353.2812 - val_loss: 55580.4102\n",
      "Epoch 276/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 39598.5195 - val_loss: 91168.8438\n",
      "Epoch 277/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 47082.2422 - val_loss: 112637.4609\n",
      "Epoch 278/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 51625.9609 - val_loss: 25364.9160\n",
      "Epoch 279/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 42865.2539 - val_loss: 10262.7539\n",
      "Epoch 280/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 44789.7148 - val_loss: 73953.3750\n",
      "Epoch 281/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 23903.9648 - val_loss: 11483.4023\n",
      "Epoch 282/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 34586.6562 - val_loss: 57929.1445\n",
      "Epoch 283/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 30846.3457 - val_loss: 18785.5547\n",
      "Epoch 284/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 49463.8906 - val_loss: 48407.1094\n",
      "Epoch 285/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 62887.4688 - val_loss: 46655.9453\n",
      "Epoch 286/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 42665.7500 - val_loss: 181975.4688\n",
      "Epoch 287/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 74597.4219 - val_loss: 44111.0898\n",
      "Epoch 288/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 40702.7734 - val_loss: 44752.2344\n",
      "Epoch 289/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 22296.0762 - val_loss: 16425.0879\n",
      "Epoch 290/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 65156.9531 - val_loss: 216642.8281\n",
      "Epoch 291/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 63327.2305 - val_loss: 44269.6719\n",
      "Epoch 292/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 23277.1484 - val_loss: 17809.7207\n",
      "Epoch 293/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 39547.3867 - val_loss: 64304.1250\n",
      "Epoch 294/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 44361.6992 - val_loss: 35392.0430\n",
      "Epoch 295/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 34085.7773 - val_loss: 147187.4688\n",
      "Epoch 296/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 44609.2969 - val_loss: 51235.2773\n",
      "Epoch 297/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 25008.4980 - val_loss: 19231.1426\n",
      "'########################################################Model1\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 8ms/step - loss: 104768648.0000 - val_loss: 52842732.0000\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 46536752.0000 - val_loss: 38323304.0000\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 32102658.0000 - val_loss: 28375788.0000\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 22996482.0000 - val_loss: 23153770.0000\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 19400138.0000 - val_loss: 21710034.0000\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 17274400.0000 - val_loss: 17575816.0000\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 14055588.0000 - val_loss: 14684618.0000\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 12501024.0000 - val_loss: 14850078.0000\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 12068090.0000 - val_loss: 13039147.0000\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 10988657.0000 - val_loss: 10921280.0000\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 9129611.0000 - val_loss: 11947554.0000\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 9067377.0000 - val_loss: 10049803.0000\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 8168500.5000 - val_loss: 8970554.0000\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 7443989.5000 - val_loss: 8674098.0000\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 7010848.5000 - val_loss: 8742749.0000\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 6406013.5000 - val_loss: 7068490.5000\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 7075603.0000 - val_loss: 7131840.0000\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 5908583.0000 - val_loss: 6235030.5000\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 5330280.0000 - val_loss: 6179751.0000\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 4990979.5000 - val_loss: 5989589.5000\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4936405.5000 - val_loss: 7372333.0000\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5048679.0000 - val_loss: 6375632.5000\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4453370.5000 - val_loss: 5748463.0000\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3877348.5000 - val_loss: 5557143.5000\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3728468.5000 - val_loss: 6460021.0000\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3995114.7500 - val_loss: 5007549.0000\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3605625.2500 - val_loss: 8209784.0000\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4188836.7500 - val_loss: 5124566.0000\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3646630.5000 - val_loss: 3804772.7500\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3101632.5000 - val_loss: 3533931.7500\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3039814.2500 - val_loss: 3346651.5000\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2711304.7500 - val_loss: 3624524.5000\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3068247.7500 - val_loss: 4970645.5000\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3789890.0000 - val_loss: 3502354.5000\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3010671.0000 - val_loss: 2986909.2500\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2498690.0000 - val_loss: 2999367.0000\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2255189.5000 - val_loss: 4480163.0000\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2525294.0000 - val_loss: 3259853.7500\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2232911.5000 - val_loss: 2822195.0000\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2055857.8750 - val_loss: 2725904.0000\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2267129.0000 - val_loss: 2845279.5000\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2123982.5000 - val_loss: 2673366.2500\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1897276.6250 - val_loss: 3384128.7500\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2356836.0000 - val_loss: 3047666.0000\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2102706.5000 - val_loss: 3320804.0000\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1950650.5000 - val_loss: 2018891.2500\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2031251.7500 - val_loss: 2471651.7500\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2076703.5000 - val_loss: 2102193.0000\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2041896.5000 - val_loss: 2844173.0000\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1950485.5000 - val_loss: 2412951.5000\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1906879.7500 - val_loss: 2953732.2500\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1658779.0000 - val_loss: 1770531.0000\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1759228.6250 - val_loss: 2350043.2500\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1786254.7500 - val_loss: 1880819.6250\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1452425.7500 - val_loss: 1927424.2500\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1818185.2500 - val_loss: 2081522.3750\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1661978.5000 - val_loss: 1511439.5000\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1481506.0000 - val_loss: 2224717.5000\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1570007.1250 - val_loss: 2244584.5000\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1692643.6250 - val_loss: 1905060.3750\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1438945.3750 - val_loss: 2113147.0000\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1474402.6250 - val_loss: 1545785.8750\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1340873.1250 - val_loss: 2381149.5000\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1536232.5000 - val_loss: 1662299.7500\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1696692.8750 - val_loss: 1530432.2500\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1244492.7500 - val_loss: 1690554.6250\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1143989.3750 - val_loss: 1285010.0000\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1445964.3750 - val_loss: 1281302.8750\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1243884.6250 - val_loss: 1621701.5000\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1076316.0000 - val_loss: 1680752.6250\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1876339.1250 - val_loss: 1373087.5000\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1280728.6250 - val_loss: 1679860.2500\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1114328.2500 - val_loss: 1176619.0000\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1181587.0000 - val_loss: 2478941.5000\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1264747.7500 - val_loss: 1464328.6250\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1075847.2500 - val_loss: 1278809.0000\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1002765.6250 - val_loss: 1054500.8750\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 969779.2500 - val_loss: 953016.5000\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1193049.0000 - val_loss: 1271069.0000\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1027730.1875 - val_loss: 1023156.8750\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 817210.2500 - val_loss: 1154615.0000\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1045878.5625 - val_loss: 1412620.2500\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1468989.0000 - val_loss: 1698460.2500\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 932009.1875 - val_loss: 1069721.5000\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1130244.6250 - val_loss: 946580.1875\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 899017.9375 - val_loss: 1144827.1250\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1137388.8750 - val_loss: 886629.9375\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1083250.8750 - val_loss: 1894000.5000\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1044137.4375 - val_loss: 1016764.5625\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 749213.6875 - val_loss: 1171031.3750\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 688650.7500 - val_loss: 726827.1250\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 717397.2500 - val_loss: 764610.8125\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 715430.3750 - val_loss: 1018653.3750\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 715764.6250 - val_loss: 892950.6250\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 685337.8750 - val_loss: 785609.1875\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 755916.6875 - val_loss: 827073.5000\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 596425.4375 - val_loss: 691599.0625\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 674642.0625 - val_loss: 672769.1875\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 595920.6250 - val_loss: 644053.3750\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 610417.5625 - val_loss: 614278.8125\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 517664.2188 - val_loss: 847121.6250\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 622428.3125 - val_loss: 564427.1250\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 741159.3125 - val_loss: 609550.5000\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 606122.9375 - val_loss: 649777.6250\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 516118.9062 - val_loss: 765153.6250\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 376602.8125 - val_loss: 379040.3750\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 440485.1562 - val_loss: 559701.7500\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 328320.2812 - val_loss: 349809.6250\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 313996.7188 - val_loss: 350879.0938\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 279816.9688 - val_loss: 592841.6875\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 315326.3438 - val_loss: 449871.5312\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 272198.9375 - val_loss: 313412.9375\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 248910.4844 - val_loss: 443137.4688\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 296142.7812 - val_loss: 351133.5312\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 319056.0938 - val_loss: 401230.7188\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 258135.7031 - val_loss: 270219.0625\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 265360.8125 - val_loss: 384636.9688\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 262621.7188 - val_loss: 408658.9688\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 280189.5312 - val_loss: 484399.5000\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 297431.6250 - val_loss: 278606.9375\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 302151.3438 - val_loss: 517167.8750\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 275111.3438 - val_loss: 285387.8750\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 233248.1406 - val_loss: 282070.9375\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 217608.3281 - val_loss: 261572.1875\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 206921.3125 - val_loss: 253840.6094\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 267228.2812 - val_loss: 353772.0312\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 234213.6250 - val_loss: 286242.7188\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 250898.7969 - val_loss: 255348.5469\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 195684.2812 - val_loss: 238736.3594\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 217000.4844 - val_loss: 310948.7188\n",
      "Epoch 131/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 238367.9375 - val_loss: 297702.6562\n",
      "Epoch 132/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 205589.2344 - val_loss: 307365.6875\n",
      "Epoch 133/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 227096.7188 - val_loss: 272046.0625\n",
      "Epoch 134/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 195809.6250 - val_loss: 233327.0938\n",
      "Epoch 135/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 213778.2656 - val_loss: 297607.8438\n",
      "Epoch 136/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 275447.5938 - val_loss: 223548.1719\n",
      "Epoch 137/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 197860.5469 - val_loss: 217499.9375\n",
      "Epoch 138/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 208961.5625 - val_loss: 194869.9688\n",
      "Epoch 139/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 255842.9062 - val_loss: 346655.1250\n",
      "Epoch 140/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 216079.3281 - val_loss: 191374.5938\n",
      "Epoch 141/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 183264.7812 - val_loss: 237457.6875\n",
      "Epoch 142/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 200569.0156 - val_loss: 422414.7188\n",
      "Epoch 143/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 179666.7031 - val_loss: 165686.7969\n",
      "Epoch 144/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 227576.3750 - val_loss: 265051.7812\n",
      "Epoch 145/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 185873.0156 - val_loss: 211158.8906\n",
      "Epoch 146/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 175951.4531 - val_loss: 112603.1719\n",
      "Epoch 147/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 156965.0156 - val_loss: 189844.4062\n",
      "Epoch 148/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 176751.3281 - val_loss: 309693.0312\n",
      "Epoch 149/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 175181.7812 - val_loss: 180865.7500\n",
      "Epoch 150/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 162826.2188 - val_loss: 285703.0312\n",
      "Epoch 151/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 173725.6406 - val_loss: 217590.1562\n",
      "Epoch 152/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 189249.5469 - val_loss: 236809.5781\n",
      "Epoch 153/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 184103.8906 - val_loss: 380950.2500\n",
      "Epoch 154/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 223612.5625 - val_loss: 158863.5938\n",
      "Epoch 155/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 138752.0000 - val_loss: 128006.6875\n",
      "Epoch 156/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 146581.1094 - val_loss: 159455.2969\n",
      "Epoch 157/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 166361.9219 - val_loss: 211755.1250\n",
      "Epoch 158/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 157415.9375 - val_loss: 154574.2969\n",
      "Epoch 159/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 118406.6406 - val_loss: 182048.5781\n",
      "Epoch 160/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 152569.2344 - val_loss: 137142.3125\n",
      "Epoch 161/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 122118.9609 - val_loss: 148168.5938\n",
      "Epoch 162/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 160287.1875 - val_loss: 242078.4219\n",
      "Epoch 163/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 132983.7969 - val_loss: 186964.9219\n",
      "Epoch 164/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 125978.4062 - val_loss: 121449.6016\n",
      "Epoch 165/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 131089.3594 - val_loss: 122284.0938\n",
      "Epoch 166/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 119689.5625 - val_loss: 223998.9531\n",
      "Epoch 167/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 142987.7031 - val_loss: 172176.7188\n",
      "Epoch 168/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 153554.8750 - val_loss: 151036.2969\n",
      "Epoch 169/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 133016.0625 - val_loss: 138353.8906\n",
      "Epoch 170/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 133150.6719 - val_loss: 90421.8906\n",
      "Epoch 171/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 159107.8906 - val_loss: 154664.5000\n",
      "Epoch 172/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 96029.6562 - val_loss: 178181.3281\n",
      "Epoch 173/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 109803.6094 - val_loss: 115256.0469\n",
      "Epoch 174/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 99915.6797 - val_loss: 125596.7031\n",
      "Epoch 175/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 137894.3906 - val_loss: 114060.1094\n",
      "Epoch 176/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 119907.1562 - val_loss: 87428.2578\n",
      "Epoch 177/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 105079.9297 - val_loss: 127993.6406\n",
      "Epoch 178/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 113474.7109 - val_loss: 144201.5938\n",
      "Epoch 179/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 92464.9688 - val_loss: 170251.4844\n",
      "Epoch 180/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 159604.1719 - val_loss: 157523.5156\n",
      "Epoch 181/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 148465.7500 - val_loss: 223968.8906\n",
      "Epoch 182/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 119614.0938 - val_loss: 140009.7500\n",
      "Epoch 183/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 100178.4375 - val_loss: 189603.0000\n",
      "Epoch 184/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 110493.5234 - val_loss: 81923.2969\n",
      "Epoch 185/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 108774.3672 - val_loss: 131431.2344\n",
      "Epoch 186/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 130942.2422 - val_loss: 123318.9375\n",
      "Epoch 187/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 92112.7578 - val_loss: 163469.6250\n",
      "Epoch 188/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 86636.6719 - val_loss: 150568.8750\n",
      "Epoch 189/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 84840.0156 - val_loss: 95217.7734\n",
      "Epoch 190/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 84480.5000 - val_loss: 81408.9297\n",
      "Epoch 191/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 111979.0781 - val_loss: 101764.0312\n",
      "Epoch 192/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 117626.8672 - val_loss: 71735.1953\n",
      "Epoch 193/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 106397.3828 - val_loss: 126333.1562\n",
      "Epoch 194/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 72697.1250 - val_loss: 88985.6172\n",
      "Epoch 195/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 106659.8906 - val_loss: 83351.2656\n",
      "Epoch 196/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 79991.0938 - val_loss: 66381.6953\n",
      "Epoch 197/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 115314.4531 - val_loss: 68540.2734\n",
      "Epoch 198/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 78640.5156 - val_loss: 185483.4688\n",
      "Epoch 199/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 73163.7109 - val_loss: 192724.5312\n",
      "Epoch 200/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 84226.9375 - val_loss: 148210.5938\n",
      "Epoch 201/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 74925.0625 - val_loss: 166878.3750\n",
      "Epoch 202/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 99263.5391 - val_loss: 74557.0312\n",
      "Epoch 203/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 83826.3594 - val_loss: 110699.5000\n",
      "Epoch 204/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 72669.1250 - val_loss: 58870.7383\n",
      "Epoch 205/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 85943.9766 - val_loss: 126985.8750\n",
      "Epoch 206/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 89758.8203 - val_loss: 123313.7500\n",
      "Epoch 207/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 87534.3203 - val_loss: 48314.8555\n",
      "Epoch 208/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 60443.7930 - val_loss: 68971.6875\n",
      "Epoch 209/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 72775.5000 - val_loss: 74430.6875\n",
      "Epoch 210/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 71964.1875 - val_loss: 103998.0312\n",
      "Epoch 211/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 74277.1172 - val_loss: 91012.1094\n",
      "Epoch 212/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 85825.6953 - val_loss: 92418.8125\n",
      "Epoch 213/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 62769.3789 - val_loss: 150278.1562\n",
      "Epoch 214/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 67296.6484 - val_loss: 68577.1484\n",
      "Epoch 215/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 84809.8516 - val_loss: 114564.9844\n",
      "Epoch 216/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 71794.7422 - val_loss: 36820.3086\n",
      "Epoch 217/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 50973.3906 - val_loss: 53961.0156\n",
      "Epoch 218/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 94495.7109 - val_loss: 62407.0273\n",
      "Epoch 219/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 49790.0469 - val_loss: 52601.2266\n",
      "Epoch 220/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 80712.6484 - val_loss: 33947.6250\n",
      "Epoch 221/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 100724.4844 - val_loss: 154830.4062\n",
      "Epoch 222/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 105050.6953 - val_loss: 99456.2031\n",
      "Epoch 223/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 79798.6562 - val_loss: 123876.7734\n",
      "Epoch 224/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 81687.5391 - val_loss: 224159.7344\n",
      "Epoch 225/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 142752.4844 - val_loss: 54493.0312\n",
      "Epoch 226/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 109481.4297 - val_loss: 82365.1562\n",
      "Epoch 227/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 103978.4922 - val_loss: 172659.5781\n",
      "Epoch 228/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 89929.8359 - val_loss: 182157.9062\n",
      "Epoch 229/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 133455.2656 - val_loss: 78971.1875\n",
      "Epoch 230/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 63041.1055 - val_loss: 105280.7266\n",
      "Epoch 231/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 58626.5312 - val_loss: 77649.9531\n",
      "Epoch 232/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 65209.3984 - val_loss: 131496.3594\n",
      "Epoch 233/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 74267.6406 - val_loss: 58024.3242\n",
      "Epoch 234/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 77637.0312 - val_loss: 147119.3594\n",
      "Epoch 235/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 93871.0547 - val_loss: 165869.9531\n",
      "Epoch 236/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 71242.6016 - val_loss: 31798.1582\n",
      "Epoch 237/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 78952.1406 - val_loss: 48717.9102\n",
      "Epoch 238/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 65629.0469 - val_loss: 31302.3926\n",
      "Epoch 239/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 66252.8047 - val_loss: 177173.1094\n",
      "Epoch 240/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 93943.8594 - val_loss: 153825.2500\n",
      "Epoch 241/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 94239.7188 - val_loss: 136974.1406\n",
      "Epoch 242/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 60346.5039 - val_loss: 12890.3721\n",
      "Epoch 243/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 106648.7969 - val_loss: 21103.4629\n",
      "Epoch 244/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 59819.5859 - val_loss: 15133.1777\n",
      "Epoch 245/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 42539.7422 - val_loss: 71183.9922\n",
      "Epoch 246/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 79692.5781 - val_loss: 29650.0312\n",
      "Epoch 247/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 36082.6641 - val_loss: 19252.2578\n",
      "Epoch 248/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 50444.5586 - val_loss: 32827.4180\n",
      "Epoch 249/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 80820.7422 - val_loss: 109356.0312\n",
      "Epoch 250/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 52916.8867 - val_loss: 35046.1523\n",
      "Epoch 251/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 78454.7578 - val_loss: 194788.6875\n",
      "Epoch 252/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 59463.7305 - val_loss: 153328.1094\n",
      "Epoch 253/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 75182.5469 - val_loss: 44687.3242\n",
      "Epoch 254/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 44147.9414 - val_loss: 30739.3008\n",
      "Epoch 255/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 46716.4297 - val_loss: 24147.3633\n",
      "Epoch 256/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 59233.2930 - val_loss: 76374.9766\n",
      "Epoch 257/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 63382.1250 - val_loss: 70711.9141\n",
      "Epoch 258/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 61658.5312 - val_loss: 27649.2695\n",
      "Epoch 259/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 71365.5469 - val_loss: 22128.9648\n",
      "Epoch 260/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 70488.0312 - val_loss: 34755.7070\n",
      "Epoch 261/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 53940.5234 - val_loss: 58131.9453\n",
      "Epoch 262/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 58720.2148 - val_loss: 115067.7188\n",
      "Epoch 263/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 71981.1094 - val_loss: 44525.6758\n",
      "Epoch 264/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 51731.2617 - val_loss: 122188.8516\n",
      "Epoch 265/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 70024.2109 - val_loss: 22104.3691\n",
      "Epoch 266/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 71283.7422 - val_loss: 54321.6172\n",
      "Epoch 267/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 45353.5625 - val_loss: 44787.9609\n",
      "Epoch 268/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 51955.4844 - val_loss: 81706.2422\n",
      "Epoch 269/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 71213.6953 - val_loss: 29526.7578\n",
      "Epoch 270/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 50117.5352 - val_loss: 72688.3047\n",
      "Epoch 271/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 60230.9961 - val_loss: 110117.8359\n",
      "Epoch 272/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 58624.6094 - val_loss: 41531.3867\n",
      "'########################################################Model2\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 9ms/step - loss: 112705320.0000 - val_loss: 49604624.0000\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 42519600.0000 - val_loss: 35506036.0000\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 30663570.0000 - val_loss: 29645542.0000\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 24664074.0000 - val_loss: 25036098.0000\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 20334592.0000 - val_loss: 20171602.0000\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 17142678.0000 - val_loss: 18737154.0000\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 14879034.0000 - val_loss: 17135640.0000\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 13257024.0000 - val_loss: 15568328.0000\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 12865821.0000 - val_loss: 15856983.0000\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 11215569.0000 - val_loss: 13359997.0000\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 9912167.0000 - val_loss: 12510442.0000\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 10125991.0000 - val_loss: 12274376.0000\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 9485138.0000 - val_loss: 9350146.0000\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 8224492.5000 - val_loss: 9825415.0000\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 7490329.5000 - val_loss: 8211185.0000\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 7479714.0000 - val_loss: 8895792.0000\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 6664162.5000 - val_loss: 9297512.0000\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 6197264.5000 - val_loss: 7243868.5000\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5752590.0000 - val_loss: 7197646.0000\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5316539.0000 - val_loss: 8472142.0000\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 5288836.0000 - val_loss: 6522521.0000\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5663262.5000 - val_loss: 6543469.5000\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5201002.5000 - val_loss: 5777097.0000\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4495548.5000 - val_loss: 6130942.0000\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4570072.0000 - val_loss: 6688465.0000\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4250167.0000 - val_loss: 5988207.5000\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4792475.5000 - val_loss: 5830517.5000\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4911552.5000 - val_loss: 5903001.0000\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3821938.2500 - val_loss: 5014167.5000\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3637638.0000 - val_loss: 4493136.5000\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4068315.7500 - val_loss: 4802060.5000\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3740927.5000 - val_loss: 4983739.5000\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3243613.0000 - val_loss: 4091085.2500\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3022138.7500 - val_loss: 4878100.5000\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2907414.2500 - val_loss: 3712334.0000\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2716722.7500 - val_loss: 3873581.0000\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2659487.7500 - val_loss: 3971484.7500\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2819253.7500 - val_loss: 4470320.0000\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2768029.7500 - val_loss: 4749306.5000\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2755942.0000 - val_loss: 3474699.5000\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2473300.7500 - val_loss: 3256289.0000\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2576752.7500 - val_loss: 3145002.2500\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2591099.2500 - val_loss: 3896491.7500\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2472382.2500 - val_loss: 3466362.2500\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2258411.7500 - val_loss: 3292288.7500\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2433946.5000 - val_loss: 3231412.0000\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2121322.7500 - val_loss: 3128001.2500\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2058429.7500 - val_loss: 3019094.0000\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2272139.5000 - val_loss: 2824408.0000\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2201316.7500 - val_loss: 2423161.2500\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2304780.5000 - val_loss: 2934323.5000\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1907609.7500 - val_loss: 2359320.2500\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1705027.0000 - val_loss: 2396410.0000\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1744970.2500 - val_loss: 2190319.7500\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1674124.5000 - val_loss: 3202933.7500\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1851234.2500 - val_loss: 3474825.5000\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1962769.2500 - val_loss: 2517372.2500\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1674794.8750 - val_loss: 2284302.0000\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1615535.0000 - val_loss: 2432631.7500\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1607189.5000 - val_loss: 2408148.2500\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1547337.3750 - val_loss: 1938957.0000\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1649657.1250 - val_loss: 2015146.1250\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1565143.5000 - val_loss: 1921035.5000\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1553946.1250 - val_loss: 1770535.2500\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1314212.6250 - val_loss: 1631203.8750\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1324402.1250 - val_loss: 1942765.0000\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1432766.6250 - val_loss: 2701235.0000\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1352712.7500 - val_loss: 3006186.2500\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1311425.5000 - val_loss: 2029644.3750\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1410793.2500 - val_loss: 1494255.0000\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1058502.8750 - val_loss: 1540522.6250\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1311675.6250 - val_loss: 2622180.0000\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1222521.1250 - val_loss: 1526014.5000\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1067247.6250 - val_loss: 1640131.7500\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1195244.0000 - val_loss: 1403407.7500\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1067835.1250 - val_loss: 1526543.5000\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1040149.1250 - val_loss: 2280992.7500\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1015674.6875 - val_loss: 1581789.0000\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1399901.2500 - val_loss: 1259109.0000\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1187575.5000 - val_loss: 1534203.7500\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1082247.2500 - val_loss: 1259122.8750\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1025143.9375 - val_loss: 1879625.8750\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 929606.7500 - val_loss: 1033684.4375\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 843456.3750 - val_loss: 1236626.3750\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 867866.8750 - val_loss: 1257581.6250\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 859916.1875 - val_loss: 1016024.2500\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 828145.0625 - val_loss: 1083919.6250\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 907318.7500 - val_loss: 1209078.2500\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 746982.6250 - val_loss: 975978.2500\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 661449.2500 - val_loss: 961329.1875\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 720106.9375 - val_loss: 974644.6250\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 677814.1875 - val_loss: 872509.8750\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 859782.7500 - val_loss: 1194103.5000\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 912038.5625 - val_loss: 1477113.5000\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 689130.7500 - val_loss: 1264467.0000\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 783156.5625 - val_loss: 883102.0000\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 888515.6875 - val_loss: 1042669.4375\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 756828.9375 - val_loss: 846089.5000\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 692148.6250 - val_loss: 710455.9375\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 624136.8125 - val_loss: 1318752.6250\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 619590.9375 - val_loss: 935581.3750\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 740167.8750 - val_loss: 1048375.7500\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 604512.4375 - val_loss: 679114.5625\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 591409.0625 - val_loss: 821565.8125\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 534311.8125 - val_loss: 841445.8750\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 551787.1250 - val_loss: 690387.8125\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 504277.6875 - val_loss: 725605.8750\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 469454.6562 - val_loss: 626954.3750\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 411907.1562 - val_loss: 576795.5000\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 412012.3438 - val_loss: 605017.6250\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 391446.5312 - val_loss: 786987.0000\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 414018.3125 - val_loss: 486531.7500\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 534513.0625 - val_loss: 739128.6875\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 392158.6562 - val_loss: 596593.6875\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 472485.4688 - val_loss: 515580.3438\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 351541.4688 - val_loss: 407825.3438\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 485974.1875 - val_loss: 511011.8125\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 387529.3438 - val_loss: 559515.6250\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 484969.3438 - val_loss: 752274.3750\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 495597.9062 - val_loss: 427948.8750\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 392623.5938 - val_loss: 436480.9062\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 354154.7812 - val_loss: 430282.1875\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 346359.9062 - val_loss: 413224.0625\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 321118.3125 - val_loss: 592161.6250\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 303077.4375 - val_loss: 381056.9062\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 292552.8438 - val_loss: 537548.0625\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 360133.1250 - val_loss: 446511.0938\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 273620.0000 - val_loss: 409390.7500\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 305474.4688 - val_loss: 385089.0625\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 272238.5938 - val_loss: 340713.1250\n",
      "Epoch 131/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 271856.3438 - val_loss: 349245.5000\n",
      "Epoch 132/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 295792.3750 - val_loss: 446332.5000\n",
      "Epoch 133/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 297245.2500 - val_loss: 273002.4688\n",
      "Epoch 134/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 205174.2031 - val_loss: 304061.6562\n",
      "Epoch 135/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 205401.9375 - val_loss: 211824.7656\n",
      "Epoch 136/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 196637.2500 - val_loss: 226228.9688\n",
      "Epoch 137/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 219877.4219 - val_loss: 237427.8281\n",
      "Epoch 138/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 232475.5469 - val_loss: 232476.5000\n",
      "Epoch 139/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 227411.1719 - val_loss: 200455.2031\n",
      "Epoch 140/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 220420.3906 - val_loss: 315408.5938\n",
      "Epoch 141/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 189517.5312 - val_loss: 197753.6719\n",
      "Epoch 142/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 194120.3750 - val_loss: 174525.5156\n",
      "Epoch 143/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 181740.7812 - val_loss: 199510.7656\n",
      "Epoch 144/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 199025.6094 - val_loss: 260449.2656\n",
      "Epoch 145/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 210245.7812 - val_loss: 268644.0938\n",
      "Epoch 146/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 156658.2031 - val_loss: 196948.9844\n",
      "Epoch 147/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 216455.4531 - val_loss: 167815.6875\n",
      "Epoch 148/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 187106.7500 - val_loss: 250442.6719\n",
      "Epoch 149/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 170813.0312 - val_loss: 202638.3750\n",
      "Epoch 150/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 199926.2031 - val_loss: 153488.0469\n",
      "Epoch 151/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 165436.9375 - val_loss: 129358.3828\n",
      "Epoch 152/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 188730.8750 - val_loss: 236281.6875\n",
      "Epoch 153/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 156655.7500 - val_loss: 120208.5781\n",
      "Epoch 154/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 163242.2969 - val_loss: 151593.1250\n",
      "Epoch 155/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 146228.7031 - val_loss: 78107.7578\n",
      "Epoch 156/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 213867.1250 - val_loss: 185200.2031\n",
      "Epoch 157/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 142104.0625 - val_loss: 105887.0312\n",
      "Epoch 158/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 145644.0000 - val_loss: 186853.5938\n",
      "Epoch 159/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 161267.4844 - val_loss: 166884.8750\n",
      "Epoch 160/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 158371.3125 - val_loss: 147310.3438\n",
      "Epoch 161/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 124733.7891 - val_loss: 186193.0781\n",
      "Epoch 162/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 145917.9531 - val_loss: 132825.7188\n",
      "Epoch 163/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 136882.3125 - val_loss: 158087.1875\n",
      "Epoch 164/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 133235.4688 - val_loss: 176012.9531\n",
      "Epoch 165/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 131412.7500 - val_loss: 214978.7344\n",
      "Epoch 166/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 136093.9062 - val_loss: 178377.5938\n",
      "Epoch 167/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 142327.2344 - val_loss: 72156.0547\n",
      "Epoch 168/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 144102.0781 - val_loss: 100068.7969\n",
      "Epoch 169/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 153515.5781 - val_loss: 116555.6719\n",
      "Epoch 170/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 148626.9375 - val_loss: 243977.9531\n",
      "Epoch 171/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 128450.0078 - val_loss: 232631.3438\n",
      "Epoch 172/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 118881.5938 - val_loss: 169337.3281\n",
      "Epoch 173/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 115247.0703 - val_loss: 159004.6562\n",
      "Epoch 174/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 151753.6875 - val_loss: 118718.1484\n",
      "Epoch 175/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 191130.2656 - val_loss: 322424.1250\n",
      "Epoch 176/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 109021.9375 - val_loss: 148437.1406\n",
      "Epoch 177/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 194304.0625 - val_loss: 114841.5000\n",
      "Epoch 178/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 140104.3281 - val_loss: 92675.6016\n",
      "Epoch 179/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 75961.5156 - val_loss: 107180.1328\n",
      "Epoch 180/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 85085.3281 - val_loss: 131225.7188\n",
      "Epoch 181/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 94372.8906 - val_loss: 54456.0820\n",
      "Epoch 182/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 106429.7578 - val_loss: 88975.5859\n",
      "Epoch 183/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 120963.8359 - val_loss: 74113.3828\n",
      "Epoch 184/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 83902.6641 - val_loss: 177294.7500\n",
      "Epoch 185/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 93155.6094 - val_loss: 106344.6484\n",
      "Epoch 186/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 103145.5391 - val_loss: 170252.8438\n",
      "Epoch 187/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 102164.5078 - val_loss: 96952.7266\n",
      "Epoch 188/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 107483.2422 - val_loss: 167871.1719\n",
      "Epoch 189/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 111556.6641 - val_loss: 62857.1641\n",
      "Epoch 190/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 94204.3750 - val_loss: 73643.0312\n",
      "Epoch 191/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 113025.7031 - val_loss: 178502.7969\n",
      "Epoch 192/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 111968.2188 - val_loss: 122995.1719\n",
      "Epoch 193/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 71076.6719 - val_loss: 123873.3359\n",
      "Epoch 194/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 84112.0547 - val_loss: 126879.3906\n",
      "Epoch 195/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 70541.8672 - val_loss: 61280.4961\n",
      "Epoch 196/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 74514.0391 - val_loss: 69734.1719\n",
      "Epoch 197/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 68671.5781 - val_loss: 55385.9531\n",
      "Epoch 198/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 101092.3984 - val_loss: 136071.6250\n",
      "Epoch 199/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 89241.3203 - val_loss: 86839.8438\n",
      "Epoch 200/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 71820.4141 - val_loss: 128799.0859\n",
      "Epoch 201/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 104847.7500 - val_loss: 570429.1875\n",
      "Epoch 202/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 116211.4766 - val_loss: 120675.2969\n",
      "Epoch 203/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 113241.0625 - val_loss: 32646.4590\n",
      "Epoch 204/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 118093.4844 - val_loss: 27298.6289\n",
      "Epoch 205/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 89061.6094 - val_loss: 154463.6875\n",
      "Epoch 206/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 99919.6484 - val_loss: 80245.6562\n",
      "Epoch 207/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 104276.4297 - val_loss: 24387.4453\n",
      "Epoch 208/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 116414.2031 - val_loss: 40723.1641\n",
      "Epoch 209/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 124878.7969 - val_loss: 126607.6406\n",
      "Epoch 210/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 94571.0859 - val_loss: 145824.9531\n",
      "Epoch 211/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 107005.3906 - val_loss: 37755.9180\n",
      "Epoch 212/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 91492.2656 - val_loss: 22409.8418\n",
      "Epoch 213/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 58734.8516 - val_loss: 26641.9375\n",
      "Epoch 214/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 89115.4609 - val_loss: 107885.8906\n",
      "Epoch 215/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 61244.6094 - val_loss: 168718.4688\n",
      "Epoch 216/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 53311.9141 - val_loss: 71850.3828\n",
      "Epoch 217/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 104585.4609 - val_loss: 201356.2188\n",
      "Epoch 218/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 99039.0469 - val_loss: 144021.4062\n",
      "Epoch 219/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 68697.5312 - val_loss: 100003.9688\n",
      "Epoch 220/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 57319.6211 - val_loss: 173655.8906\n",
      "Epoch 221/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 110146.6016 - val_loss: 28102.1113\n",
      "Epoch 222/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 65375.3281 - val_loss: 64914.1016\n",
      "Epoch 223/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 91748.0859 - val_loss: 96224.0469\n",
      "Epoch 224/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 83604.3359 - val_loss: 165627.6562\n",
      "Epoch 225/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 80229.7031 - val_loss: 193057.5312\n",
      "Epoch 226/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 77697.3047 - val_loss: 43149.9570\n",
      "Epoch 227/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 80487.0156 - val_loss: 106336.7891\n",
      "Epoch 228/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 71685.5703 - val_loss: 60027.7109\n",
      "Epoch 229/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 87681.1719 - val_loss: 53924.1211\n",
      "Epoch 230/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 68715.5312 - val_loss: 47896.5117\n",
      "Epoch 231/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 62541.4102 - val_loss: 43734.1758\n",
      "Epoch 232/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 81873.4375 - val_loss: 66209.8281\n",
      "Epoch 233/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 70338.2344 - val_loss: 134940.2656\n",
      "Epoch 234/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 86517.8438 - val_loss: 34282.3242\n",
      "Epoch 235/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 64483.5352 - val_loss: 106328.1953\n",
      "Epoch 236/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 64807.7148 - val_loss: 161247.8281\n",
      "Epoch 237/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 69988.5391 - val_loss: 33556.9648\n",
      "Epoch 238/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 42416.7734 - val_loss: 62907.4258\n",
      "Epoch 239/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 56623.1055 - val_loss: 40728.2812\n",
      "Epoch 240/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 76120.0859 - val_loss: 24995.0234\n",
      "Epoch 241/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 65742.3438 - val_loss: 71591.8438\n",
      "Epoch 242/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 90411.2188 - val_loss: 115979.4922\n",
      "'########################################################Model3\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 9ms/step - loss: 130816304.0000 - val_loss: 61546940.0000\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 50337976.0000 - val_loss: 48568644.0000\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 34664192.0000 - val_loss: 31231616.0000\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 25816996.0000 - val_loss: 28438474.0000\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 22418980.0000 - val_loss: 24800286.0000\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 18754530.0000 - val_loss: 20615492.0000\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 16217921.0000 - val_loss: 20371360.0000\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 14878763.0000 - val_loss: 18037640.0000\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 13407444.0000 - val_loss: 15614817.0000\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 11997434.0000 - val_loss: 13657063.0000\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 11616187.0000 - val_loss: 15853727.0000\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 10090503.0000 - val_loss: 11645330.0000\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 9512059.0000 - val_loss: 11592654.0000\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 8663972.0000 - val_loss: 10685097.0000\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 8515247.0000 - val_loss: 10694881.0000\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 7400132.0000 - val_loss: 9255684.0000\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 7051614.0000 - val_loss: 8698292.0000\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 6569163.5000 - val_loss: 10251423.0000\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 6530509.0000 - val_loss: 7699206.0000\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5855292.5000 - val_loss: 7336212.0000\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5651440.5000 - val_loss: 7609585.0000\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 6230360.0000 - val_loss: 6904642.0000\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5265468.5000 - val_loss: 6362626.0000\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4886761.5000 - val_loss: 6548272.0000\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4490167.0000 - val_loss: 7013114.5000\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5157328.5000 - val_loss: 5751536.0000\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4356218.5000 - val_loss: 5099410.5000\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3981650.7500 - val_loss: 4878769.0000\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3801811.7500 - val_loss: 4828792.5000\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3697630.7500 - val_loss: 4862387.5000\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3670781.0000 - val_loss: 5250635.5000\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3676614.2500 - val_loss: 4703433.5000\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3569931.7500 - val_loss: 4095789.5000\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3558481.0000 - val_loss: 4037326.5000\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3314856.5000 - val_loss: 4327411.0000\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3674701.7500 - val_loss: 4434966.5000\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3223692.2500 - val_loss: 4425338.5000\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3185574.2500 - val_loss: 3883060.0000\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3324163.7500 - val_loss: 5032266.0000\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2743159.2500 - val_loss: 3648705.5000\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2714482.5000 - val_loss: 3322368.0000\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2498682.5000 - val_loss: 3988763.0000\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2615209.0000 - val_loss: 3724767.2500\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2512535.0000 - val_loss: 3006260.2500\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2569694.0000 - val_loss: 3565607.2500\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2452833.7500 - val_loss: 2746886.5000\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2192867.0000 - val_loss: 3167360.2500\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2348808.7500 - val_loss: 2842058.2500\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2152016.5000 - val_loss: 2770547.0000\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2171384.7500 - val_loss: 2568824.7500\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2254850.5000 - val_loss: 2455430.5000\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1958535.5000 - val_loss: 2502139.5000\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2124860.2500 - val_loss: 2664440.5000\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2510348.2500 - val_loss: 3090139.2500\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2034893.5000 - val_loss: 2642008.2500\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2106569.7500 - val_loss: 2369274.5000\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1830822.5000 - val_loss: 3180106.2500\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2329074.0000 - val_loss: 2309802.2500\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1685486.6250 - val_loss: 1820300.7500\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1630883.1250 - val_loss: 2011386.0000\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1694587.5000 - val_loss: 3011792.0000\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1838506.1250 - val_loss: 2007190.7500\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1499241.2500 - val_loss: 3526267.5000\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1914856.7500 - val_loss: 2311924.2500\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1658693.5000 - val_loss: 1914408.8750\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1719384.6250 - val_loss: 2094365.7500\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1318291.8750 - val_loss: 1637291.1250\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1360178.8750 - val_loss: 2930522.2500\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1425818.8750 - val_loss: 2254822.0000\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1400890.2500 - val_loss: 1954400.5000\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1251889.2500 - val_loss: 1644917.8750\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1349393.3750 - val_loss: 1754987.3750\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1746996.7500 - val_loss: 1854637.8750\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1249035.3750 - val_loss: 1823232.2500\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1121821.3750 - val_loss: 2153276.2500\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1208401.0000 - val_loss: 1606072.6250\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1284297.7500 - val_loss: 1659722.8750\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1091760.0000 - val_loss: 2122022.2500\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1175481.3750 - val_loss: 1942372.6250\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 944564.3750 - val_loss: 2104546.2500\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1040859.2500 - val_loss: 1313810.3750\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1021674.5000 - val_loss: 1346985.6250\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1056266.6250 - val_loss: 1376937.8750\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1102032.7500 - val_loss: 1396566.6250\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1021379.4375 - val_loss: 1366915.8750\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 976762.9375 - val_loss: 1324785.8750\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 983764.0625 - val_loss: 2106272.0000\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 976474.9375 - val_loss: 1862201.6250\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 981443.3125 - val_loss: 1481276.5000\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 980589.1875 - val_loss: 1573555.6250\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 916821.8125 - val_loss: 1233970.0000\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 837600.3125 - val_loss: 1127021.2500\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1037846.2500 - val_loss: 1266265.2500\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1055760.1250 - val_loss: 1526455.1250\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1010279.1875 - val_loss: 1214259.2500\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 950702.8125 - val_loss: 1171053.6250\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1017892.8750 - val_loss: 1599468.1250\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1037118.6875 - val_loss: 1516069.7500\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 904373.1875 - val_loss: 1297571.5000\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 810171.1250 - val_loss: 934138.1250\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 825191.6875 - val_loss: 1177230.6250\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 847546.0000 - val_loss: 1099170.3750\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 738448.1250 - val_loss: 1198126.7500\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 886208.9375 - val_loss: 1693808.7500\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 936680.7500 - val_loss: 852167.9375\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 925603.2500 - val_loss: 1265603.1250\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 809355.3750 - val_loss: 995293.4375\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 723201.8125 - val_loss: 999336.6875\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 691338.5625 - val_loss: 1113734.6250\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 629783.5625 - val_loss: 885806.4375\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 636962.7500 - val_loss: 1091893.5000\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 670297.0000 - val_loss: 1657021.2500\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 985609.0625 - val_loss: 719280.0000\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 675052.6875 - val_loss: 1118655.5000\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 911601.3125 - val_loss: 1318993.7500\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 716392.6250 - val_loss: 641181.3750\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 595680.3750 - val_loss: 826154.3750\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 669653.0625 - val_loss: 1194455.2500\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 660763.9375 - val_loss: 887037.7500\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 591432.1875 - val_loss: 671681.1875\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 528904.6875 - val_loss: 1078937.0000\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 678477.8750 - val_loss: 758310.4375\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 532232.9375 - val_loss: 906193.1875\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 616882.6875 - val_loss: 969492.0625\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 479411.7188 - val_loss: 643937.6875\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 558873.0000 - val_loss: 662309.6875\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 528471.2500 - val_loss: 674754.4375\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 453014.0312 - val_loss: 722287.8125\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 548869.7500 - val_loss: 588244.0000\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 670779.8750 - val_loss: 531023.8125\n",
      "Epoch 131/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 540965.6250 - val_loss: 952830.5625\n",
      "Epoch 132/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 402611.1250 - val_loss: 509805.5312\n",
      "Epoch 133/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 427059.6562 - val_loss: 581955.4375\n",
      "Epoch 134/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 356744.7812 - val_loss: 421952.1250\n",
      "Epoch 135/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 345199.8438 - val_loss: 910236.3125\n",
      "Epoch 136/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 463609.3750 - val_loss: 431447.4375\n",
      "Epoch 137/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 377085.0000 - val_loss: 881964.6875\n",
      "Epoch 138/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 389434.5938 - val_loss: 492915.5938\n",
      "Epoch 139/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 467587.2812 - val_loss: 935723.0625\n",
      "Epoch 140/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 431516.0625 - val_loss: 402040.5000\n",
      "Epoch 141/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 355330.1250 - val_loss: 859287.0000\n",
      "Epoch 142/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 403232.0938 - val_loss: 359616.2500\n",
      "Epoch 143/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 263872.8750 - val_loss: 428543.2188\n",
      "Epoch 144/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 255505.1875 - val_loss: 443397.3750\n",
      "Epoch 145/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 244441.2969 - val_loss: 350077.4688\n",
      "Epoch 146/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 287284.5000 - val_loss: 344348.3438\n",
      "Epoch 147/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 236058.8281 - val_loss: 328947.2500\n",
      "Epoch 148/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 285593.0938 - val_loss: 403649.0312\n",
      "Epoch 149/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 264641.2812 - val_loss: 308582.9062\n",
      "Epoch 150/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 243843.1875 - val_loss: 285382.0625\n",
      "Epoch 151/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 218726.3594 - val_loss: 309021.7812\n",
      "Epoch 152/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 289606.4688 - val_loss: 325082.3750\n",
      "Epoch 153/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 300686.4688 - val_loss: 379512.1250\n",
      "Epoch 154/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 209780.0469 - val_loss: 240626.9531\n",
      "Epoch 155/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 284210.6562 - val_loss: 231904.7500\n",
      "Epoch 156/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 178936.0469 - val_loss: 367883.6875\n",
      "Epoch 157/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 225846.4688 - val_loss: 312933.2500\n",
      "Epoch 158/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 185908.5469 - val_loss: 189220.4844\n",
      "Epoch 159/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 220268.4062 - val_loss: 295383.1875\n",
      "Epoch 160/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 182402.7656 - val_loss: 302211.8750\n",
      "Epoch 161/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 178450.5156 - val_loss: 219077.8906\n",
      "Epoch 162/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 172287.4531 - val_loss: 238652.4688\n",
      "Epoch 163/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 198581.8750 - val_loss: 309472.5312\n",
      "Epoch 164/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 198749.5469 - val_loss: 236071.3594\n",
      "Epoch 165/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 166031.0469 - val_loss: 513902.2500\n",
      "Epoch 166/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 199343.0000 - val_loss: 396804.1562\n",
      "Epoch 167/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 201410.3594 - val_loss: 148661.3594\n",
      "Epoch 168/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 226617.4844 - val_loss: 147048.3750\n",
      "Epoch 169/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 201112.5938 - val_loss: 136434.8750\n",
      "Epoch 170/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 154967.3438 - val_loss: 208754.9062\n",
      "Epoch 171/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 197133.6875 - val_loss: 190214.0156\n",
      "Epoch 172/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 146934.5625 - val_loss: 192864.0000\n",
      "Epoch 173/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 211494.2344 - val_loss: 178879.6250\n",
      "Epoch 174/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 184048.9219 - val_loss: 136079.8281\n",
      "Epoch 175/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 130823.7109 - val_loss: 177412.8750\n",
      "Epoch 176/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 132328.8906 - val_loss: 212955.3750\n",
      "Epoch 177/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 188281.5469 - val_loss: 194926.8906\n",
      "Epoch 178/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 178743.0938 - val_loss: 133922.8750\n",
      "Epoch 179/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 118473.1250 - val_loss: 144716.9375\n",
      "Epoch 180/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 146562.6406 - val_loss: 125020.6797\n",
      "Epoch 181/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 101929.3047 - val_loss: 226881.0938\n",
      "Epoch 182/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 254378.7344 - val_loss: 117906.1094\n",
      "Epoch 183/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 114692.5625 - val_loss: 173710.7656\n",
      "Epoch 184/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 162812.2969 - val_loss: 88380.5078\n",
      "Epoch 185/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 138611.1875 - val_loss: 107406.4375\n",
      "Epoch 186/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 128360.6250 - val_loss: 192955.1562\n",
      "Epoch 187/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 105659.8672 - val_loss: 75007.5000\n",
      "Epoch 188/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 160465.6406 - val_loss: 112922.0156\n",
      "Epoch 189/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 133929.0156 - val_loss: 241066.8438\n",
      "Epoch 190/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 120967.2656 - val_loss: 192652.9844\n",
      "Epoch 191/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 98134.4297 - val_loss: 135800.1406\n",
      "Epoch 192/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 119430.6172 - val_loss: 126606.9219\n",
      "Epoch 193/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 238500.3125 - val_loss: 483773.4062\n",
      "Epoch 194/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 161560.3750 - val_loss: 389277.6250\n",
      "Epoch 195/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 187765.5312 - val_loss: 99333.5625\n",
      "Epoch 196/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 110205.7891 - val_loss: 130058.5391\n",
      "Epoch 197/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 104084.6094 - val_loss: 269691.7188\n",
      "Epoch 198/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 194911.5781 - val_loss: 173535.3594\n",
      "Epoch 199/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 102685.2734 - val_loss: 91716.1328\n",
      "Epoch 200/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 103047.5938 - val_loss: 151784.5781\n",
      "Epoch 201/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 150565.3906 - val_loss: 150414.9219\n",
      "Epoch 202/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 101234.9766 - val_loss: 71674.0078\n",
      "Epoch 203/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 85243.7891 - val_loss: 230209.5156\n",
      "Epoch 204/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 83246.6953 - val_loss: 189201.9531\n",
      "Epoch 205/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 94616.3828 - val_loss: 54960.6484\n",
      "Epoch 206/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 99402.9688 - val_loss: 60476.5508\n",
      "Epoch 207/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 87106.4531 - val_loss: 182749.7812\n",
      "Epoch 208/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 90545.8984 - val_loss: 69446.2500\n",
      "Epoch 209/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 78173.2031 - val_loss: 93347.0000\n",
      "Epoch 210/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 69821.3984 - val_loss: 100998.3203\n",
      "Epoch 211/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 106385.0469 - val_loss: 85546.8594\n",
      "Epoch 212/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 78164.7969 - val_loss: 71832.0781\n",
      "Epoch 213/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 92414.5938 - val_loss: 204790.6250\n",
      "Epoch 214/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 93237.2891 - val_loss: 144335.5156\n",
      "Epoch 215/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 88214.8594 - val_loss: 55883.2070\n",
      "Epoch 216/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 77665.9062 - val_loss: 119894.9375\n",
      "Epoch 217/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 88800.5859 - val_loss: 99748.4375\n",
      "Epoch 218/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 113645.3281 - val_loss: 75138.2266\n",
      "Epoch 219/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 158523.7031 - val_loss: 184329.3594\n",
      "Epoch 220/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 85144.2109 - val_loss: 79267.7109\n",
      "Epoch 221/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 90793.4219 - val_loss: 338659.0312\n",
      "Epoch 222/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 209664.0469 - val_loss: 175007.6719\n",
      "Epoch 223/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 106577.0391 - val_loss: 86643.2344\n",
      "Epoch 224/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 77499.2578 - val_loss: 56743.4688\n",
      "Epoch 225/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 106955.3125 - val_loss: 119485.2266\n",
      "Epoch 226/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 89716.5547 - val_loss: 99222.9531\n",
      "Epoch 227/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 175499.2969 - val_loss: 215835.4531\n",
      "Epoch 228/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 106352.7422 - val_loss: 139781.8906\n",
      "Epoch 229/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 87124.5781 - val_loss: 71864.6641\n",
      "Epoch 230/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 87884.4375 - val_loss: 78009.9844\n",
      "Epoch 231/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 93705.4141 - val_loss: 29561.3652\n",
      "Epoch 232/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 69355.9609 - val_loss: 82695.0859\n",
      "Epoch 233/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 77685.1875 - val_loss: 47231.3633\n",
      "Epoch 234/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 84878.2656 - val_loss: 93248.6094\n",
      "Epoch 235/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 82012.8281 - val_loss: 104792.0859\n",
      "Epoch 236/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 124864.9531 - val_loss: 112842.9688\n",
      "Epoch 237/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 79252.7344 - val_loss: 12600.2422\n",
      "Epoch 238/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 86471.7578 - val_loss: 35299.3164\n",
      "Epoch 239/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 96774.8984 - val_loss: 150290.6875\n",
      "Epoch 240/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 129929.1094 - val_loss: 41601.1914\n",
      "Epoch 241/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 85065.9062 - val_loss: 231286.2500\n",
      "Epoch 242/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 72541.7109 - val_loss: 51791.2812\n",
      "Epoch 243/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 102070.7578 - val_loss: 39353.5430\n",
      "Epoch 244/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 81102.2891 - val_loss: 256409.8750\n",
      "Epoch 245/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 153956.6719 - val_loss: 105933.9688\n",
      "Epoch 246/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 69601.0781 - val_loss: 34286.8125\n",
      "Epoch 247/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 96449.0312 - val_loss: 22292.2773\n",
      "Epoch 248/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 91353.9844 - val_loss: 144594.8281\n",
      "Epoch 249/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 166267.0938 - val_loss: 123950.9219\n",
      "Epoch 250/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 59664.9492 - val_loss: 196772.9844\n",
      "Epoch 251/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 88457.7734 - val_loss: 45593.8320\n",
      "Epoch 252/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 46472.9414 - val_loss: 116532.1641\n",
      "Epoch 253/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 78086.7031 - val_loss: 43894.6914\n",
      "Epoch 254/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 137631.0625 - val_loss: 182334.9688\n",
      "Epoch 255/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 65150.8516 - val_loss: 138672.8438\n",
      "Epoch 256/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 95549.3828 - val_loss: 87660.3828\n",
      "Epoch 257/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 79278.2266 - val_loss: 59380.6953\n",
      "Epoch 258/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 91216.8281 - val_loss: 100529.8125\n",
      "Epoch 259/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 84733.0078 - val_loss: 34321.9609\n",
      "Epoch 260/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 69716.0391 - val_loss: 88069.3281\n",
      "Epoch 261/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 49632.3945 - val_loss: 81394.8750\n",
      "Epoch 262/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 95379.9219 - val_loss: 78542.5312\n",
      "Epoch 263/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 76747.0156 - val_loss: 44695.6094\n",
      "Epoch 264/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 62586.7266 - val_loss: 130341.0312\n",
      "Epoch 265/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 65728.6328 - val_loss: 25599.0801\n",
      "Epoch 266/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 56471.9922 - val_loss: 78261.5000\n",
      "Epoch 267/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 47941.6445 - val_loss: 16751.0957\n",
      "'########################################################Model4\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 8ms/step - loss: 132801376.0000 - val_loss: 57128816.0000\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 43576856.0000 - val_loss: 46099744.0000\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 33629352.0000 - val_loss: 34074504.0000\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 26168000.0000 - val_loss: 33226960.0000\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 23022976.0000 - val_loss: 26070504.0000\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 18305962.0000 - val_loss: 19629182.0000\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 16229672.0000 - val_loss: 17149132.0000\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 15111180.0000 - val_loss: 22108924.0000\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 14626192.0000 - val_loss: 15812790.0000\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 12254170.0000 - val_loss: 18733630.0000\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 10658391.0000 - val_loss: 13159048.0000\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 10949818.0000 - val_loss: 12616077.0000\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 10803575.0000 - val_loss: 11644542.0000\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 9512515.0000 - val_loss: 11101552.0000\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 7993313.0000 - val_loss: 9619257.0000\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 7356564.0000 - val_loss: 11191021.0000\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 7634052.0000 - val_loss: 9589154.0000\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 7088394.5000 - val_loss: 8654648.0000\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 6545800.5000 - val_loss: 9025859.0000\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 6251909.0000 - val_loss: 7763979.5000\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 5592952.0000 - val_loss: 8377090.0000\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 5257883.5000 - val_loss: 7756381.5000\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5066095.0000 - val_loss: 7044134.0000\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4742793.0000 - val_loss: 6660200.0000\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4535571.5000 - val_loss: 6268442.5000\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4575152.5000 - val_loss: 6794187.0000\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4120342.2500 - val_loss: 5870784.0000\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 4161383.2500 - val_loss: 5433131.0000\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4429724.0000 - val_loss: 5465513.0000\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3893113.7500 - val_loss: 5579939.5000\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3816313.0000 - val_loss: 5177508.5000\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3503806.5000 - val_loss: 4853005.0000\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3534816.5000 - val_loss: 4574460.0000\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3296645.2500 - val_loss: 4891928.5000\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3770641.2500 - val_loss: 5503493.0000\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3688125.7500 - val_loss: 3864490.2500\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3147891.2500 - val_loss: 4351960.0000\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3155193.7500 - val_loss: 4061216.2500\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2903341.0000 - val_loss: 3748772.7500\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2908792.7500 - val_loss: 3772389.5000\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2594345.5000 - val_loss: 4525479.5000\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2689737.5000 - val_loss: 3362758.5000\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2579847.7500 - val_loss: 3697784.2500\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2543525.7500 - val_loss: 3115690.2500\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2482219.0000 - val_loss: 3572501.7500\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2376889.2500 - val_loss: 3595002.5000\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2495410.7500 - val_loss: 2974447.7500\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2127365.2500 - val_loss: 3085403.2500\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1960161.8750 - val_loss: 3160523.5000\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1909810.5000 - val_loss: 2569226.0000\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1818967.8750 - val_loss: 2291636.5000\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2309224.7500 - val_loss: 3633006.7500\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1953743.7500 - val_loss: 2249924.7500\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1925900.1250 - val_loss: 2349694.5000\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1854325.8750 - val_loss: 2688940.2500\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2014834.2500 - val_loss: 2057079.8750\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1845676.3750 - val_loss: 2116582.0000\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1624043.0000 - val_loss: 2142241.2500\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1486716.8750 - val_loss: 2198606.7500\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1511604.8750 - val_loss: 1815416.5000\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1833700.8750 - val_loss: 2280804.7500\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1652865.3750 - val_loss: 1643883.0000\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1518126.7500 - val_loss: 1608235.7500\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1466053.6250 - val_loss: 1901625.3750\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1448419.3750 - val_loss: 1949189.7500\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1483840.2500 - val_loss: 2770321.5000\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1431841.5000 - val_loss: 2056718.1250\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1394097.8750 - val_loss: 3866880.5000\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1653124.2500 - val_loss: 1752145.7500\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1281790.8750 - val_loss: 1470209.2500\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1499243.2500 - val_loss: 1481801.6250\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1041596.4375 - val_loss: 1455658.0000\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1186706.2500 - val_loss: 1445588.5000\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1134685.5000 - val_loss: 1290270.6250\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1040685.7500 - val_loss: 1479544.0000\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1098894.3750 - val_loss: 1567317.6250\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1272539.6250 - val_loss: 1383319.5000\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1280669.1250 - val_loss: 1328291.1250\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1267461.0000 - val_loss: 1342313.6250\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 943381.1250 - val_loss: 1274532.2500\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 970143.4375 - val_loss: 1141050.5000\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1059316.7500 - val_loss: 2058885.1250\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1058080.3750 - val_loss: 1396745.8750\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 912743.5000 - val_loss: 1000169.2500\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 837704.8125 - val_loss: 977742.4375\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1058913.5000 - val_loss: 1219227.7500\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 795804.1250 - val_loss: 1564165.0000\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 892514.6875 - val_loss: 1037729.8750\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 927028.1875 - val_loss: 1144566.3750\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 798197.6875 - val_loss: 867312.3750\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 772148.6250 - val_loss: 895886.8125\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 916614.4375 - val_loss: 847799.5625\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 888040.0625 - val_loss: 930872.0625\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 700845.8750 - val_loss: 814871.5000\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 670365.3125 - val_loss: 832884.7500\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 804886.3125 - val_loss: 1134763.7500\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 729417.8125 - val_loss: 865988.0000\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 724050.1875 - val_loss: 610936.3125\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 797817.1250 - val_loss: 1087423.3750\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 735006.5625 - val_loss: 791738.2500\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 660128.9375 - val_loss: 760015.3125\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 664667.0625 - val_loss: 632793.2500\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 573914.5625 - val_loss: 933635.6250\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 563879.5625 - val_loss: 664448.0000\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 617004.6250 - val_loss: 1155305.6250\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 763635.6250 - val_loss: 810067.3125\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 640585.9375 - val_loss: 737205.1875\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 509303.5938 - val_loss: 718457.7500\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 558188.1875 - val_loss: 1067634.5000\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 776718.3125 - val_loss: 2684145.7500\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 877384.6250 - val_loss: 1402788.1250\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 736006.1250 - val_loss: 954010.5000\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 529362.5625 - val_loss: 692976.1250\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 529484.5000 - val_loss: 955504.6875\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 467763.5938 - val_loss: 640329.1250\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 619802.7500 - val_loss: 544620.5000\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 540287.1875 - val_loss: 570448.1250\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 514648.3750 - val_loss: 1022140.3750\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 583488.4375 - val_loss: 640763.4375\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 593651.3750 - val_loss: 851115.6250\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 516628.1562 - val_loss: 549000.3125\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 383958.1875 - val_loss: 768728.3750\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 507734.4688 - val_loss: 432755.3750\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 334794.6250 - val_loss: 460976.1250\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 480418.8750 - val_loss: 646804.0625\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 465589.9375 - val_loss: 743655.8750\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 391258.7500 - val_loss: 406327.2188\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 344437.8125 - val_loss: 490858.6562\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 317945.5000 - val_loss: 623165.6875\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 513629.9062 - val_loss: 471975.8750\n",
      "Epoch 131/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 368436.9688 - val_loss: 398820.8750\n",
      "Epoch 132/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 396004.5000 - val_loss: 467080.2812\n",
      "Epoch 133/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 315944.0312 - val_loss: 403447.2500\n",
      "Epoch 134/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 341428.4375 - val_loss: 358268.1875\n",
      "Epoch 135/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 346982.0938 - val_loss: 445153.5000\n",
      "Epoch 136/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 329746.3750 - val_loss: 429338.3750\n",
      "Epoch 137/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 278141.2188 - val_loss: 491610.3750\n",
      "Epoch 138/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 275900.0000 - val_loss: 227893.3750\n",
      "Epoch 139/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 269981.2500 - val_loss: 339165.7188\n",
      "Epoch 140/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 260276.4531 - val_loss: 421237.3125\n",
      "Epoch 141/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 246773.7812 - val_loss: 259619.3438\n",
      "Epoch 142/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 259941.7031 - val_loss: 422467.7500\n",
      "Epoch 143/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 233864.4688 - val_loss: 367936.2500\n",
      "Epoch 144/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 227570.8750 - val_loss: 357548.8750\n",
      "Epoch 145/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 251312.0625 - val_loss: 271226.0000\n",
      "Epoch 146/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 88502.5156 - val_loss: 49296.6328\n",
      "Epoch 223/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 102903.9609 - val_loss: 217729.9688\n",
      "Epoch 224/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 127431.1016 - val_loss: 93421.4531\n",
      "Epoch 225/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 82228.3359 - val_loss: 75844.1797\n",
      "Epoch 226/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 85436.3906 - val_loss: 35075.0820\n",
      "Epoch 227/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 48563.1250 - val_loss: 129712.9219\n",
      "Epoch 228/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 75534.8594 - val_loss: 27058.6973\n",
      "Epoch 229/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 83305.2578 - val_loss: 96656.7969\n",
      "Epoch 230/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 42780.0898 - val_loss: 102263.6328\n",
      "Epoch 231/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 73484.9141 - val_loss: 38783.2109\n",
      "Epoch 232/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 45419.4102 - val_loss: 111191.3516\n",
      "Epoch 233/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 82575.5078 - val_loss: 58412.9258\n",
      "Epoch 234/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 64793.7734 - val_loss: 52505.5977\n",
      "Epoch 235/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 46819.8164 - val_loss: 71551.8984\n",
      "Epoch 236/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 68000.9688 - val_loss: 107489.4062\n",
      "Epoch 237/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 63660.0000 - val_loss: 83342.8203\n",
      "Epoch 238/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 96702.4297 - val_loss: 93300.4375\n",
      "Epoch 239/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 38163.0859 - val_loss: 21254.2969\n",
      "Epoch 240/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 91724.6797 - val_loss: 30426.3145\n",
      "Epoch 241/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 87352.0625 - val_loss: 48200.2031\n",
      "Epoch 242/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 56658.8047 - val_loss: 23331.1602\n",
      "Epoch 243/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 53575.0742 - val_loss: 49402.7305\n",
      "Epoch 244/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 49439.8672 - val_loss: 129561.3906\n",
      "Epoch 245/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 69739.2422 - val_loss: 83187.3672\n",
      "Epoch 246/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 75929.2031 - val_loss: 122203.3359\n",
      "Epoch 247/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 42044.5156 - val_loss: 41790.3516\n",
      "Epoch 248/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 65789.5469 - val_loss: 26898.3496\n",
      "Epoch 249/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 61607.3008 - val_loss: 86646.7031\n",
      "Epoch 250/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 48832.9844 - val_loss: 53873.3984\n",
      "Epoch 251/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 59640.6172 - val_loss: 57288.6719\n",
      "Epoch 252/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 62605.2891 - val_loss: 60882.9023\n",
      "Epoch 253/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 45319.8477 - val_loss: 51721.2695\n",
      "Epoch 254/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 50534.8438 - val_loss: 38260.8711\n",
      "Epoch 255/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 42123.9648 - val_loss: 35507.4023\n",
      "Epoch 256/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 68086.7578 - val_loss: 33584.4648\n",
      "Epoch 257/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 45825.9219 - val_loss: 131383.7031\n",
      "Epoch 258/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 48994.6250 - val_loss: 30518.5508\n",
      "Epoch 259/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 44502.8906 - val_loss: 138782.4688\n",
      "Epoch 260/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 48833.9766 - val_loss: 21003.0723\n",
      "Epoch 261/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 41765.0938 - val_loss: 70350.7344\n",
      "Epoch 262/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 53482.2695 - val_loss: 124925.5859\n",
      "Epoch 263/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 53259.8164 - val_loss: 82174.4531\n",
      "Epoch 264/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 65372.0977 - val_loss: 25889.1621\n",
      "Epoch 265/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 43219.5625 - val_loss: 92194.2656\n",
      "Epoch 266/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 56871.3789 - val_loss: 87745.4219\n",
      "Epoch 267/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 70366.5859 - val_loss: 62004.3672\n",
      "Epoch 268/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 52413.3633 - val_loss: 16859.5879\n",
      "Epoch 269/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 45868.1055 - val_loss: 29856.1621\n",
      "Epoch 270/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 62756.6172 - val_loss: 118764.8672\n",
      "Epoch 271/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 82478.1328 - val_loss: 32699.3301\n",
      "Epoch 272/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 42864.4141 - val_loss: 37354.1953\n",
      "Epoch 273/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 81621.6328 - val_loss: 124115.8047\n",
      "Epoch 274/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 48230.1680 - val_loss: 134356.2812\n",
      "Epoch 275/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 54513.6172 - val_loss: 37136.9961\n",
      "Epoch 276/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 34024.3672 - val_loss: 13493.5693\n",
      "Epoch 277/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 39484.8516 - val_loss: 35845.7305\n",
      "Epoch 278/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 45983.0742 - val_loss: 25984.2422\n",
      "Epoch 279/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 52215.4492 - val_loss: 60320.4688\n",
      "Epoch 280/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 83390.1797 - val_loss: 33325.7930\n",
      "Epoch 281/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 55644.2500 - val_loss: 71028.1719\n",
      "Epoch 282/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 62822.7070 - val_loss: 38900.6953\n",
      "Epoch 283/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 53681.3750 - val_loss: 120706.3281\n",
      "Epoch 284/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 51123.0391 - val_loss: 36143.8086\n",
      "Epoch 285/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 60991.3906 - val_loss: 61837.9297\n",
      "Epoch 286/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 25757.3574 - val_loss: 33956.2617\n",
      "Epoch 287/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 61024.8594 - val_loss: 145746.8281\n",
      "Epoch 288/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 64649.0469 - val_loss: 55836.3906\n",
      "Epoch 289/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 46114.0938 - val_loss: 30553.8281\n",
      "Epoch 290/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 37913.1289 - val_loss: 62963.3516\n",
      "Epoch 291/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 53838.6172 - val_loss: 20954.1426\n",
      "Epoch 292/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 58872.3789 - val_loss: 52593.7461\n",
      "Epoch 293/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 33938.5273 - val_loss: 94613.6875\n",
      "Epoch 294/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 41842.8398 - val_loss: 32718.4863\n",
      "Epoch 295/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 33021.6562 - val_loss: 24826.0488\n",
      "Epoch 296/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 49714.0273 - val_loss: 79081.0859\n",
      "Epoch 297/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 42938.0469 - val_loss: 29173.9141\n",
      "Epoch 298/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 36941.5195 - val_loss: 47715.4688\n",
      "Epoch 299/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 36599.8633 - val_loss: 14496.9863\n",
      "Epoch 300/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 46979.6602 - val_loss: 87833.7031\n",
      "'########################################################Model5\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 7ms/step - loss: 122564096.0000 - val_loss: 54266832.0000\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 47172004.0000 - val_loss: 47769948.0000\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 33550654.0000 - val_loss: 33290502.0000\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 26542242.0000 - val_loss: 25945150.0000\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 23371868.0000 - val_loss: 23372448.0000\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 19644032.0000 - val_loss: 20707158.0000\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 16531495.0000 - val_loss: 20529878.0000\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 15779390.0000 - val_loss: 16210600.0000\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 12580384.0000 - val_loss: 15770022.0000\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 11599007.0000 - val_loss: 12537177.0000\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 10501536.0000 - val_loss: 12417169.0000\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 10291772.0000 - val_loss: 12021133.0000\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 9543510.0000 - val_loss: 10691628.0000\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 8478897.0000 - val_loss: 10319725.0000\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 8453821.0000 - val_loss: 9497799.0000\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 6807308.5000 - val_loss: 8698064.0000\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 7104755.0000 - val_loss: 7653542.0000\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 6972632.0000 - val_loss: 8808948.0000\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 5920808.0000 - val_loss: 6761816.5000\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5988724.0000 - val_loss: 6349091.0000\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5600575.5000 - val_loss: 6650855.5000\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4939361.5000 - val_loss: 5589173.5000\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4500941.0000 - val_loss: 5373393.5000\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 4497423.5000 - val_loss: 5258630.0000\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4764456.0000 - val_loss: 5511940.5000\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4534807.0000 - val_loss: 5234085.5000\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 4122940.7500 - val_loss: 4452004.5000\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3902839.2500 - val_loss: 4720934.0000\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3756653.7500 - val_loss: 4891131.5000\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 4301189.0000 - val_loss: 4314887.0000\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3307337.2500 - val_loss: 4342718.0000\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3596199.7500 - val_loss: 6611489.0000\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3777105.0000 - val_loss: 3657322.2500\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3151393.0000 - val_loss: 3731496.2500\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2944710.7500 - val_loss: 3457034.2500\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2803980.5000 - val_loss: 3115816.5000\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2526248.7500 - val_loss: 3199342.0000\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2553096.5000 - val_loss: 2985843.7500\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2396628.5000 - val_loss: 3067986.7500\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2400830.7500 - val_loss: 3097448.5000\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2232148.5000 - val_loss: 2410953.5000\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2165008.7500 - val_loss: 2983276.2500\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2328428.7500 - val_loss: 3331851.5000\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2521616.7500 - val_loss: 4101651.7500\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2441180.7500 - val_loss: 2373421.5000\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2110953.5000 - val_loss: 2497441.2500\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2034841.0000 - val_loss: 2411062.0000\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1996413.3750 - val_loss: 1979753.7500\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2254559.7500 - val_loss: 2139339.2500\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2175361.5000 - val_loss: 2306751.0000\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2144935.7500 - val_loss: 1985560.5000\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1640459.5000 - val_loss: 2214771.0000\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1543942.2500 - val_loss: 2008941.0000\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1763421.5000 - val_loss: 1731004.0000\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1473426.3750 - val_loss: 1811415.1250\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1376220.3750 - val_loss: 1718727.6250\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1392042.6250 - val_loss: 2512167.5000\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1490597.6250 - val_loss: 3144229.2500\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1470712.7500 - val_loss: 1836327.0000\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1335225.8750 - val_loss: 1690375.7500\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1485394.3750 - val_loss: 1879609.1250\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1362651.1250 - val_loss: 1905160.0000\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1366800.7500 - val_loss: 2056311.8750\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1413893.3750 - val_loss: 1413681.5000\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1192664.3750 - val_loss: 1506351.5000\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1111617.7500 - val_loss: 1415595.1250\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1116816.8750 - val_loss: 1757932.7500\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1231989.5000 - val_loss: 1351645.7500\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1544301.3750 - val_loss: 1623317.0000\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1358101.1250 - val_loss: 2730314.0000\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1422036.8750 - val_loss: 1542461.6250\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1362095.8750 - val_loss: 1297963.0000\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1102787.2500 - val_loss: 2250543.2500\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1559921.8750 - val_loss: 1159023.1250\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 984174.3125 - val_loss: 1134701.8750\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 936514.6875 - val_loss: 1390702.5000\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1024410.2500 - val_loss: 2100288.7500\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1068550.0000 - val_loss: 1130552.0000\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 848904.5000 - val_loss: 907128.4375\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 774629.6875 - val_loss: 1126160.6250\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1079491.0000 - val_loss: 1620685.6250\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1104021.8750 - val_loss: 1013425.4375\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 910989.6250 - val_loss: 891060.1875\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 859409.2500 - val_loss: 942224.7500\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 750150.8750 - val_loss: 858525.8750\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 907919.0000 - val_loss: 851536.3750\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 839915.3125 - val_loss: 905800.2500\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 910611.0000 - val_loss: 823507.0625\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 895616.5625 - val_loss: 857615.6875\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 711648.4375 - val_loss: 1191685.3750\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 667738.4375 - val_loss: 1440715.7500\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 764126.1875 - val_loss: 900353.8750\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 712358.6250 - val_loss: 879490.6250\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 699442.5000 - val_loss: 1625319.6250\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1026523.8750 - val_loss: 900131.3125\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 852023.1250 - val_loss: 738571.6250\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 732335.2500 - val_loss: 1031132.9375\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 751611.3750 - val_loss: 919999.6875\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 749438.0625 - val_loss: 713941.8750\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 678374.9375 - val_loss: 714268.7500\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 650911.3125 - val_loss: 1375270.7500\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 583500.1875 - val_loss: 759383.3750\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 490048.6562 - val_loss: 700832.8750\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 479497.2500 - val_loss: 726184.9375\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 432951.5938 - val_loss: 652674.1875\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 619438.8125 - val_loss: 858702.3125\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 560698.5625 - val_loss: 579114.8750\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 672544.6875 - val_loss: 683538.1250\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 455264.6250 - val_loss: 888786.6875\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 557005.3750 - val_loss: 676232.0000\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 513075.1562 - val_loss: 482410.8125\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 390955.3438 - val_loss: 515761.2812\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 426097.7188 - val_loss: 459558.3750\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 346687.1562 - val_loss: 736527.7500\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 482605.3438 - val_loss: 369737.1250\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 318907.7812 - val_loss: 419464.3438\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 377934.0938 - val_loss: 451744.7188\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 349662.3750 - val_loss: 457625.4688\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 311018.7812 - val_loss: 290690.2500\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 272301.7812 - val_loss: 350349.4375\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 274019.5312 - val_loss: 314038.2812\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 263917.4688 - val_loss: 343028.8750\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 291155.3750 - val_loss: 297328.0312\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 206842.5000 - val_loss: 288001.5312\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 224419.2656 - val_loss: 436097.0938\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 223793.8281 - val_loss: 265118.1875\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 208966.3438 - val_loss: 332021.0000\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 218330.6875 - val_loss: 270216.5938\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 253220.6250 - val_loss: 284244.2812\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 234852.0625 - val_loss: 232227.9375\n",
      "Epoch 131/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 178236.0781 - val_loss: 252703.0000\n",
      "Epoch 132/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 211913.5000 - val_loss: 245114.7344\n",
      "Epoch 133/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 222982.0312 - val_loss: 383012.8438\n",
      "Epoch 134/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 181305.7500 - val_loss: 234864.2812\n",
      "Epoch 135/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 163680.5156 - val_loss: 224583.6250\n",
      "Epoch 136/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 163486.1875 - val_loss: 199795.0625\n",
      "Epoch 137/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 196109.8281 - val_loss: 254895.8906\n",
      "Epoch 138/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 169665.2031 - val_loss: 229920.9062\n",
      "Epoch 139/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 185164.9219 - val_loss: 143835.1094\n",
      "Epoch 140/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 194820.7188 - val_loss: 187367.8750\n",
      "Epoch 141/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 196882.1562 - val_loss: 287532.0938\n",
      "Epoch 142/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 153192.8906 - val_loss: 202408.5469\n",
      "Epoch 143/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 203792.9219 - val_loss: 194493.3594\n",
      "Epoch 144/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 149396.7812 - val_loss: 208252.8750\n",
      "Epoch 145/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 172485.9844 - val_loss: 168296.8438\n",
      "Epoch 146/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 190259.7812 - val_loss: 477623.1250\n",
      "Epoch 147/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 199766.6250 - val_loss: 104156.3047\n",
      "Epoch 148/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 174548.4219 - val_loss: 208703.5781\n",
      "Epoch 149/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 169434.5000 - val_loss: 189483.5938\n",
      "Epoch 150/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 173515.0312 - val_loss: 249631.6094\n",
      "Epoch 151/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 172794.0000 - val_loss: 149507.6406\n",
      "Epoch 152/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 169980.8438 - val_loss: 283537.2812\n",
      "Epoch 153/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 162615.1250 - val_loss: 226073.2188\n",
      "Epoch 154/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 150079.7031 - val_loss: 189988.8906\n",
      "Epoch 155/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 155242.3594 - val_loss: 152732.3438\n",
      "Epoch 156/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 172508.0156 - val_loss: 141868.5312\n",
      "Epoch 157/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 157371.7500 - val_loss: 165896.2656\n",
      "Epoch 158/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 168462.6250 - val_loss: 164597.6406\n",
      "Epoch 159/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 154706.0156 - val_loss: 180757.9844\n",
      "Epoch 160/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 182102.8594 - val_loss: 108445.1172\n",
      "Epoch 161/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 152692.5625 - val_loss: 159865.1562\n",
      "Epoch 162/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 135055.6250 - val_loss: 231717.2969\n",
      "Epoch 163/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 165678.4062 - val_loss: 160008.3125\n",
      "Epoch 164/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 143463.4375 - val_loss: 219848.4375\n",
      "Epoch 165/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 142195.7031 - val_loss: 182585.0156\n",
      "Epoch 166/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 135648.0938 - val_loss: 122298.7422\n",
      "Epoch 167/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 155058.0781 - val_loss: 204944.1562\n",
      "Epoch 168/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 126194.2266 - val_loss: 141997.4062\n",
      "Epoch 169/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 132866.3594 - val_loss: 100287.2188\n",
      "Epoch 170/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 125606.3516 - val_loss: 80638.0078\n",
      "Epoch 171/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 115897.0938 - val_loss: 171606.3125\n",
      "Epoch 172/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 109734.3516 - val_loss: 90018.7188\n",
      "Epoch 173/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 104599.9844 - val_loss: 117045.5312\n",
      "Epoch 174/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 102950.0312 - val_loss: 182823.7031\n",
      "Epoch 175/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 105472.2344 - val_loss: 103219.4375\n",
      "Epoch 176/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 154710.0000 - val_loss: 127275.0625\n",
      "Epoch 177/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 137887.3125 - val_loss: 141070.6875\n",
      "Epoch 178/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 105604.0938 - val_loss: 92188.4609\n",
      "Epoch 179/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 101543.1328 - val_loss: 59605.7656\n",
      "Epoch 180/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 131238.5781 - val_loss: 171119.0625\n",
      "Epoch 181/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 138910.1250 - val_loss: 242750.1562\n",
      "Epoch 182/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 121992.5703 - val_loss: 81452.3203\n",
      "Epoch 183/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 171172.3281 - val_loss: 297319.4375\n",
      "Epoch 184/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 158780.9375 - val_loss: 42385.3711\n",
      "Epoch 185/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 109237.1953 - val_loss: 123702.3203\n",
      "Epoch 186/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 147197.4375 - val_loss: 154196.8750\n",
      "Epoch 187/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 86082.9766 - val_loss: 66737.2188\n",
      "Epoch 188/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 88593.9609 - val_loss: 127536.2344\n",
      "Epoch 189/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 112610.8047 - val_loss: 150314.0625\n",
      "Epoch 190/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 134424.5625 - val_loss: 90681.4141\n",
      "Epoch 191/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 81015.0234 - val_loss: 54423.0078\n",
      "Epoch 192/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 93896.4219 - val_loss: 135704.6719\n",
      "Epoch 193/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 112139.6328 - val_loss: 129956.2891\n",
      "Epoch 194/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 97101.5781 - val_loss: 231155.4688\n",
      "Epoch 195/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 97154.5156 - val_loss: 80251.6250\n",
      "Epoch 196/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 111702.7500 - val_loss: 54110.7422\n",
      "Epoch 197/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 75849.2812 - val_loss: 94262.0156\n",
      "Epoch 198/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 91979.2031 - val_loss: 59204.6680\n",
      "Epoch 199/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 79928.5156 - val_loss: 111451.0391\n",
      "Epoch 200/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 145805.3906 - val_loss: 148032.6406\n",
      "Epoch 201/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 149673.4844 - val_loss: 103262.1875\n",
      "Epoch 202/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 120484.4844 - val_loss: 101163.0859\n",
      "Epoch 203/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 116690.5859 - val_loss: 97049.7266\n",
      "Epoch 204/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 79969.2891 - val_loss: 28615.1562\n",
      "Epoch 205/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 105682.7891 - val_loss: 52599.0703\n",
      "Epoch 206/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 59038.4648 - val_loss: 49594.3086\n",
      "Epoch 207/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 100466.7344 - val_loss: 78824.1562\n",
      "Epoch 208/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 171302.7031 - val_loss: 149875.2031\n",
      "Epoch 209/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 113894.0078 - val_loss: 87788.3984\n",
      "Epoch 210/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 80557.1562 - val_loss: 33282.5430\n",
      "Epoch 211/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 83799.1484 - val_loss: 64928.4414\n",
      "Epoch 212/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 70383.8828 - val_loss: 46908.3555\n",
      "Epoch 213/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 72552.9297 - val_loss: 61635.0820\n",
      "Epoch 214/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 74054.9375 - val_loss: 128688.5078\n",
      "Epoch 215/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 55828.7930 - val_loss: 70323.2266\n",
      "Epoch 216/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 96149.7109 - val_loss: 17335.0547\n",
      "Epoch 217/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 83476.0078 - val_loss: 112877.6016\n",
      "Epoch 218/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 86289.1641 - val_loss: 123202.4688\n",
      "Epoch 219/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 81890.2422 - val_loss: 150080.2344\n",
      "Epoch 220/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 88195.7266 - val_loss: 44779.5586\n",
      "Epoch 221/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 57495.5508 - val_loss: 160736.2188\n",
      "Epoch 222/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 62716.3672 - val_loss: 86338.1484\n",
      "Epoch 223/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 70076.7812 - val_loss: 41170.6641\n",
      "Epoch 224/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 58975.6250 - val_loss: 57663.8047\n",
      "Epoch 225/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 55176.2695 - val_loss: 90859.7734\n",
      "Epoch 226/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 55363.9648 - val_loss: 50901.7031\n",
      "Epoch 227/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 70207.5078 - val_loss: 64206.0430\n",
      "Epoch 228/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 68228.1016 - val_loss: 107046.7734\n",
      "Epoch 229/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 52621.5586 - val_loss: 106689.4297\n",
      "Epoch 230/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 73722.6797 - val_loss: 157728.2188\n",
      "Epoch 231/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 78075.5391 - val_loss: 134229.2656\n",
      "Epoch 232/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 76753.7266 - val_loss: 32387.0371\n",
      "Epoch 233/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 104351.0000 - val_loss: 52948.3984\n",
      "Epoch 234/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 50021.5703 - val_loss: 68215.2422\n",
      "Epoch 235/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 43145.9023 - val_loss: 65089.6289\n",
      "Epoch 236/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 72141.4688 - val_loss: 34121.0625\n",
      "Epoch 237/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 64929.8203 - val_loss: 39823.7266\n",
      "Epoch 238/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 51671.9805 - val_loss: 81098.6094\n",
      "Epoch 239/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 64156.1367 - val_loss: 23600.9141\n",
      "Epoch 240/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 65203.8320 - val_loss: 71875.5547\n",
      "Epoch 241/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 52643.9492 - val_loss: 38579.0156\n",
      "Epoch 242/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 42868.9766 - val_loss: 130072.5938\n",
      "Epoch 243/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 67851.0156 - val_loss: 29797.2559\n",
      "Epoch 244/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 101420.1562 - val_loss: 50651.1523\n",
      "Epoch 245/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 46322.4102 - val_loss: 53515.0586\n",
      "Epoch 246/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 68173.8828 - val_loss: 24628.7109\n",
      "'########################################################Model6\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 9ms/step - loss: 110382456.0000 - val_loss: 64677784.0000\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 50299056.0000 - val_loss: 44865576.0000\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 36142632.0000 - val_loss: 36631728.0000\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 32333626.0000 - val_loss: 29376204.0000\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 24956708.0000 - val_loss: 26224782.0000\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 21743444.0000 - val_loss: 22297716.0000\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 19156128.0000 - val_loss: 18948806.0000\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 17167410.0000 - val_loss: 18726990.0000\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 14513400.0000 - val_loss: 17745968.0000\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 14531119.0000 - val_loss: 14332646.0000\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 12545338.0000 - val_loss: 14949138.0000\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 12771135.0000 - val_loss: 15694167.0000\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 10550771.0000 - val_loss: 13318667.0000\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 9786800.0000 - val_loss: 11427858.0000\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 10121300.0000 - val_loss: 10853734.0000\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 8710206.0000 - val_loss: 10731985.0000\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 8404488.0000 - val_loss: 10448127.0000\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 7639088.0000 - val_loss: 9619194.0000\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 7147084.5000 - val_loss: 9941698.0000\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 6958726.0000 - val_loss: 9715872.0000\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 7197815.0000 - val_loss: 9035047.0000\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 6443382.0000 - val_loss: 7925737.0000\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 6303227.0000 - val_loss: 7588583.5000\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5676716.5000 - val_loss: 7201872.0000\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5467768.5000 - val_loss: 7310938.5000\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5457127.0000 - val_loss: 6747206.0000\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5315070.0000 - val_loss: 6614526.0000\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 5063565.5000 - val_loss: 7197337.5000\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4891608.0000 - val_loss: 5963682.0000\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4806744.5000 - val_loss: 5918204.0000\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4420229.5000 - val_loss: 5786458.5000\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4545423.0000 - val_loss: 5674923.5000\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4147462.7500 - val_loss: 5239474.0000\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4099713.0000 - val_loss: 5313115.0000\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4110540.5000 - val_loss: 4507994.0000\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4090712.2500 - val_loss: 6723991.5000\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3734014.2500 - val_loss: 5998569.5000\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3665716.5000 - val_loss: 4595336.5000\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3281027.0000 - val_loss: 4352772.0000\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3245842.7500 - val_loss: 4019392.0000\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3031505.7500 - val_loss: 4283631.5000\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3034495.7500 - val_loss: 4057379.2500\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3086137.5000 - val_loss: 4308623.0000\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2910133.0000 - val_loss: 4074172.0000\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2746629.2500 - val_loss: 3612930.2500\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2802502.7500 - val_loss: 4230636.0000\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2676923.2500 - val_loss: 3706520.2500\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2552596.7500 - val_loss: 3458363.7500\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2495383.7500 - val_loss: 3247521.2500\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2539079.2500 - val_loss: 3025023.2500\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3071089.2500 - val_loss: 4938249.0000\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2989231.0000 - val_loss: 3080239.5000\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2558338.5000 - val_loss: 2960657.5000\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2261087.5000 - val_loss: 2964942.7500\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2460040.2500 - val_loss: 4511371.0000\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2545390.0000 - val_loss: 2771748.5000\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2076197.6250 - val_loss: 3029855.0000\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2374979.7500 - val_loss: 3102139.7500\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2184322.0000 - val_loss: 2883367.2500\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1923531.5000 - val_loss: 2776944.0000\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1952631.1250 - val_loss: 2378904.7500\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1960440.2500 - val_loss: 2335852.0000\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2263920.0000 - val_loss: 2608412.7500\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1722996.6250 - val_loss: 2442873.5000\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1871088.0000 - val_loss: 2223037.7500\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1755300.2500 - val_loss: 2392689.7500\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2289327.5000 - val_loss: 3191777.0000\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1568643.5000 - val_loss: 2010051.7500\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1625017.3750 - val_loss: 1940994.2500\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1545816.3750 - val_loss: 2785661.2500\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1643586.6250 - val_loss: 3442159.2500\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1690569.8750 - val_loss: 2427524.7500\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1483012.5000 - val_loss: 1865673.2500\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1451260.3750 - val_loss: 1706093.2500\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1264483.7500 - val_loss: 1685538.3750\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1270723.7500 - val_loss: 1622472.6250\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1392064.2500 - val_loss: 1796612.6250\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1653393.8750 - val_loss: 1901541.2500\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1647940.1250 - val_loss: 3666097.7500\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1818698.0000 - val_loss: 1656601.6250\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1193045.0000 - val_loss: 1447461.1250\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1297279.1250 - val_loss: 1799408.7500\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1224272.0000 - val_loss: 1613097.7500\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1467112.8750 - val_loss: 1791761.5000\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1646937.8750 - val_loss: 1667297.1250\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1479716.5000 - val_loss: 1435880.8750\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1102287.0000 - val_loss: 1246988.2500\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1365382.2500 - val_loss: 1525377.8750\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1151569.3750 - val_loss: 1266688.6250\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1251449.3750 - val_loss: 1382018.6250\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1021075.6875 - val_loss: 1793292.8750\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1359820.1250 - val_loss: 1989473.5000\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1226755.8750 - val_loss: 1365682.0000\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1122825.3750 - val_loss: 1921370.5000\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1092560.0000 - val_loss: 1775399.8750\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1025184.3125 - val_loss: 2440742.0000\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1249366.7500 - val_loss: 1203302.7500\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1126327.8750 - val_loss: 1120720.0000\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 920248.6875 - val_loss: 932531.8750\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 902605.1250 - val_loss: 1146389.2500\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 814101.5000 - val_loss: 974897.7500\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 812382.6250 - val_loss: 1063616.5000\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 755775.5625 - val_loss: 1093308.3750\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 773147.5625 - val_loss: 1494681.1250\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 905084.6250 - val_loss: 1126826.8750\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 961604.8750 - val_loss: 952908.5000\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 898965.5625 - val_loss: 924719.8125\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 706675.8750 - val_loss: 1327466.7500\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 706427.1875 - val_loss: 1646327.3750\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 859966.3125 - val_loss: 806624.9375\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 732335.5625 - val_loss: 810770.5000\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 670888.5000 - val_loss: 837926.8125\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 705553.7500 - val_loss: 965831.7500\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 731464.6250 - val_loss: 650418.8125\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 632935.6250 - val_loss: 738365.3750\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 668887.0000 - val_loss: 774423.5625\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 711667.5625 - val_loss: 1073608.3750\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 677932.6875 - val_loss: 842601.0625\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 588195.8125 - val_loss: 631364.3125\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 518334.2812 - val_loss: 661955.9375\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 521440.7812 - val_loss: 882112.0625\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 476178.3750 - val_loss: 682346.2500\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 608471.1875 - val_loss: 693131.7500\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 527191.0625 - val_loss: 1059442.7500\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 536170.3750 - val_loss: 600954.7500\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 542656.4375 - val_loss: 627241.5000\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 414036.2812 - val_loss: 675022.2500\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 435349.5312 - val_loss: 794877.3125\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 429141.2812 - val_loss: 620658.2500\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 395461.5312 - val_loss: 778948.6875\n",
      "Epoch 131/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 478874.2500 - val_loss: 522442.0000\n",
      "Epoch 132/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 345197.9375 - val_loss: 557813.0625\n",
      "Epoch 133/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 374274.4688 - val_loss: 605947.7500\n",
      "Epoch 134/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 367085.4375 - val_loss: 512032.2188\n",
      "Epoch 135/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 362425.5625 - val_loss: 416028.4688\n",
      "Epoch 136/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 399688.3750 - val_loss: 398519.1875\n",
      "Epoch 137/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 329764.0938 - val_loss: 846564.8750\n",
      "Epoch 138/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 361472.1250 - val_loss: 405298.5625\n",
      "Epoch 139/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 384145.1875 - val_loss: 494942.7188\n",
      "Epoch 140/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 333379.0625 - val_loss: 479268.7500\n",
      "Epoch 141/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 310619.6562 - val_loss: 448399.3438\n",
      "Epoch 142/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 343870.3750 - val_loss: 331551.8125\n",
      "Epoch 143/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 306684.5312 - val_loss: 373356.1250\n",
      "Epoch 144/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 369419.8750 - val_loss: 536815.3125\n",
      "Epoch 145/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 287637.6250 - val_loss: 338297.5312\n",
      "Epoch 146/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 368305.9062 - val_loss: 599099.6250\n",
      "Epoch 147/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 361890.5312 - val_loss: 487393.7188\n",
      "Epoch 148/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 311677.8125 - val_loss: 443273.9062\n",
      "Epoch 149/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 271286.0000 - val_loss: 300167.6562\n",
      "Epoch 150/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 278262.7188 - val_loss: 291291.8750\n",
      "Epoch 151/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 256807.3125 - val_loss: 352124.1562\n",
      "Epoch 152/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 330165.6250 - val_loss: 367933.9375\n",
      "Epoch 153/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 254741.6719 - val_loss: 364879.7812\n",
      "Epoch 154/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 247525.2344 - val_loss: 385884.7812\n",
      "Epoch 155/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 310502.3438 - val_loss: 331764.9062\n",
      "Epoch 156/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 229776.0625 - val_loss: 277609.2812\n",
      "Epoch 157/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 221585.6406 - val_loss: 318545.1250\n",
      "Epoch 158/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 239669.1562 - val_loss: 323980.9375\n",
      "Epoch 159/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 227144.2500 - val_loss: 226845.2656\n",
      "Epoch 160/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 253846.6719 - val_loss: 497310.6250\n",
      "Epoch 161/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 268279.2188 - val_loss: 306241.9375\n",
      "Epoch 162/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 208167.8125 - val_loss: 719654.5000\n",
      "Epoch 163/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 289454.2812 - val_loss: 356232.3438\n",
      "Epoch 164/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 259242.9062 - val_loss: 195722.4062\n",
      "Epoch 165/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 199466.1094 - val_loss: 288775.1875\n",
      "Epoch 166/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 215071.5781 - val_loss: 265209.5312\n",
      "Epoch 167/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 268978.5312 - val_loss: 304866.0625\n",
      "Epoch 168/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 203456.6250 - val_loss: 196674.6562\n",
      "Epoch 169/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 222824.1562 - val_loss: 183104.7344\n",
      "Epoch 170/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 180772.5312 - val_loss: 289240.5938\n",
      "Epoch 171/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 181130.1875 - val_loss: 213151.5781\n",
      "Epoch 172/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 187619.3125 - val_loss: 284620.3750\n",
      "Epoch 173/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 222050.2500 - val_loss: 283134.2500\n",
      "Epoch 174/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 258911.6094 - val_loss: 286961.5312\n",
      "Epoch 175/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 190959.5625 - val_loss: 250252.5312\n",
      "Epoch 176/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 233048.1875 - val_loss: 273447.0312\n",
      "Epoch 177/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 215197.0781 - val_loss: 265659.2500\n",
      "Epoch 178/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 199671.7656 - val_loss: 114408.8516\n",
      "Epoch 179/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 212738.6562 - val_loss: 173569.8438\n",
      "Epoch 180/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 236805.5938 - val_loss: 381062.7188\n",
      "Epoch 181/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 231444.3906 - val_loss: 212535.0625\n",
      "Epoch 182/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 203271.2344 - val_loss: 266738.7812\n",
      "Epoch 183/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 212601.3594 - val_loss: 227209.1094\n",
      "Epoch 184/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 177745.1719 - val_loss: 226568.0312\n",
      "Epoch 185/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 155800.7656 - val_loss: 255430.6250\n",
      "Epoch 186/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 187331.2031 - val_loss: 199618.5000\n",
      "Epoch 187/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 172690.7344 - val_loss: 143536.5312\n",
      "Epoch 188/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 158764.4219 - val_loss: 125421.3516\n",
      "Epoch 189/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 137311.4688 - val_loss: 103190.4844\n",
      "Epoch 190/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 147875.7188 - val_loss: 184540.6562\n",
      "Epoch 191/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 153995.4844 - val_loss: 257356.1719\n",
      "Epoch 192/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 183303.0781 - val_loss: 87202.6719\n",
      "Epoch 193/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 159949.5312 - val_loss: 176385.2188\n",
      "Epoch 194/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 159791.2656 - val_loss: 186074.7656\n",
      "Epoch 195/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 147588.4844 - val_loss: 135112.2031\n",
      "Epoch 196/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 165612.7500 - val_loss: 207713.2656\n",
      "Epoch 197/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 132707.7500 - val_loss: 139530.3438\n",
      "Epoch 198/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 138975.5781 - val_loss: 156090.8750\n",
      "Epoch 199/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 181194.9062 - val_loss: 242536.0625\n",
      "Epoch 200/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 193087.7812 - val_loss: 266842.2500\n",
      "Epoch 201/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 158024.2969 - val_loss: 136534.0625\n",
      "Epoch 202/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 117989.2344 - val_loss: 230605.1875\n",
      "Epoch 203/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 174226.5781 - val_loss: 186633.6406\n",
      "Epoch 204/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 171694.5938 - val_loss: 140084.2969\n",
      "Epoch 205/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 158983.5781 - val_loss: 174447.5156\n",
      "Epoch 206/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 109062.2734 - val_loss: 129042.3828\n",
      "Epoch 207/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 117933.4375 - val_loss: 132885.9375\n",
      "Epoch 208/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 134239.5938 - val_loss: 225735.8281\n",
      "Epoch 209/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 138051.2969 - val_loss: 136930.9531\n",
      "Epoch 210/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 105785.9688 - val_loss: 122064.6875\n",
      "Epoch 211/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 118975.6406 - val_loss: 58106.3945\n",
      "Epoch 212/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 117335.4219 - val_loss: 119332.6172\n",
      "Epoch 213/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 172699.5312 - val_loss: 162306.3438\n",
      "Epoch 214/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 140656.5469 - val_loss: 101881.9688\n",
      "Epoch 215/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 97076.4453 - val_loss: 135819.2344\n",
      "Epoch 216/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 135266.6094 - val_loss: 155316.8594\n",
      "Epoch 217/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 187707.5781 - val_loss: 112582.9375\n",
      "Epoch 218/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 133740.8750 - val_loss: 97638.2891\n",
      "Epoch 219/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 110437.2891 - val_loss: 96280.6641\n",
      "Epoch 220/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 111506.8750 - val_loss: 116281.6172\n",
      "Epoch 221/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 99358.8984 - val_loss: 50048.3945\n",
      "Epoch 222/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 122301.3281 - val_loss: 134689.4219\n",
      "Epoch 223/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 111968.7656 - val_loss: 52871.6328\n",
      "Epoch 224/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 126010.5156 - val_loss: 199845.9062\n",
      "Epoch 225/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 152760.9688 - val_loss: 210873.7969\n",
      "Epoch 226/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 147571.3281 - val_loss: 98562.4219\n",
      "Epoch 227/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 123739.4766 - val_loss: 75634.0703\n",
      "Epoch 228/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 71652.1016 - val_loss: 78088.4688\n",
      "Epoch 229/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 98566.2656 - val_loss: 252829.9844\n",
      "Epoch 230/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 126049.3438 - val_loss: 99255.6562\n",
      "Epoch 231/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 88589.6406 - val_loss: 69196.4141\n",
      "Epoch 232/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 119969.3281 - val_loss: 103142.6641\n",
      "Epoch 233/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 114631.2891 - val_loss: 160902.6406\n",
      "Epoch 234/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 80858.4922 - val_loss: 117674.6797\n",
      "Epoch 235/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 89240.3359 - val_loss: 75480.0391\n",
      "Epoch 236/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 119925.7031 - val_loss: 176257.7188\n",
      "Epoch 237/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 82542.2188 - val_loss: 58320.8281\n",
      "Epoch 238/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 123830.9062 - val_loss: 78853.5078\n",
      "Epoch 239/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 105627.6641 - val_loss: 30490.8926\n",
      "Epoch 240/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 126963.1953 - val_loss: 46291.4844\n",
      "Epoch 241/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 85090.1016 - val_loss: 83921.2656\n",
      "Epoch 242/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 103113.4844 - val_loss: 70410.8594\n",
      "Epoch 243/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 80364.5234 - val_loss: 52765.5898\n",
      "Epoch 244/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 102170.9844 - val_loss: 71551.2656\n",
      "Epoch 245/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 84097.6797 - val_loss: 169788.5000\n",
      "Epoch 246/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 75499.8672 - val_loss: 72910.0312\n",
      "Epoch 247/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 79834.3906 - val_loss: 111306.5625\n",
      "Epoch 248/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 118731.8047 - val_loss: 53806.9531\n",
      "Epoch 249/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 101149.1406 - val_loss: 105092.7656\n",
      "Epoch 250/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 82807.1484 - val_loss: 49970.3945\n",
      "Epoch 251/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 127502.0469 - val_loss: 59537.3398\n",
      "Epoch 252/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 77124.7422 - val_loss: 80320.8203\n",
      "Epoch 253/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 63984.5547 - val_loss: 165587.8750\n",
      "Epoch 254/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 86314.0625 - val_loss: 33818.9102\n",
      "Epoch 255/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 57732.0625 - val_loss: 124704.3203\n",
      "Epoch 256/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 81391.5156 - val_loss: 58627.9844\n",
      "Epoch 257/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 60260.7969 - val_loss: 50280.2930\n",
      "Epoch 258/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 74377.1797 - val_loss: 24957.6582\n",
      "Epoch 259/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 104190.8750 - val_loss: 210605.0312\n",
      "Epoch 260/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 154677.5000 - val_loss: 106008.7344\n",
      "Epoch 261/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 94448.8047 - val_loss: 45528.9883\n",
      "Epoch 262/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 108070.3125 - val_loss: 201622.4062\n",
      "Epoch 263/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 126425.3047 - val_loss: 187070.5312\n",
      "Epoch 264/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 93502.4844 - val_loss: 92842.9688\n",
      "Epoch 265/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 115569.7266 - val_loss: 45164.8555\n",
      "Epoch 266/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 101059.7422 - val_loss: 163310.4688\n",
      "Epoch 267/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 74781.9922 - val_loss: 226936.2500\n",
      "Epoch 268/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 103892.3984 - val_loss: 74847.3828\n",
      "Epoch 269/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 121467.3750 - val_loss: 56611.3906\n",
      "Epoch 270/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 69340.1172 - val_loss: 38863.5586\n",
      "Epoch 271/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 65334.4297 - val_loss: 30405.9590\n",
      "Epoch 272/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 50518.8203 - val_loss: 25436.3301\n",
      "Epoch 273/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 64269.3164 - val_loss: 23020.4668\n",
      "Epoch 274/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 73567.7656 - val_loss: 315990.3438\n",
      "Epoch 275/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 124212.5000 - val_loss: 142099.1250\n",
      "Epoch 276/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 111278.1562 - val_loss: 45575.6836\n",
      "Epoch 277/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 106103.9219 - val_loss: 57892.4766\n",
      "Epoch 278/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 119755.4219 - val_loss: 158923.2188\n",
      "Epoch 279/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 107197.4922 - val_loss: 253688.7188\n",
      "Epoch 280/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 115045.7578 - val_loss: 104200.6797\n",
      "Epoch 281/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 89662.3750 - val_loss: 57650.6328\n",
      "Epoch 282/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 95117.7266 - val_loss: 42522.0742\n",
      "Epoch 283/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 68511.4609 - val_loss: 84341.7344\n",
      "Epoch 284/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 95398.7734 - val_loss: 88108.0547\n",
      "Epoch 285/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 60416.6992 - val_loss: 119141.6953\n",
      "Epoch 286/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 104351.2891 - val_loss: 46359.1016\n",
      "Epoch 287/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 48111.3750 - val_loss: 236253.5156\n",
      "Epoch 288/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 74689.9375 - val_loss: 133327.5781\n",
      "Epoch 289/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 46202.8633 - val_loss: 64117.7188\n",
      "Epoch 290/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 92901.3203 - val_loss: 38343.5000\n",
      "Epoch 291/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 73585.5469 - val_loss: 349232.8438\n",
      "Epoch 292/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 121633.6172 - val_loss: 132973.1719\n",
      "Epoch 293/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 50425.6836 - val_loss: 120920.8828\n",
      "Epoch 294/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 49539.7656 - val_loss: 137217.5938\n",
      "Epoch 295/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 74875.9844 - val_loss: 40864.6875\n",
      "Epoch 296/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 92015.4297 - val_loss: 134442.4062\n",
      "Epoch 297/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 80581.1875 - val_loss: 240717.8438\n",
      "Epoch 298/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 78671.1250 - val_loss: 78644.4297\n",
      "Epoch 299/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 58806.9336 - val_loss: 47753.4766\n",
      "Epoch 300/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 65588.8047 - val_loss: 26490.6445\n",
      "'########################################################Model7\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 9ms/step - loss: 106197872.0000 - val_loss: 55771544.0000\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 44201748.0000 - val_loss: 38400920.0000\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 31949416.0000 - val_loss: 32672560.0000\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 25778726.0000 - val_loss: 22921796.0000\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 20873024.0000 - val_loss: 19432796.0000\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 17061428.0000 - val_loss: 18147984.0000\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 15015963.0000 - val_loss: 15452194.0000\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 13735462.0000 - val_loss: 14889310.0000\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 11816782.0000 - val_loss: 15067897.0000\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 10993849.0000 - val_loss: 12111977.0000\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 11278906.0000 - val_loss: 11703402.0000\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 9243055.0000 - val_loss: 12685312.0000\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 8800172.0000 - val_loss: 9955430.0000\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 7980705.0000 - val_loss: 9930977.0000\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 7778112.0000 - val_loss: 9286128.0000\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 7156627.5000 - val_loss: 9019440.0000\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 6440911.5000 - val_loss: 7637031.5000\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5818818.0000 - val_loss: 7181564.5000\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 5791893.5000 - val_loss: 8016605.5000\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 6069276.0000 - val_loss: 6820938.5000\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5375969.5000 - val_loss: 6372068.0000\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 5023100.0000 - val_loss: 6453800.0000\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4463981.5000 - val_loss: 5881756.0000\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 4189498.0000 - val_loss: 5456206.0000\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4166885.7500 - val_loss: 5988465.0000\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4073475.0000 - val_loss: 7023399.5000\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 4042166.5000 - val_loss: 5346299.0000\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3786527.5000 - val_loss: 5466776.0000\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3600528.5000 - val_loss: 4370401.0000\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3149991.7500 - val_loss: 4428691.5000\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3380140.5000 - val_loss: 4441858.0000\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3689342.0000 - val_loss: 6312645.5000\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3264321.5000 - val_loss: 4352192.0000\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3201997.0000 - val_loss: 4498735.5000\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2934231.7500 - val_loss: 5819288.5000\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3025394.0000 - val_loss: 3516528.0000\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2783427.7500 - val_loss: 3441132.0000\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2321529.7500 - val_loss: 3814706.2500\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2362045.0000 - val_loss: 3355332.2500\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2309658.0000 - val_loss: 3381326.0000\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2420599.7500 - val_loss: 2917320.2500\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2375315.0000 - val_loss: 4085724.2500\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2374382.0000 - val_loss: 3325914.2500\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2628481.2500 - val_loss: 4498870.5000\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2622038.0000 - val_loss: 3416289.0000\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2413341.0000 - val_loss: 2747871.7500\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2523672.2500 - val_loss: 2604857.5000\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1944480.3750 - val_loss: 3606593.0000\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1991420.0000 - val_loss: 2420326.5000\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1717439.0000 - val_loss: 2752576.2500\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1619546.1250 - val_loss: 2926906.7500\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1812410.8750 - val_loss: 2658332.0000\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1958018.6250 - val_loss: 3320618.5000\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1981923.0000 - val_loss: 2207247.0000\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1679031.8750 - val_loss: 1911956.1250\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1638847.8750 - val_loss: 3404419.0000\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2268685.5000 - val_loss: 2932582.7500\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1750904.8750 - val_loss: 1794350.6250\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1611224.7500 - val_loss: 2282222.2500\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1655731.5000 - val_loss: 2413854.5000\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1878818.5000 - val_loss: 1991456.5000\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1454140.5000 - val_loss: 1954150.0000\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1463433.7500 - val_loss: 1555790.6250\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1206720.6250 - val_loss: 2745629.5000\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1397940.3750 - val_loss: 2420533.0000\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1427150.0000 - val_loss: 1894580.2500\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1333425.3750 - val_loss: 2007416.2500\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1571572.0000 - val_loss: 1626265.8750\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1322256.6250 - val_loss: 1884157.3750\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1104803.6250 - val_loss: 1674702.7500\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1041715.9375 - val_loss: 1446484.3750\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1049361.3750 - val_loss: 1871488.8750\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1206965.7500 - val_loss: 1991871.1250\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1220369.0000 - val_loss: 1467529.6250\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 939631.2500 - val_loss: 1448476.5000\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 972227.6250 - val_loss: 1333267.6250\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1158241.7500 - val_loss: 1289838.6250\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1195025.0000 - val_loss: 1691845.8750\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 925693.4375 - val_loss: 1110749.5000\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 898725.1250 - val_loss: 1269391.3750\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 992385.4375 - val_loss: 1280219.6250\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 985158.1875 - val_loss: 2132078.7500\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1173607.3750 - val_loss: 1813964.7500\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 905089.0625 - val_loss: 1031074.5625\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 859879.3125 - val_loss: 1440218.6250\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 830642.4375 - val_loss: 1058757.0000\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 905519.1250 - val_loss: 1205143.7500\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 814398.8125 - val_loss: 985854.6875\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 840718.2500 - val_loss: 1022657.6250\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 727010.2500 - val_loss: 987889.6250\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 720916.0625 - val_loss: 1453918.8750\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 803181.4375 - val_loss: 1095438.0000\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 804352.3125 - val_loss: 1022693.5000\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 654034.0625 - val_loss: 807569.0625\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 643867.9375 - val_loss: 1320923.8750\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 699930.3750 - val_loss: 872230.5000\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 768062.3750 - val_loss: 1055259.7500\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 612541.0000 - val_loss: 773622.2500\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 600152.5000 - val_loss: 762823.8750\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 524611.1250 - val_loss: 629092.7500\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 720373.7500 - val_loss: 737326.5000\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 637465.3750 - val_loss: 1371674.5000\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 657732.8750 - val_loss: 662575.3125\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 476308.0000 - val_loss: 776454.6250\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 459109.2812 - val_loss: 760795.4375\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 435905.0000 - val_loss: 526876.8750\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 468195.4375 - val_loss: 677942.6875\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 424874.8125 - val_loss: 659417.5000\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 554861.0000 - val_loss: 560970.9375\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 404333.5938 - val_loss: 558961.7500\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 484703.6562 - val_loss: 531937.1875\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 374865.0312 - val_loss: 565464.5625\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 406218.0938 - val_loss: 410752.7500\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 323938.5312 - val_loss: 452370.5000\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 322613.1250 - val_loss: 441163.9375\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 287549.0000 - val_loss: 324167.5625\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 286026.0625 - val_loss: 517420.2500\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 291035.9375 - val_loss: 531087.4375\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 291541.0625 - val_loss: 375882.1250\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 262105.1094 - val_loss: 290372.3438\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 279935.3125 - val_loss: 277464.0625\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 346008.9062 - val_loss: 346390.0000\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 194655.9375 - val_loss: 331568.0000\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 300410.4375 - val_loss: 252117.5156\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 210722.8906 - val_loss: 337070.5312\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 214081.0625 - val_loss: 452693.0625\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 223749.0938 - val_loss: 212183.1250\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 205098.9688 - val_loss: 202134.6250\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 207797.5000 - val_loss: 337627.0312\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 192920.4844 - val_loss: 289189.0938\n",
      "Epoch 131/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 222372.5469 - val_loss: 330516.9375\n",
      "Epoch 132/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 246202.2969 - val_loss: 249313.1250\n",
      "Epoch 133/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 234641.7969 - val_loss: 359174.0000\n",
      "Epoch 134/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 189640.4531 - val_loss: 217612.9688\n",
      "Epoch 135/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 226191.2812 - val_loss: 238110.5938\n",
      "Epoch 136/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 197996.9844 - val_loss: 337450.1875\n",
      "Epoch 137/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 181020.9688 - val_loss: 231465.2969\n",
      "Epoch 138/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 187629.6406 - val_loss: 224916.5156\n",
      "Epoch 139/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 215728.1875 - val_loss: 364078.4062\n",
      "Epoch 140/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 231311.2188 - val_loss: 374661.9062\n",
      "Epoch 141/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 195629.2500 - val_loss: 282363.3438\n",
      "Epoch 142/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 198974.0781 - val_loss: 288419.2500\n",
      "Epoch 143/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 172896.2031 - val_loss: 187078.9531\n",
      "Epoch 144/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 168367.7031 - val_loss: 148991.0156\n",
      "Epoch 145/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 168991.0781 - val_loss: 363005.0625\n",
      "Epoch 146/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 190432.6719 - val_loss: 172124.5156\n",
      "Epoch 147/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 174060.2344 - val_loss: 203473.0625\n",
      "Epoch 148/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 190098.2969 - val_loss: 163762.5000\n",
      "Epoch 149/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 227494.8281 - val_loss: 383380.0312\n",
      "Epoch 150/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 203710.7344 - val_loss: 255106.0625\n",
      "Epoch 151/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 211836.3594 - val_loss: 294605.9688\n",
      "Epoch 152/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 170594.4219 - val_loss: 291674.9688\n",
      "Epoch 153/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 197338.6250 - val_loss: 164955.1406\n",
      "Epoch 154/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 255218.8281 - val_loss: 206915.6406\n",
      "Epoch 155/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 175228.3125 - val_loss: 155936.7656\n",
      "Epoch 156/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 195685.8594 - val_loss: 223754.3750\n",
      "Epoch 157/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 197077.1562 - val_loss: 174153.2812\n",
      "Epoch 158/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 170320.6562 - val_loss: 259140.7188\n",
      "Epoch 159/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 191560.7656 - val_loss: 170145.8281\n",
      "Epoch 160/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 156194.5469 - val_loss: 219910.5156\n",
      "Epoch 161/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 180115.8125 - val_loss: 194280.6562\n",
      "Epoch 162/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 177747.9531 - val_loss: 209627.6562\n",
      "Epoch 163/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 179503.0156 - val_loss: 191765.6719\n",
      "Epoch 164/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 150859.4531 - val_loss: 199485.9062\n",
      "Epoch 165/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 162341.7500 - val_loss: 177916.5312\n",
      "Epoch 166/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 193970.5156 - val_loss: 176878.0625\n",
      "Epoch 167/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 153635.7031 - val_loss: 128128.0156\n",
      "Epoch 168/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 175918.7656 - val_loss: 187089.1250\n",
      "Epoch 169/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 130591.7891 - val_loss: 119148.1641\n",
      "Epoch 170/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 153628.9219 - val_loss: 152572.7188\n",
      "Epoch 171/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 156007.0469 - val_loss: 117775.0625\n",
      "Epoch 172/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 122371.7266 - val_loss: 146307.7031\n",
      "Epoch 173/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 146880.5625 - val_loss: 190422.2969\n",
      "Epoch 174/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 141295.2812 - val_loss: 125193.2422\n",
      "Epoch 175/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 120523.1016 - val_loss: 137593.7031\n",
      "Epoch 176/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 141344.7500 - val_loss: 106027.5781\n",
      "Epoch 177/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 148524.4844 - val_loss: 116001.3906\n",
      "Epoch 178/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 118128.2734 - val_loss: 117556.6875\n",
      "Epoch 179/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 129689.5078 - val_loss: 161707.4375\n",
      "Epoch 180/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 210530.1406 - val_loss: 328664.3438\n",
      "Epoch 181/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 156430.2344 - val_loss: 158050.5781\n",
      "Epoch 182/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 110135.4375 - val_loss: 80452.6484\n",
      "Epoch 183/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 109072.0938 - val_loss: 119467.6016\n",
      "Epoch 184/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 116241.9062 - val_loss: 172373.8906\n",
      "Epoch 185/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 134940.1875 - val_loss: 130855.7969\n",
      "Epoch 186/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 100984.9688 - val_loss: 142491.9844\n",
      "Epoch 187/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 108998.6016 - val_loss: 209965.7969\n",
      "Epoch 188/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 199074.8125 - val_loss: 217681.4062\n",
      "Epoch 189/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 182495.2500 - val_loss: 257519.2344\n",
      "Epoch 190/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 118949.9531 - val_loss: 99112.1953\n",
      "Epoch 191/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 107245.9531 - val_loss: 59165.5430\n",
      "Epoch 192/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 80380.1250 - val_loss: 339404.3438\n",
      "Epoch 193/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 143408.3281 - val_loss: 155961.9844\n",
      "Epoch 194/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 94736.3281 - val_loss: 54237.1094\n",
      "Epoch 195/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 100503.4219 - val_loss: 102475.4375\n",
      "Epoch 196/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 109538.0312 - val_loss: 144309.5938\n",
      "Epoch 197/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 118503.4766 - val_loss: 90877.5312\n",
      "Epoch 198/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 94495.1250 - val_loss: 106140.1953\n",
      "Epoch 199/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 95467.6250 - val_loss: 105389.4844\n",
      "Epoch 200/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 90750.0547 - val_loss: 86264.5625\n",
      "Epoch 201/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 139741.8594 - val_loss: 65625.1484\n",
      "Epoch 202/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 86434.9844 - val_loss: 98573.5781\n",
      "Epoch 203/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 82156.9062 - val_loss: 59249.9180\n",
      "Epoch 204/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 134889.6562 - val_loss: 102064.6094\n",
      "Epoch 205/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 87610.4531 - val_loss: 92049.8125\n",
      "Epoch 206/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 81501.4219 - val_loss: 79282.9688\n",
      "Epoch 207/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 89280.4297 - val_loss: 73589.3047\n",
      "Epoch 208/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 72268.3203 - val_loss: 91792.8438\n",
      "Epoch 209/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 60872.3750 - val_loss: 71515.7500\n",
      "Epoch 210/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 138806.2031 - val_loss: 282974.2188\n",
      "Epoch 211/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 89945.5391 - val_loss: 76665.8438\n",
      "Epoch 212/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 148437.9531 - val_loss: 153338.0469\n",
      "Epoch 213/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 87649.4453 - val_loss: 128891.2578\n",
      "Epoch 214/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 73538.0469 - val_loss: 124389.0234\n",
      "Epoch 215/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 133711.5625 - val_loss: 226633.2656\n",
      "Epoch 216/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 96379.8828 - val_loss: 87070.1797\n",
      "Epoch 217/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 124384.4844 - val_loss: 216060.2188\n",
      "Epoch 218/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 103839.4062 - val_loss: 66963.7344\n",
      "Epoch 219/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 144660.4219 - val_loss: 331041.5312\n",
      "Epoch 220/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 125597.4141 - val_loss: 155964.7031\n",
      "Epoch 221/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 78736.4531 - val_loss: 33889.0664\n",
      "Epoch 222/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 69706.0625 - val_loss: 50291.0352\n",
      "Epoch 223/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 85967.7266 - val_loss: 108787.7656\n",
      "Epoch 224/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 74841.8047 - val_loss: 54910.3008\n",
      "Epoch 225/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 92829.3906 - val_loss: 109084.7891\n",
      "Epoch 226/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 79491.8359 - val_loss: 71834.7031\n",
      "Epoch 227/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 82923.0234 - val_loss: 153458.2031\n",
      "Epoch 228/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 75654.5078 - val_loss: 53121.6484\n",
      "Epoch 229/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 82029.6641 - val_loss: 384655.8125\n",
      "Epoch 230/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 84854.3906 - val_loss: 71635.2656\n",
      "Epoch 231/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 64338.9336 - val_loss: 39186.7695\n",
      "Epoch 232/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 58891.6055 - val_loss: 66438.6875\n",
      "Epoch 233/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 64317.4727 - val_loss: 152103.5938\n",
      "Epoch 234/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 105084.7578 - val_loss: 56025.0508\n",
      "Epoch 235/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 73796.0547 - val_loss: 159800.7656\n",
      "Epoch 236/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 113716.0469 - val_loss: 145954.1406\n",
      "Epoch 237/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 96738.5078 - val_loss: 156252.6406\n",
      "Epoch 238/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 94181.7734 - val_loss: 70554.0547\n",
      "Epoch 239/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 56714.2852 - val_loss: 59875.2148\n",
      "Epoch 240/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 56450.9023 - val_loss: 106503.4375\n",
      "Epoch 241/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 68187.7422 - val_loss: 80399.6562\n",
      "Epoch 242/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 118504.4688 - val_loss: 192231.7500\n",
      "Epoch 243/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 84699.9297 - val_loss: 34175.1055\n",
      "Epoch 244/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 42480.5664 - val_loss: 24172.5195\n",
      "Epoch 245/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 92598.7812 - val_loss: 74279.7969\n",
      "Epoch 246/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 87284.6484 - val_loss: 209595.4062\n",
      "Epoch 247/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 119817.7031 - val_loss: 73668.3750\n",
      "Epoch 248/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 64056.1445 - val_loss: 64703.3711\n",
      "Epoch 249/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 70524.8359 - val_loss: 31943.8828\n",
      "Epoch 250/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 67414.1250 - val_loss: 82727.2266\n",
      "Epoch 251/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 62764.1797 - val_loss: 34764.3984\n",
      "Epoch 252/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 83741.6797 - val_loss: 108911.2188\n",
      "Epoch 253/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 76953.1562 - val_loss: 77924.8047\n",
      "Epoch 254/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 71014.8750 - val_loss: 142798.4688\n",
      "Epoch 255/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 54903.4570 - val_loss: 37135.2188\n",
      "Epoch 256/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 73924.6328 - val_loss: 30808.2617\n",
      "Epoch 257/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 76844.6641 - val_loss: 53671.1953\n",
      "Epoch 258/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 87545.6406 - val_loss: 316846.0000\n",
      "Epoch 259/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 101272.8594 - val_loss: 32738.1406\n",
      "Epoch 260/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 50633.8633 - val_loss: 54894.6406\n",
      "Epoch 261/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 73242.4609 - val_loss: 104414.6797\n",
      "Epoch 262/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 70196.0234 - val_loss: 64828.9570\n",
      "Epoch 263/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 78728.7656 - val_loss: 59434.5586\n",
      "Epoch 264/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 62278.1875 - val_loss: 170791.3594\n",
      "Epoch 265/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 69812.7891 - val_loss: 31011.9785\n",
      "Epoch 266/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 66962.9766 - val_loss: 51017.8086\n",
      "Epoch 267/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 79218.0156 - val_loss: 66375.3281\n",
      "Epoch 268/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 58044.6875 - val_loss: 77908.3125\n",
      "Epoch 269/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 91021.4219 - val_loss: 73341.0625\n",
      "Epoch 270/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 61992.1992 - val_loss: 113856.4219\n",
      "Epoch 271/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 92450.3594 - val_loss: 166742.0156\n",
      "Epoch 272/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 81093.0703 - val_loss: 86873.1797\n",
      "Epoch 273/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 68829.8984 - val_loss: 112867.6641\n",
      "Epoch 274/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 56379.2930 - val_loss: 81555.4375\n",
      "'########################################################Model8\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 8ms/step - loss: 126578840.0000 - val_loss: 59256656.0000\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 49245156.0000 - val_loss: 40991892.0000\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 35049868.0000 - val_loss: 34156800.0000\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 27422462.0000 - val_loss: 33151664.0000\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 23935350.0000 - val_loss: 25050732.0000\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 20230448.0000 - val_loss: 22574402.0000\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 17236806.0000 - val_loss: 19737910.0000\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 16329072.0000 - val_loss: 17920554.0000\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 14900008.0000 - val_loss: 16063352.0000\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 13457560.0000 - val_loss: 16018319.0000\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 11248255.0000 - val_loss: 13370994.0000\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 10184778.0000 - val_loss: 12038575.0000\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 9268492.0000 - val_loss: 11176293.0000\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 9061131.0000 - val_loss: 12259242.0000\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 8564631.0000 - val_loss: 10549712.0000\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 7265708.0000 - val_loss: 9377973.0000\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 7002374.5000 - val_loss: 10167278.0000\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 7687914.0000 - val_loss: 7817033.5000\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 6877321.5000 - val_loss: 8226547.0000\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 6976974.0000 - val_loss: 7719939.5000\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5971093.0000 - val_loss: 7944041.0000\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5225856.0000 - val_loss: 7123722.0000\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5053413.5000 - val_loss: 8110510.0000\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4991487.5000 - val_loss: 5732316.0000\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4386871.5000 - val_loss: 6242890.0000\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 5107551.0000 - val_loss: 6621954.5000\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 4450742.0000 - val_loss: 5154826.0000\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4243864.0000 - val_loss: 6030955.5000\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3928485.7500 - val_loss: 5267005.5000\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3640656.2500 - val_loss: 6199646.0000\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4057047.7500 - val_loss: 4729046.5000\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3630672.7500 - val_loss: 4728667.0000\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3592247.0000 - val_loss: 6393186.5000\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3587967.0000 - val_loss: 6337941.5000\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3375812.5000 - val_loss: 3836642.7500\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2857991.5000 - val_loss: 4111513.5000\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2615887.7500 - val_loss: 3509369.0000\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2926544.0000 - val_loss: 3309763.2500\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2636421.0000 - val_loss: 3710647.2500\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2578744.2500 - val_loss: 4005904.2500\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2477720.2500 - val_loss: 3826501.7500\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2442423.0000 - val_loss: 3244482.7500\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2359768.7500 - val_loss: 3467818.5000\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2583232.5000 - val_loss: 3930779.2500\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2469168.0000 - val_loss: 3725761.2500\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2327504.7500 - val_loss: 3040733.2500\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2197903.5000 - val_loss: 2601456.7500\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2173434.7500 - val_loss: 2620200.0000\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2289681.0000 - val_loss: 3333021.5000\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2311818.2500 - val_loss: 3099736.7500\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2365581.5000 - val_loss: 2337514.2500\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2092349.6250 - val_loss: 2701367.0000\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1678663.0000 - val_loss: 2316285.7500\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1890141.6250 - val_loss: 2718578.0000\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2411765.7500 - val_loss: 2409736.2500\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1561146.0000 - val_loss: 4212497.0000\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2222173.0000 - val_loss: 2312048.7500\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1512807.1250 - val_loss: 2093780.1250\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1359059.0000 - val_loss: 2109051.2500\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1654110.7500 - val_loss: 2363266.0000\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1341375.3750 - val_loss: 1652713.2500\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1525748.0000 - val_loss: 1771264.8750\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1374627.3750 - val_loss: 2276630.7500\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1314054.1250 - val_loss: 1505539.0000\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1398023.8750 - val_loss: 2042660.8750\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1649428.2500 - val_loss: 1372425.0000\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1235614.2500 - val_loss: 1570989.6250\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1534895.5000 - val_loss: 2961186.5000\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1885797.6250 - val_loss: 2982835.2500\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1463374.6250 - val_loss: 1405424.5000\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1267459.8750 - val_loss: 1252276.2500\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1205518.2500 - val_loss: 1556063.8750\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1215480.2500 - val_loss: 1239754.8750\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1047719.8750 - val_loss: 1777735.7500\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1235764.2500 - val_loss: 1252430.7500\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1012446.8125 - val_loss: 1182196.1250\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1111686.2500 - val_loss: 1408390.2500\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1096488.1250 - val_loss: 1592533.1250\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1258406.5000 - val_loss: 1176637.7500\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 934936.0000 - val_loss: 1536172.7500\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1042263.6875 - val_loss: 1131719.0000\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 889381.5000 - val_loss: 1289812.6250\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1326853.3750 - val_loss: 1423378.7500\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1115907.5000 - val_loss: 1071469.3750\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1014233.8125 - val_loss: 1039239.3750\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 904402.5000 - val_loss: 1134689.3750\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1030142.2500 - val_loss: 866688.0000\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 970532.7500 - val_loss: 1222075.1250\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1022881.7500 - val_loss: 885036.6250\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 854152.8750 - val_loss: 1105162.6250\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 828411.2500 - val_loss: 2080654.3750\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1111499.1250 - val_loss: 1016587.5000\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 984783.5000 - val_loss: 1403586.0000\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 866628.8125 - val_loss: 992118.7500\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 839369.5000 - val_loss: 970060.2500\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 807722.9375 - val_loss: 785103.6250\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 736168.9375 - val_loss: 823394.4375\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 671342.6250 - val_loss: 689926.1875\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 829930.1250 - val_loss: 907319.7500\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 771832.8125 - val_loss: 743065.1875\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 857854.2500 - val_loss: 1148213.1250\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 707767.2500 - val_loss: 863788.5625\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 698572.5000 - val_loss: 758102.8750\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 681365.9375 - val_loss: 976323.5000\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 638350.8750 - val_loss: 735757.3750\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 623267.1875 - val_loss: 1293411.2500\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 805104.2500 - val_loss: 629429.1875\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 591878.3750 - val_loss: 608616.3750\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 696956.0625 - val_loss: 722784.6875\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 655220.8750 - val_loss: 1144284.6250\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 693233.8750 - val_loss: 961207.1875\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 612468.1250 - val_loss: 863645.3750\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 673860.8750 - val_loss: 766281.5625\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 714797.5625 - val_loss: 786806.3125\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 639159.1875 - val_loss: 854455.8750\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 500633.4062 - val_loss: 547039.3125\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 497236.5312 - val_loss: 562448.7500\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 577463.9375 - val_loss: 718570.1250\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 533367.8750 - val_loss: 677080.9375\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 561344.1250 - val_loss: 508639.7812\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 561339.7500 - val_loss: 1271207.0000\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 627044.6875 - val_loss: 480300.1875\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 478215.9688 - val_loss: 708772.3750\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 562933.1875 - val_loss: 564046.0000\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 457757.4375 - val_loss: 574858.1250\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 640728.0000 - val_loss: 479461.0312\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 482020.1562 - val_loss: 582747.6250\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 517812.0000 - val_loss: 580807.8750\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 399720.6875 - val_loss: 479266.2500\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 446513.9375 - val_loss: 1003921.6250\n",
      "Epoch 131/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 431847.4062 - val_loss: 425803.4062\n",
      "Epoch 132/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 432592.5938 - val_loss: 502564.1875\n",
      "Epoch 133/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 394417.5938 - val_loss: 864666.0000\n",
      "Epoch 134/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 472020.9688 - val_loss: 439642.6875\n",
      "Epoch 135/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 340540.7188 - val_loss: 370481.4688\n",
      "Epoch 136/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 335312.4375 - val_loss: 349061.2812\n",
      "Epoch 137/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 313029.2812 - val_loss: 416143.9688\n",
      "Epoch 138/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 306024.6562 - val_loss: 331236.3750\n",
      "Epoch 139/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 325798.5625 - val_loss: 288070.6875\n",
      "Epoch 140/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 350950.1875 - val_loss: 706953.2500\n",
      "Epoch 141/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 370620.9688 - val_loss: 515218.2188\n",
      "Epoch 142/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 286421.5625 - val_loss: 487300.6250\n",
      "Epoch 143/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 283956.2500 - val_loss: 349397.6875\n",
      "Epoch 144/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 234061.0938 - val_loss: 260502.5312\n",
      "Epoch 145/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 266168.3438 - val_loss: 251591.2344\n",
      "Epoch 146/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 253283.1875 - val_loss: 399480.9062\n",
      "Epoch 147/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 214901.8750 - val_loss: 231886.4531\n",
      "Epoch 148/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 208164.2344 - val_loss: 271739.6875\n",
      "Epoch 149/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 230285.1094 - val_loss: 257533.2656\n",
      "Epoch 150/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 206968.3750 - val_loss: 241681.2969\n",
      "Epoch 151/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 190217.6094 - val_loss: 233952.4688\n",
      "Epoch 152/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 299320.1562 - val_loss: 473187.1562\n",
      "Epoch 153/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 246105.7656 - val_loss: 255148.2188\n",
      "Epoch 154/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 230166.8438 - val_loss: 279442.5000\n",
      "Epoch 155/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 207232.4375 - val_loss: 198438.4531\n",
      "Epoch 156/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 177886.4844 - val_loss: 457280.5000\n",
      "Epoch 157/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 228710.4062 - val_loss: 260850.2969\n",
      "Epoch 158/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 178559.0938 - val_loss: 212789.1875\n",
      "Epoch 159/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 174756.5469 - val_loss: 151422.9844\n",
      "Epoch 160/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 202500.1094 - val_loss: 253809.7031\n",
      "Epoch 161/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 169308.8906 - val_loss: 215887.5625\n",
      "Epoch 162/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 168286.7344 - val_loss: 153821.7500\n",
      "Epoch 163/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 186631.0938 - val_loss: 220259.1250\n",
      "Epoch 164/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 164923.7031 - val_loss: 139350.9531\n",
      "Epoch 165/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 163314.7969 - val_loss: 120632.0156\n",
      "Epoch 166/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 228195.1094 - val_loss: 239097.7656\n",
      "Epoch 167/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 154016.2188 - val_loss: 203596.0625\n",
      "Epoch 168/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 172061.5625 - val_loss: 191065.2969\n",
      "Epoch 169/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 153967.6094 - val_loss: 185169.3125\n",
      "Epoch 170/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 136443.1250 - val_loss: 171025.2969\n",
      "Epoch 171/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 147316.7188 - val_loss: 334226.2812\n",
      "Epoch 172/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 239374.7031 - val_loss: 246067.6719\n",
      "Epoch 173/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 192800.4375 - val_loss: 134952.7500\n",
      "Epoch 174/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 124.3694 - val_loss: 130.3165\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 123.6827 - val_loss: 129.8163\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 123.9047 - val_loss: 130.1439\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 124.2816 - val_loss: 129.9870\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 125.3396 - val_loss: 129.2338\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 124.0386 - val_loss: 132.0953\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 123.6743 - val_loss: 130.2907\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 123.2442 - val_loss: 129.0245\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 124.1977 - val_loss: 132.0462\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 123.6007 - val_loss: 129.2512\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 123.7331 - val_loss: 129.8439\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 122.6956 - val_loss: 129.8967\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 123.5360 - val_loss: 131.9881\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 123.8419 - val_loss: 129.7878\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 122.9703 - val_loss: 129.6882\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 122.6600 - val_loss: 130.3216\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 121.9957 - val_loss: 130.5715\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 122.4386 - val_loss: 129.9446\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 121.3154 - val_loss: 128.6600\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 122.9831 - val_loss: 130.9492\n",
      "'########################################################Model4\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 16ms/step - loss: 142.6149 - val_loss: 142.4005\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 137.3998 - val_loss: 139.3500\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 135.5003 - val_loss: 133.1583\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 131.7838 - val_loss: 134.6277\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 131.2123 - val_loss: 136.7526\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 130.2891 - val_loss: 133.0962\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 129.9664 - val_loss: 134.1525\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 129.9727 - val_loss: 134.6712\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 129.1657 - val_loss: 133.3461\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 128.5176 - val_loss: 135.1789\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 129.4029 - val_loss: 134.4724\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 130.4023 - val_loss: 131.9793\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 128.2192 - val_loss: 131.3527\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 127.2108 - val_loss: 132.2331\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.5184 - val_loss: 130.4254\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 126.8120 - val_loss: 131.7800\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 128.0564 - val_loss: 130.6174\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 126.1839 - val_loss: 132.4926\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 127.1848 - val_loss: 132.2868\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 126.3394 - val_loss: 132.3272\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 126.8732 - val_loss: 132.5580\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 127.1977 - val_loss: 130.9702\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 126.7682 - val_loss: 133.0074\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 128.5656 - val_loss: 132.3683\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 127.2374 - val_loss: 134.2133\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 127.1862 - val_loss: 131.2314\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 125.4088 - val_loss: 133.4624\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 126.2769 - val_loss: 131.7291\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 126.2893 - val_loss: 130.3810\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 126.0203 - val_loss: 132.5872\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.0443 - val_loss: 131.7418\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 125.4242 - val_loss: 131.4909\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 124.7894 - val_loss: 130.7452\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 124.0244 - val_loss: 129.6754\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 124.4080 - val_loss: 129.9024\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.3586 - val_loss: 131.2952\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 123.6265 - val_loss: 131.3707\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 123.0967 - val_loss: 130.3176\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 122.9380 - val_loss: 130.1992\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 123.1565 - val_loss: 129.5411\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 122.2063 - val_loss: 129.7152\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 121.8472 - val_loss: 129.3760\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 122.8161 - val_loss: 129.6865\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 122.9783 - val_loss: 133.3103\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 124.5513 - val_loss: 131.8169\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 122.8291 - val_loss: 128.8555\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 122.1780 - val_loss: 129.2953\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.3255 - val_loss: 129.0837\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.1509 - val_loss: 132.2769\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.5799 - val_loss: 130.0590\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.1984 - val_loss: 129.7730\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 121.7519 - val_loss: 129.2999\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.0744 - val_loss: 129.0299\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 121.5023 - val_loss: 129.7425\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.4913 - val_loss: 130.1734\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 121.7150 - val_loss: 129.8243\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 121.7096 - val_loss: 131.2319\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 121.6329 - val_loss: 131.2646\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 120.8281 - val_loss: 128.8380\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 121.1684 - val_loss: 129.2639\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 121.1025 - val_loss: 130.1677\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 120.5480 - val_loss: 129.6355\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 120.5899 - val_loss: 129.0829\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 121.0199 - val_loss: 130.4057\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 120.2130 - val_loss: 128.8452\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 120.8690 - val_loss: 129.3346\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 121.5784 - val_loss: 130.9361\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 119.8260 - val_loss: 128.9172\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 120.2703 - val_loss: 129.2589\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 121.1435 - val_loss: 129.4845\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 120.7057 - val_loss: 129.5147\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 120.0542 - val_loss: 130.8632\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 119.1650 - val_loss: 129.5463\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 119.7215 - val_loss: 129.1863\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 120.1820 - val_loss: 128.8119\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 120.3804 - val_loss: 131.1313\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 119.6070 - val_loss: 128.5949\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 118.7189 - val_loss: 129.6084\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 118.8397 - val_loss: 129.9407\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 118.5526 - val_loss: 129.8554\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 118.6919 - val_loss: 128.5212\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 118.2623 - val_loss: 129.5184\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 118.3699 - val_loss: 129.0491\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 118.1020 - val_loss: 129.8920\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 118.5976 - val_loss: 130.1913\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 117.8375 - val_loss: 129.0155\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 118.3186 - val_loss: 130.2851\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 119.9279 - val_loss: 130.1655\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 118.3710 - val_loss: 129.9026\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 119.2891 - val_loss: 129.7154\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 118.3968 - val_loss: 129.2017\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 118.2069 - val_loss: 129.9459\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 117.0642 - val_loss: 129.5633\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 117.3430 - val_loss: 130.4150\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 118.5590 - val_loss: 129.8587\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 117.6394 - val_loss: 129.5046\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 117.6327 - val_loss: 128.8688\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 116.9318 - val_loss: 129.1884\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 116.5703 - val_loss: 130.2980\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 117.2989 - val_loss: 130.0760\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 117.3196 - val_loss: 129.3149\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 116.4299 - val_loss: 130.0349\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 117.0300 - val_loss: 129.6559\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 116.8450 - val_loss: 129.5222\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 117.3604 - val_loss: 130.6190\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 117.2627 - val_loss: 130.3383\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 116.6263 - val_loss: 129.9567\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 116.1234 - val_loss: 129.8171\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 116.6112 - val_loss: 129.7278\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 115.9716 - val_loss: 129.8218\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 116.1694 - val_loss: 128.2493\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 115.6655 - val_loss: 129.2365\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 115.7808 - val_loss: 128.7588\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 115.9294 - val_loss: 129.1893\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 115.4901 - val_loss: 130.0400\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 116.6942 - val_loss: 128.8535\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 116.3212 - val_loss: 128.5695\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 116.2692 - val_loss: 129.7032\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 114.9684 - val_loss: 127.9953\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 115.8026 - val_loss: 129.5092\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 116.6556 - val_loss: 129.5637\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 115.6465 - val_loss: 128.0447\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 114.5872 - val_loss: 128.8348\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 114.6895 - val_loss: 129.5231\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 115.2658 - val_loss: 128.4673\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 114.4857 - val_loss: 129.3106\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 114.4998 - val_loss: 130.6068\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 114.2707 - val_loss: 129.5171\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 114.1226 - val_loss: 129.2256\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 114.1348 - val_loss: 127.6462\n",
      "Epoch 131/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 114.5361 - val_loss: 128.8335\n",
      "Epoch 132/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 114.0525 - val_loss: 130.4436\n",
      "Epoch 133/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 114.4643 - val_loss: 130.2296\n",
      "Epoch 134/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 114.1909 - val_loss: 129.2469\n",
      "Epoch 135/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 113.3721 - val_loss: 128.7797\n",
      "Epoch 136/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 113.8135 - val_loss: 130.4612\n",
      "Epoch 137/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 113.0890 - val_loss: 129.4136\n",
      "Epoch 138/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 113.2249 - val_loss: 128.9731\n",
      "Epoch 139/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 114.3960 - val_loss: 130.0851\n",
      "Epoch 140/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 112.9972 - val_loss: 128.8397\n",
      "Epoch 141/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 113.7502 - val_loss: 128.8169\n",
      "Epoch 142/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 112.7230 - val_loss: 128.8098\n",
      "Epoch 143/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 113.2884 - val_loss: 128.6255\n",
      "Epoch 144/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 113.1567 - val_loss: 127.8938\n",
      "Epoch 145/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 112.7866 - val_loss: 129.4188\n",
      "Epoch 146/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 113.9080 - val_loss: 128.9058\n",
      "Epoch 147/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 113.3020 - val_loss: 128.8121\n",
      "Epoch 148/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 112.4052 - val_loss: 130.1501\n",
      "Epoch 149/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 113.6824 - val_loss: 129.9993\n",
      "Epoch 150/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 112.9920 - val_loss: 129.1475\n",
      "Epoch 151/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 112.1595 - val_loss: 129.0274\n",
      "Epoch 152/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 111.7076 - val_loss: 129.1354\n",
      "Epoch 153/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 111.5188 - val_loss: 128.6509\n",
      "Epoch 154/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 111.4264 - val_loss: 128.1342\n",
      "Epoch 155/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 111.7348 - val_loss: 129.6859\n",
      "Epoch 156/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 111.4167 - val_loss: 128.5244\n",
      "Epoch 157/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 110.8389 - val_loss: 128.3808\n",
      "Epoch 158/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 110.3269 - val_loss: 129.3866\n",
      "Epoch 159/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 111.2085 - val_loss: 129.5012\n",
      "Epoch 160/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 111.8277 - val_loss: 130.5563\n",
      "'########################################################Model5\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 9ms/step - loss: 144.4517 - val_loss: 139.8335\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 139.8313 - val_loss: 138.3845\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 135.5464 - val_loss: 135.9679\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 132.6745 - val_loss: 135.7020\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 132.9989 - val_loss: 138.2881\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 131.8517 - val_loss: 135.2878\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 130.8536 - val_loss: 134.7231\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 129.3174 - val_loss: 134.9396\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 134.3835 - val_loss: 136.4205\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 132.1935 - val_loss: 134.7643\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 129.7268 - val_loss: 134.0017\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 128.7272 - val_loss: 131.9894\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 127.2283 - val_loss: 132.6581\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 129.5362 - val_loss: 133.4893\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 127.7101 - val_loss: 133.1648\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 128.1200 - val_loss: 132.6291\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 128.6207 - val_loss: 134.2821\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 127.8984 - val_loss: 133.3003\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 126.6812 - val_loss: 131.9256\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 126.7369 - val_loss: 130.5933\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 126.1745 - val_loss: 131.9275\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 125.6048 - val_loss: 131.3158\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 126.3583 - val_loss: 138.8954\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 128.0254 - val_loss: 134.0582\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 128.2806 - val_loss: 132.0519\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 125.4575 - val_loss: 131.1446\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 125.7904 - val_loss: 132.8274\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 125.7268 - val_loss: 131.7443\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 125.5388 - val_loss: 130.3917\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 127.0794 - val_loss: 130.0779\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 124.8750 - val_loss: 131.2574\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 126.2792 - val_loss: 133.7966\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 125.7556 - val_loss: 130.9348\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 124.7430 - val_loss: 130.4488\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 124.7284 - val_loss: 131.3349\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 123.9527 - val_loss: 130.6436\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 123.4238 - val_loss: 130.1725\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 124.1218 - val_loss: 130.6026\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 124.4853 - val_loss: 130.8126\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 123.9672 - val_loss: 130.5082\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 123.1681 - val_loss: 128.5308\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 124.2617 - val_loss: 130.5000\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 123.4864 - val_loss: 128.6368\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 122.9677 - val_loss: 129.6332\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 123.7113 - val_loss: 129.7517\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 122.5555 - val_loss: 128.0497\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 123.6906 - val_loss: 131.3685\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 122.9110 - val_loss: 130.5825\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 122.8445 - val_loss: 130.8054\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 122.6994 - val_loss: 130.1721\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 123.7914 - val_loss: 129.2897\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 122.3460 - val_loss: 129.8200\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 123.4578 - val_loss: 130.0583\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 122.5072 - val_loss: 128.8071\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 122.0416 - val_loss: 129.9730\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 122.1606 - val_loss: 128.7077\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 125.0838 - val_loss: 129.5999\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 123.0643 - val_loss: 130.3726\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 122.8505 - val_loss: 128.7039\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 122.3352 - val_loss: 128.6362\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 122.1969 - val_loss: 128.9693\n",
      "Epoch 62/300\n"
     ]
    }
   ],
   "source": [
    "model_num = 10\n",
    "\n",
    "mase_models = train_bagging_models(model_num, MASE(y_train,24),300,30,8,0.0005)\n",
    "mape_models = train_bagging_models(model_num,'mape',300,30,8,0.0005)\n",
    "smape_models = train_bagging_models(model_num, SMAPE(),300,30,8,0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c961ec8-129c-4f36-a2dc-04b0b9661a19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 895us/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 996us/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 930us/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 1s 999us/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.20655650336177, 0.23496238368031028)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred1,_=smape_models\n",
    "pred2,_=mase_models\n",
    "pred3,_=mape_models\n",
    "\n",
    "smape_predictions = bagging_predict2(pred1, test_X)\n",
    "mase_predictions = bagging_predict2(pred2, test_X)\n",
    "mape_predictions = bagging_predict2(pred3, test_X)\n",
    "concat_I = np.concatenate([smape_predictions, mase_predictions,mape_predictions],axis=0)\n",
    "fin_pred_I = np.median(concat_I,axis=0)\n",
    "#pd.DataFrame(fin_pred).to_csv(\"freezing_I.csv\")\n",
    "mean_squared_error(test_y.flatten()[2:],fin_pred_I.flatten()[2:]),mean_absolute_error(test_y.flatten()[2:],fin_pred_I.flatten()[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02005ee4-9b13-4a5a-a2c3-d25441395630",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(fin_pred_I.reshape(-1,24)).to_csv(\"../result5_new/NBEATs/pred_mid_I.csv\")\n",
    "for i in range(10):\n",
    "    pd.DataFrame(concat_I[i].reshape(-1,24)).to_csv(f\"../result5_new/NBEATs/pred_I{i}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a104b3-22fb-46e4-855e-ca5e5202a204",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 일반블락"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df7fa618-a25e-48c5-9544-ca3e091f28ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-29 20:16:22.650797: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-08-29 20:16:22.650856: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ymlee2-desktop): /proc/driver/nvidia/version does not exist\n",
      "2024-08-29 20:16:22.651515: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 9ms/step - loss: 1.0613 - val_loss: 0.6945\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.8264 - val_loss: 0.6947\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.8063 - val_loss: 0.6654\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7840 - val_loss: 0.6437\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7684 - val_loss: 0.6501\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7558 - val_loss: 0.6951\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7366 - val_loss: 0.6478\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7258 - val_loss: 0.6413\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7129 - val_loss: 0.6463\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7156 - val_loss: 0.6462\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6713\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6857 - val_loss: 0.6359\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6792 - val_loss: 0.6511\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6521 - val_loss: 0.6450\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6401 - val_loss: 0.6471\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6250 - val_loss: 0.6865\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6293 - val_loss: 0.6656\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6047 - val_loss: 0.6666\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5918 - val_loss: 0.6956\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5817 - val_loss: 0.6611\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5708 - val_loss: 0.6716\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5414 - val_loss: 0.6758\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5153 - val_loss: 0.6864\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5131 - val_loss: 0.6931\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5181 - val_loss: 0.7069\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4961 - val_loss: 0.6742\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4945 - val_loss: 0.6591\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.4498 - val_loss: 0.6843\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4370 - val_loss: 0.7550\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4495 - val_loss: 0.6936\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.4282 - val_loss: 0.6924\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.4228 - val_loss: 0.7120\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.4387 - val_loss: 0.6622\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.3919 - val_loss: 0.7200\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.3885 - val_loss: 0.7059\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.3686 - val_loss: 0.6869\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.3803 - val_loss: 0.7445\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.3657 - val_loss: 0.6831\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.3584 - val_loss: 0.7104\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.3395 - val_loss: 0.6828\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.3505 - val_loss: 0.7047\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.3370 - val_loss: 0.7087\n",
      "'########################################################Model0\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 9ms/step - loss: 1.1061 - val_loss: 0.7631\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.8508 - val_loss: 0.7086\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.8003 - val_loss: 0.6856\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7861 - val_loss: 0.6568\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7679 - val_loss: 0.6517\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7557 - val_loss: 0.6394\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7432 - val_loss: 0.6409\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7214 - val_loss: 0.6425\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7152 - val_loss: 0.6603\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.7240 - val_loss: 0.6422\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6965 - val_loss: 0.6596\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6967 - val_loss: 0.6480\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6753 - val_loss: 0.6598\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6781 - val_loss: 0.6555\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6691 - val_loss: 0.6356\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6561 - val_loss: 0.6441\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6354 - val_loss: 0.6588\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6250 - val_loss: 0.6507\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6172 - val_loss: 0.6827\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6012 - val_loss: 0.6884\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5810 - val_loss: 0.6854\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5592 - val_loss: 0.6525\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5420 - val_loss: 0.6717\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5381 - val_loss: 0.6646\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.5225 - val_loss: 0.7036\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5194 - val_loss: 0.6821\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.5175 - val_loss: 0.6551\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4913 - val_loss: 0.6604\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4753 - val_loss: 0.7074\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.4494 - val_loss: 0.6749\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.4465 - val_loss: 0.6764\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.4335 - val_loss: 0.7165\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4433 - val_loss: 0.6619\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4337 - val_loss: 0.6637\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4370 - val_loss: 0.6811\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4144 - val_loss: 0.7002\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.3863 - val_loss: 0.6916\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.3798 - val_loss: 0.6722\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.3828 - val_loss: 0.7221\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.3651 - val_loss: 0.6888\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.3615 - val_loss: 0.6949\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.3547 - val_loss: 0.6982\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.3349 - val_loss: 0.7012\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.3275 - val_loss: 0.6847\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.3377 - val_loss: 0.6882\n",
      "'########################################################Model1\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 10ms/step - loss: 1.1090 - val_loss: 0.7321\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.8513 - val_loss: 0.6999\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.8101 - val_loss: 0.6860\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7834 - val_loss: 0.6725\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7732 - val_loss: 0.6575\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7734 - val_loss: 0.6689\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7463 - val_loss: 0.6593\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7421 - val_loss: 0.6545\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7355 - val_loss: 0.6522\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7237 - val_loss: 0.6491\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7021 - val_loss: 0.6430\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7044 - val_loss: 0.6647\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6891 - val_loss: 0.6631\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6903 - val_loss: 0.6459\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6704 - val_loss: 0.6410\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6522 - val_loss: 0.6597\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6538 - val_loss: 0.6695\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6296 - val_loss: 0.6613\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6107 - val_loss: 0.6710\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6151 - val_loss: 0.6735\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5826 - val_loss: 0.6569\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5751 - val_loss: 0.6643\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.5486 - val_loss: 0.6934\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.5547 - val_loss: 0.6538\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.5295 - val_loss: 0.6677\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5122 - val_loss: 0.6767\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.5060 - val_loss: 0.6719\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.4856 - val_loss: 0.6719\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.4781 - val_loss: 0.6663\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4449 - val_loss: 0.6899\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4450 - val_loss: 0.6644\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4402 - val_loss: 0.6597\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4132 - val_loss: 0.6982\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.3930 - val_loss: 0.7032\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4143 - val_loss: 0.6881\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.3936 - val_loss: 0.6815\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4024 - val_loss: 0.6958\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.3817 - val_loss: 0.6874\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.3691 - val_loss: 0.6806\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.3511 - val_loss: 0.6632\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.3635 - val_loss: 0.7411\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4058 - val_loss: 0.6728\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3645 - val_loss: 0.7438\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.3379 - val_loss: 0.6890\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.3266 - val_loss: 0.7196\n",
      "'########################################################Model2\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 10ms/step - loss: 1.0738 - val_loss: 0.7251\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.8501 - val_loss: 0.6906\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.8160 - val_loss: 0.7292\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7844 - val_loss: 0.6806\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7744 - val_loss: 0.6633\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7555 - val_loss: 0.6587\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7391 - val_loss: 0.6548\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7255 - val_loss: 0.6602\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7209 - val_loss: 0.6549\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6996 - val_loss: 0.6541\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6992 - val_loss: 0.6549\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6972 - val_loss: 0.6477\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6937 - val_loss: 0.6448\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6838 - val_loss: 0.6637\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6675 - val_loss: 0.7441\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6639 - val_loss: 0.6593\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6383 - val_loss: 0.6595\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6204 - val_loss: 0.6963\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6171 - val_loss: 0.6897\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.5931 - val_loss: 0.7521\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5807 - val_loss: 0.6865\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5529 - val_loss: 0.6811\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5377 - val_loss: 0.6831\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5390 - val_loss: 0.7239\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5333 - val_loss: 0.7106\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5151 - val_loss: 0.7150\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5089 - val_loss: 0.7265\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5013 - val_loss: 0.7043\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4779 - val_loss: 0.7085\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4767 - val_loss: 0.6700\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4642 - val_loss: 0.7282\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4488 - val_loss: 0.7687\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4484 - val_loss: 0.7560\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4303 - val_loss: 0.7369\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4180 - val_loss: 0.7017\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.4190 - val_loss: 0.7115\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.4519 - val_loss: 0.6901\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4017 - val_loss: 0.7356\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3924 - val_loss: 0.7401\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.3945 - val_loss: 0.7393\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.3687 - val_loss: 0.7438\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.3561 - val_loss: 0.7382\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.3457 - val_loss: 0.7276\n",
      "'########################################################Model3\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 7ms/step - loss: 1.0001 - val_loss: 0.7096\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.8332 - val_loss: 0.6963\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7881 - val_loss: 0.6622\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7744 - val_loss: 0.6432\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7551 - val_loss: 0.6489\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7509 - val_loss: 0.6326\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7303 - val_loss: 0.6552\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7269 - val_loss: 0.6575\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7168 - val_loss: 0.6346\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6933 - val_loss: 0.6331\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6946 - val_loss: 0.6401\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6849 - val_loss: 0.6534\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6709 - val_loss: 0.6605\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6566 - val_loss: 0.6604\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6456 - val_loss: 0.6832\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6374 - val_loss: 0.6745\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6350 - val_loss: 0.6475\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6014 - val_loss: 0.6565\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5855 - val_loss: 0.6516\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.5596 - val_loss: 0.6631\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.5741 - val_loss: 0.6824\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.5483 - val_loss: 0.6616\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5307 - val_loss: 0.6526\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5244 - val_loss: 0.6688\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5284 - val_loss: 0.6973\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4965 - val_loss: 0.6664\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4773 - val_loss: 0.7147\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4783 - val_loss: 0.6893\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4601 - val_loss: 0.7218\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4380 - val_loss: 0.7193\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4170 - val_loss: 0.7092\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4293 - val_loss: 0.6750\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4496 - val_loss: 0.7020\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4121 - val_loss: 0.6619\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4016 - val_loss: 0.6928\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.3840 - val_loss: 0.6750\n",
      "'########################################################Model4\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 10ms/step - loss: 1.0624 - val_loss: 0.7325\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.8424 - val_loss: 0.6720\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.8092 - val_loss: 0.7020\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7769 - val_loss: 0.6561\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.7701 - val_loss: 0.6829\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.7526 - val_loss: 0.6685\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7442 - val_loss: 0.6444\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7434 - val_loss: 0.6329\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7210 - val_loss: 0.6732\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7147 - val_loss: 0.6549\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7035 - val_loss: 0.6486\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6902 - val_loss: 0.6742\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6949 - val_loss: 0.6520\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6732 - val_loss: 0.6432\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6475 - val_loss: 0.7021\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6521 - val_loss: 0.6550\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6296 - val_loss: 0.6864\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6139 - val_loss: 0.6631\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6287 - val_loss: 0.6750\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5867 - val_loss: 0.6836\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.5833 - val_loss: 0.6701\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5622 - val_loss: 0.7114\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5529 - val_loss: 0.6602\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.5313 - val_loss: 0.6725\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.5312 - val_loss: 0.6758\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5259 - val_loss: 0.6847\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.4850 - val_loss: 0.6706\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4896 - val_loss: 0.6877\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4892 - val_loss: 0.6902\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4472 - val_loss: 0.6981\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4378 - val_loss: 0.7069\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4503 - val_loss: 0.6730\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4250 - val_loss: 0.7069\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4256 - val_loss: 0.6952\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4042 - val_loss: 0.6826\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4020 - val_loss: 0.6984\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.3803 - val_loss: 0.6816\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.3665 - val_loss: 0.6645\n",
      "'########################################################Model5\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 10ms/step - loss: 1.0155 - val_loss: 0.6859\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.8387 - val_loss: 0.6859\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7954 - val_loss: 0.6440\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7727 - val_loss: 0.6796\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7605 - val_loss: 0.6575\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7505 - val_loss: 0.6391\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7408 - val_loss: 0.6368\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7174 - val_loss: 0.6342\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.7192 - val_loss: 0.6642\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.7084 - val_loss: 0.6647\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7054 - val_loss: 0.6381\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6857 - val_loss: 0.6660\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6745 - val_loss: 0.6620\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6730 - val_loss: 0.6632\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6596 - val_loss: 0.6573\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6353 - val_loss: 0.6627\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6190 - val_loss: 0.6478\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6093 - val_loss: 0.6490\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5943 - val_loss: 0.6609\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5913 - val_loss: 0.6731\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5740 - val_loss: 0.6701\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5538 - val_loss: 0.7022\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.5446 - val_loss: 0.6802\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5267 - val_loss: 0.7036\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5391 - val_loss: 0.7010\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4938 - val_loss: 0.6795\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4876 - val_loss: 0.6866\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.4765 - val_loss: 0.6773\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4724 - val_loss: 0.6844\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4593 - val_loss: 0.6705\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4345 - val_loss: 0.7104\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4420 - val_loss: 0.7054\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4238 - val_loss: 0.7024\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4184 - val_loss: 0.7318\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.3936 - val_loss: 0.6973\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4140 - val_loss: 0.6926\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.3815 - val_loss: 0.6938\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4005 - val_loss: 0.7273\n",
      "'########################################################Model6\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 10ms/step - loss: 1.0655 - val_loss: 0.7268\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.8526 - val_loss: 0.6720\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.8045 - val_loss: 0.6828\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7909 - val_loss: 0.6749\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7841 - val_loss: 0.6534\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7620 - val_loss: 0.6602\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7521 - val_loss: 0.6451\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.7326 - val_loss: 0.6505\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.7328 - val_loss: 0.6538\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7196 - val_loss: 0.6589\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7078 - val_loss: 0.6682\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7043 - val_loss: 0.6600\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6973 - val_loss: 0.6423\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6784 - val_loss: 0.6516\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6685 - val_loss: 0.6544\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6536 - val_loss: 0.6433\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6407 - val_loss: 0.6832\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6467 - val_loss: 0.6760\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6258 - val_loss: 0.6698\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5998 - val_loss: 0.6751\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5962 - val_loss: 0.6660\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5644 - val_loss: 0.6751\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5572 - val_loss: 0.6504\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.5540 - val_loss: 0.6925\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.5563 - val_loss: 0.6783\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5240 - val_loss: 0.7453\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5314 - val_loss: 0.6676\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4987 - val_loss: 0.7071\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4894 - val_loss: 0.6869\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4754 - val_loss: 0.6724\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4577 - val_loss: 0.7160\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4441 - val_loss: 0.7266\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4799 - val_loss: 0.7043\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.4242 - val_loss: 0.6797\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.4255 - val_loss: 0.7124\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4445 - val_loss: 0.6913\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4172 - val_loss: 0.6652\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.4070 - val_loss: 0.6931\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3916 - val_loss: 0.7408\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.3935 - val_loss: 0.7005\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.3794 - val_loss: 0.7012\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.3667 - val_loss: 0.6815\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.3623 - val_loss: 0.6704\n",
      "'########################################################Model7\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 9ms/step - loss: 1.0627 - val_loss: 0.7388\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.8334 - val_loss: 0.6793\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7924 - val_loss: 0.6613\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7712 - val_loss: 0.6766\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7566 - val_loss: 0.6589\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7427 - val_loss: 0.6681\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7312 - val_loss: 0.6462\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7166 - val_loss: 0.6470\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7106 - val_loss: 0.6624\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6949 - val_loss: 0.6666\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6913 - val_loss: 0.6451\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6653 - val_loss: 0.6597\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6562 - val_loss: 0.6385\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6460 - val_loss: 0.6553\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6268 - val_loss: 0.6502\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6331 - val_loss: 0.6822\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5930 - val_loss: 0.6829\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5887 - val_loss: 0.6888\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5809 - val_loss: 0.6537\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5641 - val_loss: 0.7578\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5423 - val_loss: 0.6917\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5381 - val_loss: 0.7012\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5302 - val_loss: 0.6829\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4934 - val_loss: 0.7021\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5096 - val_loss: 0.6556\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4836 - val_loss: 0.6632\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4660 - val_loss: 0.7032\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4444 - val_loss: 0.6862\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4565 - val_loss: 0.6753\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4351 - val_loss: 0.6979\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4221 - val_loss: 0.6989\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4155 - val_loss: 0.6740\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4072 - val_loss: 0.6812\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.3868 - val_loss: 0.6985\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4025 - val_loss: 0.6707\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.4048 - val_loss: 0.7036\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.3763 - val_loss: 0.7218\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.3838 - val_loss: 0.6956\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.3570 - val_loss: 0.6954\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.3631 - val_loss: 0.6817\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.3481 - val_loss: 0.7022\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.3299 - val_loss: 0.7021\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.3505 - val_loss: 0.6786\n",
      "'########################################################Model8\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 9ms/step - loss: 1.1438 - val_loss: 0.7477\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.8379 - val_loss: 0.6910\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.8099 - val_loss: 0.6644\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7707 - val_loss: 0.6800\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7565 - val_loss: 0.6566\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7446 - val_loss: 0.6724\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7398 - val_loss: 0.6559\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7303 - val_loss: 0.6332\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7222 - val_loss: 0.6478\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7031 - val_loss: 0.6529\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7041 - val_loss: 0.6470\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6868 - val_loss: 0.7181\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6880 - val_loss: 0.6561\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6689 - val_loss: 0.6407\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6598 - val_loss: 0.6598\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6433 - val_loss: 0.6497\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6324 - val_loss: 0.6558\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6185 - val_loss: 0.6837\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6238 - val_loss: 0.6529\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5881 - val_loss: 0.6504\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.5680 - val_loss: 0.6591\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5761 - val_loss: 0.6842\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5518 - val_loss: 0.7300\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.5400 - val_loss: 0.6700\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5247 - val_loss: 0.6891\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.5138 - val_loss: 0.7309\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5037 - val_loss: 0.7199\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4825 - val_loss: 0.7303\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4918 - val_loss: 0.6943\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4872 - val_loss: 0.7083\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4388 - val_loss: 0.7053\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4353 - val_loss: 0.7459\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4208 - val_loss: 0.7182\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4059 - val_loss: 0.7151\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4065 - val_loss: 0.6958\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3899 - val_loss: 0.6901\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.4257 - val_loss: 0.8098\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.3935 - val_loss: 0.7148\n",
      "'########################################################Model9\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 3s 9ms/step - loss: 44256892.0000 - val_loss: 25815244.0000\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 21819496.0000 - val_loss: 16554298.0000\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 16662087.0000 - val_loss: 13583153.0000\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 12469480.0000 - val_loss: 13966792.0000\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 10252083.0000 - val_loss: 12329167.0000\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 8981991.0000 - val_loss: 8349609.5000\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 7289518.0000 - val_loss: 9128163.0000\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 6423364.0000 - val_loss: 6306059.0000\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 5917881.0000 - val_loss: 6263913.0000\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 5095719.0000 - val_loss: 5859416.0000\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 4449879.5000 - val_loss: 5139093.0000\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 4173010.0000 - val_loss: 5150011.0000\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3661520.0000 - val_loss: 4150203.2500\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3598558.7500 - val_loss: 4839694.0000\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3467981.7500 - val_loss: 3730667.7500\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3113442.7500 - val_loss: 3699425.2500\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2695601.2500 - val_loss: 3350289.7500\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2600185.2500 - val_loss: 3122220.2500\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2358620.2500 - val_loss: 2882126.0000\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2293687.5000 - val_loss: 2589673.5000\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2028719.0000 - val_loss: 2978511.5000\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2124337.5000 - val_loss: 2393989.0000\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2109708.7500 - val_loss: 2652665.0000\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1835646.7500 - val_loss: 2495821.5000\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1717035.2500 - val_loss: 2117830.5000\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1536346.2500 - val_loss: 1936712.3750\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1682475.2500 - val_loss: 2322493.5000\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1426223.8750 - val_loss: 1644646.1250\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1272914.0000 - val_loss: 1982383.8750\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1379275.5000 - val_loss: 1612425.3750\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1233073.2500 - val_loss: 1513655.6250\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1196115.6250 - val_loss: 1570117.3750\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1143311.1250 - val_loss: 1491150.3750\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1063945.2500 - val_loss: 1660137.1250\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1121989.3750 - val_loss: 1494454.3750\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 936841.8750 - val_loss: 1495811.1250\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1021288.1875 - val_loss: 1397620.6250\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 974033.2500 - val_loss: 1346960.6250\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 855124.2500 - val_loss: 1347118.5000\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 883228.0625 - val_loss: 1223820.7500\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 894006.5625 - val_loss: 1470398.2500\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 827839.2500 - val_loss: 1266090.5000\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 810460.4375 - val_loss: 1112418.3750\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 769808.8125 - val_loss: 1124229.3750\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 719464.5000 - val_loss: 1099114.6250\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 664975.7500 - val_loss: 1089924.2500\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 701219.1250 - val_loss: 1029817.8125\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 694344.1875 - val_loss: 922143.3750\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 724867.4375 - val_loss: 1065045.6250\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 634629.3125 - val_loss: 900209.7500\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 605777.5000 - val_loss: 980923.0625\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 572568.0000 - val_loss: 843433.6250\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 509566.4375 - val_loss: 913996.8125\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 617011.8750 - val_loss: 779013.1875\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 602414.4375 - val_loss: 783096.6875\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 518284.6250 - val_loss: 836936.9375\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 484440.5312 - val_loss: 750201.6250\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 526020.1875 - val_loss: 885278.3750\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 504520.9062 - val_loss: 857536.8125\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 442525.6250 - val_loss: 807594.3750\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 496686.1250 - val_loss: 597753.6250\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 499724.5625 - val_loss: 1041420.5000\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 497262.9062 - val_loss: 849405.0000\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 437052.4375 - val_loss: 910438.0625\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 407327.6250 - val_loss: 806702.4375\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 497855.0625 - val_loss: 616267.4375\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 469642.2500 - val_loss: 674160.6875\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 387560.8125 - val_loss: 633824.6250\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 459463.8438 - val_loss: 704149.1875\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 406747.4375 - val_loss: 651617.6250\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 427753.5938 - val_loss: 743817.6250\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 357656.4062 - val_loss: 657344.8750\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 412362.8438 - val_loss: 595091.5000\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 374917.9688 - val_loss: 557605.1250\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 412877.0938 - val_loss: 618803.9375\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 396149.6250 - val_loss: 581924.6875\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 351205.3438 - val_loss: 591048.8125\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 345216.3438 - val_loss: 620359.3125\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 318847.5625 - val_loss: 636807.3125\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 410425.7188 - val_loss: 640113.1250\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 374072.8750 - val_loss: 756546.8750\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 347248.7812 - val_loss: 680070.4375\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 312954.9375 - val_loss: 619599.1875\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 306148.0938 - val_loss: 462990.7812\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 317447.2188 - val_loss: 507013.1875\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 364169.8125 - val_loss: 822369.0625\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 355666.7500 - val_loss: 540477.8750\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 356113.5312 - val_loss: 621091.4375\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 345299.7812 - val_loss: 625346.7500\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 322938.7812 - val_loss: 420664.4688\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 313913.3438 - val_loss: 507086.7812\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 371467.9688 - val_loss: 599101.8750\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 380169.9375 - val_loss: 512406.0000\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 360255.1562 - val_loss: 747869.6875\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 393605.6875 - val_loss: 752587.0625\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 436349.8125 - val_loss: 810075.2500\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 348482.7812 - val_loss: 531327.0625\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 340808.1875 - val_loss: 665696.1875\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 366465.5000 - val_loss: 523225.4375\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 288733.6875 - val_loss: 444757.0625\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 348798.6875 - val_loss: 579938.0625\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 324878.0938 - val_loss: 638724.3125\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 313532.9688 - val_loss: 537232.0625\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 342960.6250 - val_loss: 689341.8750\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 332558.5000 - val_loss: 579885.5000\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 350121.0625 - val_loss: 567321.6250\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 343584.1875 - val_loss: 583362.5000\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 316246.0312 - val_loss: 538405.6875\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 369081.3125 - val_loss: 647112.6250\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 353794.7812 - val_loss: 489409.1562\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 373727.2188 - val_loss: 710158.3750\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 298356.2500 - val_loss: 487777.5312\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 311661.7500 - val_loss: 551884.6875\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 305319.2188 - val_loss: 603923.5000\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 355708.6875 - val_loss: 451356.8125\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 334596.3438 - val_loss: 700465.2500\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 358328.2500 - val_loss: 535263.6250\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 341698.2500 - val_loss: 541192.3750\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 328369.5625 - val_loss: 598074.5625\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 275597.3750 - val_loss: 632100.3125\n",
      "'########################################################Model0\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 9ms/step - loss: 49250040.0000 - val_loss: 26714810.0000\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 22822240.0000 - val_loss: 18247916.0000\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 15300578.0000 - val_loss: 13390776.0000\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 12205703.0000 - val_loss: 14645181.0000\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 10173223.0000 - val_loss: 10752047.0000\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 8546714.0000 - val_loss: 9533239.0000\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 7422770.0000 - val_loss: 9023246.0000\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 7127949.0000 - val_loss: 6442726.0000\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 5765928.5000 - val_loss: 6892681.5000\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 5526940.5000 - val_loss: 6220659.5000\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 4838697.0000 - val_loss: 4553149.5000\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 4426981.5000 - val_loss: 4614399.5000\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3876377.7500 - val_loss: 3730835.7500\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3698157.5000 - val_loss: 3891831.5000\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3548611.0000 - val_loss: 3656200.5000\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3070856.7500 - val_loss: 3853895.5000\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2866746.7500 - val_loss: 3470702.7500\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2495110.7500 - val_loss: 2979393.2500\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2582203.7500 - val_loss: 3537917.5000\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2353997.2500 - val_loss: 2620981.2500\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2303091.7500 - val_loss: 3064547.0000\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2183266.0000 - val_loss: 2497614.5000\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2033610.6250 - val_loss: 2492294.2500\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1933836.3750 - val_loss: 2319645.5000\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1826180.3750 - val_loss: 2548971.0000\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1841612.0000 - val_loss: 2100226.7500\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1523823.1250 - val_loss: 2138636.0000\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1475900.5000 - val_loss: 1821588.6250\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1522320.3750 - val_loss: 1800879.1250\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1295620.3750 - val_loss: 1825245.2500\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1365340.5000 - val_loss: 1833442.6250\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1248845.6250 - val_loss: 1557751.0000\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1273397.1250 - val_loss: 1702556.5000\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1096642.2500 - val_loss: 1434709.0000\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1093680.7500 - val_loss: 1454292.2500\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1006817.4375 - val_loss: 1367464.7500\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 941331.5000 - val_loss: 1413397.3750\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 865230.4375 - val_loss: 1647246.3750\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 909475.1250 - val_loss: 1575000.6250\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 892296.0000 - val_loss: 1257737.8750\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 951450.0000 - val_loss: 1206625.1250\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 935178.5000 - val_loss: 1380421.7500\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 816786.0000 - val_loss: 1067391.2500\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 812495.2500 - val_loss: 1174794.2500\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 727164.8750 - val_loss: 1177959.0000\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 723010.2500 - val_loss: 1023198.6875\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 660219.1250 - val_loss: 920795.0000\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 713749.6875 - val_loss: 1277105.1250\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 715899.3125 - val_loss: 1011991.3750\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 651698.1875 - val_loss: 1038867.0000\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 621174.0625 - val_loss: 1098410.0000\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 624585.8750 - val_loss: 803431.3750\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 658433.1875 - val_loss: 973380.4375\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 578048.7500 - val_loss: 1041815.1875\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 590057.6875 - val_loss: 920733.1875\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 559737.1875 - val_loss: 785299.5625\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 499243.2500 - val_loss: 919206.5000\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 538896.0000 - val_loss: 838655.7500\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 592578.1875 - val_loss: 890463.4375\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 550264.1250 - val_loss: 839190.8125\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 531507.5000 - val_loss: 986539.8125\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 437431.0938 - val_loss: 776295.7500\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 522661.6562 - val_loss: 765003.4375\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 495755.1250 - val_loss: 804664.8750\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 479244.9062 - val_loss: 798102.6250\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 457302.3750 - val_loss: 688590.1250\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 423204.2500 - val_loss: 574943.7500\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 469129.6250 - val_loss: 764283.5000\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 450612.4062 - val_loss: 919160.2500\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 450677.5625 - val_loss: 650059.1250\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 372760.5312 - val_loss: 707816.7500\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 377887.1250 - val_loss: 614381.8750\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 394294.9062 - val_loss: 694636.0000\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 427691.6250 - val_loss: 639452.9375\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 392717.0938 - val_loss: 632514.1875\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 415654.6875 - val_loss: 608515.8750\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 416636.3125 - val_loss: 887991.0625\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 396650.1250 - val_loss: 587025.5000\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 420316.5312 - val_loss: 657911.3750\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 350440.4062 - val_loss: 552072.6875\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 359471.4688 - val_loss: 462869.0625\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 349739.2188 - val_loss: 572738.9375\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 350757.8438 - val_loss: 766764.5000\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 310578.9375 - val_loss: 661683.6250\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 335540.4062 - val_loss: 590554.1250\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 352463.6250 - val_loss: 590131.5000\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 423333.2500 - val_loss: 617154.0000\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 367050.3125 - val_loss: 564021.0000\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 323053.9062 - val_loss: 576007.2500\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 338042.7500 - val_loss: 642399.8750\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 311321.8438 - val_loss: 659132.6875\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 364437.3438 - val_loss: 525501.8750\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 310087.3750 - val_loss: 515458.9375\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 395285.7500 - val_loss: 656423.7500\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 309527.5312 - val_loss: 570268.0000\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 360469.1875 - val_loss: 543775.1875\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 338921.5000 - val_loss: 502203.4688\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 295148.3125 - val_loss: 567544.8750\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 351654.4688 - val_loss: 666056.8750\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 349412.7500 - val_loss: 438321.5000\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 330058.7812 - val_loss: 447518.7188\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 354977.6250 - val_loss: 740182.3125\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 409931.7500 - val_loss: 658860.5000\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 384940.9688 - val_loss: 660480.0000\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 353489.5312 - val_loss: 758701.6875\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 410292.1875 - val_loss: 686937.3125\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 348151.7500 - val_loss: 527418.8750\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 315360.5000 - val_loss: 656883.0000\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 347364.3125 - val_loss: 532242.1250\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 317508.9062 - val_loss: 765917.9375\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 423513.4062 - val_loss: 667634.6875\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 373481.3750 - val_loss: 655172.3125\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 382048.2812 - val_loss: 490161.3125\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 352444.1875 - val_loss: 634399.2500\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 323110.7812 - val_loss: 535993.5625\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 374818.6562 - val_loss: 692931.6875\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 346052.3750 - val_loss: 566208.4375\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 421449.1875 - val_loss: 597323.7500\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 395238.4375 - val_loss: 602283.1250\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 369337.9062 - val_loss: 535508.3750\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 366974.8438 - val_loss: 698570.8750\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 342089.0938 - val_loss: 527345.5000\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 381255.8750 - val_loss: 537580.8125\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 334938.4062 - val_loss: 708785.8750\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 358311.1562 - val_loss: 721950.1875\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 392440.5938 - val_loss: 551662.2500\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 345252.8438 - val_loss: 535160.2500\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 294206.1875 - val_loss: 489392.0000\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 329256.2812 - val_loss: 484306.1562\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 397104.8438 - val_loss: 642565.1250\n",
      "'########################################################Model1\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 9ms/step - loss: 48371760.0000 - val_loss: 29303180.0000\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 21681314.0000 - val_loss: 18400774.0000\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 16156977.0000 - val_loss: 13858368.0000\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 13417392.0000 - val_loss: 14728262.0000\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 11574158.0000 - val_loss: 12009887.0000\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 9832675.0000 - val_loss: 9822366.0000\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 8614521.0000 - val_loss: 7710907.0000\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 7139328.5000 - val_loss: 8685180.0000\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 6482256.5000 - val_loss: 5896112.0000\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 5330883.0000 - val_loss: 6342947.5000\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 5005581.5000 - val_loss: 5494333.0000\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 4605206.0000 - val_loss: 5485955.5000\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 4080716.2500 - val_loss: 4174514.7500\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 4007926.2500 - val_loss: 3905473.2500\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3284832.0000 - val_loss: 3837820.5000\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3246062.7500 - val_loss: 3379145.7500\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2908376.2500 - val_loss: 3332496.0000\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2783025.2500 - val_loss: 3637055.0000\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2698122.7500 - val_loss: 3283495.5000\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2808831.2500 - val_loss: 3072586.2500\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2411360.7500 - val_loss: 3087154.2500\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2139410.0000 - val_loss: 2668880.0000\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2065581.1250 - val_loss: 2610674.0000\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2053670.2500 - val_loss: 2255105.2500\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1827085.6250 - val_loss: 2698732.7500\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1769985.1250 - val_loss: 2177343.5000\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1665462.8750 - val_loss: 2358995.5000\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1618788.2500 - val_loss: 1892832.6250\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1547370.1250 - val_loss: 1856310.7500\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1516119.3750 - val_loss: 2256834.7500\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1411462.8750 - val_loss: 1779910.2500\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1255776.6250 - val_loss: 1703760.1250\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1271428.8750 - val_loss: 1879802.2500\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1214513.2500 - val_loss: 1665171.2500\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1161399.5000 - val_loss: 1530950.6250\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1010570.6250 - val_loss: 1309327.5000\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1073744.0000 - val_loss: 1181863.7500\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 959566.7500 - val_loss: 1237642.5000\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 935026.9375 - val_loss: 1304159.0000\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 922444.8750 - val_loss: 1582965.7500\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 904758.4375 - val_loss: 1109022.5000\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 850311.5000 - val_loss: 1176413.2500\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 830602.5000 - val_loss: 1006238.3750\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 764975.8750 - val_loss: 924158.3750\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 719544.3125 - val_loss: 1393937.5000\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 765790.8125 - val_loss: 1003800.3750\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 679767.0625 - val_loss: 1123974.2500\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 681949.6875 - val_loss: 955949.0000\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 743695.3750 - val_loss: 1180489.1250\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 600942.8125 - val_loss: 865655.8750\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 694064.6875 - val_loss: 1007556.8750\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 583976.1250 - val_loss: 777541.0000\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 632050.4375 - val_loss: 973821.0000\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 622542.3750 - val_loss: 756195.5000\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 555591.4375 - val_loss: 776525.1875\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 542371.5000 - val_loss: 787953.0000\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 541295.5625 - val_loss: 731738.3125\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 506421.0312 - val_loss: 1086264.3750\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 492423.3125 - val_loss: 888154.9375\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 494093.2812 - val_loss: 891641.6250\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 550225.8750 - val_loss: 796003.8750\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 448030.6875 - val_loss: 732222.0625\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 491888.1250 - val_loss: 803903.0625\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 429343.9062 - val_loss: 844665.8125\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 429661.5000 - val_loss: 723131.9375\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 424395.9375 - val_loss: 656086.5000\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 435394.1250 - val_loss: 809589.0625\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 421623.4375 - val_loss: 790198.3750\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 445521.4375 - val_loss: 780973.3750\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 503049.0938 - val_loss: 770155.6875\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 481758.9062 - val_loss: 778275.5625\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 381136.5312 - val_loss: 644767.7500\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 418409.1250 - val_loss: 643675.0625\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 365520.0938 - val_loss: 564547.4375\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 400763.0000 - val_loss: 565552.2500\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 323950.1875 - val_loss: 484555.3125\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 346456.3438 - val_loss: 614264.5625\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 372491.9688 - val_loss: 527929.7500\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 358101.2188 - val_loss: 518245.9062\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 405909.8750 - val_loss: 556148.9375\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 414714.8125 - val_loss: 646014.5625\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 415001.5312 - val_loss: 641531.1250\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 351624.9688 - val_loss: 570425.0625\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 377342.2812 - val_loss: 696410.4375\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 379761.6250 - val_loss: 657011.6875\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 388292.5625 - val_loss: 576807.6250\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 358121.9375 - val_loss: 467489.0000\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 336369.4688 - val_loss: 479256.9375\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 348676.8438 - val_loss: 619037.9375\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 385110.9688 - val_loss: 629644.8125\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 368535.2500 - val_loss: 550087.8750\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 348738.8750 - val_loss: 640089.8750\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 355290.5312 - val_loss: 468720.8125\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 388152.8438 - val_loss: 572513.3125\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 368165.2812 - val_loss: 583390.5000\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 346349.6250 - val_loss: 575352.7500\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 364724.2500 - val_loss: 573586.1250\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 405709.4688 - val_loss: 707192.0000\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 389458.4688 - val_loss: 618935.3750\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 344106.1562 - val_loss: 667375.6875\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 352396.3125 - val_loss: 555906.6875\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 346098.0000 - val_loss: 573673.1250\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 388520.3750 - val_loss: 721389.0625\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 349331.8125 - val_loss: 504995.1875\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 304379.0000 - val_loss: 503411.0938\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 334141.4375 - val_loss: 527348.5000\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 381204.1875 - val_loss: 601389.9375\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 381197.2188 - val_loss: 722150.9375\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 390426.1562 - val_loss: 629208.1250\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 376819.5312 - val_loss: 767415.5000\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 448331.6562 - val_loss: 715304.2500\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 450793.1562 - val_loss: 570076.2500\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 339212.0000 - val_loss: 695088.4375\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 358913.3438 - val_loss: 555044.7500\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 313649.0938 - val_loss: 516797.4062\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 368929.4062 - val_loss: 480421.1250\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 347667.7188 - val_loss: 666510.3125\n",
      "'########################################################Model2\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 9ms/step - loss: 45418760.0000 - val_loss: 23265724.0000\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 21990372.0000 - val_loss: 17370518.0000\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 15704443.0000 - val_loss: 12481446.0000\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 12604555.0000 - val_loss: 14155509.0000\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 10446241.0000 - val_loss: 9402277.0000\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 9650927.0000 - val_loss: 9907839.0000\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 7989192.0000 - val_loss: 7296918.5000\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 6894173.5000 - val_loss: 7673517.0000\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 6423302.0000 - val_loss: 6175375.5000\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 6528092.0000 - val_loss: 5193195.0000\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 4890061.5000 - val_loss: 6378993.5000\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 4521254.0000 - val_loss: 4730762.5000\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 4685234.0000 - val_loss: 4485316.5000\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3533167.0000 - val_loss: 3884546.7500\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3037448.7500 - val_loss: 4046813.2500\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3139519.5000 - val_loss: 4023108.5000\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2929958.5000 - val_loss: 3250148.7500\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2630738.2500 - val_loss: 3181995.5000\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2721648.0000 - val_loss: 3073300.2500\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2524995.5000 - val_loss: 3366392.5000\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2326406.7500 - val_loss: 2874146.2500\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2082936.5000 - val_loss: 2728365.5000\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2014798.6250 - val_loss: 2186573.0000\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2182742.2500 - val_loss: 2662368.2500\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1934522.0000 - val_loss: 2437802.5000\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1709166.0000 - val_loss: 2251863.0000\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1697306.2500 - val_loss: 2228737.0000\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1544048.1250 - val_loss: 2092521.2500\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1486133.8750 - val_loss: 2122793.5000\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1503429.0000 - val_loss: 1912872.6250\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1327041.6250 - val_loss: 1576008.3750\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1198058.1250 - val_loss: 2211399.5000\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1372340.3750 - val_loss: 1746729.8750\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1222874.8750 - val_loss: 1378795.1250\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1022886.3125 - val_loss: 1352972.3750\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1011958.8125 - val_loss: 1622237.7500\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1080187.8750 - val_loss: 1399947.1250\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 886038.6875 - val_loss: 1166096.7500\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 943667.3750 - val_loss: 1153142.7500\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 851707.2500 - val_loss: 1271033.5000\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 909447.1875 - val_loss: 1247021.6250\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 951970.5625 - val_loss: 1190661.0000\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 792400.0000 - val_loss: 1236968.7500\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 744930.7500 - val_loss: 1056572.7500\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 727058.9375 - val_loss: 1362884.7500\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 777910.8125 - val_loss: 922752.8125\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 602224.6250 - val_loss: 1181281.0000\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 652308.1250 - val_loss: 1140636.6250\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 614886.7500 - val_loss: 931611.8125\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 608175.5000 - val_loss: 1053736.5000\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 623068.8125 - val_loss: 807290.6875\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 575617.5000 - val_loss: 975811.5000\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 557688.3125 - val_loss: 741919.8125\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 524732.1875 - val_loss: 870888.2500\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 615248.7500 - val_loss: 871695.8750\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 554789.3750 - val_loss: 860416.8750\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 525923.6250 - val_loss: 876518.7500\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 538663.1875 - val_loss: 813294.0625\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 521288.9688 - val_loss: 765054.8750\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 500161.2188 - val_loss: 977210.8125\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 522699.6875 - val_loss: 644378.2500\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 460231.5312 - val_loss: 737780.5000\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 460149.9062 - val_loss: 856443.1875\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 451757.5625 - val_loss: 675662.6250\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 477103.9375 - val_loss: 652504.5000\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 445142.0938 - val_loss: 509410.4375\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 390093.8125 - val_loss: 754582.5000\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 400640.9375 - val_loss: 860568.1250\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 430327.5938 - val_loss: 688144.3750\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 423212.1562 - val_loss: 546978.5625\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 347122.5000 - val_loss: 685490.0625\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 462732.4688 - val_loss: 634761.6875\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 428288.2188 - val_loss: 522640.1562\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 387228.0312 - val_loss: 727074.6875\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 393900.1875 - val_loss: 729966.1875\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 418235.6562 - val_loss: 618795.3750\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 371808.8438 - val_loss: 685023.1250\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 391995.0312 - val_loss: 544736.9375\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 333095.3750 - val_loss: 637626.9375\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 349135.9375 - val_loss: 664637.4375\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 329578.0000 - val_loss: 557114.0000\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 365753.3750 - val_loss: 761777.1875\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 404176.9062 - val_loss: 695751.3750\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 337448.1250 - val_loss: 590358.1250\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 393309.1875 - val_loss: 487933.1875\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 323478.0000 - val_loss: 635804.5000\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 418793.5000 - val_loss: 552039.1875\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 336544.5312 - val_loss: 602665.1875\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 377148.4688 - val_loss: 651792.0000\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 397619.4375 - val_loss: 659244.5000\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 387970.4688 - val_loss: 574584.6875\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 334059.9688 - val_loss: 578287.1875\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 290898.1875 - val_loss: 513287.9375\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 337585.8125 - val_loss: 539301.1875\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 339962.5000 - val_loss: 720324.5625\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 334747.8438 - val_loss: 699687.1875\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 383772.6562 - val_loss: 638009.9375\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 355157.7812 - val_loss: 551690.5000\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 387293.0625 - val_loss: 655911.5000\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 309178.0938 - val_loss: 584018.3125\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 338794.8750 - val_loss: 610806.5625\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 362294.0938 - val_loss: 601651.7500\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 385093.9688 - val_loss: 509795.1562\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 374588.1562 - val_loss: 825359.8750\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 395717.9375 - val_loss: 942537.0625\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 430929.1875 - val_loss: 729910.1875\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 379044.4062 - val_loss: 599292.6875\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 385614.1875 - val_loss: 753343.8125\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 417401.0938 - val_loss: 576525.6250\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 389299.6875 - val_loss: 617779.9375\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 363905.8125 - val_loss: 605732.4375\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 378526.5625 - val_loss: 513271.4375\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 418659.3750 - val_loss: 715066.8750\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 352678.8438 - val_loss: 564069.8750\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 335811.4375 - val_loss: 874658.9375\n",
      "'########################################################Model3\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 7ms/step - loss: 42104684.0000 - val_loss: 25586144.0000\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 22326170.0000 - val_loss: 19893432.0000\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 15754013.0000 - val_loss: 13511757.0000\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 12113012.0000 - val_loss: 11952971.0000\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 9796992.0000 - val_loss: 9905931.0000\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 8547883.0000 - val_loss: 10567448.0000\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 7637489.0000 - val_loss: 8055798.5000\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 7005396.0000 - val_loss: 8230130.0000\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 6256341.0000 - val_loss: 5932842.5000\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 5637608.0000 - val_loss: 6774303.0000\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 5076480.5000 - val_loss: 5346451.0000\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 4353781.5000 - val_loss: 5542420.5000\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3989958.5000 - val_loss: 4635312.0000\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3826743.7500 - val_loss: 4535934.0000\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3636195.0000 - val_loss: 3791971.2500\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3359393.7500 - val_loss: 3791359.5000\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3122008.5000 - val_loss: 3417603.2500\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2779519.0000 - val_loss: 3326168.0000\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2733207.7500 - val_loss: 3160664.0000\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2404199.7500 - val_loss: 2694644.7500\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2221871.7500 - val_loss: 2694610.2500\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2184282.0000 - val_loss: 2409168.0000\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2094674.1250 - val_loss: 2607474.0000\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1845356.1250 - val_loss: 2343807.2500\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1806632.1250 - val_loss: 2579198.2500\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1890923.3750 - val_loss: 2175320.2500\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1728095.7500 - val_loss: 1843008.0000\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1623759.3750 - val_loss: 2071993.8750\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1495415.8750 - val_loss: 1867207.5000\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1370259.2500 - val_loss: 2019304.1250\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1339542.5000 - val_loss: 2102861.5000\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1385040.7500 - val_loss: 1568147.5000\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1224997.7500 - val_loss: 1690112.0000\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1200000.3750 - val_loss: 1383493.2500\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1035356.4375 - val_loss: 1719150.6250\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1072696.2500 - val_loss: 1420467.5000\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 964359.8750 - val_loss: 1532929.1250\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 907227.0000 - val_loss: 1502873.8750\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 941491.6875 - val_loss: 1226232.3750\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 860790.2500 - val_loss: 1448095.0000\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 945392.7500 - val_loss: 1275985.2500\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 844966.1875 - val_loss: 1052133.6250\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 818972.3125 - val_loss: 988893.8750\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 851767.3125 - val_loss: 1114666.0000\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 706283.8750 - val_loss: 850135.3125\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 637689.4375 - val_loss: 1087967.2500\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 689941.5625 - val_loss: 829280.8750\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 618297.1875 - val_loss: 1203354.0000\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 614468.1250 - val_loss: 927343.8750\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 630948.0000 - val_loss: 921748.9375\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 573800.5000 - val_loss: 1123135.2500\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 672701.0625 - val_loss: 851647.8750\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 512743.5312 - val_loss: 723816.8125\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 499652.9375 - val_loss: 738943.8750\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 475937.7188 - val_loss: 897491.0000\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 495422.9375 - val_loss: 870634.6875\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 543250.5000 - val_loss: 1014991.2500\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 487736.6250 - val_loss: 648587.1250\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 472254.1875 - val_loss: 581582.5000\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 415017.1562 - val_loss: 831034.3125\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 463985.8438 - val_loss: 736618.8750\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 470617.5625 - val_loss: 673227.8125\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 435906.9062 - val_loss: 622677.3750\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 393795.9688 - val_loss: 748742.8125\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 436057.5625 - val_loss: 845025.6250\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 464801.8125 - val_loss: 805354.1250\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 432374.4688 - val_loss: 823277.6875\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 387358.2500 - val_loss: 683407.9375\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 355918.8750 - val_loss: 621022.8750\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 386396.0000 - val_loss: 599656.6875\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 381372.2500 - val_loss: 830938.3125\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 413895.9688 - val_loss: 719642.6875\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 333186.4688 - val_loss: 520411.6875\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 382710.7188 - val_loss: 721585.1875\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 367450.6875 - val_loss: 721010.5625\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 367491.4062 - val_loss: 736650.5625\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 369346.0625 - val_loss: 685012.6250\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 350147.3750 - val_loss: 673709.0625\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 310696.7188 - val_loss: 713107.0625\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 331065.0938 - val_loss: 485970.3125\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 353099.8750 - val_loss: 517061.7500\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 318499.7500 - val_loss: 581901.5000\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 388440.6875 - val_loss: 536732.0000\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 334700.5938 - val_loss: 613975.8750\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 337667.5625 - val_loss: 745226.8125\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 362728.3750 - val_loss: 501289.5938\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 354040.5000 - val_loss: 567252.5000\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 357625.5000 - val_loss: 613763.1250\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 407920.5000 - val_loss: 578024.8125\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 351574.7500 - val_loss: 501242.0312\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 318809.6875 - val_loss: 546716.3125\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 388428.4375 - val_loss: 636657.5625\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 350959.5938 - val_loss: 615688.1250\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 383187.7812 - val_loss: 488652.8125\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 344243.2500 - val_loss: 640191.6875\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 379903.5312 - val_loss: 732762.3125\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 345639.9062 - val_loss: 659652.3750\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 366046.9062 - val_loss: 485471.6250\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 414596.5312 - val_loss: 661855.9375\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 336315.9375 - val_loss: 645441.6250\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 295883.8125 - val_loss: 452941.0625\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 316650.2500 - val_loss: 599800.4375\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 435176.5000 - val_loss: 512239.4062\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 367138.0625 - val_loss: 494045.1875\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 336646.0312 - val_loss: 614503.6875\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 338980.8125 - val_loss: 651994.9375\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 373212.0938 - val_loss: 559690.2500\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 369232.9062 - val_loss: 719340.0000\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 403629.5625 - val_loss: 515038.8438\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 355067.1250 - val_loss: 671617.0000\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 390613.7188 - val_loss: 496445.3438\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 431146.4375 - val_loss: 623516.8750\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 403791.1250 - val_loss: 852844.9375\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 345614.4375 - val_loss: 740610.2500\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 371437.4688 - val_loss: 650646.2500\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 386574.6562 - val_loss: 610116.5625\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 317383.5625 - val_loss: 615324.1250\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 394131.1875 - val_loss: 609040.1250\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 348098.7812 - val_loss: 414486.9688\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 376707.2500 - val_loss: 566232.8750\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 393278.7812 - val_loss: 572267.8125\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 349656.0312 - val_loss: 636370.9375\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 328422.1875 - val_loss: 541034.1875\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 371851.3438 - val_loss: 849803.8125\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 396313.7812 - val_loss: 654026.3125\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 367397.0312 - val_loss: 649026.7500\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 329958.4375 - val_loss: 520425.5312\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 364275.2812 - val_loss: 566378.5000\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 394370.0625 - val_loss: 619430.8125\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 402406.7188 - val_loss: 594680.3125\n",
      "Epoch 131/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 414600.9375 - val_loss: 738689.4375\n",
      "Epoch 132/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 410031.2188 - val_loss: 542238.4375\n",
      "Epoch 133/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 368249.7812 - val_loss: 402320.7188\n",
      "Epoch 134/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 373212.6875 - val_loss: 554566.1250\n",
      "Epoch 135/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 341398.7812 - val_loss: 470095.5000\n",
      "Epoch 136/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 396122.2188 - val_loss: 669403.4375\n",
      "Epoch 137/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 399714.0938 - val_loss: 624154.0625\n",
      "Epoch 138/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 349781.4062 - val_loss: 543112.2500\n",
      "Epoch 139/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 349684.2188 - val_loss: 658660.1875\n",
      "Epoch 140/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 334033.5625 - val_loss: 522349.0312\n",
      "Epoch 141/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 365848.7812 - val_loss: 726966.3750\n",
      "Epoch 142/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 336239.8750 - val_loss: 537971.3125\n",
      "Epoch 143/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 353525.4375 - val_loss: 536571.0625\n",
      "Epoch 144/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 384014.0625 - val_loss: 573516.3125\n",
      "Epoch 145/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 363278.2812 - val_loss: 497339.4062\n",
      "Epoch 146/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 282382.6562 - val_loss: 585846.3750\n",
      "Epoch 147/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 317082.7500 - val_loss: 475802.8125\n",
      "Epoch 148/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 324123.0312 - val_loss: 609375.8750\n",
      "Epoch 149/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 361466.4688 - val_loss: 619743.0625\n",
      "Epoch 150/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 357027.5312 - val_loss: 766851.2500\n",
      "Epoch 151/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 354095.2188 - val_loss: 461599.6875\n",
      "Epoch 152/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 332060.4688 - val_loss: 605976.8125\n",
      "Epoch 153/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 339287.6250 - val_loss: 535627.1250\n",
      "Epoch 154/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 339351.6250 - val_loss: 432367.7812\n",
      "Epoch 155/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 302194.7812 - val_loss: 493892.9062\n",
      "Epoch 156/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 349122.3125 - val_loss: 551121.1875\n",
      "Epoch 157/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 370128.0312 - val_loss: 693920.6250\n",
      "Epoch 158/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 369809.5938 - val_loss: 594102.1875\n",
      "Epoch 159/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 334457.4375 - val_loss: 463970.8750\n",
      "Epoch 160/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 298626.5000 - val_loss: 401730.9688\n",
      "Epoch 161/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 337020.0312 - val_loss: 647833.5625\n",
      "Epoch 162/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 290541.3125 - val_loss: 403080.3125\n",
      "Epoch 163/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 285518.6562 - val_loss: 479051.3750\n",
      "Epoch 164/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 290555.9375 - val_loss: 504570.0938\n",
      "Epoch 165/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 292817.8125 - val_loss: 533330.1250\n",
      "Epoch 166/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 303429.6562 - val_loss: 501484.5312\n",
      "Epoch 167/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 326266.6875 - val_loss: 468959.9375\n",
      "Epoch 168/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 328771.3125 - val_loss: 572634.5000\n",
      "Epoch 169/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 274382.6875 - val_loss: 554922.4375\n",
      "Epoch 170/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 298427.7500 - val_loss: 556036.1250\n",
      "Epoch 171/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 331364.8438 - val_loss: 562785.9375\n",
      "Epoch 172/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 353977.5938 - val_loss: 568825.8750\n",
      "Epoch 173/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 275297.0938 - val_loss: 506049.5000\n",
      "Epoch 174/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 298387.9375 - val_loss: 496353.2188\n",
      "Epoch 175/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 266631.5938 - val_loss: 493396.7500\n",
      "Epoch 176/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 315858.8438 - val_loss: 394057.2188\n",
      "Epoch 177/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 265181.2188 - val_loss: 505413.4688\n",
      "Epoch 178/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 269972.6875 - val_loss: 552737.8125\n",
      "Epoch 179/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 282185.0000 - val_loss: 676460.0000\n",
      "Epoch 180/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 305058.2188 - val_loss: 483824.3438\n",
      "Epoch 181/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 296890.3750 - val_loss: 548907.6875\n",
      "Epoch 182/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 324145.7500 - val_loss: 602523.7500\n",
      "Epoch 183/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 304217.2188 - val_loss: 424027.9062\n",
      "Epoch 184/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 313107.1562 - val_loss: 611905.9375\n",
      "Epoch 185/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 321798.9375 - val_loss: 677465.0000\n",
      "Epoch 186/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 331804.5000 - val_loss: 558439.0625\n",
      "Epoch 187/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 340736.5938 - val_loss: 701790.5000\n",
      "Epoch 188/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 297773.0312 - val_loss: 601163.0625\n",
      "Epoch 189/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 336247.6250 - val_loss: 519223.2188\n",
      "Epoch 190/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 330938.5938 - val_loss: 439700.6250\n",
      "Epoch 191/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 293649.2188 - val_loss: 473609.7500\n",
      "Epoch 192/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 317760.6875 - val_loss: 619577.5625\n",
      "Epoch 193/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 282564.5312 - val_loss: 458785.7812\n",
      "Epoch 194/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 293429.1562 - val_loss: 434402.1875\n",
      "Epoch 195/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 303577.8125 - val_loss: 602102.8125\n",
      "Epoch 196/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 304135.4062 - val_loss: 600299.7500\n",
      "Epoch 197/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 304552.1250 - val_loss: 607086.5000\n",
      "Epoch 198/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 317877.6250 - val_loss: 549350.8750\n",
      "Epoch 199/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 283039.5625 - val_loss: 610380.0000\n",
      "Epoch 200/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 303807.3750 - val_loss: 469178.4375\n",
      "Epoch 201/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 300966.6250 - val_loss: 567664.8750\n",
      "Epoch 202/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 284427.4375 - val_loss: 526857.5000\n",
      "Epoch 203/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 278444.0000 - val_loss: 515451.2500\n",
      "Epoch 204/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 291619.8750 - val_loss: 432260.3438\n",
      "Epoch 205/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 271983.3438 - val_loss: 615331.0625\n",
      "Epoch 206/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 292427.0312 - val_loss: 460266.4688\n",
      "'########################################################Model4\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 9ms/step - loss: 41056240.0000 - val_loss: 24519392.0000\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 20957804.0000 - val_loss: 16907848.0000\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 15050189.0000 - val_loss: 18976220.0000\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 12840115.0000 - val_loss: 12988071.0000\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 10989354.0000 - val_loss: 12976557.0000\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 9577645.0000 - val_loss: 9025781.0000\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 7490083.5000 - val_loss: 10349774.0000\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 6795227.5000 - val_loss: 7318407.5000\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 6267002.0000 - val_loss: 7429594.0000\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 5678388.0000 - val_loss: 6889759.0000\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 4552014.5000 - val_loss: 5349315.0000\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 4433572.0000 - val_loss: 5472406.0000\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 4353840.5000 - val_loss: 5247458.0000\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3624789.5000 - val_loss: 4187198.2500\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3177352.0000 - val_loss: 3526296.2500\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3064718.5000 - val_loss: 3570449.7500\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2846280.0000 - val_loss: 4070013.7500\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2628758.7500 - val_loss: 2961566.5000\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2554500.5000 - val_loss: 2918007.5000\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2457058.0000 - val_loss: 2870026.2500\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2359182.0000 - val_loss: 3284162.7500\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2305282.0000 - val_loss: 3114136.7500\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2147452.5000 - val_loss: 2568899.5000\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1915200.6250 - val_loss: 2053920.0000\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1744269.3750 - val_loss: 1981941.0000\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1696499.3750 - val_loss: 2227120.7500\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1559285.0000 - val_loss: 2214240.7500\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1585339.5000 - val_loss: 2254200.7500\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1475571.6250 - val_loss: 2255569.5000\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1457366.1250 - val_loss: 2498969.2500\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1367720.7500 - val_loss: 1608808.2500\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1343215.0000 - val_loss: 1448302.6250\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1231054.8750 - val_loss: 1746915.8750\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1216747.1250 - val_loss: 1651316.7500\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1197314.0000 - val_loss: 1635740.0000\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1075364.7500 - val_loss: 1339240.0000\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1051700.5000 - val_loss: 1628246.1250\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1008529.8125 - val_loss: 1740273.1250\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 978818.1250 - val_loss: 1460138.8750\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 951350.5000 - val_loss: 1209190.8750\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 928445.8125 - val_loss: 1456050.3750\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 861936.0000 - val_loss: 1343069.2500\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 899318.6250 - val_loss: 1148937.7500\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 785524.7500 - val_loss: 911747.4375\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 865725.1250 - val_loss: 1006267.5000\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 802655.9375 - val_loss: 947516.3750\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 780191.1875 - val_loss: 1146207.5000\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 648159.0625 - val_loss: 999362.1875\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 635902.1250 - val_loss: 972472.0625\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 668354.7500 - val_loss: 1049904.5000\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 591611.6250 - val_loss: 781360.5625\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 641825.8750 - val_loss: 955303.5000\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 556263.8750 - val_loss: 871049.5000\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 558212.7500 - val_loss: 882344.8125\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 540295.0000 - val_loss: 714010.7500\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 518589.2188 - val_loss: 802192.3750\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 507272.7500 - val_loss: 766611.8750\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 528324.3750 - val_loss: 759177.4375\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 510678.9062 - val_loss: 909018.6250\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 441770.3438 - val_loss: 725719.1875\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 483585.0000 - val_loss: 801051.4375\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 459227.3438 - val_loss: 770732.2500\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 431181.6250 - val_loss: 780876.8750\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 452306.1250 - val_loss: 682676.6875\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 449628.2188 - val_loss: 722355.8125\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 407124.2500 - val_loss: 605712.1250\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 361719.8750 - val_loss: 676428.1875\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 401467.0000 - val_loss: 658431.5000\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 388853.2812 - val_loss: 687769.1250\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 411101.2188 - val_loss: 557766.3125\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 410231.0625 - val_loss: 622553.6875\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 434803.1250 - val_loss: 669649.5625\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 427449.8125 - val_loss: 633803.0625\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 387560.6875 - val_loss: 667171.0625\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 351452.1562 - val_loss: 661174.3750\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 373479.2188 - val_loss: 675041.8125\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 343366.5000 - val_loss: 680500.0000\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 389208.4375 - val_loss: 886842.4375\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 380936.0625 - val_loss: 674015.6875\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 415413.7188 - val_loss: 659830.4375\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 364580.1562 - val_loss: 544915.2500\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 407054.1250 - val_loss: 682509.5625\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 366067.7500 - val_loss: 536010.5625\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 354969.5000 - val_loss: 643313.9375\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 369631.1562 - val_loss: 543851.9375\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 322982.3438 - val_loss: 798497.5625\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 356725.3125 - val_loss: 568201.6875\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 360509.4688 - val_loss: 602670.9375\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 439838.1562 - val_loss: 631046.0625\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 390226.1562 - val_loss: 484370.4688\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 363962.3125 - val_loss: 619411.9375\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 400587.5000 - val_loss: 572412.5000\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 351584.7188 - val_loss: 480141.9062\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 360225.3125 - val_loss: 589996.2500\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 330004.0000 - val_loss: 691766.3750\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 374936.2500 - val_loss: 772106.3125\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 339228.0000 - val_loss: 605720.0000\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 395804.2188 - val_loss: 640715.7500\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 429142.6250 - val_loss: 639159.7500\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 364717.6250 - val_loss: 620936.8125\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 401970.4688 - val_loss: 951465.6875\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 401639.8125 - val_loss: 712813.5625\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 480904.9062 - val_loss: 614092.8125\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 362168.3750 - val_loss: 798851.0000\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 451978.6875 - val_loss: 592577.1250\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 439481.1875 - val_loss: 691843.0000\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 431886.0312 - val_loss: 848965.8750\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 448325.6250 - val_loss: 734908.4375\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 438602.1562 - val_loss: 670454.0000\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 439132.6875 - val_loss: 673656.1250\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 432877.7500 - val_loss: 687357.8750\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 420732.6562 - val_loss: 794197.8750\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 396531.0938 - val_loss: 629329.3750\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 402885.8438 - val_loss: 812605.6875\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 451729.4062 - val_loss: 786511.3125\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 355251.4688 - val_loss: 474692.3438\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 350700.8438 - val_loss: 660036.7500\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 364729.4688 - val_loss: 505856.0625\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 401998.0312 - val_loss: 708995.0625\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 371718.0312 - val_loss: 590597.3750\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 363942.8125 - val_loss: 694793.6250\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 406916.1250 - val_loss: 635295.1875\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 299792.2188 - val_loss: 682615.1250\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 375837.8750 - val_loss: 590069.4375\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 399845.4688 - val_loss: 588795.0000\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 332549.0312 - val_loss: 669406.1250\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 377372.2500 - val_loss: 717690.2500\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 339255.2188 - val_loss: 551480.9375\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 311113.3438 - val_loss: 513125.6250\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 334371.3750 - val_loss: 488362.8750\n",
      "Epoch 131/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 358698.9375 - val_loss: 649542.3125\n",
      "Epoch 132/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 316234.2188 - val_loss: 655321.8125\n",
      "Epoch 133/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 367396.1562 - val_loss: 502963.2500\n",
      "Epoch 134/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 338468.1562 - val_loss: 726154.8125\n",
      "Epoch 135/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 353385.8125 - val_loss: 505923.8125\n",
      "Epoch 136/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 365421.7188 - val_loss: 574497.0000\n",
      "Epoch 137/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 352167.4062 - val_loss: 759749.6875\n",
      "Epoch 138/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 360116.6562 - val_loss: 603337.7500\n",
      "Epoch 139/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 321062.0938 - val_loss: 571996.7500\n",
      "Epoch 140/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 376132.8438 - val_loss: 728136.1875\n",
      "Epoch 141/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 340922.6562 - val_loss: 602784.1250\n",
      "Epoch 142/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 308705.3438 - val_loss: 476563.1562\n",
      "Epoch 143/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 300993.1875 - val_loss: 505136.0625\n",
      "Epoch 144/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 406583.5625 - val_loss: 744922.6250\n",
      "Epoch 145/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 411954.7500 - val_loss: 754939.0625\n",
      "Epoch 146/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 407602.5938 - val_loss: 676306.9375\n",
      "'########################################################Model5\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 9ms/step - loss: 43327224.0000 - val_loss: 23553780.0000\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 21515438.0000 - val_loss: 15559650.0000\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 14637063.0000 - val_loss: 17449056.0000\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 12422315.0000 - val_loss: 10781858.0000\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 9526381.0000 - val_loss: 8102707.0000\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 7692515.5000 - val_loss: 7578444.0000\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 6901720.5000 - val_loss: 8926393.0000\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 6311592.5000 - val_loss: 5535957.0000\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 5430127.0000 - val_loss: 6043909.5000\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 5252882.0000 - val_loss: 5222210.0000\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 4473633.0000 - val_loss: 4906656.0000\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3732790.5000 - val_loss: 4014437.5000\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3409037.5000 - val_loss: 3779829.5000\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3321495.0000 - val_loss: 3660166.7500\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3202337.2500 - val_loss: 3811401.7500\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2839013.7500 - val_loss: 3240956.2500\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2693082.5000 - val_loss: 3576084.7500\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2484296.7500 - val_loss: 3087806.7500\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2344464.5000 - val_loss: 2682580.0000\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2105730.7500 - val_loss: 3059624.0000\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2176150.5000 - val_loss: 2373874.2500\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1864027.2500 - val_loss: 2423768.0000\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1757222.3750 - val_loss: 2394032.0000\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1724609.5000 - val_loss: 2484491.2500\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1588358.6250 - val_loss: 1997803.8750\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1503194.6250 - val_loss: 2267738.2500\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1432527.5000 - val_loss: 1813148.5000\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1386937.5000 - val_loss: 1965124.2500\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1521265.0000 - val_loss: 1746055.3750\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1226272.7500 - val_loss: 1551422.6250\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1185477.3750 - val_loss: 1618581.5000\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1071573.5000 - val_loss: 1501672.0000\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 973996.8750 - val_loss: 1218614.8750\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 983721.6250 - val_loss: 1431504.5000\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1014225.6250 - val_loss: 1213601.5000\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 878135.9375 - val_loss: 1205119.5000\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 846621.5000 - val_loss: 1268722.6250\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 771312.2500 - val_loss: 1209152.0000\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 773258.3750 - val_loss: 1419922.3750\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 802522.3125 - val_loss: 1111174.6250\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 736892.6250 - val_loss: 1024061.1250\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 700699.3750 - val_loss: 937034.5000\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 684457.0000 - val_loss: 1018599.0625\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 692129.3750 - val_loss: 933177.6250\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 630022.3750 - val_loss: 1472284.2500\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 653564.3750 - val_loss: 921009.1875\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 609065.3125 - val_loss: 821744.8125\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 563343.2500 - val_loss: 926056.6250\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 564347.3750 - val_loss: 863839.3125\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 592728.0000 - val_loss: 848716.0000\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 508543.5000 - val_loss: 722335.8750\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 528237.0625 - val_loss: 953210.2500\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 516557.0000 - val_loss: 700607.6875\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 501989.0938 - val_loss: 874651.4375\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 506284.7188 - val_loss: 810852.5625\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 507917.3438 - val_loss: 737614.0000\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 512193.7188 - val_loss: 822691.5000\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 538421.1250 - val_loss: 759330.6250\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 440776.9688 - val_loss: 599305.5625\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 419060.5625 - val_loss: 708676.9375\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 492352.3438 - val_loss: 783199.7500\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 406580.0000 - val_loss: 673435.2500\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 387785.5625 - val_loss: 584270.8750\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 437559.6562 - val_loss: 622788.0000\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 411679.0938 - val_loss: 604797.0625\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 390927.1875 - val_loss: 620776.7500\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 378849.1875 - val_loss: 648398.2500\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 393347.6562 - val_loss: 602222.2500\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 404894.4375 - val_loss: 742254.6875\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 327868.9062 - val_loss: 644784.8750\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 356414.0000 - val_loss: 628563.0625\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 366399.2500 - val_loss: 705876.0000\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 416202.1250 - val_loss: 579631.3750\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 354860.7188 - val_loss: 562475.8750\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 350751.6250 - val_loss: 513504.3750\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 305360.0625 - val_loss: 677186.2500\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 346301.9062 - val_loss: 678345.5625\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 337699.5938 - val_loss: 604786.0625\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 345705.3438 - val_loss: 669177.9375\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 319492.3750 - val_loss: 645806.1875\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 324035.3438 - val_loss: 749899.3750\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 327032.2188 - val_loss: 466405.9688\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 298889.8125 - val_loss: 588583.3125\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 335164.2500 - val_loss: 657626.8125\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 318698.7188 - val_loss: 623123.1250\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 377053.0625 - val_loss: 736086.9375\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 393525.5312 - val_loss: 513775.9375\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 295578.8750 - val_loss: 485169.5312\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 348863.9062 - val_loss: 603735.3125\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 372491.0938 - val_loss: 553236.5625\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 337737.4688 - val_loss: 565873.3750\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 382766.3750 - val_loss: 538576.8125\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 411180.6875 - val_loss: 547287.4375\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 383724.7188 - val_loss: 550002.1875\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 390166.8438 - val_loss: 520438.3438\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 304118.6875 - val_loss: 600651.5000\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 337729.8438 - val_loss: 510056.7812\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 343466.6250 - val_loss: 660717.4375\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 335340.2500 - val_loss: 683437.6875\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 372117.2188 - val_loss: 754436.8750\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 369246.5938 - val_loss: 470683.6562\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 306996.0625 - val_loss: 563597.1250\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 330163.0312 - val_loss: 554999.1875\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 372916.6875 - val_loss: 708316.4375\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 332603.8750 - val_loss: 596656.6875\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 329304.0000 - val_loss: 431586.2500\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 345413.3438 - val_loss: 715463.8125\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 351757.2812 - val_loss: 617542.0000\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 345326.0312 - val_loss: 577793.9375\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 324327.8750 - val_loss: 608751.6250\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 323121.6250 - val_loss: 544504.5625\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 372674.7812 - val_loss: 561839.8125\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 363888.1562 - val_loss: 556561.1250\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 355621.1562 - val_loss: 685887.6250\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 381790.8750 - val_loss: 524655.3125\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 377691.5625 - val_loss: 545736.6875\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 365230.4062 - val_loss: 604282.0625\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 335724.3438 - val_loss: 528320.4375\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 304797.6562 - val_loss: 588251.3750\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 316304.7500 - val_loss: 654479.2500\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 354230.9688 - val_loss: 572105.5000\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 312280.4688 - val_loss: 652584.3750\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 307264.9062 - val_loss: 538076.5000\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 316314.5625 - val_loss: 622698.5625\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 367952.8125 - val_loss: 615421.4375\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 330677.6250 - val_loss: 548000.7500\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 381623.1250 - val_loss: 703266.8125\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 374659.8750 - val_loss: 637220.9375\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 338248.4688 - val_loss: 569823.9375\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 371908.2812 - val_loss: 877404.1875\n",
      "Epoch 131/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 397686.0312 - val_loss: 680607.6875\n",
      "Epoch 132/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 345374.9062 - val_loss: 686868.9375\n",
      "Epoch 133/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 320072.8438 - val_loss: 598495.1250\n",
      "Epoch 134/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 373628.5000 - val_loss: 598984.3125\n",
      "Epoch 135/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 365747.8125 - val_loss: 493383.1250\n",
      "Epoch 136/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 345345.9062 - val_loss: 554827.3750\n",
      "'########################################################Model6\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 9ms/step - loss: 40987812.0000 - val_loss: 22766364.0000\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 22104922.0000 - val_loss: 18513356.0000\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 16031069.0000 - val_loss: 13752567.0000\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 13559276.0000 - val_loss: 11333378.0000\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 11037239.0000 - val_loss: 10110898.0000\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 9386350.0000 - val_loss: 8112948.0000\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 8064543.0000 - val_loss: 7344563.5000\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 7023134.5000 - val_loss: 10390157.0000\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 6150883.5000 - val_loss: 5884241.0000\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 5168258.0000 - val_loss: 5071152.5000\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 5145674.0000 - val_loss: 5149075.5000\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 4433886.0000 - val_loss: 4449218.0000\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 4146360.2500 - val_loss: 5187387.5000\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3897473.7500 - val_loss: 4760418.0000\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3344447.5000 - val_loss: 3554745.0000\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3513061.7500 - val_loss: 4478547.0000\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3158293.2500 - val_loss: 3552966.5000\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2635177.2500 - val_loss: 2836672.2500\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2415568.2500 - val_loss: 2632257.0000\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2279659.7500 - val_loss: 2726094.0000\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2223708.0000 - val_loss: 2486769.0000\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2126870.2500 - val_loss: 2679218.2500\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2025538.6250 - val_loss: 2487981.0000\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1779460.3750 - val_loss: 2070068.2500\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1790516.5000 - val_loss: 2651877.7500\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1755992.1250 - val_loss: 1881306.2500\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1514262.2500 - val_loss: 2257920.0000\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1661830.8750 - val_loss: 2216125.2500\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1415526.1250 - val_loss: 2461437.7500\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1536400.1250 - val_loss: 1582281.2500\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1274024.8750 - val_loss: 1588091.3750\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1263391.0000 - val_loss: 2110936.7500\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1279720.5000 - val_loss: 1492325.8750\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1170013.0000 - val_loss: 1712148.3750\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1097653.0000 - val_loss: 1434064.0000\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1123692.6250 - val_loss: 1466343.0000\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1214558.2500 - val_loss: 1291138.6250\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1003220.8125 - val_loss: 1098040.0000\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 905295.9375 - val_loss: 1194185.6250\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 921670.0625 - val_loss: 1257797.7500\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 942434.5625 - val_loss: 1443627.7500\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 958751.5625 - val_loss: 1209696.2500\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 743501.0625 - val_loss: 1047462.0625\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 708133.5000 - val_loss: 932001.7500\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 707672.7500 - val_loss: 1554239.8750\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 856848.0000 - val_loss: 1144515.3750\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 718761.1875 - val_loss: 923434.1875\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 681816.8125 - val_loss: 1277315.6250\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 653087.5000 - val_loss: 928431.6875\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 609951.0000 - val_loss: 936287.5625\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 576593.8750 - val_loss: 837491.6250\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 572689.2500 - val_loss: 879477.3125\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 681937.7500 - val_loss: 1021232.7500\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 657497.3750 - val_loss: 1013959.8125\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 580091.3125 - val_loss: 798740.9375\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 531044.8125 - val_loss: 772367.4375\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 523802.2500 - val_loss: 880274.1250\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 468146.8125 - val_loss: 772259.6250\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 537979.9375 - val_loss: 852933.9375\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 536394.9375 - val_loss: 668715.8125\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 472719.5625 - val_loss: 624173.8750\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 484047.5625 - val_loss: 695269.9375\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 447977.5000 - val_loss: 770304.0625\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 494766.0000 - val_loss: 641764.0000\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 516189.9062 - val_loss: 876962.8125\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 443448.3750 - val_loss: 732399.8125\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 423100.1875 - val_loss: 683275.5000\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 429951.7812 - val_loss: 567733.5000\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 425183.2188 - val_loss: 756678.6875\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 394602.6250 - val_loss: 528439.1250\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 415354.5625 - val_loss: 636640.7500\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 370427.1562 - val_loss: 807479.0625\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 433492.4375 - val_loss: 682819.7500\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 384295.8438 - val_loss: 618174.0625\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 531328.7500 - val_loss: 761014.8125\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 387559.5938 - val_loss: 544198.5000\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 358804.5312 - val_loss: 554552.8125\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 341799.8750 - val_loss: 643110.9375\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 347901.3125 - val_loss: 710563.1250\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 320438.3438 - val_loss: 681171.4375\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 377500.1562 - val_loss: 630103.2500\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 371889.8125 - val_loss: 717377.0625\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 389560.2812 - val_loss: 680187.6250\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 384020.5000 - val_loss: 595350.3125\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 438275.4062 - val_loss: 699037.6250\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 360942.5938 - val_loss: 495576.8750\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 366913.5000 - val_loss: 623635.7500\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 361540.3125 - val_loss: 547903.5625\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 378906.5312 - val_loss: 654991.3125\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 405263.6250 - val_loss: 600372.3125\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 400129.3750 - val_loss: 697703.4375\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 364081.5312 - val_loss: 679012.6875\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 344953.7188 - val_loss: 561784.3125\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 370616.6875 - val_loss: 628057.0000\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 366022.7500 - val_loss: 463609.3750\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 375330.5312 - val_loss: 698893.4375\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 354485.8438 - val_loss: 584135.3125\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 300653.8125 - val_loss: 654762.7500\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 369505.1875 - val_loss: 511159.6250\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 315591.7500 - val_loss: 574611.3750\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 380085.5000 - val_loss: 538796.0000\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 317022.6562 - val_loss: 446175.2188\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 385888.1250 - val_loss: 570625.1875\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 394602.2188 - val_loss: 691059.1250\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 486051.9375 - val_loss: 702848.7500\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 369930.5938 - val_loss: 674327.3125\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 433716.6562 - val_loss: 840746.2500\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 350134.3438 - val_loss: 605928.6875\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 408983.2188 - val_loss: 606732.7500\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 389261.6562 - val_loss: 488216.8125\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 409864.1250 - val_loss: 625302.0000\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 293242.2188 - val_loss: 641985.0000\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 432164.1562 - val_loss: 579945.1875\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 432895.5000 - val_loss: 846828.1250\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 408854.0000 - val_loss: 503913.4375\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 430120.5625 - val_loss: 794794.3750\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 441420.9062 - val_loss: 657874.1875\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 396257.8750 - val_loss: 689212.6875\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 450360.4062 - val_loss: 995200.0000\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 375555.2812 - val_loss: 695061.6250\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 399958.3750 - val_loss: 593893.6875\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 328398.9688 - val_loss: 636733.5625\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 434469.9375 - val_loss: 534765.4375\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 401438.6562 - val_loss: 620164.4375\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 384020.1562 - val_loss: 631437.8125\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 322338.5312 - val_loss: 598866.5625\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 405777.8125 - val_loss: 574799.0625\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 453201.9062 - val_loss: 556828.6875\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 375377.0938 - val_loss: 711098.3125\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 373875.0625 - val_loss: 564701.8750\n",
      "Epoch 131/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 377985.5000 - val_loss: 706207.5625\n",
      "Epoch 132/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 415719.8750 - val_loss: 714121.6875\n",
      "'########################################################Model7\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 9ms/step - loss: 47306708.0000 - val_loss: 32035984.0000\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 22368010.0000 - val_loss: 18046472.0000\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 16942518.0000 - val_loss: 15380284.0000\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 13168288.0000 - val_loss: 12029444.0000\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 11157159.0000 - val_loss: 9671949.0000\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 9331229.0000 - val_loss: 10167684.0000\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 8891735.0000 - val_loss: 9119951.0000\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 7092057.0000 - val_loss: 8292891.5000\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 6829235.0000 - val_loss: 7065104.0000\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 5475371.5000 - val_loss: 5148815.5000\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 4979773.5000 - val_loss: 5254448.0000\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 4641844.5000 - val_loss: 4378483.0000\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 4246752.0000 - val_loss: 4790022.5000\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3728651.0000 - val_loss: 4576609.0000\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3499997.0000 - val_loss: 3902705.0000\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3027019.7500 - val_loss: 4119695.0000\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3352203.7500 - val_loss: 3665308.2500\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2925664.0000 - val_loss: 3476444.5000\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2742342.2500 - val_loss: 3762146.7500\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2508269.0000 - val_loss: 3057711.0000\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2251184.0000 - val_loss: 2757873.0000\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2034819.1250 - val_loss: 2345743.0000\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2106355.0000 - val_loss: 2544713.7500\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2015907.2500 - val_loss: 2166414.7500\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1673136.6250 - val_loss: 2267215.2500\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1764041.7500 - val_loss: 2313179.5000\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1623706.0000 - val_loss: 1898730.3750\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1675412.1250 - val_loss: 2425085.2500\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1501729.5000 - val_loss: 1896769.1250\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1355117.6250 - val_loss: 2281855.0000\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1249920.1250 - val_loss: 1695072.3750\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1233651.5000 - val_loss: 1686147.2500\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1195656.1250 - val_loss: 2008985.1250\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1117522.0000 - val_loss: 1851169.0000\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1148216.8750 - val_loss: 1604125.1250\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1103433.2500 - val_loss: 1427791.2500\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1053604.2500 - val_loss: 1301397.1250\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 900585.1250 - val_loss: 1156774.7500\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 940238.0625 - val_loss: 1501440.2500\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 901436.1875 - val_loss: 1174461.0000\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 829835.3750 - val_loss: 1076470.7500\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 806527.5625 - val_loss: 1155668.2500\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 780183.0000 - val_loss: 1206322.6250\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 726834.9375 - val_loss: 967182.8750\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 702581.8750 - val_loss: 999563.2500\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 732468.3750 - val_loss: 911141.6250\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 644581.1875 - val_loss: 1209259.6250\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 661494.3750 - val_loss: 1037119.1250\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 665164.8125 - val_loss: 1201826.5000\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 636251.8125 - val_loss: 809379.8750\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 567320.9375 - val_loss: 902765.6250\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 654350.5000 - val_loss: 1006915.6250\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 641067.1250 - val_loss: 965527.8125\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 517848.9062 - val_loss: 923309.9375\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 546904.9375 - val_loss: 971080.3750\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 582682.5625 - val_loss: 911549.5000\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 558807.8125 - val_loss: 801607.3125\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 475331.0938 - val_loss: 848096.3750\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 481633.3750 - val_loss: 685801.5625\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 488084.9688 - val_loss: 853135.0000\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 480247.2500 - val_loss: 667089.4375\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 435160.3750 - val_loss: 607134.5000\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 422828.9688 - val_loss: 803727.8125\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 428596.6875 - val_loss: 533241.1875\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 428726.6875 - val_loss: 895875.3125\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 443698.7812 - val_loss: 670944.5000\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 357416.5312 - val_loss: 773160.2500\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 443724.2500 - val_loss: 801692.2500\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 459561.0938 - val_loss: 649014.6875\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 401987.1250 - val_loss: 675690.8125\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 415695.6250 - val_loss: 692904.1875\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 345015.7500 - val_loss: 727242.6875\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 344826.8125 - val_loss: 617028.6250\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 367792.0312 - val_loss: 778593.2500\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 360832.5938 - val_loss: 688728.5625\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 368555.9062 - val_loss: 571312.3125\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 408098.0625 - val_loss: 690098.0000\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 364113.5938 - val_loss: 665048.6875\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 402967.2188 - val_loss: 562129.8125\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 360331.7500 - val_loss: 526815.7500\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 366964.3125 - val_loss: 663493.8750\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 378859.4062 - val_loss: 505847.0000\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 343717.8125 - val_loss: 487386.0938\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 331839.4688 - val_loss: 550725.5000\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 324058.2188 - val_loss: 521810.9688\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 339365.3125 - val_loss: 543944.4375\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 342276.7812 - val_loss: 605113.1875\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 303323.2812 - val_loss: 566963.5625\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 380465.0625 - val_loss: 728689.2500\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 356417.1875 - val_loss: 585116.1875\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 337562.7812 - val_loss: 400991.5938\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 334315.0938 - val_loss: 540770.8125\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 306293.6562 - val_loss: 470381.0625\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 357004.0000 - val_loss: 637553.9375\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 356631.9062 - val_loss: 598418.6250\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 407352.4375 - val_loss: 530506.7500\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 332769.0938 - val_loss: 599613.4375\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 377190.9062 - val_loss: 460870.6250\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 310180.2812 - val_loss: 546025.2500\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 357000.6250 - val_loss: 592398.5625\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 317524.8125 - val_loss: 599677.4375\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 342643.3125 - val_loss: 558046.4375\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 365790.1875 - val_loss: 577422.6250\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 349472.8750 - val_loss: 399284.8750\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 326154.5000 - val_loss: 615465.3125\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 319065.5625 - val_loss: 518591.3438\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 311187.0000 - val_loss: 635437.7500\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 358982.6562 - val_loss: 710341.0625\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 349852.0938 - val_loss: 559080.3750\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 393525.8438 - val_loss: 623035.6875\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 403326.8438 - val_loss: 827991.9375\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 373947.6250 - val_loss: 486409.5938\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 345097.7812 - val_loss: 566089.4375\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 363122.1875 - val_loss: 627337.8750\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 331212.5000 - val_loss: 579367.5625\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 346762.7188 - val_loss: 526094.1875\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 366564.7188 - val_loss: 568160.8750\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 336253.6875 - val_loss: 451357.0625\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 345059.7812 - val_loss: 579911.4375\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 390204.3750 - val_loss: 736102.8125\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 354301.2188 - val_loss: 516801.6562\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 333239.9062 - val_loss: 642960.9375\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 344742.1875 - val_loss: 605475.0000\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 366886.2500 - val_loss: 514342.5625\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 405947.1875 - val_loss: 612958.2500\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 386133.1875 - val_loss: 573813.7500\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 378532.2812 - val_loss: 636348.5625\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 434286.7812 - val_loss: 696567.8750\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 398353.8438 - val_loss: 674364.7500\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 426100.0000 - val_loss: 736960.8750\n",
      "Epoch 131/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 455402.0312 - val_loss: 623385.1875\n",
      "Epoch 132/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 365334.0000 - val_loss: 484266.4688\n",
      "Epoch 133/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 317594.5625 - val_loss: 507440.9375\n",
      "Epoch 134/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 356468.1875 - val_loss: 664436.8125\n",
      "'########################################################Model8\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 3s 9ms/step - loss: 43419480.0000 - val_loss: 31460380.0000\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 23249610.0000 - val_loss: 19210272.0000\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 16096555.0000 - val_loss: 18395666.0000\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 13521637.0000 - val_loss: 11177143.0000\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 10685113.0000 - val_loss: 11659152.0000\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 9087739.0000 - val_loss: 9794210.0000\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 8058370.5000 - val_loss: 7472680.5000\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 7125854.0000 - val_loss: 7255463.0000\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 6484452.5000 - val_loss: 6069924.0000\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 5295726.5000 - val_loss: 6516302.5000\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 5251566.0000 - val_loss: 6197273.0000\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 4830909.0000 - val_loss: 5542387.0000\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 4253310.0000 - val_loss: 4763568.0000\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 4203616.0000 - val_loss: 5259599.5000\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3582857.7500 - val_loss: 4287725.5000\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3125343.0000 - val_loss: 3527115.2500\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2978338.5000 - val_loss: 3759694.5000\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3157997.5000 - val_loss: 3644010.5000\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2952829.0000 - val_loss: 4528987.0000\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2683403.7500 - val_loss: 2801039.5000\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2517243.7500 - val_loss: 2640681.2500\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2092464.5000 - val_loss: 2610445.2500\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1997903.5000 - val_loss: 2533149.5000\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1853555.8750 - val_loss: 2225026.2500\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1811129.8750 - val_loss: 2308405.0000\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1671920.5000 - val_loss: 2220106.2500\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1742102.1250 - val_loss: 1890108.7500\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1580494.1250 - val_loss: 2035024.3750\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1510469.5000 - val_loss: 1926044.8750\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1371557.6250 - val_loss: 1899897.0000\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1367760.7500 - val_loss: 1598597.1250\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1374039.0000 - val_loss: 1886297.1250\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1168605.3750 - val_loss: 1442804.0000\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1181758.8750 - val_loss: 2065661.7500\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1201976.8750 - val_loss: 1526102.1250\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1113113.0000 - val_loss: 1488201.0000\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 998248.1875 - val_loss: 1471461.1250\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1015266.1250 - val_loss: 1468824.2500\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 982887.6250 - val_loss: 1443782.0000\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 867765.7500 - val_loss: 1531818.0000\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 934966.3750 - val_loss: 1520965.1250\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 924355.0000 - val_loss: 1089433.2500\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 808238.0625 - val_loss: 1003295.3125\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 771028.6875 - val_loss: 1137929.0000\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 822430.0625 - val_loss: 1253220.3750\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 724989.2500 - val_loss: 1005535.6875\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 782212.3125 - val_loss: 890936.6875\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 717501.2500 - val_loss: 927201.1875\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 692930.3125 - val_loss: 892669.5000\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 594993.8750 - val_loss: 1051616.7500\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 692437.3125 - val_loss: 874903.2500\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 670398.5625 - val_loss: 1066460.7500\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 686346.0000 - val_loss: 787235.6875\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 527985.1250 - val_loss: 844978.8125\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 551969.1250 - val_loss: 1020840.1875\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 613881.1250 - val_loss: 927658.8125\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 590638.7500 - val_loss: 631893.2500\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 477916.7188 - val_loss: 644421.5000\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 466425.0938 - val_loss: 847738.8125\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 517784.4688 - val_loss: 833971.0625\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 508220.0000 - val_loss: 634711.9375\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 504138.8438 - val_loss: 858230.5625\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 447227.2812 - val_loss: 774097.7500\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 448015.8125 - val_loss: 817525.3125\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 518496.3438 - val_loss: 748641.3750\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 455029.0000 - val_loss: 709072.0000\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 435703.7188 - val_loss: 683541.4375\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 417751.4062 - val_loss: 861096.0625\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 470977.9375 - val_loss: 774498.5625\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 437236.1562 - val_loss: 621185.5625\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 393636.2188 - val_loss: 638393.7500\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 426281.1562 - val_loss: 547482.2500\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 327046.8750 - val_loss: 610500.3125\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 392234.2812 - val_loss: 662083.3125\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 401656.2188 - val_loss: 703105.0625\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 418164.0938 - val_loss: 538310.7500\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 426433.0938 - val_loss: 722642.6250\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 395947.8438 - val_loss: 652058.0625\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 390143.2188 - val_loss: 787014.8750\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 396672.0000 - val_loss: 487143.8750\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 352653.1562 - val_loss: 603610.5000\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 381136.2500 - val_loss: 612407.1875\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 408699.7500 - val_loss: 747848.0625\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 429533.0312 - val_loss: 658858.4375\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 386313.3125 - val_loss: 706944.2500\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 446792.5938 - val_loss: 852785.3125\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 441476.2188 - val_loss: 633400.8750\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 351867.6562 - val_loss: 564832.3750\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 427015.1562 - val_loss: 748978.0000\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 358681.3750 - val_loss: 519387.5312\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 387029.8750 - val_loss: 566602.1250\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 270493.4375 - val_loss: 407304.5000\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 356454.4688 - val_loss: 597828.5000\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 373397.9062 - val_loss: 605912.9375\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 428062.8750 - val_loss: 598244.0625\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 389932.5000 - val_loss: 599915.0625\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 374277.4062 - val_loss: 632880.2500\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 351736.6562 - val_loss: 844454.7500\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 371550.2500 - val_loss: 447564.6250\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 347160.0312 - val_loss: 532985.3125\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 369357.4688 - val_loss: 646344.2500\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 395560.9688 - val_loss: 722049.6250\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 394150.1875 - val_loss: 680809.3750\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 404850.1875 - val_loss: 683971.1250\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 410636.9375 - val_loss: 596291.0625\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 407898.5312 - val_loss: 579111.2500\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 396850.8125 - val_loss: 633690.6875\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 425869.2812 - val_loss: 712548.7500\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 366718.4375 - val_loss: 659390.6875\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 420390.6875 - val_loss: 680287.2500\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 408375.5625 - val_loss: 735157.0625\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 406947.2500 - val_loss: 660913.8125\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 348528.4062 - val_loss: 632260.2500\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 367950.9375 - val_loss: 620782.0000\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 306270.5625 - val_loss: 552562.4375\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 385274.7812 - val_loss: 612194.1875\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 341239.0625 - val_loss: 511078.3438\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 352449.7188 - val_loss: 601085.5625\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 372956.5312 - val_loss: 540910.9375\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 396322.8750 - val_loss: 539966.3125\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 379019.5000 - val_loss: 642195.4375\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 395414.6875 - val_loss: 726754.5000\n",
      "'########################################################Model9\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 10ms/step - loss: 154.8490 - val_loss: 153.6859\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 151.7575 - val_loss: 152.1321\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 152.4545 - val_loss: 155.5549\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 150.9751 - val_loss: 151.5254\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 150.4250 - val_loss: 153.4512\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 151.1815 - val_loss: 154.8182\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 150.8676 - val_loss: 152.6844\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 149.6392 - val_loss: 151.1916\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 149.1544 - val_loss: 150.8217\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 149.6106 - val_loss: 151.2022\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 144.2645 - val_loss: 143.9018\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 143.0717 - val_loss: 144.3211\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 142.7033 - val_loss: 143.5117\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 142.6333 - val_loss: 143.5589\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 141.9999 - val_loss: 144.3486\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 141.7809 - val_loss: 144.3436\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 141.9654 - val_loss: 143.4977\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 141.2801 - val_loss: 144.3928\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 141.6843 - val_loss: 143.2761\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 140.9755 - val_loss: 144.1066\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 141.6855 - val_loss: 143.9378\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 140.7643 - val_loss: 143.7159\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 140.9655 - val_loss: 141.9240\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 134.3244 - val_loss: 135.7085\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 133.4534 - val_loss: 136.6975\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 130.2384 - val_loss: 133.3482\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 130.8239 - val_loss: 133.5546\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 127.8759 - val_loss: 132.0309\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 127.2113 - val_loss: 131.7095\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 126.3931 - val_loss: 132.3983\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 127.6359 - val_loss: 131.6885\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 125.2061 - val_loss: 131.2529\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 124.3778 - val_loss: 131.0065\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 123.9174 - val_loss: 132.2887\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 124.1870 - val_loss: 131.2716\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 122.7615 - val_loss: 131.7545\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 122.6313 - val_loss: 129.1184\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 121.7085 - val_loss: 134.1642\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 122.5483 - val_loss: 131.3568\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 122.0508 - val_loss: 131.2076\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 123.1737 - val_loss: 130.3861\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 121.2330 - val_loss: 132.2769\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 122.0493 - val_loss: 132.0067\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 121.1223 - val_loss: 130.6762\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 120.6365 - val_loss: 130.1303\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 120.4268 - val_loss: 130.2421\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 119.6357 - val_loss: 131.2745\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 119.9232 - val_loss: 129.9407\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 119.1400 - val_loss: 129.3026\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 118.6975 - val_loss: 129.5615\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 119.9447 - val_loss: 130.0751\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 118.9424 - val_loss: 130.4019\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 118.2448 - val_loss: 129.6291\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 117.5148 - val_loss: 130.8420\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 120.1773 - val_loss: 129.4394\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 118.9234 - val_loss: 130.1976\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 118.6826 - val_loss: 129.0068\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 118.3562 - val_loss: 129.3232\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 117.2915 - val_loss: 129.1458\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 117.1164 - val_loss: 130.0348\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 117.9535 - val_loss: 129.0296\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 118.0230 - val_loss: 129.3859\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 116.7101 - val_loss: 129.2110\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 116.4688 - val_loss: 130.0573\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 117.4919 - val_loss: 129.7408\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 116.4490 - val_loss: 128.9005\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 116.3266 - val_loss: 129.0219\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 115.8651 - val_loss: 128.7680\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 116.2016 - val_loss: 129.0556\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 116.6627 - val_loss: 130.3721\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 115.6802 - val_loss: 129.7539\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 115.5765 - val_loss: 129.9595\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 114.5004 - val_loss: 129.7253\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 115.1538 - val_loss: 129.5012\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 114.8238 - val_loss: 128.5808\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 114.6404 - val_loss: 129.5871\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 115.1432 - val_loss: 129.2781\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 114.4065 - val_loss: 129.4906\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 114.1315 - val_loss: 129.5805\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 114.1966 - val_loss: 130.7185\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 114.0851 - val_loss: 129.7389\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 113.5236 - val_loss: 129.9832\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 112.8487 - val_loss: 131.3896\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 112.9224 - val_loss: 129.6860\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 112.9060 - val_loss: 130.2317\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 112.9917 - val_loss: 130.7677\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 113.5046 - val_loss: 129.9957\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 113.1404 - val_loss: 130.1469\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 112.5094 - val_loss: 129.9317\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 112.1247 - val_loss: 129.6063\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 112.3429 - val_loss: 129.1557\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 112.0516 - val_loss: 129.9960\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 111.7829 - val_loss: 129.8597\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 111.5275 - val_loss: 129.5338\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 111.9753 - val_loss: 130.7640\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 112.0094 - val_loss: 129.0114\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 111.9843 - val_loss: 129.7839\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 111.7543 - val_loss: 129.4617\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 111.9198 - val_loss: 129.6318\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 111.1731 - val_loss: 130.5876\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 111.0807 - val_loss: 132.0835\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 111.1760 - val_loss: 129.7626\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 110.4616 - val_loss: 128.9094\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 110.8235 - val_loss: 128.9588\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 110.5720 - val_loss: 129.5367\n",
      "'########################################################Model0\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 9ms/step - loss: 142.3117 - val_loss: 137.0188\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 135.3578 - val_loss: 141.4731\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 134.7251 - val_loss: 133.8475\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 133.5379 - val_loss: 134.7143\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 132.4842 - val_loss: 137.0221\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 131.4988 - val_loss: 134.8293\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 132.2436 - val_loss: 134.5383\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 131.1244 - val_loss: 134.9843\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 131.3414 - val_loss: 135.6614\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 130.7970 - val_loss: 135.5414\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 130.1981 - val_loss: 132.9727\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 130.5249 - val_loss: 133.4577\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 129.8229 - val_loss: 133.1838\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 128.7367 - val_loss: 132.2142\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 126.7784 - val_loss: 130.6910\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 127.9950 - val_loss: 130.8483\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 127.6651 - val_loss: 131.9944\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 126.6650 - val_loss: 133.1418\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 125.9964 - val_loss: 131.2122\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 125.0322 - val_loss: 130.5373\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 125.1065 - val_loss: 129.7407\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 124.4492 - val_loss: 130.5854\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 126.0291 - val_loss: 130.6129\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 124.1541 - val_loss: 131.2190\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 125.5510 - val_loss: 129.9606\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 125.3003 - val_loss: 128.7963\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 124.7485 - val_loss: 130.5322\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 123.9883 - val_loss: 130.5572\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 123.8764 - val_loss: 129.0586\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 123.1843 - val_loss: 129.5071\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 124.1715 - val_loss: 130.7388\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 123.1148 - val_loss: 129.2139\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 123.0219 - val_loss: 128.7184\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 124.9092 - val_loss: 131.3617\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 123.8774 - val_loss: 129.8524\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 122.2644 - val_loss: 129.3567\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 122.2179 - val_loss: 128.9677\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 122.0933 - val_loss: 129.8549\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 122.2604 - val_loss: 128.8446\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 121.3683 - val_loss: 129.8852\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 121.9727 - val_loss: 130.3369\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 121.3137 - val_loss: 128.5684\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 120.7997 - val_loss: 128.9853\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 120.6858 - val_loss: 130.4080\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 120.9268 - val_loss: 128.1693\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 120.8445 - val_loss: 129.6019\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 120.1876 - val_loss: 127.8578\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 119.2869 - val_loss: 129.5418\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 119.2580 - val_loss: 128.7769\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 119.3963 - val_loss: 128.6542\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 119.0344 - val_loss: 129.2180\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 119.3817 - val_loss: 129.7344\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 118.8035 - val_loss: 128.7521\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 119.0265 - val_loss: 129.1105\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 118.8085 - val_loss: 129.1770\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 118.4363 - val_loss: 129.6967\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 117.7458 - val_loss: 129.9631\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 117.4225 - val_loss: 130.0803\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 117.1585 - val_loss: 129.2402\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 117.1382 - val_loss: 131.4694\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 117.4481 - val_loss: 129.7827\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 117.2898 - val_loss: 131.1848\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 117.6909 - val_loss: 129.0683\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 116.6208 - val_loss: 130.0825\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 116.4397 - val_loss: 129.3961\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 115.9086 - val_loss: 129.8213\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 115.8460 - val_loss: 130.6448\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 115.7690 - val_loss: 129.4477\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 115.2492 - val_loss: 129.5650\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 115.4883 - val_loss: 130.6473\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 115.3557 - val_loss: 130.3334\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 114.7961 - val_loss: 130.1019\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 114.9021 - val_loss: 129.5613\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 114.5471 - val_loss: 131.9248\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 114.7477 - val_loss: 129.8875\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 114.8246 - val_loss: 129.1629\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 114.5437 - val_loss: 132.1679\n",
      "'########################################################Model1\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 9ms/step - loss: 138.7209 - val_loss: 138.0161\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 134.8077 - val_loss: 133.3643\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 135.3683 - val_loss: 137.3899\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 133.6386 - val_loss: 133.8867\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 131.5096 - val_loss: 135.2629\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 129.5504 - val_loss: 132.7232\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 129.7718 - val_loss: 132.7593\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 128.2365 - val_loss: 133.8938\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 129.9198 - val_loss: 134.6010\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 131.9412 - val_loss: 131.1892\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 130.3881 - val_loss: 133.3543\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 129.7100 - val_loss: 133.1341\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 129.3011 - val_loss: 132.0369\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 130.5425 - val_loss: 133.5568\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 130.1865 - val_loss: 132.3454\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 128.6405 - val_loss: 132.5350\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 127.7356 - val_loss: 130.3313\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 126.4589 - val_loss: 130.7938\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 126.6996 - val_loss: 131.6595\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 125.4563 - val_loss: 130.2552\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 125.2282 - val_loss: 129.1458\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 125.6791 - val_loss: 132.1399\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 125.3078 - val_loss: 130.3406\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 124.1299 - val_loss: 130.1133\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 123.4601 - val_loss: 129.8085\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 124.6371 - val_loss: 128.5583\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 124.1169 - val_loss: 128.5847\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 124.3888 - val_loss: 130.4596\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 123.2912 - val_loss: 128.7373\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.8175 - val_loss: 128.6883\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.5291 - val_loss: 128.4687\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.9106 - val_loss: 129.6441\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 124.8336 - val_loss: 129.8020\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 123.3958 - val_loss: 130.1425\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 125.2837 - val_loss: 129.5031\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 123.1931 - val_loss: 129.9855\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.2802 - val_loss: 128.8028\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.1713 - val_loss: 128.5436\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.5121 - val_loss: 131.2126\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 123.0222 - val_loss: 128.9624\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.0146 - val_loss: 128.6050\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 121.8401 - val_loss: 129.5895\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 121.3348 - val_loss: 129.8893\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 121.8927 - val_loss: 128.8563\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 121.5025 - val_loss: 129.5623\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 121.3332 - val_loss: 128.8156\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 120.9976 - val_loss: 128.4836\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 120.1719 - val_loss: 128.4674\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 120.2763 - val_loss: 128.3925\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 119.9769 - val_loss: 129.6951\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 119.7687 - val_loss: 130.1734\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 119.9133 - val_loss: 129.3609\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 120.3362 - val_loss: 129.7425\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 119.1056 - val_loss: 129.1348\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 119.2451 - val_loss: 129.3545\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 119.0652 - val_loss: 128.7414\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 118.7016 - val_loss: 130.1277\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 118.9058 - val_loss: 129.5159\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 118.9389 - val_loss: 129.3903\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 118.8994 - val_loss: 129.7211\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 118.3809 - val_loss: 129.2658\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 117.8497 - val_loss: 129.8053\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 117.7985 - val_loss: 129.9773\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 117.8487 - val_loss: 129.4062\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 117.1680 - val_loss: 128.3666\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 117.8395 - val_loss: 129.7565\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 117.4100 - val_loss: 129.0353\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 116.3486 - val_loss: 129.8528\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 117.3455 - val_loss: 128.9223\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 117.1874 - val_loss: 128.9093\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 116.0336 - val_loss: 129.1053\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 116.1670 - val_loss: 129.4440\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 115.7986 - val_loss: 130.7113\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 116.1322 - val_loss: 129.4581\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 116.5033 - val_loss: 130.5381\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 115.9204 - val_loss: 129.7098\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 115.8259 - val_loss: 129.1213\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 115.0719 - val_loss: 129.7562\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 115.1056 - val_loss: 130.1950\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 114.8258 - val_loss: 130.7621\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 116.0912 - val_loss: 129.3820\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 114.7380 - val_loss: 130.0658\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 114.4509 - val_loss: 129.4948\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 114.7119 - val_loss: 129.7039\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 115.1564 - val_loss: 130.0345\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 116.3861 - val_loss: 128.8727\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 114.7029 - val_loss: 129.7488\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 114.7367 - val_loss: 130.3020\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 114.7398 - val_loss: 130.1813\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 113.3904 - val_loss: 130.5768\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 114.1503 - val_loss: 130.9813\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 113.9075 - val_loss: 130.5085\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 113.5621 - val_loss: 130.3728\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 112.9950 - val_loss: 130.1683\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 114.3715 - val_loss: 129.6131\n",
      "'########################################################Model2\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 9ms/step - loss: 152.7413 - val_loss: 145.1774\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 141.0208 - val_loss: 139.5114\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 137.7504 - val_loss: 140.3580\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 137.8894 - val_loss: 138.8347\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 135.7742 - val_loss: 140.2568\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 136.2464 - val_loss: 137.4904\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 135.6461 - val_loss: 137.7370\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 138.0477 - val_loss: 138.5256\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 136.6311 - val_loss: 137.6743\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 137.3915 - val_loss: 138.5001\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 136.6042 - val_loss: 139.3145\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 136.4233 - val_loss: 137.5873\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 134.8107 - val_loss: 137.2086\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 135.3656 - val_loss: 138.5596\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 134.8992 - val_loss: 137.2129\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 134.6779 - val_loss: 137.0765\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 134.5285 - val_loss: 136.4177\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 131.6292 - val_loss: 135.0811\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 134.0042 - val_loss: 136.9142\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 127.9345 - val_loss: 132.9263\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 128.1973 - val_loss: 135.4172\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 126.2741 - val_loss: 133.5643\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 126.3920 - val_loss: 133.4550\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 125.3092 - val_loss: 132.7856\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 125.3994 - val_loss: 130.7399\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 124.6673 - val_loss: 131.4554\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 124.1158 - val_loss: 130.7589\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 123.6093 - val_loss: 130.2520\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 123.8236 - val_loss: 131.4623\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 123.6586 - val_loss: 131.6150\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 121.9739 - val_loss: 130.8927\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.3857 - val_loss: 130.8789\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.6241 - val_loss: 131.5798\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 121.7924 - val_loss: 129.4569\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 121.8563 - val_loss: 131.0310\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.2151 - val_loss: 131.0050\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 121.3736 - val_loss: 131.1314\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 121.1898 - val_loss: 131.0404\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 121.1263 - val_loss: 129.4152\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 120.3494 - val_loss: 129.3923\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 120.1816 - val_loss: 129.6413\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 119.0361 - val_loss: 130.0890\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 118.5307 - val_loss: 129.5972\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 119.1433 - val_loss: 130.2782\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 119.0105 - val_loss: 130.6983\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 119.0004 - val_loss: 130.6008\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 119.2154 - val_loss: 130.0403\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 119.6760 - val_loss: 130.1851\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 118.6298 - val_loss: 129.6676\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 118.8880 - val_loss: 132.0715\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 118.4088 - val_loss: 131.1494\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 117.3285 - val_loss: 130.2518\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 118.3990 - val_loss: 129.2930\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 116.8499 - val_loss: 128.6176\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 116.1260 - val_loss: 130.1711\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 116.8435 - val_loss: 129.0654\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 118.3257 - val_loss: 129.7349\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 116.7148 - val_loss: 131.5791\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 116.6151 - val_loss: 129.4415\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 115.7820 - val_loss: 130.3578\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 115.4497 - val_loss: 129.5685\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 115.3436 - val_loss: 130.4030\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 115.2455 - val_loss: 129.9802\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 116.7887 - val_loss: 130.4285\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 115.8827 - val_loss: 128.6379\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 115.4812 - val_loss: 130.6558\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 116.1889 - val_loss: 129.8934\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 115.7993 - val_loss: 129.2990\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 115.0896 - val_loss: 129.8443\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 114.2310 - val_loss: 130.2685\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 115.4976 - val_loss: 129.8370\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 114.1181 - val_loss: 130.2940\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 114.0843 - val_loss: 130.6146\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 113.7976 - val_loss: 130.1335\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 113.4857 - val_loss: 129.4733\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 113.3289 - val_loss: 130.0145\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 113.4008 - val_loss: 130.7390\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 112.7806 - val_loss: 130.2175\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 113.1171 - val_loss: 130.8066\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 112.8942 - val_loss: 130.7838\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 111.9134 - val_loss: 129.0552\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 111.9835 - val_loss: 131.6003\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 112.5561 - val_loss: 130.5079\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 111.7147 - val_loss: 129.8150\n",
      "'########################################################Model3\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 9ms/step - loss: 150.6979 - val_loss: 149.7253\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 148.7063 - val_loss: 148.7814\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 144.4949 - val_loss: 145.8079\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 143.3244 - val_loss: 145.7950\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 140.9865 - val_loss: 143.2694\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 142.1132 - val_loss: 143.6233\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 138.5527 - val_loss: 144.8962\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 138.7903 - val_loss: 139.6279\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 138.8561 - val_loss: 142.5788\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 139.2068 - val_loss: 140.2954\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 136.1273 - val_loss: 139.2495\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 136.6250 - val_loss: 139.4650\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 135.7939 - val_loss: 140.4027\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 134.3135 - val_loss: 139.2489\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 133.5362 - val_loss: 138.0763\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 134.2872 - val_loss: 138.1694\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 134.1797 - val_loss: 138.1004\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 132.7572 - val_loss: 136.9741\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 132.7534 - val_loss: 137.4859\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 132.9927 - val_loss: 137.4674\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 131.1984 - val_loss: 136.1368\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 131.1919 - val_loss: 136.6387\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 130.8061 - val_loss: 132.0934\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 126.2684 - val_loss: 132.4541\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 125.8074 - val_loss: 129.4142\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 124.9275 - val_loss: 128.6675\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 124.4225 - val_loss: 130.3213\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 124.3979 - val_loss: 129.9177\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 123.5020 - val_loss: 129.8522\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 123.2368 - val_loss: 129.4546\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 124.3472 - val_loss: 131.5367\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 124.2521 - val_loss: 129.0966\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 124.0557 - val_loss: 130.7094\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 123.8329 - val_loss: 129.2038\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.8407 - val_loss: 129.1266\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.2515 - val_loss: 129.1144\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.1508 - val_loss: 130.1014\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.2894 - val_loss: 128.2951\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 121.9397 - val_loss: 129.9538\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.1532 - val_loss: 128.7326\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 121.1352 - val_loss: 127.9277\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.3865 - val_loss: 129.9321\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 120.9605 - val_loss: 127.8758\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 121.0759 - val_loss: 129.3895\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 120.3033 - val_loss: 129.5366\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 120.1681 - val_loss: 128.4001\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 120.1184 - val_loss: 128.9362\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 120.6723 - val_loss: 128.6724\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 119.8755 - val_loss: 128.7544\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 119.7740 - val_loss: 129.1693\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 119.3308 - val_loss: 129.8418\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 120.2357 - val_loss: 129.0427\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 119.0918 - val_loss: 127.9871\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 119.4379 - val_loss: 128.9551\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 118.4814 - val_loss: 128.9439\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 118.1642 - val_loss: 129.0367\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 117.9180 - val_loss: 128.5926\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 117.3976 - val_loss: 129.6366\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 118.1131 - val_loss: 128.4552\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 118.1182 - val_loss: 129.6426\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 117.5878 - val_loss: 130.1742\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 116.9284 - val_loss: 128.6886\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 117.1285 - val_loss: 129.7772\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 116.9161 - val_loss: 129.2157\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 116.3186 - val_loss: 128.7693\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 115.9372 - val_loss: 130.0229\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 115.7043 - val_loss: 130.1236\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 115.5110 - val_loss: 128.8682\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 115.0655 - val_loss: 129.1329\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 114.6140 - val_loss: 130.7598\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 115.2617 - val_loss: 129.9897\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 115.0725 - val_loss: 130.4866\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 114.7481 - val_loss: 128.9427\n",
      "'########################################################Model4\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 3s 9ms/step - loss: 140.5728 - val_loss: 138.3682\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 133.0187 - val_loss: 137.7351\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 132.8740 - val_loss: 137.4719\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 133.3752 - val_loss: 133.3659\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 129.4689 - val_loss: 134.9227\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 132.5137 - val_loss: 135.4988\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 129.9893 - val_loss: 137.4394\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 129.0090 - val_loss: 133.5102\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 129.2747 - val_loss: 131.8429\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 127.1600 - val_loss: 130.4849\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 127.5336 - val_loss: 133.1385\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 127.7655 - val_loss: 131.8042\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 126.5542 - val_loss: 130.8881\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 127.0775 - val_loss: 130.3839\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 125.9993 - val_loss: 130.5974\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 125.0906 - val_loss: 132.7169\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 126.7712 - val_loss: 130.5165\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 124.0384 - val_loss: 129.5050\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 125.5815 - val_loss: 129.5145\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 125.1922 - val_loss: 130.8073\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 124.4357 - val_loss: 129.5169\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 123.9667 - val_loss: 128.9266\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 124.0873 - val_loss: 129.1273\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 123.5568 - val_loss: 130.1746\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 123.0592 - val_loss: 130.4153\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 123.5006 - val_loss: 128.7948\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 123.1548 - val_loss: 128.4243\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 123.4765 - val_loss: 128.3409\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.8526 - val_loss: 130.1632\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.2699 - val_loss: 129.4878\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.4861 - val_loss: 130.0868\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.1283 - val_loss: 129.3904\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.5704 - val_loss: 129.4695\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.3371 - val_loss: 128.0500\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 121.2282 - val_loss: 128.4455\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 121.3546 - val_loss: 128.3484\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.9661 - val_loss: 128.4862\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 122.2133 - val_loss: 127.7996\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 121.7217 - val_loss: 131.1136\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 121.5628 - val_loss: 129.3364\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 121.5711 - val_loss: 128.9498\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 120.4415 - val_loss: 130.1170\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 120.8102 - val_loss: 129.0605\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 120.9473 - val_loss: 128.7954\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 120.8096 - val_loss: 130.0853\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 120.2198 - val_loss: 129.4871\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 119.9914 - val_loss: 131.2821\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 119.8976 - val_loss: 130.7754\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 119.9770 - val_loss: 128.6617\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 119.7297 - val_loss: 130.4882\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 119.9134 - val_loss: 128.1348\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 119.2102 - val_loss: 129.3112\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 119.0758 - val_loss: 128.3792\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 118.7710 - val_loss: 129.5596\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 118.6467 - val_loss: 128.8925\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 119.0449 - val_loss: 130.6684\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 118.4738 - val_loss: 128.6495\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 117.6916 - val_loss: 130.0665\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 118.6811 - val_loss: 130.3584\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 0s 6ms/step - loss: 118.9090 - val_loss: 130.5186\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 118.5105 - val_loss: 129.9911\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 117.6793 - val_loss: 130.0316\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 117.6544 - val_loss: 130.3897\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 117.0902 - val_loss: 129.9101\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 116.6314 - val_loss: 129.7911\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 116.5823 - val_loss: 130.6608\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 116.6188 - val_loss: 131.1774\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 116.3921 - val_loss: 129.8527\n",
      "'########################################################Model5\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 9ms/step - loss: 139.3063 - val_loss: 140.2760\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 140.5884 - val_loss: 141.0314\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 138.5150 - val_loss: 137.8936\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 140.4966 - val_loss: 142.1994\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 140.1311 - val_loss: 139.4804\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 134.2509 - val_loss: 135.3029\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 129.9423 - val_loss: 131.7458\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 131.1261 - val_loss: 136.0010\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 128.7974 - val_loss: 133.3916\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 128.6900 - val_loss: 136.7952\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 128.4759 - val_loss: 130.9825\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 127.0112 - val_loss: 133.4007\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 127.4299 - val_loss: 135.0536\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 127.0605 - val_loss: 131.1047\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 125.2021 - val_loss: 128.7605\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 125.3577 - val_loss: 131.5692\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 125.0571 - val_loss: 129.4196\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 127.6574 - val_loss: 129.2570\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 126.6897 - val_loss: 132.2280\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 128.1308 - val_loss: 133.0287\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 127.5590 - val_loss: 131.6779\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 126.0629 - val_loss: 131.4911\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 125.5778 - val_loss: 133.8234\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 125.2349 - val_loss: 130.0178\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 124.1770 - val_loss: 128.4927\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 124.6064 - val_loss: 130.2169\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 123.9765 - val_loss: 130.0063\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 123.6818 - val_loss: 129.1560\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 123.1772 - val_loss: 129.5723\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 123.3219 - val_loss: 129.8652\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 123.4923 - val_loss: 130.4245\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 123.2381 - val_loss: 128.2318\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 123.8637 - val_loss: 130.4160\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 123.0065 - val_loss: 128.5002\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.1688 - val_loss: 130.2973\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.4758 - val_loss: 128.2760\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.2616 - val_loss: 128.5382\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 121.6000 - val_loss: 128.6880\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.0590 - val_loss: 127.8196\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 121.7807 - val_loss: 129.2027\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 121.6666 - val_loss: 127.8050\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.2050 - val_loss: 129.3267\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 121.5655 - val_loss: 128.8882\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 120.7920 - val_loss: 129.3276\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 120.4507 - val_loss: 127.7047\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 121.8238 - val_loss: 134.4654\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.1720 - val_loss: 129.2740\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 120.4725 - val_loss: 128.8853\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 120.5005 - val_loss: 129.5598\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 120.3881 - val_loss: 129.0426\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 119.8027 - val_loss: 128.1616\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 119.9216 - val_loss: 128.8826\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 119.0997 - val_loss: 128.7682\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 120.2059 - val_loss: 128.2270\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 119.4869 - val_loss: 129.4998\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 119.0225 - val_loss: 128.6524\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 118.3849 - val_loss: 128.1639\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 118.8103 - val_loss: 129.2112\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 118.4322 - val_loss: 129.6401\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 118.3643 - val_loss: 130.6017\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 118.1431 - val_loss: 129.2531\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 117.6820 - val_loss: 128.6600\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 117.6574 - val_loss: 129.3906\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 118.1717 - val_loss: 129.3376\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 117.7202 - val_loss: 128.5901\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 116.9300 - val_loss: 128.4051\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 117.9329 - val_loss: 128.5674\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 117.3573 - val_loss: 128.8522\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 116.6178 - val_loss: 128.5352\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 116.2349 - val_loss: 128.5090\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 115.8269 - val_loss: 129.1613\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 115.7509 - val_loss: 129.4663\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 116.8639 - val_loss: 128.5577\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 115.7841 - val_loss: 129.0724\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 116.3903 - val_loss: 128.8307\n",
      "'########################################################Model6\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 9ms/step - loss: 146.1642 - val_loss: 145.6080\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 140.9321 - val_loss: 141.1504\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 140.7303 - val_loss: 143.6047\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 139.6784 - val_loss: 140.8561\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 140.4116 - val_loss: 144.2943\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 142.0386 - val_loss: 140.2702\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 138.9896 - val_loss: 140.1080\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 139.5461 - val_loss: 143.0658\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 138.0251 - val_loss: 141.9987\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 139.2453 - val_loss: 142.0785\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 140.5695 - val_loss: 140.6939\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 138.9711 - val_loss: 140.1368\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 137.5957 - val_loss: 139.8429\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 137.2498 - val_loss: 140.5476\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 136.8294 - val_loss: 142.7518\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 134.9866 - val_loss: 139.0311\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 137.1384 - val_loss: 139.5179\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 133.8183 - val_loss: 137.8546\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 132.4095 - val_loss: 136.7408\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 132.8547 - val_loss: 137.0630\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 132.6536 - val_loss: 136.6742\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 131.7594 - val_loss: 136.8954\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 131.5914 - val_loss: 137.7660\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 130.1686 - val_loss: 135.9564\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 130.8488 - val_loss: 136.5408\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 130.2945 - val_loss: 132.1718\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 124.1484 - val_loss: 128.8406\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 123.5552 - val_loss: 129.6392\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 124.1528 - val_loss: 131.4106\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 125.3447 - val_loss: 130.2641\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 123.8369 - val_loss: 130.1537\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 123.2131 - val_loss: 129.0785\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.7139 - val_loss: 130.7316\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 123.1768 - val_loss: 129.9729\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.2064 - val_loss: 128.6048\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.1837 - val_loss: 129.6009\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 121.9801 - val_loss: 128.8564\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.0766 - val_loss: 129.5589\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 121.1966 - val_loss: 128.6880\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 121.8023 - val_loss: 128.5648\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 120.6513 - val_loss: 130.3150\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 120.9915 - val_loss: 129.5009\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 121.9627 - val_loss: 128.7396\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 121.3553 - val_loss: 130.8510\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 120.7215 - val_loss: 129.5015\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 120.3980 - val_loss: 128.4543\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 119.2221 - val_loss: 129.7819\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 121.0351 - val_loss: 129.0827\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 120.5340 - val_loss: 129.0595\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 119.0586 - val_loss: 128.7802\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 118.9151 - val_loss: 128.7533\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 118.9199 - val_loss: 129.5382\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 118.6547 - val_loss: 131.7929\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 118.9713 - val_loss: 128.6313\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 117.9392 - val_loss: 128.5059\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 117.6491 - val_loss: 128.6472\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 118.4298 - val_loss: 128.8721\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 117.2424 - val_loss: 128.5197\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 117.1957 - val_loss: 128.9848\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 116.5122 - val_loss: 129.3442\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 116.8972 - val_loss: 129.4979\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 116.8785 - val_loss: 129.7512\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 116.3540 - val_loss: 129.8641\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 116.3585 - val_loss: 128.9244\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 116.1643 - val_loss: 129.1507\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 115.7935 - val_loss: 128.0893\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 115.7624 - val_loss: 129.2497\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 115.2325 - val_loss: 129.1781\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 114.8632 - val_loss: 129.2947\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 114.5370 - val_loss: 130.4385\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 114.7311 - val_loss: 129.1498\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 115.4047 - val_loss: 130.7124\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 114.6068 - val_loss: 129.6385\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 114.2565 - val_loss: 128.7456\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 114.8348 - val_loss: 128.9594\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 114.2144 - val_loss: 128.7141\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 113.3483 - val_loss: 129.2066\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 113.2804 - val_loss: 130.2227\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 113.2081 - val_loss: 129.4494\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 112.8269 - val_loss: 128.9960\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 113.9600 - val_loss: 130.4745\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 113.5107 - val_loss: 129.0830\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 112.5724 - val_loss: 129.5816\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 112.1038 - val_loss: 131.2188\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 113.4438 - val_loss: 128.7852\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 112.3918 - val_loss: 129.7438\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 112.0577 - val_loss: 129.3073\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 112.2221 - val_loss: 129.5588\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 111.9110 - val_loss: 130.1514\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 111.8691 - val_loss: 130.0961\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 111.5639 - val_loss: 130.3015\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 111.0483 - val_loss: 129.4265\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 110.9392 - val_loss: 129.6730\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 110.7901 - val_loss: 131.2594\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 110.5966 - val_loss: 130.5371\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 110.4140 - val_loss: 130.0937\n",
      "'########################################################Model7\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 9ms/step - loss: 152.2476 - val_loss: 149.8217\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 146.9901 - val_loss: 149.0004\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 150.6122 - val_loss: 148.9540\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 140.8810 - val_loss: 142.8972\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 141.4146 - val_loss: 147.9761\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 145.1174 - val_loss: 142.6602\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 137.8601 - val_loss: 141.6871\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 144.3826 - val_loss: 145.3770\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 136.9374 - val_loss: 136.6826\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 133.1492 - val_loss: 133.0289\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 135.5203 - val_loss: 134.0144\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 132.7060 - val_loss: 133.9608\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 132.4460 - val_loss: 135.6383\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 131.6180 - val_loss: 135.3211\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 129.7056 - val_loss: 132.7199\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 128.6264 - val_loss: 133.2112\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 130.2205 - val_loss: 135.6893\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 128.9332 - val_loss: 131.4419\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 128.8000 - val_loss: 133.8620\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 128.1476 - val_loss: 132.4128\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 128.4337 - val_loss: 131.9394\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 129.2916 - val_loss: 133.3697\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 127.6221 - val_loss: 131.5405\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 127.8142 - val_loss: 131.4995\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 126.6062 - val_loss: 131.6377\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 126.7585 - val_loss: 132.2457\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 126.4079 - val_loss: 131.0759\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 126.7088 - val_loss: 131.3129\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 126.7285 - val_loss: 130.7292\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 125.9027 - val_loss: 131.5489\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 125.6836 - val_loss: 131.0394\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 125.6040 - val_loss: 132.2845\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 125.0287 - val_loss: 131.3878\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 125.5713 - val_loss: 131.7943\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 126.1441 - val_loss: 131.5676\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 123.1102 - val_loss: 132.0934\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.6702 - val_loss: 131.2025\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.7907 - val_loss: 130.9020\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.2257 - val_loss: 129.2942\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 121.5604 - val_loss: 128.4779\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 121.5024 - val_loss: 129.3510\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 121.1212 - val_loss: 130.4834\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 120.9704 - val_loss: 129.4182\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 119.9015 - val_loss: 129.0439\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 119.9618 - val_loss: 131.2605\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 121.0826 - val_loss: 129.8882\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 119.8626 - val_loss: 129.3800\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 120.0825 - val_loss: 130.8396\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 119.5728 - val_loss: 128.4564\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 119.7477 - val_loss: 129.4746\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 118.6783 - val_loss: 130.5233\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 120.4757 - val_loss: 130.3370\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 119.2720 - val_loss: 129.7863\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 118.6328 - val_loss: 129.5406\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 117.4584 - val_loss: 129.5121\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 118.3669 - val_loss: 129.0291\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 118.5223 - val_loss: 130.2649\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 118.0805 - val_loss: 128.0974\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 116.8187 - val_loss: 128.8484\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 117.4866 - val_loss: 130.0798\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 118.1285 - val_loss: 129.4016\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 117.0558 - val_loss: 128.1966\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 116.9298 - val_loss: 129.0665\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 116.2318 - val_loss: 128.6308\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 116.1001 - val_loss: 130.7775\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 116.1800 - val_loss: 127.9719\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 116.0690 - val_loss: 127.6813\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 115.4061 - val_loss: 128.4750\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 115.5141 - val_loss: 128.3351\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 115.9561 - val_loss: 129.2295\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 114.5212 - val_loss: 129.7154\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 115.5799 - val_loss: 128.5883\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 114.9717 - val_loss: 129.2565\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 115.5395 - val_loss: 128.8773\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 114.8104 - val_loss: 128.1820\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 114.5538 - val_loss: 128.6380\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 114.2032 - val_loss: 129.3635\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 113.1312 - val_loss: 129.4431\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 113.6661 - val_loss: 128.5914\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 113.2625 - val_loss: 128.8154\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 112.6971 - val_loss: 129.5563\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 112.5229 - val_loss: 129.7949\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 112.0268 - val_loss: 128.9245\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 111.9175 - val_loss: 129.6703\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 112.2813 - val_loss: 129.0237\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 111.3948 - val_loss: 128.6157\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 111.7091 - val_loss: 129.7240\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 111.7435 - val_loss: 129.8563\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 113.7871 - val_loss: 128.9378\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 112.5418 - val_loss: 129.1755\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 113.9107 - val_loss: 129.0742\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 113.2661 - val_loss: 129.3306\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 111.8735 - val_loss: 129.2000\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 112.6725 - val_loss: 128.7736\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 112.4097 - val_loss: 128.6917\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 111.0616 - val_loss: 129.7903\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 110.5736 - val_loss: 129.5037\n",
      "'########################################################Model8\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 9ms/step - loss: 148.8988 - val_loss: 150.4014\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 146.5172 - val_loss: 152.0262\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 142.4402 - val_loss: 141.3302\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 142.1478 - val_loss: 142.6477\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 138.9374 - val_loss: 140.5429\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 138.0646 - val_loss: 142.6002\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 139.7385 - val_loss: 141.8082\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 139.7882 - val_loss: 141.0966\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 137.5122 - val_loss: 141.6277\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 133.6320 - val_loss: 133.8331\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 133.0386 - val_loss: 133.7315\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 131.4171 - val_loss: 134.5916\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 129.8936 - val_loss: 133.8138\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 131.0802 - val_loss: 132.9450\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 129.6656 - val_loss: 133.7026\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 129.9460 - val_loss: 133.1380\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 131.1303 - val_loss: 134.2279\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 129.5836 - val_loss: 131.2212\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 128.6512 - val_loss: 132.4689\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 127.8921 - val_loss: 132.2144\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 127.6441 - val_loss: 132.6962\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 127.8489 - val_loss: 130.8591\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 126.1161 - val_loss: 131.6183\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 127.7558 - val_loss: 132.2713\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 125.1456 - val_loss: 129.9314\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 123.9404 - val_loss: 130.0294\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 124.3499 - val_loss: 128.8187\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.9157 - val_loss: 129.5576\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 124.0549 - val_loss: 130.1334\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 124.0544 - val_loss: 131.1657\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 122.6130 - val_loss: 128.9726\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 123.1071 - val_loss: 129.8317\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.8350 - val_loss: 129.7224\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.8010 - val_loss: 129.7975\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 123.2685 - val_loss: 129.1966\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.4860 - val_loss: 129.7075\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.1819 - val_loss: 129.4953\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.6098 - val_loss: 129.5172\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.5623 - val_loss: 129.6695\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 121.8051 - val_loss: 130.0597\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 121.9856 - val_loss: 130.3622\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 121.4520 - val_loss: 129.3154\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 121.2269 - val_loss: 129.8687\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 120.9323 - val_loss: 128.6373\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 121.2408 - val_loss: 129.6501\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 121.0332 - val_loss: 128.7739\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 120.2334 - val_loss: 131.3330\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 120.7582 - val_loss: 129.9917\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 119.5510 - val_loss: 128.4441\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 119.5716 - val_loss: 129.6096\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 119.1911 - val_loss: 130.5619\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 119.0961 - val_loss: 128.8645\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 118.6583 - val_loss: 130.4409\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 118.7727 - val_loss: 129.5011\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 118.8011 - val_loss: 130.1452\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 117.9742 - val_loss: 129.1935\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 117.8168 - val_loss: 128.9013\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 118.1276 - val_loss: 129.4617\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 117.8550 - val_loss: 129.6461\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 117.9898 - val_loss: 129.4902\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 117.1957 - val_loss: 128.3932\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 117.1740 - val_loss: 131.8830\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 116.8223 - val_loss: 130.6662\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 116.5039 - val_loss: 129.0340\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 116.7601 - val_loss: 130.4592\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 116.2147 - val_loss: 129.0393\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 116.8085 - val_loss: 129.7543\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 115.7708 - val_loss: 130.2930\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 116.0673 - val_loss: 130.3634\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 115.2832 - val_loss: 130.5252\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 115.2145 - val_loss: 130.0958\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 115.5125 - val_loss: 129.6054\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 115.3405 - val_loss: 128.9758\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 114.9546 - val_loss: 129.3026\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 114.6450 - val_loss: 130.2273\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 114.5582 - val_loss: 128.9028\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 114.6797 - val_loss: 131.7951\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 114.9205 - val_loss: 130.4979\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 115.1340 - val_loss: 130.0650\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 114.0811 - val_loss: 129.7521\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 114.2530 - val_loss: 129.5110\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 113.5310 - val_loss: 129.9551\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 113.4597 - val_loss: 130.3599\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 113.3157 - val_loss: 128.6297\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 112.5955 - val_loss: 129.2947\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 112.8285 - val_loss: 129.7159\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 112.9304 - val_loss: 128.8051\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 112.8564 - val_loss: 129.8568\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 112.5111 - val_loss: 129.9391\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 111.6509 - val_loss: 129.1264\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 112.1399 - val_loss: 130.1254\n",
      "'########################################################Model9\n"
     ]
    }
   ],
   "source": [
    "model_num = 10\n",
    "\n",
    "mase_models_G = train_bagging_models_G(model_num, MASE(y_train,24),300,30,8,0.0005)\n",
    "mape_models_G = train_bagging_models_G(model_num,'mape',300,30,8,0.0005)\n",
    "smape_models_G = train_bagging_models_G(model_num, SMAPE(),300,30,8,0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc208e0-5d61-4b8f-a16c-367a71c4fd26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "710bc729-fad7-43fd-8316-3f186071c1a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356, 168)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dadee4a-9500-45e2-8e2c-d49c03fe54f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b8e382f-5a29-464f-abe0-eeee880e371b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.2085259828563707, 0.2355006375401909)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred1,_=smape_models_G\n",
    "pred2,_=mase_models_G\n",
    "pred3,_=mape_models_G\n",
    "\n",
    "smape_predictions_G = bagging_predict2(pred1, test_X)\n",
    "mase_predictions_G = bagging_predict2(pred2, test_X)\n",
    "mape_predictions_G = bagging_predict2(pred3, test_X)\n",
    "concat_G = np.concatenate([smape_predictions_G, mase_predictions_G,mape_predictions_G],axis=0)\n",
    "fin_pred_G = np.median(concat_G,axis=0)\n",
    "#pd.DataFrame(fin_pred).to_csv(\"freezing_I.csv\")\n",
    "mean_squared_error(test_y.flatten(),fin_pred_G.flatten()),mean_absolute_error(test_y.flatten(),fin_pred_G.flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0763c952-878d-4ee7-8113-fe68df7b3e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2081588466784903, 0.23499467065824628)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pd.DataFrame(fin_pred_G.reshape(-1,24)).to_csv(\"../result5_new/NBEATs/pred_mid_G.csv\")\n",
    "for i in range(10):\n",
    "    pd.DataFrame(concat_G[i].reshape(-1,24)).to_csv(f\"../result5_new/NBEATs/pred_G{i}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
