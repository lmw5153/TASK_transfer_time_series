{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f0036d6-fe11-4032-9ebd-2bf63597776b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-29 21:10:13.768151: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-29 21:10:13.842136: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-08-29 21:10:13.842152: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-08-29 21:10:14.200929: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-08-29 21:10:14.200977: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-08-29 21:10:14.200983: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nbeats_keras.model import NBeatsNet as NBeatsKeras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "#from nbeats_pytorch.model import NBeatsNet as NBeatsPytorch\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "import time\n",
    "from keras.models import load_model\n",
    "#from target_data_electronic70_7 import target_X, target_y ,test_X, test_y\n",
    "#from m4databasis21_7 import base_domain,zt_in,zt_out,M4Meta,inputsize,train_12,train_12_y\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error,mean_absolute_percentage_error\n",
    "plt.rcParams['font.family'] ='Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] =False\n",
    "from tensorflow.keras.losses import Loss\n",
    "import tensorflow as tf\n",
    "#from m4databasis35_7_70_7 import train_35,train_35_y,train_70,train_70_y\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, LayerNormalization, MultiHeadAttention, Dropout, Add, Concatenate,Flatten,Reshape\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c11e4f2-f795-4d8d-8c76-7cd76c0187d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((723, 120), (358, 120))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "target_X= pd.read_csv(\"../data/solor_train_input_5.csv\").iloc[:,(1):].values\n",
    "target_y =pd.read_csv(\"../data/solor_train_output_5.csv\").iloc[:,1:].values\n",
    "test_X= pd.read_csv(\"../data/solor_val_input_5.csv\").iloc[:,(1):].values\n",
    "test_y =pd.read_csv(\"../data/solor_val_output_5.csv\").iloc[:,1:].values\n",
    "#backcast_length = X_train.shape[1]\n",
    "#forecast_length = y_train.shape[1]\n",
    "\n",
    "X_train= target_X\n",
    "\n",
    "y_train=target_y\n",
    "\n",
    "target_X.shape,test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cff7750c-7635-4132-984a-0f92f50db72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "# loss SMAPE\n",
    "class SMAPE(Loss):\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_pred = tf.reshape(y_pred, tf.shape(y_true))  # 예측 값의 차원을 맞춤\n",
    "       # y_pred=tf.clip_by_value(y_pred, 1e-10, tf.reduce_max(y_pred))\n",
    "       # y_true = tf.clip_by_value(y_true, 1e-10, tf.reduce_max(y_true))\n",
    "        \n",
    "        numerator = 100 * tf.abs(y_true- y_pred )\n",
    "        denominator =  (tf.abs(y_true ) + tf.abs(y_pred))/2\n",
    "        smape =  numerator /  denominator #tf.clip_by_value(denominator, 1e-10, tf.reduce_max(denominator))\n",
    "        return tf.reduce_mean(smape)\n",
    "\n",
    "#################################################################################\n",
    "# loss MASE\n",
    "class MASE(Loss):\n",
    "    def __init__(self, training_data, period, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.scale = self.calculate_scale(training_data, period)\n",
    "    def seasonal_diff(data, period):\n",
    "        return data[period:] - data[:-period]\n",
    "\n",
    "    def calculate_scale(self, training_data, period):\n",
    "        # 주기 차분 계산\n",
    "        diff = seasonal_diff(training_data, period)\n",
    "        scale = np.mean(np.abs(diff))\n",
    "        return scale\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        y_pred = tf.reshape(y_pred, tf.shape(y_true))  # 차원 맞추기\n",
    "        error = tf.abs(y_true - y_pred)\n",
    "        return tf.reduce_mean(error / self.scale)\n",
    "\n",
    "def seasonal_diff(data, period):\n",
    "    return data[period:] - data[:-period]\n",
    "\n",
    "#################################################################################\n",
    "#################################################################################\n",
    "# 하이퍼파라미터 인자 설정\n",
    "def hyperparameter():\n",
    "    # 1 backcast\n",
    "    # 2 forecast\n",
    "    # 3 unit\n",
    "    # 4 nhead\n",
    "    # 5 nlayers\n",
    "    # dropout\n",
    "    return X_train.shape[1],y_train.shape[1],64,1,1,0.1\n",
    "\n",
    "#################################################################################\n",
    "# nbeats + I모델 부트스트랩 샘플링 배깅\n",
    "\n",
    "def train_bagging_models(num_models, loss_fn , epochs_, patience_,batch_size_,lr):\n",
    "    models = {}\n",
    "    backcast,forecast,in_dim,out_dim,unit = hyperparameter()\n",
    "    historys = []\n",
    "    for n in range(num_models):\n",
    "        K.clear_session()\n",
    "        model = bulid_model(backcast,forecast,in_dim,out_dim,unit)\n",
    "       # model.set_weights(pretrained_weights)  # 전이 학습 가중치 적용\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "        model.compile(optimizer=optimizer , loss=loss_fn)\n",
    "        \n",
    "        # 부트스트랩 샘플링\n",
    "        #select = np.random.choice(len(X_train), size=len(X_train), replace=True)\n",
    "        #X_bootstrap = X_train[select]\n",
    "        #y_bootstrap = y_train[select]\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience = patience_, verbose = 0, restore_best_weights=True)\n",
    "        history = model.fit(X_train, y_train, batch_size = batch_size_,\n",
    "                  epochs=epochs_, verbose=1, \n",
    "                  callbacks=[early_stop],\n",
    "                 validation_split = 0.2)\n",
    "        models[f'model_{n+1}'] = model\n",
    "        historys.append(history)\n",
    "        #models.append(model)\n",
    "        print(f\"'########################################################Model{n}\")\n",
    "    return models,historys\n",
    "#################################################################################\n",
    "# nbeats + I모델 부트스트랩 샘플링 배깅\n",
    "\n",
    "def train_bagging_models_G(num_models, loss_fn , epochs_, patience_,batch_size_,lr):\n",
    "    models = {}\n",
    "    backcast,forecast,in_dim,out_dim,unit = hyperparameter()\n",
    "    historys = []\n",
    "    for n in range(num_models):\n",
    "        K.clear_session()\n",
    "        model = bulid_model_G(backcast,forecast,in_dim,out_dim,unit)\n",
    "       # model.set_weights(pretrained_weights)  # 전이 학습 가중치 적용\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "        model.compile(optimizer=optimizer , loss=loss_fn)\n",
    "        \n",
    "        # 부트스트랩 샘플링\n",
    "        select = np.random.choice(len(X_train), size=len(X_train), replace=True)\n",
    "        X_bootstrap = X_train[select]\n",
    "        y_bootstrap = y_train[select]\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience = patience_, verbose = 0, restore_best_weights=True)\n",
    "        history = model.fit(X_bootstrap, y_bootstrap, batch_size = batch_size_,\n",
    "                  epochs=epochs_, verbose=1, \n",
    "                  callbacks=[early_stop],\n",
    "                 validation_split = 0.2)\n",
    "        models[f'model_{n+1}'] = model\n",
    "        historys.append(history)\n",
    "        #models.append(model)\n",
    "        print(f\"'########################################################Model{n}\")\n",
    "    return models,historys\n",
    "\n",
    "#################################################################################\n",
    "# SMAPE 용\n",
    "def train_bagging_models_smape(num_models, loss_fn , epochs_, patience_,batch_size_,lr):\n",
    "    models = {}\n",
    "    backcast,forecast,in_dim,out_dim,unit = hyperparameter()\n",
    "    historys = []\n",
    "    for n in range(num_models):\n",
    "        K.clear_session()\n",
    "        model = bulid_model(backcast,forecast,in_dim,out_dim,unit)\n",
    "       # model.set_weights(pretrained_weights)  # 전이 학습 가중치 적용\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "        model.compile(optimizer=optimizer , loss=loss_fn)\n",
    "        \n",
    "        # 부트스트랩 샘플링\n",
    "        select = np.random.choice(len(X_train), size=len(X_train), replace=True)\n",
    "        X_bootstrap = X_train[select]\n",
    "        y_bootstrap = y_train[select]\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience = patience_, verbose = 0, restore_best_weights=True)\n",
    "        history = model.fit(X_bootstrap, y_bootstrap, batch_size = batch_size_,\n",
    "                  epochs=epochs_, verbose=1, \n",
    "                  callbacks=[early_stop],\n",
    "                 validation_split = 0.2)\n",
    "        models[f'model_{n+1}'] = model\n",
    "        historys.append(history)\n",
    "        #models.append(model)\n",
    "        print(f\"'########################################################Model{n}\")\n",
    "    return models,historys\n",
    "\n",
    "##########################################################################################\n",
    "# 트랜스퍼 레이어\n",
    "class PositionalEncoding(layers.Layer):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = layers.Dropout(rate=dropout)\n",
    "\n",
    "        position = np.arange(max_len)[:, np.newaxis]\n",
    "        div_term = np.exp(np.arange(0, d_model, 2) * (-np.log(10000.0) / d_model))\n",
    "        pe = np.zeros((max_len, d_model))\n",
    "        pe[:, 0::2] = np.sin(position * div_term)\n",
    "        pe[:, 1::2] = np.cos(position * div_term)\n",
    "        pe = pe[np.newaxis, ...]\n",
    "\n",
    "        self.pe = tf.constant(pe, dtype=tf.float32)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = x + self.pe[:, :tf.shape(x)[1], :]\n",
    "        return self.dropout(x)\n",
    "##########################################################################################\n",
    "# 트랜스퍼 레이어\n",
    "def create_model(fn,d_model, nlayers, nhead, dropout, iw, ow,lr):\n",
    "    \n",
    "    \n",
    "    x = layers.Dense(d_model // 2, activation='relu')(pretrained_output_reshaped)\n",
    "    x = layers.Dense(d_model, activation='relu')(x)\n",
    "    \n",
    "    pos_encoding = PositionalEncoding(d_model, dropout)\n",
    "    x = pos_encoding(x)\n",
    "    \n",
    "    for _ in range(nlayers):\n",
    "        attn_output = layers.MultiHeadAttention(num_heads=nhead, key_dim=d_model, dropout=dropout)(x, x)\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x + attn_output)\n",
    "        ffn_output = layers.Dense(d_model, activation='relu')(x)\n",
    "        ffn_output = layers.Dense(d_model)(ffn_output)\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x + ffn_output)\n",
    "    \n",
    "    x = layers.Dense(d_model // 2, activation='relu')(x)\n",
    "    x = layers.Dense(1)(x)\n",
    "    x = tf.squeeze(x, axis=-1)\n",
    "    \n",
    "    outputs = layers.Dense((iw + ow) // 2, activation='relu')(x)\n",
    "    outputs = layers.Dense(ow)(outputs)\n",
    "    \n",
    "    optimizer = Adam(learning_rate=lr)\n",
    "    target_model = Model(inputs=inputs, outputs=outputs)\n",
    "    target_model.compile(optimizer=optimizer, loss=fn)\n",
    "    \n",
    "    return target_model\n",
    "\n",
    "#################################################################################\n",
    "# 트랜스포머 모델 생성 함수\n",
    "def bulid_model(iw, ow, d_model, nhead, nlayers, dropout=0.5):\n",
    "    inputs = tf.keras.Input(shape=(iw, 1))\n",
    "    x = layers.Dense(d_model // 2, activation='relu')(inputs)\n",
    "    x = layers.Dense(d_model, activation='relu')(x)\n",
    "\n",
    "    pos_encoding = PositionalEncoding(d_model, dropout)\n",
    "    x = pos_encoding(x)\n",
    "\n",
    "    for _ in range(nlayers):\n",
    "        attn_output = layers.MultiHeadAttention(num_heads=nhead, key_dim=d_model, dropout=dropout)(x, x)\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x + attn_output)\n",
    "        ffn_output = layers.Dense(d_model, activation='relu')(x)\n",
    "        ffn_output = layers.Dense(d_model)(ffn_output)\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x + ffn_output)\n",
    "\n",
    "    x = layers.Dense(d_model // 2, activation='relu')(x)\n",
    "    x = layers.Dense(1)(x)\n",
    "    x = tf.squeeze(x, axis=-1)\n",
    "\n",
    "    outputs = layers.Dense((iw + ow) // 2, activation='relu')(x)\n",
    "    outputs = layers.Dense(ow)(outputs)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "#################################################################################\n",
    "# 부트스트랩 샘플링\n",
    "# 배깅\n",
    "\n",
    "def train_bagging_models(num_models, loss_fn , epochs_, patience_,batch_size_,lr=0.0005):\n",
    "    models = {}\n",
    "    iw, ow, d_model, nhead, nlayers, dropout = hyperparameter()\n",
    "    historys = []\n",
    "    for n in range(num_models):\n",
    "        K.clear_session()\n",
    "        model = bulid_model(iw, ow, d_model, nhead, nlayers, dropout=0.5)\n",
    "       # model.set_weights(pretrained_weights)  # 전이 학습 가중치 적용\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "        model.compile(optimizer=optimizer , loss=loss_fn)\n",
    "        \n",
    "        # 부트스트랩 샘플링\n",
    "        #select = np.random.choice(len(X_train), size=len(X_train), replace=True)\n",
    "        #X_bootstrap = X_train[select]\n",
    "        #y_bootstrap = y_train[select]\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience = patience_, verbose = 1, restore_best_weights=True)\n",
    "        history = model.fit(X_train, y_train, batch_size = batch_size_,\n",
    "                  epochs=epochs_, verbose=1, \n",
    "                  callbacks=[early_stop],\n",
    "                 validation_split = 0.2)\n",
    "        models[f'model_{n+1}'] = model\n",
    "        historys.append(history)\n",
    "        #models.append(model)\n",
    "        print(f\"'########################################################Model{n}\")\n",
    "    return models,historys\n",
    "#################################################################################\n",
    "# 예측\n",
    "\n",
    "def bagging_predict(models, X):\n",
    "    predictions = np.array([model.predict(X) for model in models.values()])\n",
    "    return np.median(predictions, axis=0)\n",
    "\n",
    "def bagging_predict2(models, X):\n",
    "    predictions = np.array([model.predict(X) for model in models.values()])\n",
    "    return predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93870f9b-5e3c-42bf-ae32-acfc580104ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-29 21:10:38.280365: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-08-29 21:10:38.280407: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ymlee2-desktop): /proc/driver/nvidia/version does not exist\n",
      "2024-08-29 21:10:38.280991: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 2s 10ms/step - loss: 1.7119 - val_loss: 0.8458\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 1.0496 - val_loss: 0.7553\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.9362 - val_loss: 0.7148\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.9077 - val_loss: 0.7469\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8997 - val_loss: 0.7400\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8909 - val_loss: 0.7363\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8760 - val_loss: 0.6869\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8612 - val_loss: 0.6531\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8479 - val_loss: 0.6590\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8275 - val_loss: 0.6620\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8348 - val_loss: 0.6617\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8212 - val_loss: 0.7202\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8129 - val_loss: 0.7339\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8176 - val_loss: 0.6457\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8151 - val_loss: 0.6440\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8204 - val_loss: 0.6306\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8032 - val_loss: 0.6383\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7965 - val_loss: 0.6451\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8047 - val_loss: 0.6562\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8088 - val_loss: 0.6534\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8199 - val_loss: 0.6325\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8016 - val_loss: 0.6508\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7944 - val_loss: 0.6425\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7879 - val_loss: 0.6231\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7909 - val_loss: 0.6271\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7843 - val_loss: 0.6310\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7789 - val_loss: 0.6242\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8005 - val_loss: 0.6430\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7818 - val_loss: 0.6361\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7754 - val_loss: 0.6379\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7868 - val_loss: 0.6708\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7886 - val_loss: 0.6526\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7826 - val_loss: 0.6379\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7731 - val_loss: 0.6408\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7846 - val_loss: 0.6159\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7851 - val_loss: 0.6166\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7809 - val_loss: 0.6172\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7733 - val_loss: 0.6100\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7821 - val_loss: 0.6555\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7864 - val_loss: 0.6192\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7924 - val_loss: 0.6113\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7719 - val_loss: 0.6128\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7698 - val_loss: 0.6088\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7628 - val_loss: 0.6167\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7678 - val_loss: 0.6091\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7725 - val_loss: 0.6085\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7669 - val_loss: 0.6094\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7570 - val_loss: 0.6095\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7727 - val_loss: 0.6082\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7651 - val_loss: 0.6171\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7693 - val_loss: 0.6177\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7620 - val_loss: 0.6106\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7598 - val_loss: 0.6167\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7727 - val_loss: 0.6068\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7678 - val_loss: 0.6204\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7586 - val_loss: 0.6036\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7624 - val_loss: 0.5981\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7601 - val_loss: 0.6066\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7761 - val_loss: 0.6087\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7613 - val_loss: 0.5940\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7724 - val_loss: 0.6165\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7661 - val_loss: 0.6168\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7660 - val_loss: 0.6157\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7720 - val_loss: 0.6273\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7633 - val_loss: 0.6431\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7621 - val_loss: 0.6130\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7627 - val_loss: 0.6166\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7686 - val_loss: 0.6018\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7591 - val_loss: 0.6141\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7558 - val_loss: 0.5956\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7546 - val_loss: 0.6154\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7535 - val_loss: 0.6062\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7507 - val_loss: 0.5925\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7544 - val_loss: 0.6052\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7604 - val_loss: 0.5986\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7557 - val_loss: 0.6575\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7627 - val_loss: 0.5995\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7583 - val_loss: 0.6038\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7561 - val_loss: 0.6098\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7519 - val_loss: 0.6003\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7467 - val_loss: 0.6144\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7445 - val_loss: 0.6051\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7519 - val_loss: 0.5967\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7641 - val_loss: 0.6345\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7581 - val_loss: 0.6030\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7445 - val_loss: 0.6066\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7584 - val_loss: 0.5920\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7487 - val_loss: 0.5892\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7502 - val_loss: 0.6040\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7489 - val_loss: 0.5909\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7482 - val_loss: 0.5859\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7540 - val_loss: 0.5976\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7540 - val_loss: 0.5882\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7495 - val_loss: 0.6214\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7474 - val_loss: 0.5921\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7404 - val_loss: 0.6107\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7513 - val_loss: 0.5840\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7429 - val_loss: 0.6025\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7398 - val_loss: 0.6063\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7498 - val_loss: 0.5950\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7454 - val_loss: 0.5870\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7449 - val_loss: 0.5914\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7538 - val_loss: 0.5943\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7424 - val_loss: 0.5920\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7356 - val_loss: 0.5819\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7478 - val_loss: 0.6333\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7526 - val_loss: 0.5876\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7410 - val_loss: 0.6019\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7531 - val_loss: 0.5881\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7482 - val_loss: 0.5950\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7460 - val_loss: 0.5952\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7502 - val_loss: 0.6000\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7363 - val_loss: 0.6296\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7420 - val_loss: 0.5944\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7593 - val_loss: 0.5906\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7426 - val_loss: 0.5996\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7518 - val_loss: 0.5971\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7505 - val_loss: 0.5952\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7469 - val_loss: 0.6056\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7489 - val_loss: 0.5887\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7465 - val_loss: 0.5866\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7452 - val_loss: 0.5806\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7406 - val_loss: 0.5901\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7408 - val_loss: 0.5923\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7470 - val_loss: 0.5896\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7397 - val_loss: 0.5858\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7430 - val_loss: 0.6006\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7361 - val_loss: 0.5822\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7503 - val_loss: 0.6063\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7400 - val_loss: 0.5968\n",
      "Epoch 131/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7392 - val_loss: 0.5805\n",
      "Epoch 132/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7458 - val_loss: 0.5836\n",
      "Epoch 133/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7410 - val_loss: 0.6178\n",
      "Epoch 134/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7384 - val_loss: 0.5859\n",
      "Epoch 135/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7385 - val_loss: 0.5924\n",
      "Epoch 136/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7280 - val_loss: 0.5938\n",
      "Epoch 137/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7367 - val_loss: 0.6193\n",
      "Epoch 138/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7352 - val_loss: 0.5869\n",
      "Epoch 139/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7497 - val_loss: 0.5928\n",
      "Epoch 140/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7399 - val_loss: 0.5841\n",
      "Epoch 141/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7411 - val_loss: 0.5766\n",
      "Epoch 142/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7342 - val_loss: 0.5853\n",
      "Epoch 143/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7314 - val_loss: 0.5866\n",
      "Epoch 144/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7348 - val_loss: 0.6003\n",
      "Epoch 145/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7345 - val_loss: 0.6008\n",
      "Epoch 146/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.7338 - val_loss: 0.6014\n",
      "Epoch 147/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7308 - val_loss: 0.5926\n",
      "Epoch 148/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7248 - val_loss: 0.5942\n",
      "Epoch 149/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7478 - val_loss: 0.5775\n",
      "Epoch 150/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7388 - val_loss: 0.6055\n",
      "Epoch 151/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7331 - val_loss: 0.5883\n",
      "Epoch 152/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7329 - val_loss: 0.5984\n",
      "Epoch 153/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7329 - val_loss: 0.5860\n",
      "Epoch 154/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7393 - val_loss: 0.5970\n",
      "Epoch 155/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7318 - val_loss: 0.6086\n",
      "Epoch 156/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7322 - val_loss: 0.5861\n",
      "Epoch 157/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7391 - val_loss: 0.6179\n",
      "Epoch 158/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7338 - val_loss: 0.5843\n",
      "Epoch 159/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7247 - val_loss: 0.5913\n",
      "Epoch 160/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7354 - val_loss: 0.5789\n",
      "Epoch 161/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7222 - val_loss: 0.5771\n",
      "Epoch 162/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7347 - val_loss: 0.5791\n",
      "Epoch 163/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7270 - val_loss: 0.5916\n",
      "Epoch 164/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7283 - val_loss: 0.5865\n",
      "Epoch 165/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7242 - val_loss: 0.5962\n",
      "Epoch 166/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7364 - val_loss: 0.6001\n",
      "Epoch 167/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7509 - val_loss: 0.5898\n",
      "Epoch 168/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7314 - val_loss: 0.6123\n",
      "Epoch 169/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7306 - val_loss: 0.5899\n",
      "Epoch 170/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7276 - val_loss: 0.6111\n",
      "Epoch 171/300\n",
      "73/73 [==============================] - ETA: 0s - loss: 0.7265Restoring model weights from the end of the best epoch: 141.\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.7265 - val_loss: 0.6416\n",
      "Epoch 171: early stopping\n",
      "'########################################################Model0\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 1.6382 - val_loss: 0.8010\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.9627 - val_loss: 0.7504\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.9245 - val_loss: 0.8246\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.9195 - val_loss: 0.7146\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.9207 - val_loss: 0.7201\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.9144 - val_loss: 0.7208\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8918 - val_loss: 0.8071\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8865 - val_loss: 0.6682\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8691 - val_loss: 0.6763\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8585 - val_loss: 0.6984\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8517 - val_loss: 0.7620\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8786 - val_loss: 0.6727\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8449 - val_loss: 0.6582\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8408 - val_loss: 0.7252\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8663 - val_loss: 0.6710\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8343 - val_loss: 0.6670\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8434 - val_loss: 0.6540\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8501 - val_loss: 0.6604\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8370 - val_loss: 0.7955\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8318 - val_loss: 0.6474\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8301 - val_loss: 0.6498\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8360 - val_loss: 0.6659\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8034 - val_loss: 0.6309\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8083 - val_loss: 0.6427\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8035 - val_loss: 0.6751\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8053 - val_loss: 0.6234\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7935 - val_loss: 0.7351\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8413 - val_loss: 0.7083\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8088 - val_loss: 0.6242\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7913 - val_loss: 0.6419\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7994 - val_loss: 0.6597\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7934 - val_loss: 0.6408\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8049 - val_loss: 0.6553\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8037 - val_loss: 0.6320\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7876 - val_loss: 0.6481\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7923 - val_loss: 0.6269\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7925 - val_loss: 0.6803\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7877 - val_loss: 0.6294\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8003 - val_loss: 0.6401\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7898 - val_loss: 0.6209\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7984 - val_loss: 0.6232\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7978 - val_loss: 0.6218\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7953 - val_loss: 0.6203\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7925 - val_loss: 0.6369\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7771 - val_loss: 0.6243\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7906 - val_loss: 0.6259\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7777 - val_loss: 0.6249\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7977 - val_loss: 0.6409\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7888 - val_loss: 0.6215\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7859 - val_loss: 0.6724\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7801 - val_loss: 0.6303\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7785 - val_loss: 0.6176\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7786 - val_loss: 0.6123\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7802 - val_loss: 0.6208\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7666 - val_loss: 0.6296\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7971 - val_loss: 0.6465\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7720 - val_loss: 0.6179\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7800 - val_loss: 0.6091\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7815 - val_loss: 0.6098\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7914 - val_loss: 0.6193\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7772 - val_loss: 0.6562\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7683 - val_loss: 0.6436\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7750 - val_loss: 0.6184\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7783 - val_loss: 0.6086\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.7911 - val_loss: 0.6058\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7681 - val_loss: 0.6056\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7673 - val_loss: 0.6135\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7805 - val_loss: 0.6086\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7728 - val_loss: 0.6064\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7746 - val_loss: 0.6076\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7609 - val_loss: 0.6367\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7691 - val_loss: 0.6100\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7707 - val_loss: 0.6040\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7672 - val_loss: 0.6157\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7661 - val_loss: 0.6426\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7771 - val_loss: 0.6133\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7551 - val_loss: 0.6412\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7675 - val_loss: 0.5975\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7522 - val_loss: 0.6333\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7867 - val_loss: 0.6034\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7575 - val_loss: 0.6062\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7621 - val_loss: 0.6031\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7573 - val_loss: 0.6050\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7649 - val_loss: 0.6298\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7678 - val_loss: 0.6157\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7611 - val_loss: 0.5989\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7585 - val_loss: 0.6039\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7668 - val_loss: 0.6132\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7670 - val_loss: 0.6227\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7626 - val_loss: 0.6072\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7623 - val_loss: 0.6039\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7643 - val_loss: 0.6039\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7617 - val_loss: 0.5964\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7572 - val_loss: 0.6016\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7543 - val_loss: 0.5965\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7524 - val_loss: 0.6094\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7574 - val_loss: 0.5898\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7677 - val_loss: 0.6091\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7608 - val_loss: 0.5896\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7623 - val_loss: 0.5974\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7567 - val_loss: 0.6040\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7618 - val_loss: 0.5948\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7529 - val_loss: 0.6194\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7526 - val_loss: 0.6130\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7648 - val_loss: 0.6334\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7522 - val_loss: 0.6016\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7488 - val_loss: 0.6070\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7571 - val_loss: 0.5862\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7574 - val_loss: 0.5915\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7493 - val_loss: 0.5894\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7520 - val_loss: 0.5899\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7417 - val_loss: 0.5938\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7390 - val_loss: 0.5925\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7571 - val_loss: 0.5937\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7520 - val_loss: 0.6056\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7537 - val_loss: 0.6116\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7602 - val_loss: 0.5871\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7423 - val_loss: 0.5956\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7500 - val_loss: 0.5839\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7457 - val_loss: 0.5861\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7486 - val_loss: 0.6055\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7434 - val_loss: 0.5999\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7522 - val_loss: 0.5939\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7409 - val_loss: 0.5938\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7481 - val_loss: 0.5909\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7543 - val_loss: 0.6069\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7474 - val_loss: 0.5994\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7482 - val_loss: 0.5942\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7375 - val_loss: 0.6009\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7457 - val_loss: 0.5846\n",
      "Epoch 131/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7480 - val_loss: 0.5838\n",
      "Epoch 132/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7438 - val_loss: 0.6166\n",
      "Epoch 133/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7473 - val_loss: 0.5902\n",
      "Epoch 134/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7446 - val_loss: 0.6333\n",
      "Epoch 135/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7519 - val_loss: 0.5878\n",
      "Epoch 136/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7376 - val_loss: 0.6104\n",
      "Epoch 137/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7391 - val_loss: 0.5923\n",
      "Epoch 138/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7492 - val_loss: 0.5997\n",
      "Epoch 139/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7499 - val_loss: 0.6177\n",
      "Epoch 140/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7513 - val_loss: 0.5811\n",
      "Epoch 141/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7336 - val_loss: 0.5951\n",
      "Epoch 142/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7440 - val_loss: 0.6112\n",
      "Epoch 143/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7442 - val_loss: 0.5871\n",
      "Epoch 144/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7387 - val_loss: 0.5869\n",
      "Epoch 145/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7341 - val_loss: 0.6268\n",
      "Epoch 146/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7399 - val_loss: 0.5903\n",
      "Epoch 147/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7491 - val_loss: 0.6216\n",
      "Epoch 148/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7462 - val_loss: 0.6164\n",
      "Epoch 149/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7441 - val_loss: 0.5978\n",
      "Epoch 150/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7514 - val_loss: 0.5874\n",
      "Epoch 151/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7486 - val_loss: 0.5843\n",
      "Epoch 152/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7370 - val_loss: 0.6092\n",
      "Epoch 153/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7479 - val_loss: 0.6272\n",
      "Epoch 154/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7423 - val_loss: 0.5887\n",
      "Epoch 155/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7414 - val_loss: 0.5893\n",
      "Epoch 156/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7344 - val_loss: 0.6198\n",
      "Epoch 157/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7423 - val_loss: 0.5903\n",
      "Epoch 158/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7461 - val_loss: 0.5862\n",
      "Epoch 159/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7372 - val_loss: 0.5889\n",
      "Epoch 160/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7402 - val_loss: 0.5871\n",
      "Epoch 161/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7358 - val_loss: 0.5973\n",
      "Epoch 162/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7516 - val_loss: 0.5887\n",
      "Epoch 163/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7436 - val_loss: 0.5883\n",
      "Epoch 164/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7439 - val_loss: 0.5907\n",
      "Epoch 165/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7354 - val_loss: 0.5918\n",
      "Epoch 166/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7441 - val_loss: 0.5986\n",
      "Epoch 167/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7430 - val_loss: 0.5836\n",
      "Epoch 168/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7336 - val_loss: 0.5953\n",
      "Epoch 169/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7379 - val_loss: 0.5862\n",
      "Epoch 170/300\n",
      "65/73 [=========================>....] - ETA: 0s - loss: 0.7420Restoring model weights from the end of the best epoch: 140.\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.7446 - val_loss: 0.5899\n",
      "Epoch 170: early stopping\n",
      "'########################################################Model1\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 1.8993 - val_loss: 0.8437\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 1.0360 - val_loss: 1.0332\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.9589 - val_loss: 0.8544\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.9306 - val_loss: 0.7953\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.9219 - val_loss: 0.8738\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.9264 - val_loss: 0.8058\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8935 - val_loss: 0.6859\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8731 - val_loss: 0.6618\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8980 - val_loss: 0.6704\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8722 - val_loss: 0.7264\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8528 - val_loss: 0.6630\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8407 - val_loss: 0.6530\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8512 - val_loss: 0.6992\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8609 - val_loss: 0.6863\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8908 - val_loss: 0.6767\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8386 - val_loss: 0.6585\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8496 - val_loss: 0.6698\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8510 - val_loss: 0.6529\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8264 - val_loss: 0.6503\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8180 - val_loss: 0.6339\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8125 - val_loss: 0.6363\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8128 - val_loss: 0.6391\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8089 - val_loss: 0.6582\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8316 - val_loss: 0.6312\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8041 - val_loss: 0.6702\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8077 - val_loss: 0.6391\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8029 - val_loss: 0.6465\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8148 - val_loss: 0.6502\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8050 - val_loss: 0.6164\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7925 - val_loss: 0.6269\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8131 - val_loss: 0.6336\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7849 - val_loss: 0.6229\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7870 - val_loss: 0.6463\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7895 - val_loss: 0.6310\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7843 - val_loss: 0.6187\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7941 - val_loss: 0.6315\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7873 - val_loss: 0.6629\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7933 - val_loss: 0.6525\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7756 - val_loss: 0.6159\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7700 - val_loss: 0.6856\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7890 - val_loss: 0.6138\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7729 - val_loss: 0.6055\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7774 - val_loss: 0.6505\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7875 - val_loss: 0.6064\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7821 - val_loss: 0.6014\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7748 - val_loss: 0.6097\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7822 - val_loss: 0.6408\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7920 - val_loss: 0.6079\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7667 - val_loss: 0.6142\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7606 - val_loss: 0.6426\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7794 - val_loss: 0.6128\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7707 - val_loss: 0.5995\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7735 - val_loss: 0.6105\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7755 - val_loss: 0.6175\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7894 - val_loss: 0.5985\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7822 - val_loss: 0.6033\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7681 - val_loss: 0.6555\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7632 - val_loss: 0.6152\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7947 - val_loss: 0.6302\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7577 - val_loss: 0.6081\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7601 - val_loss: 0.5983\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7707 - val_loss: 0.5999\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7680 - val_loss: 0.6330\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7672 - val_loss: 0.5914\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7718 - val_loss: 0.6241\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7682 - val_loss: 0.6041\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7638 - val_loss: 0.5951\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7700 - val_loss: 0.6415\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7637 - val_loss: 0.6949\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7668 - val_loss: 0.6031\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7545 - val_loss: 0.6040\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7657 - val_loss: 0.5943\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7497 - val_loss: 0.6009\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7601 - val_loss: 0.5934\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7649 - val_loss: 0.5921\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7664 - val_loss: 0.5977\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7517 - val_loss: 0.6100\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7569 - val_loss: 0.6020\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7470 - val_loss: 0.5929\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7770 - val_loss: 0.6206\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7538 - val_loss: 0.5907\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7498 - val_loss: 0.5826\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7584 - val_loss: 0.6559\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7576 - val_loss: 0.6096\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7564 - val_loss: 0.5873\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7470 - val_loss: 0.5982\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7495 - val_loss: 0.6077\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7524 - val_loss: 0.5923\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7607 - val_loss: 0.5895\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7552 - val_loss: 0.5898\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7393 - val_loss: 0.5898\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7558 - val_loss: 0.5865\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7510 - val_loss: 0.5927\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7408 - val_loss: 0.5846\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7489 - val_loss: 0.6305\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7411 - val_loss: 0.6020\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7398 - val_loss: 0.6159\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7457 - val_loss: 0.6318\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7493 - val_loss: 0.5869\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7609 - val_loss: 0.6040\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7452 - val_loss: 0.5882\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7497 - val_loss: 0.6029\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7382 - val_loss: 0.5999\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7473 - val_loss: 0.5939\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7361 - val_loss: 0.6180\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7352 - val_loss: 0.6175\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7424 - val_loss: 0.5923\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7548 - val_loss: 0.5972\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7365 - val_loss: 0.5933\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7588 - val_loss: 0.6148\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7311 - val_loss: 0.5941\n",
      "Epoch 112/300\n",
      "65/73 [=========================>....] - ETA: 0s - loss: 0.7402Restoring model weights from the end of the best epoch: 82.\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.7445 - val_loss: 0.6242\n",
      "Epoch 112: early stopping\n",
      "'########################################################Model2\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 1.6511 - val_loss: 0.9275\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 1.0335 - val_loss: 0.7247\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.9467 - val_loss: 0.7019\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.9260 - val_loss: 0.7047\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.9048 - val_loss: 0.6789\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.9045 - val_loss: 0.7005\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8985 - val_loss: 0.7072\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8807 - val_loss: 0.6798\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8726 - val_loss: 0.6996\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8850 - val_loss: 0.6534\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8472 - val_loss: 0.6739\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8455 - val_loss: 0.6700\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8416 - val_loss: 0.6923\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8490 - val_loss: 0.6465\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8559 - val_loss: 0.6496\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8372 - val_loss: 0.6488\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8292 - val_loss: 0.6625\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8233 - val_loss: 0.6469\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8304 - val_loss: 0.6509\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8180 - val_loss: 0.6893\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8099 - val_loss: 0.6554\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8168 - val_loss: 0.6356\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8034 - val_loss: 0.6401\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8139 - val_loss: 0.6541\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8232 - val_loss: 0.6426\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8058 - val_loss: 0.6357\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8085 - val_loss: 0.6657\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7943 - val_loss: 0.6374\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8130 - val_loss: 0.6431\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8119 - val_loss: 0.6499\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8081 - val_loss: 0.6478\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7906 - val_loss: 0.6316\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7952 - val_loss: 0.6461\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7934 - val_loss: 0.6259\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7830 - val_loss: 0.6274\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8025 - val_loss: 0.6305\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7815 - val_loss: 0.6293\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7953 - val_loss: 0.6549\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8018 - val_loss: 0.6290\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7941 - val_loss: 0.6314\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7856 - val_loss: 0.6384\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7774 - val_loss: 0.6348\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7818 - val_loss: 0.6204\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7766 - val_loss: 0.6213\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7787 - val_loss: 0.6213\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7780 - val_loss: 0.6353\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7808 - val_loss: 0.6174\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7759 - val_loss: 0.6206\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7781 - val_loss: 0.6114\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7850 - val_loss: 0.6097\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7816 - val_loss: 0.6260\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7913 - val_loss: 0.7094\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7864 - val_loss: 0.6214\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7833 - val_loss: 0.6281\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7725 - val_loss: 0.6465\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7789 - val_loss: 0.6435\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7878 - val_loss: 0.6204\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7638 - val_loss: 0.6726\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8016 - val_loss: 0.6604\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7807 - val_loss: 0.7039\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7882 - val_loss: 0.6527\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7700 - val_loss: 0.6201\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7640 - val_loss: 0.6240\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7684 - val_loss: 0.6052\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7732 - val_loss: 0.6174\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8032 - val_loss: 0.6278\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.7752 - val_loss: 0.6049\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7686 - val_loss: 0.6179\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7696 - val_loss: 0.6036\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7709 - val_loss: 0.6163\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7711 - val_loss: 0.6141\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7620 - val_loss: 0.6153\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7658 - val_loss: 0.6460\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7678 - val_loss: 0.6010\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7605 - val_loss: 0.6016\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7609 - val_loss: 0.6203\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7487 - val_loss: 0.6317\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7521 - val_loss: 0.6242\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7585 - val_loss: 0.6114\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7542 - val_loss: 0.6140\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7535 - val_loss: 0.6193\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7508 - val_loss: 0.6117\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.7516 - val_loss: 0.6008\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7571 - val_loss: 0.6104\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7589 - val_loss: 0.6562\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7611 - val_loss: 0.6048\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7660 - val_loss: 0.6045\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7621 - val_loss: 0.6043\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7545 - val_loss: 0.5954\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7430 - val_loss: 0.5971\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7413 - val_loss: 0.5997\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7605 - val_loss: 0.6141\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7539 - val_loss: 0.6082\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7538 - val_loss: 0.5904\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7448 - val_loss: 0.6252\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7538 - val_loss: 0.5928\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7726 - val_loss: 0.6013\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7538 - val_loss: 0.5934\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7504 - val_loss: 0.6167\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7287 - val_loss: 0.5875\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7477 - val_loss: 0.6071\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7474 - val_loss: 0.6131\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7535 - val_loss: 0.6003\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7459 - val_loss: 0.5869\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7534 - val_loss: 0.5938\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7441 - val_loss: 0.6017\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7447 - val_loss: 0.6083\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7388 - val_loss: 0.5994\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7513 - val_loss: 0.6029\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7479 - val_loss: 0.6051\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7452 - val_loss: 0.6090\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7429 - val_loss: 0.6217\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7438 - val_loss: 0.5988\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7546 - val_loss: 0.5896\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7410 - val_loss: 0.5885\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7285 - val_loss: 0.5964\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7392 - val_loss: 0.6051\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7676 - val_loss: 0.6118\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7447 - val_loss: 0.6074\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7412 - val_loss: 0.5885\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7388 - val_loss: 0.5971\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7348 - val_loss: 0.6037\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7488 - val_loss: 0.5952\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7404 - val_loss: 0.5994\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7360 - val_loss: 0.5990\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7301 - val_loss: 0.5986\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7317 - val_loss: 0.6135\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7373 - val_loss: 0.6039\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7505 - val_loss: 0.5940\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7293 - val_loss: 0.5867\n",
      "Epoch 131/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7329 - val_loss: 0.5920\n",
      "Epoch 132/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7301 - val_loss: 0.5929\n",
      "Epoch 133/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7367 - val_loss: 0.5997\n",
      "Epoch 134/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7341 - val_loss: 0.6320\n",
      "Epoch 135/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7329 - val_loss: 0.6006\n",
      "Epoch 136/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7264 - val_loss: 0.5917\n",
      "Epoch 137/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7247 - val_loss: 0.6009\n",
      "Epoch 138/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7343 - val_loss: 0.5991\n",
      "Epoch 139/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7309 - val_loss: 0.6134\n",
      "Epoch 140/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7287 - val_loss: 0.6115\n",
      "Epoch 141/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7375 - val_loss: 0.5993\n",
      "Epoch 142/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7264 - val_loss: 0.6242\n",
      "Epoch 143/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7223 - val_loss: 0.6131\n",
      "Epoch 144/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7285 - val_loss: 0.5906\n",
      "Epoch 145/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7304 - val_loss: 0.6164\n",
      "Epoch 146/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7318 - val_loss: 0.6040\n",
      "Epoch 147/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7217 - val_loss: 0.6010\n",
      "Epoch 148/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7193 - val_loss: 0.5874\n",
      "Epoch 149/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7202 - val_loss: 0.5818\n",
      "Epoch 150/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7200 - val_loss: 0.6080\n",
      "Epoch 151/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7231 - val_loss: 0.5917\n",
      "Epoch 152/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7224 - val_loss: 0.5863\n",
      "Epoch 153/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7327 - val_loss: 0.5915\n",
      "Epoch 154/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7186 - val_loss: 0.5953\n",
      "Epoch 155/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7350 - val_loss: 0.6136\n",
      "Epoch 156/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7323 - val_loss: 0.5968\n",
      "Epoch 157/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7207 - val_loss: 0.6063\n",
      "Epoch 158/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7208 - val_loss: 0.5917\n",
      "Epoch 159/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7230 - val_loss: 0.6051\n",
      "Epoch 160/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7169 - val_loss: 0.6087\n",
      "Epoch 161/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7108 - val_loss: 0.5926\n",
      "Epoch 162/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7224 - val_loss: 0.6056\n",
      "Epoch 163/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7190 - val_loss: 0.6222\n",
      "Epoch 164/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7211 - val_loss: 0.5938\n",
      "Epoch 165/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7175 - val_loss: 0.5927\n",
      "Epoch 166/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7153 - val_loss: 0.5979\n",
      "Epoch 167/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7328 - val_loss: 0.5924\n",
      "Epoch 168/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7154 - val_loss: 0.6016\n",
      "Epoch 169/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7202 - val_loss: 0.6136\n",
      "Epoch 170/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7226 - val_loss: 0.5942\n",
      "Epoch 171/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7166 - val_loss: 0.6184\n",
      "Epoch 172/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7219 - val_loss: 0.6051\n",
      "Epoch 173/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7158 - val_loss: 0.5912\n",
      "Epoch 174/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7175 - val_loss: 0.5862\n",
      "Epoch 175/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7218 - val_loss: 0.6040\n",
      "Epoch 176/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7193 - val_loss: 0.6079\n",
      "Epoch 177/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7208 - val_loss: 0.5994\n",
      "Epoch 178/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7396 - val_loss: 0.5921\n",
      "Epoch 179/300\n",
      "65/73 [=========================>....] - ETA: 0s - loss: 0.7334Restoring model weights from the end of the best epoch: 149.\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.7297 - val_loss: 0.6058\n",
      "Epoch 179: early stopping\n",
      "'########################################################Model3\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 1.7751 - val_loss: 0.8741\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.9915 - val_loss: 0.8824\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.9118 - val_loss: 0.7512\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.9048 - val_loss: 0.7228\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8880 - val_loss: 0.7891\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8719 - val_loss: 0.6697\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8623 - val_loss: 0.6960\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8486 - val_loss: 0.6499\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8365 - val_loss: 0.6961\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8465 - val_loss: 0.6522\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8382 - val_loss: 0.6497\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8265 - val_loss: 0.6447\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8135 - val_loss: 0.7459\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8248 - val_loss: 0.6675\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8123 - val_loss: 0.6419\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8200 - val_loss: 0.6394\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8055 - val_loss: 0.6386\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8033 - val_loss: 0.6412\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8067 - val_loss: 0.6347\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8085 - val_loss: 0.6360\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8000 - val_loss: 0.6522\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7967 - val_loss: 0.6716\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8084 - val_loss: 0.6577\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7999 - val_loss: 0.6281\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7894 - val_loss: 0.6557\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7857 - val_loss: 0.6263\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7846 - val_loss: 0.6291\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7957 - val_loss: 0.6437\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7866 - val_loss: 0.6441\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8061 - val_loss: 0.6217\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7870 - val_loss: 0.6390\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7947 - val_loss: 0.6290\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7921 - val_loss: 0.6207\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7830 - val_loss: 0.6175\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7876 - val_loss: 0.6265\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7777 - val_loss: 0.6204\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7861 - val_loss: 0.6247\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7800 - val_loss: 0.6283\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7880 - val_loss: 0.6502\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7819 - val_loss: 0.6156\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7779 - val_loss: 0.6317\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7814 - val_loss: 0.6162\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7670 - val_loss: 0.6097\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7645 - val_loss: 0.6183\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7805 - val_loss: 0.6464\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7724 - val_loss: 0.6123\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7745 - val_loss: 0.6149\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7760 - val_loss: 0.6323\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7636 - val_loss: 0.6386\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7818 - val_loss: 0.6489\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7760 - val_loss: 0.6081\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7651 - val_loss: 0.6105\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7668 - val_loss: 0.6135\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7699 - val_loss: 0.6109\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7762 - val_loss: 0.6077\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7686 - val_loss: 0.6213\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7835 - val_loss: 0.6101\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7641 - val_loss: 0.5966\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7669 - val_loss: 0.5984\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7561 - val_loss: 0.6244\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7621 - val_loss: 0.6153\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7598 - val_loss: 0.6059\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7619 - val_loss: 0.5998\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7647 - val_loss: 0.6367\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7793 - val_loss: 0.6026\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7611 - val_loss: 0.6265\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7656 - val_loss: 0.5983\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7550 - val_loss: 0.6995\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7714 - val_loss: 0.6031\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7502 - val_loss: 0.6031\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7620 - val_loss: 0.6182\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7569 - val_loss: 0.5968\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7732 - val_loss: 0.6051\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7556 - val_loss: 0.6060\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7743 - val_loss: 0.5992\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7640 - val_loss: 0.6011\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7658 - val_loss: 0.5994\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7686 - val_loss: 0.6065\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7557 - val_loss: 0.6025\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7505 - val_loss: 0.6111\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7572 - val_loss: 0.5973\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7499 - val_loss: 0.5997\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7482 - val_loss: 0.6082\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7517 - val_loss: 0.5934\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7570 - val_loss: 0.6025\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7440 - val_loss: 0.5958\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7431 - val_loss: 0.6009\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7712 - val_loss: 0.6045\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7430 - val_loss: 0.5860\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7528 - val_loss: 0.5911\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7570 - val_loss: 0.5911\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7494 - val_loss: 0.5905\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7502 - val_loss: 0.5985\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7499 - val_loss: 0.6041\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7470 - val_loss: 0.5948\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7563 - val_loss: 0.5852\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7436 - val_loss: 0.5944\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7646 - val_loss: 0.6018\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7451 - val_loss: 0.5988\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7443 - val_loss: 0.6000\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7474 - val_loss: 0.5865\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7707 - val_loss: 0.5887\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7443 - val_loss: 0.5935\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7425 - val_loss: 0.6079\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7421 - val_loss: 0.5997\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7446 - val_loss: 0.6269\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7488 - val_loss: 0.6490\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7553 - val_loss: 0.5947\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7594 - val_loss: 0.6225\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7533 - val_loss: 0.5949\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7576 - val_loss: 0.5950\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7414 - val_loss: 0.5943\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7627 - val_loss: 0.5914\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7480 - val_loss: 0.5904\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7431 - val_loss: 0.5943\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7499 - val_loss: 0.5828\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7355 - val_loss: 0.6203\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7431 - val_loss: 0.5943\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7450 - val_loss: 0.5980\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7476 - val_loss: 0.5841\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7415 - val_loss: 0.5877\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7578 - val_loss: 0.5925\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7362 - val_loss: 0.6069\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7516 - val_loss: 0.5963\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7445 - val_loss: 0.6186\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7381 - val_loss: 0.6046\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7433 - val_loss: 0.6053\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7411 - val_loss: 0.5909\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7340 - val_loss: 0.5914\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7355 - val_loss: 0.5894\n",
      "Epoch 131/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7352 - val_loss: 0.5845\n",
      "Epoch 132/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7445 - val_loss: 0.5843\n",
      "Epoch 133/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7420 - val_loss: 0.5914\n",
      "Epoch 134/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7350 - val_loss: 0.5917\n",
      "Epoch 135/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7454 - val_loss: 0.5892\n",
      "Epoch 136/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7486 - val_loss: 0.5959\n",
      "Epoch 137/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7503 - val_loss: 0.5943\n",
      "Epoch 138/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7398 - val_loss: 0.6015\n",
      "Epoch 139/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7393 - val_loss: 0.5875\n",
      "Epoch 140/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7333 - val_loss: 0.6154\n",
      "Epoch 141/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7409 - val_loss: 0.5980\n",
      "Epoch 142/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7408 - val_loss: 0.6037\n",
      "Epoch 143/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7487 - val_loss: 0.5989\n",
      "Epoch 144/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7419 - val_loss: 0.5918\n",
      "Epoch 145/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7493 - val_loss: 0.5900\n",
      "Epoch 146/300\n",
      "73/73 [==============================] - ETA: 0s - loss: 0.7367Restoring model weights from the end of the best epoch: 116.\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.7367 - val_loss: 0.6191\n",
      "Epoch 146: early stopping\n",
      "'########################################################Model4\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 1.6375 - val_loss: 0.8314\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 1.0203 - val_loss: 0.7243\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.9535 - val_loss: 0.7133\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.9285 - val_loss: 0.8609\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.9158 - val_loss: 0.6837\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.9259 - val_loss: 0.7082\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.9122 - val_loss: 0.6831\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8993 - val_loss: 0.6949\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.9113 - val_loss: 0.7094\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8978 - val_loss: 0.7026\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.9019 - val_loss: 0.7020\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8725 - val_loss: 0.6542\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8767 - val_loss: 0.6631\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8867 - val_loss: 0.6802\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8577 - val_loss: 0.6507\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8384 - val_loss: 0.6447\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8305 - val_loss: 0.6487\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8381 - val_loss: 0.6470\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8394 - val_loss: 0.6443\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8297 - val_loss: 0.6395\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8492 - val_loss: 0.6443\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8154 - val_loss: 0.6359\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8128 - val_loss: 0.6322\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8177 - val_loss: 0.7229\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8155 - val_loss: 0.6816\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8206 - val_loss: 0.7364\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8305 - val_loss: 0.6171\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8234 - val_loss: 0.6993\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8128 - val_loss: 0.6228\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8010 - val_loss: 0.6299\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7952 - val_loss: 0.6603\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8027 - val_loss: 0.6541\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8035 - val_loss: 0.6414\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8055 - val_loss: 0.6203\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7871 - val_loss: 0.6140\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7831 - val_loss: 0.6765\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7964 - val_loss: 0.6648\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8234 - val_loss: 0.6255\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7966 - val_loss: 0.6307\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7883 - val_loss: 0.6194\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7719 - val_loss: 0.6147\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7894 - val_loss: 0.6592\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8074 - val_loss: 0.6040\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8430 - val_loss: 0.6573\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7833 - val_loss: 0.5999\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7983 - val_loss: 0.6201\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7717 - val_loss: 0.6073\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7827 - val_loss: 0.6013\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7781 - val_loss: 0.6061\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7784 - val_loss: 0.6013\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7785 - val_loss: 0.6083\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7851 - val_loss: 0.6472\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7832 - val_loss: 0.5944\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7786 - val_loss: 0.5969\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7768 - val_loss: 0.6118\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7836 - val_loss: 0.6406\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7788 - val_loss: 0.7155\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7645 - val_loss: 0.6642\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7773 - val_loss: 0.6441\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7620 - val_loss: 0.6052\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7887 - val_loss: 0.6028\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7674 - val_loss: 0.6180\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7754 - val_loss: 0.6756\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7671 - val_loss: 0.6265\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7616 - val_loss: 0.6036\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7695 - val_loss: 0.6038\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7643 - val_loss: 0.6552\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7648 - val_loss: 0.5883\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7650 - val_loss: 0.5908\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7812 - val_loss: 0.5981\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7627 - val_loss: 0.6120\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7625 - val_loss: 0.6288\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7618 - val_loss: 0.6066\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7649 - val_loss: 0.6285\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7670 - val_loss: 0.6369\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7700 - val_loss: 0.6184\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7710 - val_loss: 0.5995\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7576 - val_loss: 0.6202\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7747 - val_loss: 0.6292\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7605 - val_loss: 0.5848\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7796 - val_loss: 0.6159\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7605 - val_loss: 0.7076\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7594 - val_loss: 0.5961\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7584 - val_loss: 0.5971\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7645 - val_loss: 0.6020\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7602 - val_loss: 0.5893\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7581 - val_loss: 0.6725\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7430 - val_loss: 0.5895\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7547 - val_loss: 0.6048\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7536 - val_loss: 0.5890\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7566 - val_loss: 0.5953\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7531 - val_loss: 0.5916\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7678 - val_loss: 0.6052\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7582 - val_loss: 0.5859\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7673 - val_loss: 0.5920\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7698 - val_loss: 0.5874\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7613 - val_loss: 0.5928\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7446 - val_loss: 0.6316\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7557 - val_loss: 0.5897\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7496 - val_loss: 0.6016\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7565 - val_loss: 0.5866\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7475 - val_loss: 0.6550\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7533 - val_loss: 0.5865\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7505 - val_loss: 0.6936\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7614 - val_loss: 0.5815\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.7788 - val_loss: 0.5853\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7638 - val_loss: 0.6206\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7499 - val_loss: 0.5791\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7618 - val_loss: 0.5869\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7574 - val_loss: 0.5961\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7544 - val_loss: 0.5891\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7404 - val_loss: 0.6073\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7467 - val_loss: 0.5954\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7750 - val_loss: 0.5910\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7451 - val_loss: 0.5908\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7520 - val_loss: 0.6146\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7376 - val_loss: 0.5846\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7527 - val_loss: 0.5920\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7408 - val_loss: 0.5899\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7417 - val_loss: 0.5930\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7505 - val_loss: 0.5860\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7518 - val_loss: 0.5883\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7581 - val_loss: 0.6260\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.7578 - val_loss: 0.5885\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7440 - val_loss: 0.5820\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7376 - val_loss: 0.5848\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7428 - val_loss: 0.5868\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7586 - val_loss: 0.5987\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7509 - val_loss: 0.5979\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7486 - val_loss: 0.5882\n",
      "Epoch 131/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7441 - val_loss: 0.5950\n",
      "Epoch 132/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7460 - val_loss: 0.6230\n",
      "Epoch 133/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7467 - val_loss: 0.5844\n",
      "Epoch 134/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7496 - val_loss: 0.5921\n",
      "Epoch 135/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7458 - val_loss: 0.6284\n",
      "Epoch 136/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7565 - val_loss: 0.6021\n",
      "Epoch 137/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7433 - val_loss: 0.5955\n",
      "Epoch 138/300\n",
      "65/73 [=========================>....] - ETA: 0s - loss: 0.7422Restoring model weights from the end of the best epoch: 108.\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.7450 - val_loss: 0.6038\n",
      "Epoch 138: early stopping\n",
      "'########################################################Model5\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 1.5486 - val_loss: 0.8390\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.9557 - val_loss: 0.7197\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.9343 - val_loss: 0.7338\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.9088 - val_loss: 0.7117\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.9030 - val_loss: 0.6752\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8940 - val_loss: 0.6696\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8797 - val_loss: 0.7126\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8709 - val_loss: 0.7238\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8607 - val_loss: 0.6706\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8677 - val_loss: 0.8016\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8669 - val_loss: 0.6480\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8473 - val_loss: 0.7496\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8470 - val_loss: 0.6585\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8362 - val_loss: 0.7186\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8391 - val_loss: 0.6512\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8260 - val_loss: 0.6880\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8342 - val_loss: 0.6388\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8175 - val_loss: 0.6430\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8139 - val_loss: 0.6734\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8101 - val_loss: 0.6654\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8138 - val_loss: 0.6308\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8153 - val_loss: 0.6503\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8105 - val_loss: 0.6177\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7902 - val_loss: 0.6296\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7967 - val_loss: 0.6317\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8037 - val_loss: 0.7023\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7927 - val_loss: 0.6345\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7926 - val_loss: 0.6366\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7848 - val_loss: 0.6257\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7952 - val_loss: 0.6223\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8093 - val_loss: 0.6338\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8041 - val_loss: 0.6237\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7943 - val_loss: 0.6196\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7884 - val_loss: 0.6264\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7769 - val_loss: 0.6307\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7929 - val_loss: 0.6265\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7951 - val_loss: 0.7338\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7846 - val_loss: 0.6259\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7829 - val_loss: 0.6175\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7752 - val_loss: 0.6847\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7799 - val_loss: 0.6185\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7897 - val_loss: 0.6187\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7823 - val_loss: 0.6165\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7748 - val_loss: 0.6710\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7812 - val_loss: 0.6063\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7713 - val_loss: 0.6117\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7773 - val_loss: 0.6134\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7688 - val_loss: 0.6077\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7660 - val_loss: 0.6167\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7602 - val_loss: 0.6155\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7986 - val_loss: 0.6238\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7815 - val_loss: 0.6030\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7809 - val_loss: 0.6135\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7759 - val_loss: 0.6003\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7800 - val_loss: 0.6004\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7680 - val_loss: 0.6043\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7665 - val_loss: 0.5939\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7697 - val_loss: 0.5997\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7736 - val_loss: 0.5996\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7625 - val_loss: 0.6017\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7603 - val_loss: 0.6171\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7749 - val_loss: 0.6071\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7577 - val_loss: 0.5995\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7645 - val_loss: 0.6463\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7842 - val_loss: 0.6143\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7707 - val_loss: 0.6140\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7657 - val_loss: 0.5939\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7611 - val_loss: 0.6114\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7640 - val_loss: 0.6084\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7707 - val_loss: 0.5970\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7622 - val_loss: 0.5893\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7624 - val_loss: 0.5979\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7610 - val_loss: 0.6010\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7578 - val_loss: 0.6045\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7643 - val_loss: 0.6038\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7541 - val_loss: 0.6152\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7619 - val_loss: 0.6045\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7473 - val_loss: 0.6035\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7451 - val_loss: 0.6337\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7618 - val_loss: 0.6107\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7489 - val_loss: 0.5944\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7601 - val_loss: 0.6264\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7529 - val_loss: 0.6084\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7491 - val_loss: 0.6063\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7618 - val_loss: 0.5990\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7540 - val_loss: 0.5910\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7635 - val_loss: 0.5871\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7444 - val_loss: 0.6083\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7401 - val_loss: 0.5932\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7500 - val_loss: 0.6077\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7461 - val_loss: 0.5968\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7598 - val_loss: 0.5875\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7461 - val_loss: 0.5942\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7564 - val_loss: 0.5879\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7464 - val_loss: 0.5829\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7543 - val_loss: 0.5928\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7515 - val_loss: 0.5877\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7365 - val_loss: 0.6089\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7470 - val_loss: 0.6474\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7414 - val_loss: 0.5902\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7565 - val_loss: 0.6228\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7440 - val_loss: 0.6187\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7569 - val_loss: 0.5878\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7561 - val_loss: 0.5910\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7460 - val_loss: 0.6118\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7368 - val_loss: 0.5932\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7494 - val_loss: 0.5909\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7385 - val_loss: 0.6278\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7391 - val_loss: 0.5948\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7493 - val_loss: 0.5975\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7361 - val_loss: 0.6043\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7403 - val_loss: 0.6043\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7474 - val_loss: 0.5913\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7321 - val_loss: 0.6007\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7422 - val_loss: 0.5894\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7449 - val_loss: 0.5999\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7450 - val_loss: 0.6102\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7416 - val_loss: 0.5997\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7382 - val_loss: 0.5835\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7328 - val_loss: 0.5924\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7428 - val_loss: 0.6061\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7439 - val_loss: 0.5958\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7360 - val_loss: 0.5863\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7474 - val_loss: 0.5918\n",
      "Epoch 125/300\n",
      "65/73 [=========================>....] - ETA: 0s - loss: 0.7254Restoring model weights from the end of the best epoch: 95.\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.7316 - val_loss: 0.6009\n",
      "Epoch 125: early stopping\n",
      "'########################################################Model6\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 1.6318 - val_loss: 1.0241\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.9620 - val_loss: 0.8155\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.9150 - val_loss: 0.7368\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.9009 - val_loss: 0.7340\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8937 - val_loss: 0.7389\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8847 - val_loss: 0.8265\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8810 - val_loss: 0.6758\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8683 - val_loss: 0.6974\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8462 - val_loss: 0.6593\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8532 - val_loss: 0.6646\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8488 - val_loss: 0.6506\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8465 - val_loss: 0.6785\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8435 - val_loss: 0.6423\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8287 - val_loss: 0.6826\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8328 - val_loss: 0.6473\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8182 - val_loss: 0.6559\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8156 - val_loss: 0.6463\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8057 - val_loss: 0.6479\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8130 - val_loss: 0.6479\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8189 - val_loss: 0.7951\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8053 - val_loss: 0.7526\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8058 - val_loss: 0.7201\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8258 - val_loss: 0.6717\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8006 - val_loss: 0.6575\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8067 - val_loss: 0.6328\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7918 - val_loss: 0.6257\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7986 - val_loss: 0.6366\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8018 - val_loss: 0.6315\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7935 - val_loss: 0.6318\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7865 - val_loss: 0.6421\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7910 - val_loss: 0.6355\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7976 - val_loss: 0.6233\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7886 - val_loss: 0.6226\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7770 - val_loss: 0.6348\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7890 - val_loss: 0.6301\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7925 - val_loss: 0.6292\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7785 - val_loss: 0.6626\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7851 - val_loss: 0.6319\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7807 - val_loss: 0.6285\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7752 - val_loss: 0.6133\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7727 - val_loss: 0.6741\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7860 - val_loss: 0.6199\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7780 - val_loss: 0.6406\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7764 - val_loss: 0.6173\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7786 - val_loss: 0.6098\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7848 - val_loss: 0.6176\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7818 - val_loss: 0.6160\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7649 - val_loss: 0.6267\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7751 - val_loss: 0.6055\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7729 - val_loss: 0.6095\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7749 - val_loss: 0.6153\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7690 - val_loss: 0.6053\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7629 - val_loss: 0.6112\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7743 - val_loss: 0.5981\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7501 - val_loss: 0.6166\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7645 - val_loss: 0.6089\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7640 - val_loss: 0.6030\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7787 - val_loss: 0.6127\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7730 - val_loss: 0.6280\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7582 - val_loss: 0.6144\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7709 - val_loss: 0.5980\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7575 - val_loss: 0.6530\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7737 - val_loss: 0.6598\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7587 - val_loss: 0.6073\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7650 - val_loss: 0.6042\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7577 - val_loss: 0.6048\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7536 - val_loss: 0.6570\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7550 - val_loss: 0.6093\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7574 - val_loss: 0.6071\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7573 - val_loss: 0.6112\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7721 - val_loss: 0.5945\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7563 - val_loss: 0.6055\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7682 - val_loss: 0.5968\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7476 - val_loss: 0.5990\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7455 - val_loss: 0.6214\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7612 - val_loss: 0.6039\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7631 - val_loss: 0.6296\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7673 - val_loss: 0.5945\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7583 - val_loss: 0.5940\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7452 - val_loss: 0.6059\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7724 - val_loss: 0.5898\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7490 - val_loss: 0.5970\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7525 - val_loss: 0.5962\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7588 - val_loss: 0.5948\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7591 - val_loss: 0.5893\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7571 - val_loss: 0.5834\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7531 - val_loss: 0.5910\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7570 - val_loss: 0.5894\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7587 - val_loss: 0.6031\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7388 - val_loss: 0.6011\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7522 - val_loss: 0.5988\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7619 - val_loss: 0.5933\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7479 - val_loss: 0.5876\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7555 - val_loss: 0.6534\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7565 - val_loss: 0.5978\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7454 - val_loss: 0.5963\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7419 - val_loss: 0.5967\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7532 - val_loss: 0.6009\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7520 - val_loss: 0.5909\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7474 - val_loss: 0.5995\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7529 - val_loss: 0.6043\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7475 - val_loss: 0.6276\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7627 - val_loss: 0.6112\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7463 - val_loss: 0.6163\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7459 - val_loss: 0.5891\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7440 - val_loss: 0.6042\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7380 - val_loss: 0.5897\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7432 - val_loss: 0.5954\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7495 - val_loss: 0.5831\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7472 - val_loss: 0.5914\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7537 - val_loss: 0.5979\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7439 - val_loss: 0.5937\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7497 - val_loss: 0.5813\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7482 - val_loss: 0.5999\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7575 - val_loss: 0.5949\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7441 - val_loss: 0.5863\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7494 - val_loss: 0.5855\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7424 - val_loss: 0.6042\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7557 - val_loss: 0.5976\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7442 - val_loss: 0.5958\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7433 - val_loss: 0.5828\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7418 - val_loss: 0.5937\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7335 - val_loss: 0.5933\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7559 - val_loss: 0.6220\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7472 - val_loss: 0.5847\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7429 - val_loss: 0.5970\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7416 - val_loss: 0.5945\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7466 - val_loss: 0.6112\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7357 - val_loss: 0.5967\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7378 - val_loss: 0.5833\n",
      "Epoch 131/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7403 - val_loss: 0.5869\n",
      "Epoch 132/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7350 - val_loss: 0.5944\n",
      "Epoch 133/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7367 - val_loss: 0.5838\n",
      "Epoch 134/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7354 - val_loss: 0.5807\n",
      "Epoch 135/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7401 - val_loss: 0.5867\n",
      "Epoch 136/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7423 - val_loss: 0.6117\n",
      "Epoch 137/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7359 - val_loss: 0.6036\n",
      "Epoch 138/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7465 - val_loss: 0.5922\n",
      "Epoch 139/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7401 - val_loss: 0.5942\n",
      "Epoch 140/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7389 - val_loss: 0.6110\n",
      "Epoch 141/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7430 - val_loss: 0.6139\n",
      "Epoch 142/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7532 - val_loss: 0.6254\n",
      "Epoch 143/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7379 - val_loss: 0.5865\n",
      "Epoch 144/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7258 - val_loss: 0.5981\n",
      "Epoch 145/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7337 - val_loss: 0.5868\n",
      "Epoch 146/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7491 - val_loss: 0.6115\n",
      "Epoch 147/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7483 - val_loss: 0.6208\n",
      "Epoch 148/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7433 - val_loss: 0.5945\n",
      "Epoch 149/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7356 - val_loss: 0.5859\n",
      "Epoch 150/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7354 - val_loss: 0.5854\n",
      "Epoch 151/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7403 - val_loss: 0.6004\n",
      "Epoch 152/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7387 - val_loss: 0.5923\n",
      "Epoch 153/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7454 - val_loss: 0.5835\n",
      "Epoch 154/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7365 - val_loss: 0.5946\n",
      "Epoch 155/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7498 - val_loss: 0.5909\n",
      "Epoch 156/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7378 - val_loss: 0.6006\n",
      "Epoch 157/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7457 - val_loss: 0.5958\n",
      "Epoch 158/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7388 - val_loss: 0.5889\n",
      "Epoch 159/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7250 - val_loss: 0.5919\n",
      "Epoch 160/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7444 - val_loss: 0.5821\n",
      "Epoch 161/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7277 - val_loss: 0.5944\n",
      "Epoch 162/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7491 - val_loss: 0.5902\n",
      "Epoch 163/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7481 - val_loss: 0.5811\n",
      "Epoch 164/300\n",
      "65/73 [=========================>....] - ETA: 0s - loss: 0.7538Restoring model weights from the end of the best epoch: 134.\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.7395 - val_loss: 0.5854\n",
      "Epoch 164: early stopping\n",
      "'########################################################Model7\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 1.8992 - val_loss: 0.8865\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 1.0835 - val_loss: 0.7880\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.9553 - val_loss: 0.8252\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.9392 - val_loss: 0.7708\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.9337 - val_loss: 0.6906\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.9032 - val_loss: 0.7196\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.9109 - val_loss: 0.7070\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8861 - val_loss: 0.6814\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8668 - val_loss: 0.6815\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8696 - val_loss: 0.9854\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8567 - val_loss: 0.7500\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8778 - val_loss: 0.6560\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8747 - val_loss: 0.8022\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8444 - val_loss: 0.7002\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8342 - val_loss: 0.7261\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8312 - val_loss: 0.6470\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8366 - val_loss: 0.6495\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8409 - val_loss: 0.6494\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8238 - val_loss: 0.6424\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8130 - val_loss: 0.6433\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8263 - val_loss: 0.6467\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8093 - val_loss: 0.6508\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8072 - val_loss: 0.6407\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8234 - val_loss: 0.6559\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8072 - val_loss: 0.6340\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8077 - val_loss: 0.6345\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7912 - val_loss: 0.6423\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8000 - val_loss: 0.6318\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7895 - val_loss: 0.6485\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8028 - val_loss: 0.6447\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7975 - val_loss: 0.6285\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7939 - val_loss: 0.6391\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7958 - val_loss: 0.6228\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7882 - val_loss: 0.6361\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8035 - val_loss: 0.6317\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8046 - val_loss: 0.6543\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7878 - val_loss: 0.6251\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7843 - val_loss: 0.6204\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7929 - val_loss: 0.6298\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7899 - val_loss: 0.6214\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7888 - val_loss: 0.6286\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.7927 - val_loss: 0.6149\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7870 - val_loss: 0.6256\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7814 - val_loss: 0.6352\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7905 - val_loss: 0.6206\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7718 - val_loss: 0.6128\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7807 - val_loss: 0.6383\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7711 - val_loss: 0.6771\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7772 - val_loss: 0.6045\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7686 - val_loss: 0.6345\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7682 - val_loss: 0.7459\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7832 - val_loss: 0.6068\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7832 - val_loss: 0.6121\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7771 - val_loss: 0.6093\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7894 - val_loss: 0.6226\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7692 - val_loss: 0.6334\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7776 - val_loss: 0.6188\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7728 - val_loss: 0.6040\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7764 - val_loss: 0.6094\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7841 - val_loss: 0.6002\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7842 - val_loss: 0.6248\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7755 - val_loss: 0.6092\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7670 - val_loss: 0.6255\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7648 - val_loss: 0.6732\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7723 - val_loss: 0.6084\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7635 - val_loss: 0.5957\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7709 - val_loss: 0.5918\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7749 - val_loss: 0.5969\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7705 - val_loss: 0.6019\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7743 - val_loss: 0.6013\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7683 - val_loss: 0.5997\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7744 - val_loss: 0.6840\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7794 - val_loss: 0.5908\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7534 - val_loss: 0.5887\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7635 - val_loss: 0.6466\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7558 - val_loss: 0.5990\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7608 - val_loss: 0.5984\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7589 - val_loss: 0.5965\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7559 - val_loss: 0.5984\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7499 - val_loss: 0.5980\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7553 - val_loss: 0.6115\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7553 - val_loss: 0.6136\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7662 - val_loss: 0.5895\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7730 - val_loss: 0.5935\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7571 - val_loss: 0.6251\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7548 - val_loss: 0.6556\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7612 - val_loss: 0.6350\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7499 - val_loss: 0.6202\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7565 - val_loss: 0.5905\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7582 - val_loss: 0.6056\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7601 - val_loss: 0.6083\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7419 - val_loss: 0.6116\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7570 - val_loss: 0.6101\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7684 - val_loss: 0.6133\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7471 - val_loss: 0.5896\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7646 - val_loss: 0.5987\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7451 - val_loss: 0.5896\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7509 - val_loss: 0.5927\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7623 - val_loss: 0.5865\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7467 - val_loss: 0.5869\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7473 - val_loss: 0.5921\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7365 - val_loss: 0.6838\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7478 - val_loss: 0.5958\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7467 - val_loss: 0.6068\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7516 - val_loss: 0.6412\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7566 - val_loss: 0.5984\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7517 - val_loss: 0.5902\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7469 - val_loss: 0.6063\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7487 - val_loss: 0.6077\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7530 - val_loss: 0.5954\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7438 - val_loss: 0.6163\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7470 - val_loss: 0.5888\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7529 - val_loss: 0.5853\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7404 - val_loss: 0.5903\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7409 - val_loss: 0.5877\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7465 - val_loss: 0.6004\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7477 - val_loss: 0.5907\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7367 - val_loss: 0.5898\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7467 - val_loss: 0.5812\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7325 - val_loss: 0.6020\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7310 - val_loss: 0.6430\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7427 - val_loss: 0.6049\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7435 - val_loss: 0.5952\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7448 - val_loss: 0.5925\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7434 - val_loss: 0.5924\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7422 - val_loss: 0.6396\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7532 - val_loss: 0.5905\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7389 - val_loss: 0.6066\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7415 - val_loss: 0.6076\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7298 - val_loss: 0.5953\n",
      "Epoch 131/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7334 - val_loss: 0.5888\n",
      "Epoch 132/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7414 - val_loss: 0.5780\n",
      "Epoch 133/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7461 - val_loss: 0.5857\n",
      "Epoch 134/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7283 - val_loss: 0.6064\n",
      "Epoch 135/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7284 - val_loss: 0.6368\n",
      "Epoch 136/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7364 - val_loss: 0.6213\n",
      "Epoch 137/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7307 - val_loss: 0.6075\n",
      "Epoch 138/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7423 - val_loss: 0.5997\n",
      "Epoch 139/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7408 - val_loss: 0.5804\n",
      "Epoch 140/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7417 - val_loss: 0.6048\n",
      "Epoch 141/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7342 - val_loss: 0.5968\n",
      "Epoch 142/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7495 - val_loss: 0.5949\n",
      "Epoch 143/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.7326 - val_loss: 0.5779\n",
      "Epoch 144/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7250 - val_loss: 0.6012\n",
      "Epoch 145/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7233 - val_loss: 0.6145\n",
      "Epoch 146/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7302 - val_loss: 0.5931\n",
      "Epoch 147/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7329 - val_loss: 0.5998\n",
      "Epoch 148/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7470 - val_loss: 0.5976\n",
      "Epoch 149/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7330 - val_loss: 0.6065\n",
      "Epoch 150/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7244 - val_loss: 0.5856\n",
      "Epoch 151/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7266 - val_loss: 0.5780\n",
      "Epoch 152/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7235 - val_loss: 0.5882\n",
      "Epoch 153/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7247 - val_loss: 0.6344\n",
      "Epoch 154/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7314 - val_loss: 0.5913\n",
      "Epoch 155/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7251 - val_loss: 0.5923\n",
      "Epoch 156/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7226 - val_loss: 0.5837\n",
      "Epoch 157/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7374 - val_loss: 0.5922\n",
      "Epoch 158/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7239 - val_loss: 0.5869\n",
      "Epoch 159/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7200 - val_loss: 0.5863\n",
      "Epoch 160/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7191 - val_loss: 0.5906\n",
      "Epoch 161/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7256 - val_loss: 0.6098\n",
      "Epoch 162/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7221 - val_loss: 0.5809\n",
      "Epoch 163/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7254 - val_loss: 0.5855\n",
      "Epoch 164/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7231 - val_loss: 0.5812\n",
      "Epoch 165/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7292 - val_loss: 0.5793\n",
      "Epoch 166/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7176 - val_loss: 0.5971\n",
      "Epoch 167/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7145 - val_loss: 0.5868\n",
      "Epoch 168/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7191 - val_loss: 0.6231\n",
      "Epoch 169/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7219 - val_loss: 0.5838\n",
      "Epoch 170/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7168 - val_loss: 0.6202\n",
      "Epoch 171/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7136 - val_loss: 0.5941\n",
      "Epoch 172/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7150 - val_loss: 0.5815\n",
      "Epoch 173/300\n",
      "65/73 [=========================>....] - ETA: 0s - loss: 0.7065Restoring model weights from the end of the best epoch: 143.\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.7218 - val_loss: 0.5918\n",
      "Epoch 173: early stopping\n",
      "'########################################################Model8\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 1.6214 - val_loss: 0.8307\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 1.0709 - val_loss: 0.7113\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.9795 - val_loss: 0.7490\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.9358 - val_loss: 0.6834\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.9113 - val_loss: 0.6841\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.9164 - val_loss: 0.6730\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8769 - val_loss: 0.6662\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8692 - val_loss: 0.6669\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8470 - val_loss: 0.6736\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8598 - val_loss: 0.6658\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8455 - val_loss: 0.6561\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8285 - val_loss: 0.6488\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8582 - val_loss: 0.6479\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8293 - val_loss: 0.7133\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8262 - val_loss: 0.6402\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8349 - val_loss: 0.6722\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8157 - val_loss: 0.6362\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8168 - val_loss: 0.6382\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8212 - val_loss: 0.6417\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8051 - val_loss: 0.6522\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8037 - val_loss: 0.6367\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8288 - val_loss: 0.7070\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8264 - val_loss: 0.6308\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8046 - val_loss: 0.6412\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8000 - val_loss: 0.6335\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8024 - val_loss: 0.6651\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8192 - val_loss: 0.6239\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8122 - val_loss: 0.6536\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7865 - val_loss: 0.7228\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7986 - val_loss: 0.6330\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8154 - val_loss: 0.6504\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7971 - val_loss: 0.6323\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7922 - val_loss: 0.6308\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7982 - val_loss: 0.6492\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7935 - val_loss: 0.6524\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7784 - val_loss: 0.6326\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7887 - val_loss: 0.6265\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7916 - val_loss: 0.6396\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7824 - val_loss: 0.6375\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.8027 - val_loss: 0.6472\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7873 - val_loss: 0.6297\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7920 - val_loss: 0.6235\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7896 - val_loss: 0.6236\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7916 - val_loss: 0.6359\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7749 - val_loss: 0.6285\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7697 - val_loss: 0.6177\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7708 - val_loss: 0.7094\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7810 - val_loss: 0.6657\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7943 - val_loss: 0.7066\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7961 - val_loss: 0.6516\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7845 - val_loss: 0.6303\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7783 - val_loss: 0.6094\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7712 - val_loss: 0.6241\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7728 - val_loss: 0.6235\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7733 - val_loss: 0.6583\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7867 - val_loss: 0.6154\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7892 - val_loss: 0.6137\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7648 - val_loss: 0.6063\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7749 - val_loss: 0.6192\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7734 - val_loss: 0.6204\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7698 - val_loss: 0.6525\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7676 - val_loss: 0.6263\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7845 - val_loss: 0.6339\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7862 - val_loss: 0.6041\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7515 - val_loss: 0.6506\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7825 - val_loss: 0.6099\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7759 - val_loss: 0.6232\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7726 - val_loss: 0.6146\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7712 - val_loss: 0.6043\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7656 - val_loss: 0.6180\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.7643 - val_loss: 0.6112\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7786 - val_loss: 0.6091\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7554 - val_loss: 0.6467\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7565 - val_loss: 0.6014\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7584 - val_loss: 0.6203\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7659 - val_loss: 0.6016\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.7699 - val_loss: 0.6010\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7637 - val_loss: 0.6191\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7686 - val_loss: 0.6015\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7568 - val_loss: 0.5951\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7625 - val_loss: 0.6106\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7591 - val_loss: 0.6435\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7836 - val_loss: 0.5997\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7879 - val_loss: 0.6058\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7628 - val_loss: 0.5967\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7495 - val_loss: 0.6180\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7727 - val_loss: 0.6000\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7498 - val_loss: 0.6121\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7524 - val_loss: 0.5980\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7575 - val_loss: 0.6000\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7625 - val_loss: 0.6806\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7565 - val_loss: 0.6067\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7699 - val_loss: 0.5969\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7512 - val_loss: 0.6020\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7552 - val_loss: 0.5960\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7580 - val_loss: 0.6251\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7484 - val_loss: 0.6064\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7505 - val_loss: 0.5959\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7470 - val_loss: 0.6269\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7489 - val_loss: 0.6376\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7510 - val_loss: 0.5940\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7499 - val_loss: 0.6162\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7443 - val_loss: 0.5857\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7431 - val_loss: 0.5949\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7485 - val_loss: 0.5884\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7449 - val_loss: 0.5981\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.7509 - val_loss: 0.6147\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7362 - val_loss: 0.6496\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7394 - val_loss: 0.6241\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7498 - val_loss: 0.5974\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7376 - val_loss: 0.5924\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7491 - val_loss: 0.6152\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7472 - val_loss: 0.6093\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7280 - val_loss: 0.6220\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7409 - val_loss: 0.6582\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7529 - val_loss: 0.5940\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7476 - val_loss: 0.5832\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7541 - val_loss: 0.6253\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7476 - val_loss: 0.6096\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7363 - val_loss: 0.6039\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7289 - val_loss: 0.5922\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7511 - val_loss: 0.5856\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7335 - val_loss: 0.6325\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7336 - val_loss: 0.5942\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7488 - val_loss: 0.5900\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7281 - val_loss: 0.6088\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7328 - val_loss: 0.5933\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7351 - val_loss: 0.5959\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7361 - val_loss: 0.6548\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7485 - val_loss: 0.6015\n",
      "Epoch 131/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7307 - val_loss: 0.5996\n",
      "Epoch 132/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7290 - val_loss: 0.5943\n",
      "Epoch 133/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7382 - val_loss: 0.5904\n",
      "Epoch 134/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7338 - val_loss: 0.6259\n",
      "Epoch 135/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7335 - val_loss: 0.6495\n",
      "Epoch 136/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7324 - val_loss: 0.6844\n",
      "Epoch 137/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7268 - val_loss: 0.5930\n",
      "Epoch 138/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7472 - val_loss: 0.6342\n",
      "Epoch 139/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7340 - val_loss: 0.5913\n",
      "Epoch 140/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7233 - val_loss: 0.5882\n",
      "Epoch 141/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7317 - val_loss: 0.5888\n",
      "Epoch 142/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7240 - val_loss: 0.6514\n",
      "Epoch 143/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7238 - val_loss: 0.6497\n",
      "Epoch 144/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7452 - val_loss: 0.6073\n",
      "Epoch 145/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7266 - val_loss: 0.6237\n",
      "Epoch 146/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 0.7429 - val_loss: 0.6323\n",
      "Epoch 147/300\n",
      "73/73 [==============================] - ETA: 0s - loss: 0.7299Restoring model weights from the end of the best epoch: 117.\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.7299 - val_loss: 0.6056\n",
      "Epoch 147: early stopping\n",
      "'########################################################Model9\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 81549656.0000 - val_loss: 9541944.0000\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 13698017.0000 - val_loss: 1946473.0000\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 2743204.7500 - val_loss: 237623.2344\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 248697.3594 - val_loss: 100663.4453\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 71094.9766 - val_loss: 84088.4922\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 55309.6367 - val_loss: 105259.9766\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 50964.9883 - val_loss: 98320.1406\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 43277.4180 - val_loss: 110374.6641\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 33860.1758 - val_loss: 98788.4062\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 34517.2969 - val_loss: 113812.5625\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 29717.5645 - val_loss: 111965.5625\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 27926.7715 - val_loss: 120949.8906\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 36659.2266 - val_loss: 121435.0859\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 32769.5000 - val_loss: 122387.2969\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 29638.4316 - val_loss: 138188.2031\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 30122.8965 - val_loss: 144847.0938\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 35533.3359 - val_loss: 148091.5469\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 36491.7812 - val_loss: 148481.5938\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 34087.2461 - val_loss: 142419.1875\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 32905.9883 - val_loss: 162135.7500\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 35127.2578 - val_loss: 166681.1562\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 36764.1680 - val_loss: 162700.7188\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 34503.1484 - val_loss: 162739.4375\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 31161.4980 - val_loss: 181332.9688\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 34142.7734 - val_loss: 183184.5312\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 35557.6836 - val_loss: 165416.8125\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 32721.6270 - val_loss: 166756.8750\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 29860.1660 - val_loss: 170333.7344\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 31801.7227 - val_loss: 172061.4688\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 32502.4531 - val_loss: 182962.6875\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 32864.8047 - val_loss: 179609.9062\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 32815.2812 - val_loss: 185237.7812\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 31625.5820 - val_loss: 183396.2812\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 34645.7734 - val_loss: 173527.2500\n",
      "Epoch 35/300\n",
      "65/73 [=========================>....] - ETA: 0s - loss: 33728.6914Restoring model weights from the end of the best epoch: 5.\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 33415.7656 - val_loss: 173196.9531\n",
      "Epoch 35: early stopping\n",
      "'########################################################Model0\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 99294720.0000 - val_loss: 19002302.0000\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 12613960.0000 - val_loss: 2875560.5000\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 2511452.5000 - val_loss: 363403.8438\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 348807.1562 - val_loss: 130378.6797\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 97266.3906 - val_loss: 102086.7344\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 60726.3164 - val_loss: 81443.7109\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 50460.5078 - val_loss: 114088.5703\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 51437.7852 - val_loss: 98836.3984\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 41329.8672 - val_loss: 104953.9219\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 42129.7422 - val_loss: 107701.0938\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 43206.3281 - val_loss: 133943.9375\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 44020.6055 - val_loss: 132198.4375\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 37058.4102 - val_loss: 135151.8438\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 41440.6016 - val_loss: 128455.3828\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 39312.4648 - val_loss: 151479.2344\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 38403.3164 - val_loss: 142099.1250\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 34223.9609 - val_loss: 146648.7344\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 37695.6836 - val_loss: 155260.8281\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 38038.3086 - val_loss: 165035.0312\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 35810.1602 - val_loss: 147158.4375\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 33991.5664 - val_loss: 148516.1406\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 32759.2598 - val_loss: 166114.2812\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 39429.7266 - val_loss: 170690.1094\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 41163.9609 - val_loss: 170933.7969\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 41291.4766 - val_loss: 164145.3594\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 39545.1953 - val_loss: 166487.7812\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 39497.0195 - val_loss: 185601.7188\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 38090.4180 - val_loss: 185343.6250\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 34698.2031 - val_loss: 175271.5312\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 33108.0391 - val_loss: 174282.9375\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 35743.2773 - val_loss: 170577.8594\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 33676.4688 - val_loss: 184480.2188\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 37316.3242 - val_loss: 196484.8125\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 35903.1367 - val_loss: 180112.8438\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 34640.3789 - val_loss: 186480.7188\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - ETA: 0s - loss: 35561.9531Restoring model weights from the end of the best epoch: 6.\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 35561.9531 - val_loss: 177802.8906\n",
      "Epoch 36: early stopping\n",
      "'########################################################Model1\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 108243784.0000 - val_loss: 17871834.0000\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 14673735.0000 - val_loss: 3225068.5000\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 4250600.5000 - val_loss: 756586.0625\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 914433.6875 - val_loss: 138794.6250\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 169120.1875 - val_loss: 92367.0312\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 71851.5078 - val_loss: 93657.7109\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 71740.7812 - val_loss: 102259.5547\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 57131.9844 - val_loss: 81365.5469\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 52914.9844 - val_loss: 109185.5234\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 42932.9375 - val_loss: 112806.1328\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 41603.8906 - val_loss: 135874.1094\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 48849.4219 - val_loss: 142446.6406\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 40950.1641 - val_loss: 142383.7500\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 42881.5469 - val_loss: 122687.3906\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 37538.0820 - val_loss: 135853.0156\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 38317.0820 - val_loss: 146527.5938\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 35297.8008 - val_loss: 153837.2812\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 36073.7656 - val_loss: 147003.1406\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 33080.8359 - val_loss: 143300.6875\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 39803.9961 - val_loss: 160559.6250\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 37456.3945 - val_loss: 174890.1094\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 41810.7031 - val_loss: 176788.5000\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 41219.7578 - val_loss: 167675.9688\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 35210.7383 - val_loss: 153810.7500\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 31593.3262 - val_loss: 170490.8281\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 32839.7539 - val_loss: 165090.3594\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 37072.0664 - val_loss: 175973.3594\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 32534.3535 - val_loss: 162338.0625\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 25688.1172 - val_loss: 176026.2031\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 27045.2266 - val_loss: 159967.8125\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 26850.2812 - val_loss: 165748.9219\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 26899.4121 - val_loss: 161001.5000\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 25588.1719 - val_loss: 168338.1250\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 26156.3066 - val_loss: 182895.6406\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 25493.3301 - val_loss: 172719.2969\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 25594.6602 - val_loss: 174703.3750\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 26439.2969 - val_loss: 176392.1719\n",
      "Epoch 38/300\n",
      "65/73 [=========================>....] - ETA: 0s - loss: 34865.9102Restoring model weights from the end of the best epoch: 8.\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 34897.7109 - val_loss: 189630.2344\n",
      "Epoch 38: early stopping\n",
      "'########################################################Model2\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 89490304.0000 - val_loss: 16258285.0000\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 11884559.0000 - val_loss: 2250552.2500\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 2287446.0000 - val_loss: 210903.1250\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 283913.7188 - val_loss: 95065.9688\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 90656.7656 - val_loss: 117572.8516\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 67137.0156 - val_loss: 92963.8125\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 53866.0117 - val_loss: 120027.6016\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 53169.7109 - val_loss: 103430.3828\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 49915.7852 - val_loss: 107223.6328\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 41001.3984 - val_loss: 121662.2891\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 39703.4414 - val_loss: 117427.7500\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 37130.9414 - val_loss: 121409.2422\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 37883.3789 - val_loss: 119458.9219\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 33973.8125 - val_loss: 141527.8906\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 42877.0391 - val_loss: 145483.6562\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 38249.2266 - val_loss: 124238.7969\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 33728.8672 - val_loss: 139854.4062\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 35964.2969 - val_loss: 145990.0781\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 36773.6445 - val_loss: 158747.0781\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 29941.5703 - val_loss: 151873.8125\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 47764.4961 - val_loss: 164814.7031\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 34723.2070 - val_loss: 165975.4688\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 37837.1328 - val_loss: 175091.1250\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 33878.5625 - val_loss: 165613.1562\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 36894.4688 - val_loss: 172236.3125\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 34109.5898 - val_loss: 171611.1094\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 37550.4297 - val_loss: 169051.6562\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 35107.7695 - val_loss: 173208.4844\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 36312.5469 - val_loss: 184997.1094\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 34393.8828 - val_loss: 171758.0938\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 31627.7715 - val_loss: 174602.2031\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 444929.6562 - val_loss: 179439.2188\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 27978.2988 - val_loss: 166913.1719\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 28481.4336 - val_loss: 173828.6719\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 28148.2871 - val_loss: 189434.2344\n",
      "Epoch 36/300\n",
      "66/73 [==========================>...] - ETA: 0s - loss: 26803.0566Restoring model weights from the end of the best epoch: 6.\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 26385.3203 - val_loss: 174245.8750\n",
      "Epoch 36: early stopping\n",
      "'########################################################Model3\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 115751552.0000 - val_loss: 11248953.0000\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 10021165.0000 - val_loss: 2528151.7500\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 1648427.1250 - val_loss: 138033.5938\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 163320.6719 - val_loss: 115044.5547\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 73902.5547 - val_loss: 77610.7266\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 56112.9531 - val_loss: 88361.3359\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 46451.5234 - val_loss: 97906.3750\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 45477.4375 - val_loss: 93696.7266\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 39168.4375 - val_loss: 99148.2656\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 40720.5195 - val_loss: 103555.2734\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 40493.0195 - val_loss: 117898.5625\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 41273.6562 - val_loss: 127513.2422\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 39470.3281 - val_loss: 122506.8672\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 31282.1973 - val_loss: 126080.1484\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 35958.4102 - val_loss: 117591.8906\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 36315.5859 - val_loss: 147620.6562\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 34216.7812 - val_loss: 149274.2812\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 37725.8789 - val_loss: 152933.0000\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 38477.5547 - val_loss: 143430.2656\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 28494.0039 - val_loss: 152070.0469\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 31732.2012 - val_loss: 157502.1094\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 31388.3848 - val_loss: 155473.5625\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 30860.3770 - val_loss: 158217.8906\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 32395.6191 - val_loss: 171238.7812\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 36000.8281 - val_loss: 169953.9844\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 31067.5645 - val_loss: 152796.0312\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 30169.5430 - val_loss: 158955.9375\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 30423.0586 - val_loss: 164389.1875\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 29677.9512 - val_loss: 179341.9844\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 29928.5293 - val_loss: 159826.0781\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 31196.7812 - val_loss: 181408.6406\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 33057.6211 - val_loss: 179461.3438\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 29764.8887 - val_loss: 171647.1562\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 26603.2930 - val_loss: 164079.2812\n",
      "Epoch 35/300\n",
      "65/73 [=========================>....] - ETA: 0s - loss: 24056.6816Restoring model weights from the end of the best epoch: 5.\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 24415.5742 - val_loss: 180782.0312\n",
      "Epoch 35: early stopping\n",
      "'########################################################Model4\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 10ms/step - loss: 68234488.0000 - val_loss: 8249389.0000\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 8770533.0000 - val_loss: 1952617.5000\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 1619347.5000 - val_loss: 99651.6641\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 169640.7812 - val_loss: 110147.2656\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 73327.8203 - val_loss: 107950.3438\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 60890.7461 - val_loss: 108249.9766\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 52058.3906 - val_loss: 112810.9688\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 45788.2383 - val_loss: 119506.7734\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 38405.8945 - val_loss: 91489.2656\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 36962.5469 - val_loss: 131217.3594\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 40483.2227 - val_loss: 123370.0391\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 39955.0703 - val_loss: 133739.4062\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 39476.6562 - val_loss: 133657.7344\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 37962.6875 - val_loss: 128821.9141\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 41649.4219 - val_loss: 145880.6250\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 38568.1836 - val_loss: 144808.6875\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 35367.5703 - val_loss: 142590.4375\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 30395.0078 - val_loss: 157442.6406\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 31595.3145 - val_loss: 157860.8750\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 31008.4043 - val_loss: 149063.1094\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 30594.3711 - val_loss: 141918.1719\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 28513.5488 - val_loss: 146314.6875\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 30315.7500 - val_loss: 156957.6719\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 27705.9395 - val_loss: 156060.3125\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 28234.6387 - val_loss: 166965.6875\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 27220.2344 - val_loss: 168356.1562\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 29970.5879 - val_loss: 175213.3125\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 30723.1895 - val_loss: 172839.0781\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 33366.9023 - val_loss: 165030.1875\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 29595.8340 - val_loss: 180114.5000\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 30757.0801 - val_loss: 159842.4219\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 29138.7852 - val_loss: 165052.7812\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 29453.4180 - val_loss: 171151.0156\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 28650.2676 - val_loss: 170511.0000\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 30328.3711 - val_loss: 173612.4844\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 29011.0371 - val_loss: 183500.2344\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 29828.2871 - val_loss: 167117.5625\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 29775.1348 - val_loss: 178675.5938\n",
      "Epoch 39/300\n",
      "65/73 [=========================>....] - ETA: 0s - loss: 33865.8945Restoring model weights from the end of the best epoch: 9.\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 32720.0000 - val_loss: 181815.0000\n",
      "Epoch 39: early stopping\n",
      "'########################################################Model5\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 86394624.0000 - val_loss: 7724822.0000\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 8051647.5000 - val_loss: 666171.5625\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 664401.1875 - val_loss: 74875.6406\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 75508.9453 - val_loss: 109027.8125\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 65246.2422 - val_loss: 74960.5859\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 57340.5898 - val_loss: 92314.5703\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 38777.2852 - val_loss: 99969.9062\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 46862.0195 - val_loss: 117000.7969\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 43722.3594 - val_loss: 103229.7500\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 37837.2109 - val_loss: 124127.0312\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 32837.9258 - val_loss: 125000.6172\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 36948.5312 - val_loss: 118265.6719\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 28460.7656 - val_loss: 120544.9922\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 36032.5312 - val_loss: 131521.1250\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 35723.7383 - val_loss: 139181.4062\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 38299.2773 - val_loss: 126397.1016\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 31820.9023 - val_loss: 141962.6719\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 35305.8320 - val_loss: 148281.6406\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 35757.1914 - val_loss: 160794.0000\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 35017.6328 - val_loss: 149253.4688\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 31051.9863 - val_loss: 161782.6562\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 30958.8262 - val_loss: 155648.0469\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 30334.0547 - val_loss: 159889.9375\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 31684.6504 - val_loss: 160646.3438\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 32238.1250 - val_loss: 156701.0312\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 33063.3164 - val_loss: 163505.4219\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 31567.7305 - val_loss: 161731.1250\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 30899.2246 - val_loss: 169259.9531\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 33342.1328 - val_loss: 175360.3750\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 33174.2578 - val_loss: 171734.5469\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 31203.0410 - val_loss: 168271.4688\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 31365.8203 - val_loss: 173326.4375\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - ETA: 0s - loss: 29347.9590Restoring model weights from the end of the best epoch: 3.\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 29347.9590 - val_loss: 164483.4688\n",
      "Epoch 33: early stopping\n",
      "'########################################################Model6\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 128875368.0000 - val_loss: 33998588.0000\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 26497314.0000 - val_loss: 7603838.0000\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 8038212.0000 - val_loss: 1225314.8750\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 2638753.5000 - val_loss: 361768.6562\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 768092.6250 - val_loss: 159501.5312\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 211132.7344 - val_loss: 148869.7031\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 230774.5938 - val_loss: 131729.1719\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 81591.5000 - val_loss: 117669.5703\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 60721.7930 - val_loss: 121476.0547\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 52356.4062 - val_loss: 134518.1875\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 49457.9570 - val_loss: 127415.9609\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 49403.0078 - val_loss: 136497.7969\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 38230.6484 - val_loss: 118100.5625\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 40486.2578 - val_loss: 145297.6094\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 37621.7539 - val_loss: 132771.4375\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 42002.7852 - val_loss: 141769.9688\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 34929.4375 - val_loss: 150044.0625\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 41189.1836 - val_loss: 162098.1719\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 38739.6562 - val_loss: 151127.2969\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 43193.1641 - val_loss: 161724.5469\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 38295.6641 - val_loss: 151385.3438\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 43797.0078 - val_loss: 172518.7500\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 41158.0156 - val_loss: 150362.9531\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 33806.3008 - val_loss: 164964.9688\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 29545.5234 - val_loss: 172271.0000\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 34895.8398 - val_loss: 154624.5000\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 32942.7383 - val_loss: 162136.4688\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 31987.6367 - val_loss: 164818.1719\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 30253.8828 - val_loss: 172069.5312\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 32988.4258 - val_loss: 166823.9375\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 87838.8672 - val_loss: 179276.8125\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 22420.9121 - val_loss: 165722.4844\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 24943.3262 - val_loss: 165798.2188\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 29141.5254 - val_loss: 165444.7188\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 25006.2012 - val_loss: 178952.8594\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 28078.6445 - val_loss: 190111.8281\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 36779.3672 - val_loss: 177325.2500\n",
      "Epoch 38/300\n",
      "65/73 [=========================>....] - ETA: 0s - loss: 32978.6836Restoring model weights from the end of the best epoch: 8.\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 32213.7949 - val_loss: 187580.9219\n",
      "Epoch 38: early stopping\n",
      "'########################################################Model7\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 86406016.0000 - val_loss: 8418643.0000\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 4822424.0000 - val_loss: 514499.9062\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 300537.3750 - val_loss: 93837.4297\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 75370.1484 - val_loss: 69219.8438\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 44282.1406 - val_loss: 86488.4688\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 43710.4688 - val_loss: 90442.9375\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 40236.6758 - val_loss: 93254.9141\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 36949.0508 - val_loss: 96725.9688\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 35512.0391 - val_loss: 101325.7188\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 37927.4023 - val_loss: 106989.9453\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 29784.2832 - val_loss: 109575.5547\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 33511.8398 - val_loss: 122640.0938\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 27885.7539 - val_loss: 121678.6875\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 31790.3008 - val_loss: 138766.5000\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 32256.7891 - val_loss: 123620.6328\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 26699.0547 - val_loss: 122283.0859\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 30143.3594 - val_loss: 131731.7500\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 30503.2969 - val_loss: 147895.7031\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 32335.5059 - val_loss: 150481.3906\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 31966.1660 - val_loss: 151785.7500\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 30509.0371 - val_loss: 141877.2344\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 31358.5977 - val_loss: 152913.0000\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 31900.7188 - val_loss: 172172.4219\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 33459.4688 - val_loss: 158152.8750\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 30855.7090 - val_loss: 157551.5781\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 34949.7617 - val_loss: 170514.2656\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 33877.9922 - val_loss: 162514.6562\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 37334.4336 - val_loss: 167493.9375\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 34365.6875 - val_loss: 170402.8125\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 34433.7305 - val_loss: 182101.3125\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 34687.2773 - val_loss: 188809.4062\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 36712.0156 - val_loss: 164238.6406\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 33253.5430 - val_loss: 167763.6250\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - ETA: 0s - loss: 29038.8262Restoring model weights from the end of the best epoch: 4.\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 29038.8262 - val_loss: 173390.1719\n",
      "Epoch 34: early stopping\n",
      "'########################################################Model8\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 112921864.0000 - val_loss: 36002960.0000\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 18467872.0000 - val_loss: 4791140.0000\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 3416887.2500 - val_loss: 122150.7031\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 110865.1172 - val_loss: 110501.1484\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 61341.6758 - val_loss: 113836.0312\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 56864.2852 - val_loss: 103643.4688\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 58381.1641 - val_loss: 103999.4375\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 44057.1367 - val_loss: 90630.7422\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 41909.3125 - val_loss: 108047.3750\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 38930.9336 - val_loss: 112452.5781\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 42922.6133 - val_loss: 124313.4375\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 42128.1484 - val_loss: 124832.8125\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 39517.9766 - val_loss: 131580.8906\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 39453.6016 - val_loss: 142115.2188\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 42617.9648 - val_loss: 146768.5625\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 39797.0312 - val_loss: 143193.7812\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 37203.2656 - val_loss: 150958.3281\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 37047.3906 - val_loss: 143708.6562\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 34827.4531 - val_loss: 151852.1250\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 36361.1055 - val_loss: 163903.4375\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 36446.0664 - val_loss: 161326.7031\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 36336.7070 - val_loss: 170687.8281\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 35161.0820 - val_loss: 168094.8750\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 33393.4688 - val_loss: 156743.5000\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 36160.5156 - val_loss: 170164.8750\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 33098.3398 - val_loss: 159205.5469\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 33930.8320 - val_loss: 161505.5938\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 32694.3711 - val_loss: 171978.7344\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 32841.3047 - val_loss: 169222.2969\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 31799.6191 - val_loss: 169338.3281\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 34083.8242 - val_loss: 185380.3750\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 33536.4297 - val_loss: 166157.0000\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 37813.6523 - val_loss: 190906.3125\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 39416.8164 - val_loss: 185197.5312\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 38197.5312 - val_loss: 180174.6719\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 39064.8320 - val_loss: 181952.9375\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 41305.7031 - val_loss: 183267.9062\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - ETA: 0s - loss: 38846.9258Restoring model weights from the end of the best epoch: 8.\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 38846.9258 - val_loss: 193547.2344\n",
      "Epoch 38: early stopping\n",
      "'########################################################Model9\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 147.0998 - val_loss: 147.0860\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 143.6681 - val_loss: 146.7835\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 142.7018 - val_loss: 143.9306\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 141.6867 - val_loss: 145.3366\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 140.7856 - val_loss: 143.5829\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 136.7538 - val_loss: 138.1812\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 133.6122 - val_loss: 137.4252\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 132.7638 - val_loss: 137.5416\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 133.4825 - val_loss: 137.2295\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 132.5679 - val_loss: 136.2615\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 132.0262 - val_loss: 135.8551\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 132.0660 - val_loss: 135.9287\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 132.4907 - val_loss: 137.8991\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 132.1557 - val_loss: 138.4755\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 132.1672 - val_loss: 136.0374\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.9760 - val_loss: 136.0899\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 132.1038 - val_loss: 135.9692\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.5863 - val_loss: 136.1382\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.5103 - val_loss: 136.2567\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.5779 - val_loss: 134.7805\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 132.1900 - val_loss: 138.8347\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.8023 - val_loss: 135.3920\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.1956 - val_loss: 136.2590\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.4562 - val_loss: 135.8456\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.4476 - val_loss: 135.6476\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.4545 - val_loss: 134.6771\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.1171 - val_loss: 135.0675\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.0731 - val_loss: 134.4658\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.2606 - val_loss: 135.6304\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.5723 - val_loss: 135.7655\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.0253 - val_loss: 134.5628\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.7637 - val_loss: 134.4601\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.8484 - val_loss: 134.3404\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.9411 - val_loss: 134.3084\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.6028 - val_loss: 134.0689\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.7313 - val_loss: 133.6336\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.6914 - val_loss: 135.5669\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.3782 - val_loss: 134.3955\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.6747 - val_loss: 135.1995\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.3849 - val_loss: 135.3350\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.3803 - val_loss: 138.7578\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.4662 - val_loss: 135.4311\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.3511 - val_loss: 133.4105\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.4899 - val_loss: 135.0359\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.9584 - val_loss: 134.8552\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.1160 - val_loss: 136.0430\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.9804 - val_loss: 134.6218\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 130.2099 - val_loss: 133.8769\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.6654 - val_loss: 134.5300\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.8501 - val_loss: 134.5970\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.9685 - val_loss: 133.8627\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 130.0171 - val_loss: 133.5181\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.0568 - val_loss: 133.5388\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.5952 - val_loss: 134.5337\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.2827 - val_loss: 134.3865\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.5710 - val_loss: 134.9776\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.4400 - val_loss: 134.5370\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.1786 - val_loss: 134.1578\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.8835 - val_loss: 133.5643\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.1309 - val_loss: 134.3826\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.9643 - val_loss: 134.3626\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.8799 - val_loss: 133.1949\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.9590 - val_loss: 134.2035\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.8273 - val_loss: 132.8888\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.8061 - val_loss: 133.5999\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.3475 - val_loss: 134.3915\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.2274 - val_loss: 133.0983\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.4176 - val_loss: 133.3523\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.1788 - val_loss: 134.3851\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.2653 - val_loss: 133.7154\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 130.2766 - val_loss: 134.3929\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.0079 - val_loss: 132.7892\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.9671 - val_loss: 133.3696\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.8445 - val_loss: 135.5701\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.8526 - val_loss: 132.4766\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.9179 - val_loss: 134.4270\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.1684 - val_loss: 134.0443\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.0010 - val_loss: 133.9694\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.6516 - val_loss: 133.2715\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.9378 - val_loss: 134.1730\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.1878 - val_loss: 133.3795\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.5266 - val_loss: 133.3824\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.5529 - val_loss: 134.8649\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.3624 - val_loss: 129.9341\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.0026 - val_loss: 129.0202\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 124.5277 - val_loss: 128.3363\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.5732 - val_loss: 128.4955\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.4798 - val_loss: 130.1147\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.5361 - val_loss: 128.8718\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.3898 - val_loss: 127.5734\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.4713 - val_loss: 128.9413\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.7107 - val_loss: 129.5329\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.2519 - val_loss: 129.1925\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.4621 - val_loss: 128.1490\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.0877 - val_loss: 130.5029\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.2968 - val_loss: 128.0475\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.9391 - val_loss: 128.4880\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.1113 - val_loss: 129.2617\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.5743 - val_loss: 128.5739\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.1637 - val_loss: 128.5013\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.9749 - val_loss: 127.8770\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.8941 - val_loss: 127.6649\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.9808 - val_loss: 127.2838\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.1282 - val_loss: 128.6607\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.8369 - val_loss: 128.0022\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.9284 - val_loss: 127.9976\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.0584 - val_loss: 129.3888\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.6691 - val_loss: 127.9956\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.9274 - val_loss: 126.8707\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.9824 - val_loss: 127.7113\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.8762 - val_loss: 127.6278\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.8034 - val_loss: 128.4194\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.0549 - val_loss: 128.0215\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.8381 - val_loss: 128.3295\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 123.9145 - val_loss: 128.1044\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.9479 - val_loss: 126.8738\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.0104 - val_loss: 127.2055\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.5339 - val_loss: 127.6040\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.6868 - val_loss: 127.5047\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.5589 - val_loss: 126.9251\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.6995 - val_loss: 127.3891\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.6921 - val_loss: 127.3941\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.6225 - val_loss: 127.8677\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.5773 - val_loss: 128.5180\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.3024 - val_loss: 127.6425\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.6872 - val_loss: 127.4469\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.4530 - val_loss: 127.2536\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.6157 - val_loss: 127.9117\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.4682 - val_loss: 127.1461\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.8696 - val_loss: 128.8650\n",
      "Epoch 131/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.9967 - val_loss: 128.4402\n",
      "Epoch 132/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.7063 - val_loss: 127.6304\n",
      "Epoch 133/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.1779 - val_loss: 127.8669\n",
      "Epoch 134/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 123.5101 - val_loss: 127.6351\n",
      "Epoch 135/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.2284 - val_loss: 127.9981\n",
      "Epoch 136/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.5207 - val_loss: 126.9497\n",
      "Epoch 137/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.2421 - val_loss: 127.1543\n",
      "Epoch 138/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.3632 - val_loss: 127.7077\n",
      "Epoch 139/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 123.4188 - val_loss: 126.4454\n",
      "Epoch 140/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.4657 - val_loss: 127.9143\n",
      "Epoch 141/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.3962 - val_loss: 127.1144\n",
      "Epoch 142/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.3431 - val_loss: 127.3459\n",
      "Epoch 143/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.6201 - val_loss: 127.4152\n",
      "Epoch 144/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.1293 - val_loss: 126.6479\n",
      "Epoch 145/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.4064 - val_loss: 127.1656\n",
      "Epoch 146/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.1826 - val_loss: 127.7522\n",
      "Epoch 147/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.2278 - val_loss: 126.9986\n",
      "Epoch 148/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.1243 - val_loss: 127.6730\n",
      "Epoch 149/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.4473 - val_loss: 127.0056\n",
      "Epoch 150/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.8421 - val_loss: 126.7289\n",
      "Epoch 151/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.9528 - val_loss: 126.6836\n",
      "Epoch 152/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 123.3327 - val_loss: 126.4016\n",
      "Epoch 153/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.0534 - val_loss: 127.8150\n",
      "Epoch 154/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.2017 - val_loss: 127.4404\n",
      "Epoch 155/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.1002 - val_loss: 127.1597\n",
      "Epoch 156/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.0480 - val_loss: 126.9490\n",
      "Epoch 157/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.3868 - val_loss: 126.1587\n",
      "Epoch 158/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.9407 - val_loss: 126.6987\n",
      "Epoch 159/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.9739 - val_loss: 128.0957\n",
      "Epoch 160/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.3763 - val_loss: 127.2006\n",
      "Epoch 161/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.2000 - val_loss: 127.8118\n",
      "Epoch 162/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.8418 - val_loss: 126.6128\n",
      "Epoch 163/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.6499 - val_loss: 126.9852\n",
      "Epoch 164/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.4530 - val_loss: 127.5668\n",
      "Epoch 165/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.0444 - val_loss: 127.4511\n",
      "Epoch 166/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.2840 - val_loss: 126.5770\n",
      "Epoch 167/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.9894 - val_loss: 126.8925\n",
      "Epoch 168/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.4515 - val_loss: 128.0190\n",
      "Epoch 169/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.2172 - val_loss: 126.1296\n",
      "Epoch 170/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.8604 - val_loss: 127.5120\n",
      "Epoch 171/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.3144 - val_loss: 127.4356\n",
      "Epoch 172/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.7996 - val_loss: 126.2861\n",
      "Epoch 173/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.7926 - val_loss: 127.3851\n",
      "Epoch 174/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.1108 - val_loss: 126.6278\n",
      "Epoch 175/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.9417 - val_loss: 126.4337\n",
      "Epoch 176/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.7007 - val_loss: 126.3438\n",
      "Epoch 177/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.0165 - val_loss: 127.5031\n",
      "Epoch 178/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.7569 - val_loss: 127.3821\n",
      "Epoch 179/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.9713 - val_loss: 126.7900\n",
      "Epoch 180/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.6346 - val_loss: 126.6671\n",
      "Epoch 181/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.9076 - val_loss: 126.6914\n",
      "Epoch 182/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.6947 - val_loss: 126.8325\n",
      "Epoch 183/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.9595 - val_loss: 127.3954\n",
      "Epoch 184/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 122.7818 - val_loss: 127.3855\n",
      "Epoch 185/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.8732 - val_loss: 126.2792\n",
      "Epoch 186/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.6926 - val_loss: 126.5412\n",
      "Epoch 187/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 122.6953 - val_loss: 125.8765\n",
      "Epoch 188/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.5105 - val_loss: 126.3837\n",
      "Epoch 189/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.5811 - val_loss: 127.4618\n",
      "Epoch 190/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.5758 - val_loss: 126.6782\n",
      "Epoch 191/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.8943 - val_loss: 126.1198\n",
      "Epoch 192/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.5454 - val_loss: 126.6401\n",
      "Epoch 193/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.7693 - val_loss: 127.3434\n",
      "Epoch 194/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.5061 - val_loss: 126.8157\n",
      "Epoch 195/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.7586 - val_loss: 126.7303\n",
      "Epoch 196/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.3903 - val_loss: 126.4719\n",
      "Epoch 197/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.4820 - val_loss: 125.8573\n",
      "Epoch 198/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.5125 - val_loss: 126.4841\n",
      "Epoch 199/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 122.7732 - val_loss: 126.5476\n",
      "Epoch 200/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.7309 - val_loss: 126.0788\n",
      "Epoch 201/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.5399 - val_loss: 125.7639\n",
      "Epoch 202/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 122.3304 - val_loss: 125.7629\n",
      "Epoch 203/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.3604 - val_loss: 126.8264\n",
      "Epoch 204/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.6255 - val_loss: 128.8634\n",
      "Epoch 205/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.5665 - val_loss: 126.5239\n",
      "Epoch 206/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.6385 - val_loss: 126.3072\n",
      "Epoch 207/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.6837 - val_loss: 126.9022\n",
      "Epoch 208/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.3354 - val_loss: 125.9369\n",
      "Epoch 209/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 122.5659 - val_loss: 126.1613\n",
      "Epoch 210/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.2961 - val_loss: 125.9431\n",
      "Epoch 211/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.4027 - val_loss: 126.3526\n",
      "Epoch 212/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.1891 - val_loss: 125.8459\n",
      "Epoch 213/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.3236 - val_loss: 125.9506\n",
      "Epoch 214/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.5789 - val_loss: 127.3613\n",
      "Epoch 215/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.5950 - val_loss: 126.0958\n",
      "Epoch 216/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.5476 - val_loss: 126.6971\n",
      "Epoch 217/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.3102 - val_loss: 125.9076\n",
      "Epoch 218/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.2117 - val_loss: 126.0776\n",
      "Epoch 219/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.5178 - val_loss: 126.3823\n",
      "Epoch 220/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.1326 - val_loss: 126.1007\n",
      "Epoch 221/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.5569 - val_loss: 126.8780\n",
      "Epoch 222/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.3839 - val_loss: 126.0300\n",
      "Epoch 223/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.5001 - val_loss: 126.4770\n",
      "Epoch 224/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.6952 - val_loss: 126.5301\n",
      "Epoch 225/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.1812 - val_loss: 125.6311\n",
      "Epoch 226/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.3409 - val_loss: 126.6908\n",
      "Epoch 227/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 122.6281 - val_loss: 126.4902\n",
      "Epoch 228/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.6686 - val_loss: 126.0491\n",
      "Epoch 229/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.4041 - val_loss: 126.1406\n",
      "Epoch 230/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.1056 - val_loss: 125.6659\n",
      "Epoch 231/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.2854 - val_loss: 126.5208\n",
      "Epoch 232/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.3028 - val_loss: 125.9899\n",
      "Epoch 233/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.2849 - val_loss: 126.5913\n",
      "Epoch 234/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.5129 - val_loss: 126.9173\n",
      "Epoch 235/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.5407 - val_loss: 125.6654\n",
      "Epoch 236/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.7887 - val_loss: 125.8379\n",
      "Epoch 237/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 122.1564 - val_loss: 125.5026\n",
      "Epoch 238/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.2852 - val_loss: 125.7130\n",
      "Epoch 239/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.2324 - val_loss: 126.2325\n",
      "Epoch 240/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.1283 - val_loss: 126.4354\n",
      "Epoch 241/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.2731 - val_loss: 126.5986\n",
      "Epoch 242/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.2404 - val_loss: 127.0457\n",
      "Epoch 243/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.2661 - val_loss: 125.7583\n",
      "Epoch 244/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.1305 - val_loss: 126.2936\n",
      "Epoch 245/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.1800 - val_loss: 125.7047\n",
      "Epoch 246/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 121.9901 - val_loss: 125.5117\n",
      "Epoch 247/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.1146 - val_loss: 126.3626\n",
      "Epoch 248/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.0423 - val_loss: 125.3857\n",
      "Epoch 249/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.1973 - val_loss: 126.3941\n",
      "Epoch 250/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 121.9863 - val_loss: 126.0949\n",
      "Epoch 251/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.2492 - val_loss: 126.1314\n",
      "Epoch 252/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 121.9745 - val_loss: 126.1409\n",
      "Epoch 253/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.1782 - val_loss: 126.2436\n",
      "Epoch 254/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.2448 - val_loss: 125.5499\n",
      "Epoch 255/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 121.9852 - val_loss: 125.8596\n",
      "Epoch 256/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.1997 - val_loss: 125.6240\n",
      "Epoch 257/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.0842 - val_loss: 126.4200\n",
      "Epoch 258/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.2633 - val_loss: 127.0088\n",
      "Epoch 259/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.1873 - val_loss: 126.2657\n",
      "Epoch 260/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.3573 - val_loss: 125.7803\n",
      "Epoch 261/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 121.9401 - val_loss: 125.4727\n",
      "Epoch 262/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 121.8117 - val_loss: 125.9627\n",
      "Epoch 263/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 121.9301 - val_loss: 125.8892\n",
      "Epoch 264/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.1143 - val_loss: 125.9075\n",
      "Epoch 265/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 121.9772 - val_loss: 125.4507\n",
      "Epoch 266/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.2151 - val_loss: 125.7280\n",
      "Epoch 267/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 121.9341 - val_loss: 126.8033\n",
      "Epoch 268/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.2832 - val_loss: 125.9087\n",
      "Epoch 269/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 121.9023 - val_loss: 126.4534\n",
      "Epoch 270/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.1815 - val_loss: 126.2318\n",
      "Epoch 271/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.1089 - val_loss: 125.9949\n",
      "Epoch 272/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 121.8275 - val_loss: 125.6958\n",
      "Epoch 273/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 121.7586 - val_loss: 125.8710\n",
      "Epoch 274/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 122.1290 - val_loss: 126.4394\n",
      "Epoch 275/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 121.9563 - val_loss: 125.4058\n",
      "Epoch 276/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 121.7124 - val_loss: 126.3216\n",
      "Epoch 277/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 121.8859 - val_loss: 125.7578\n",
      "Epoch 278/300\n",
      "65/73 [=========================>....] - ETA: 0s - loss: 121.9955Restoring model weights from the end of the best epoch: 248.\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 121.9570 - val_loss: 125.6724\n",
      "Epoch 278: early stopping\n",
      "'########################################################Model0\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 156.5834 - val_loss: 146.2202\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 143.8411 - val_loss: 144.4019\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 141.7585 - val_loss: 146.9075\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 141.8974 - val_loss: 144.9848\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 140.4969 - val_loss: 141.4926\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 139.1064 - val_loss: 143.3537\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 139.5434 - val_loss: 141.0613\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 137.9020 - val_loss: 143.2529\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 138.1030 - val_loss: 141.3679\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 137.4453 - val_loss: 141.3538\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 136.9914 - val_loss: 139.5294\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 136.8909 - val_loss: 140.0516\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 136.3945 - val_loss: 139.4418\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 137.4602 - val_loss: 141.3206\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 136.9984 - val_loss: 140.0405\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 136.4633 - val_loss: 139.2079\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 136.7349 - val_loss: 141.0396\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 132.6718 - val_loss: 134.0807\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 130.6042 - val_loss: 132.9626\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.5917 - val_loss: 133.2858\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.3991 - val_loss: 133.3248\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.3577 - val_loss: 132.4949\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.1615 - val_loss: 132.1693\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.3366 - val_loss: 133.1262\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.8045 - val_loss: 134.4770\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.3634 - val_loss: 135.8112\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.6560 - val_loss: 133.4675\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.7239 - val_loss: 133.0648\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.0164 - val_loss: 132.4960\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.2324 - val_loss: 135.3188\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 130.0918 - val_loss: 132.1295\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.9018 - val_loss: 134.5721\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.4713 - val_loss: 132.2047\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.8686 - val_loss: 132.6241\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.2658 - val_loss: 133.1891\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.0437 - val_loss: 132.4927\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.8584 - val_loss: 132.6534\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.8303 - val_loss: 131.9550\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.8622 - val_loss: 133.6227\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.9450 - val_loss: 135.2410\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.0515 - val_loss: 131.6994\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.9781 - val_loss: 132.8029\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.5530 - val_loss: 130.1886\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.6987 - val_loss: 132.4529\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.8193 - val_loss: 132.1171\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.8316 - val_loss: 134.1026\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.6192 - val_loss: 131.8432\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.8234 - val_loss: 131.9625\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.1360 - val_loss: 132.3399\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.5133 - val_loss: 133.2621\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.0411 - val_loss: 131.5447\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.6529 - val_loss: 132.3374\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.6752 - val_loss: 132.1703\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.1923 - val_loss: 131.4727\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.0785 - val_loss: 131.5474\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.7123 - val_loss: 132.7601\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.9942 - val_loss: 131.4494\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.4182 - val_loss: 132.2602\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.1810 - val_loss: 130.9649\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.3195 - val_loss: 130.8200\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.2629 - val_loss: 132.2886\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.3913 - val_loss: 134.0057\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.9695 - val_loss: 131.4769\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.2360 - val_loss: 130.6899\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.1296 - val_loss: 131.9961\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.4320 - val_loss: 132.0812\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.2910 - val_loss: 131.3636\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.4681 - val_loss: 131.2185\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.1064 - val_loss: 131.8824\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.1126 - val_loss: 131.0054\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.9097 - val_loss: 131.3098\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.8907 - val_loss: 130.8957\n",
      "Epoch 73/300\n",
      "65/73 [=========================>....] - ETA: 0s - loss: 129.1474Restoring model weights from the end of the best epoch: 43.\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 129.3171 - val_loss: 132.0291\n",
      "Epoch 73: early stopping\n",
      "'########################################################Model1\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 10ms/step - loss: 154.3967 - val_loss: 154.1787\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 145.5074 - val_loss: 151.4867\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 143.0016 - val_loss: 148.4694\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 138.7741 - val_loss: 143.2058\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 135.8958 - val_loss: 140.9144\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 136.0550 - val_loss: 140.2564\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 134.1913 - val_loss: 138.6048\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 134.6893 - val_loss: 139.0457\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 133.7161 - val_loss: 139.0074\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 134.8322 - val_loss: 137.0826\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 133.3459 - val_loss: 137.8387\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 133.1794 - val_loss: 137.3522\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 132.8770 - val_loss: 137.8803\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 132.5856 - val_loss: 137.9337\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 132.3989 - val_loss: 136.8675\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 132.6268 - val_loss: 137.7236\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 132.6993 - val_loss: 137.9866\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 132.0273 - val_loss: 137.2225\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 132.4541 - val_loss: 137.2003\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.8303 - val_loss: 137.0167\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 132.6439 - val_loss: 137.3149\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.8738 - val_loss: 136.6551\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.7029 - val_loss: 136.5360\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.6841 - val_loss: 137.3712\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 132.0484 - val_loss: 136.2915\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.7760 - val_loss: 136.8792\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 131.8561 - val_loss: 135.8115\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.7579 - val_loss: 136.7236\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.6620 - val_loss: 136.4783\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.1295 - val_loss: 135.7981\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.0322 - val_loss: 135.8760\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.7196 - val_loss: 136.6129\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 131.0391 - val_loss: 135.8545\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.0222 - val_loss: 136.6301\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.9933 - val_loss: 135.8720\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 132.1404 - val_loss: 136.6609\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 132.1984 - val_loss: 136.7288\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.9477 - val_loss: 136.9865\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 132.7854 - val_loss: 136.6967\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 131.8615 - val_loss: 135.5378\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 132.0376 - val_loss: 135.6338\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.8431 - val_loss: 137.7562\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 132.0675 - val_loss: 136.5726\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 132.0692 - val_loss: 135.7496\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 132.2630 - val_loss: 136.3016\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.9735 - val_loss: 136.9189\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.7003 - val_loss: 135.5830\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.7370 - val_loss: 135.9354\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.2682 - val_loss: 135.2512\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.7710 - val_loss: 135.0910\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 131.3091 - val_loss: 134.6368\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.5619 - val_loss: 135.5413\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 131.8759 - val_loss: 136.7495\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.5259 - val_loss: 135.1994\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.2764 - val_loss: 136.8392\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.2748 - val_loss: 134.9001\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 131.0138 - val_loss: 134.6287\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.4768 - val_loss: 136.8008\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 131.4616 - val_loss: 134.3193\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.0234 - val_loss: 135.9446\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.1638 - val_loss: 134.5164\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.9836 - val_loss: 135.3400\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.9081 - val_loss: 134.8265\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.2213 - val_loss: 135.1360\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.2835 - val_loss: 134.8673\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.7334 - val_loss: 137.1544\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.3107 - val_loss: 134.6448\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.9669 - val_loss: 134.7979\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.2008 - val_loss: 134.7468\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.9236 - val_loss: 134.4134\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.9180 - val_loss: 134.7853\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.7142 - val_loss: 135.0084\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.8660 - val_loss: 134.9955\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.9595 - val_loss: 135.2176\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 130.5412 - val_loss: 134.8443\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.6687 - val_loss: 134.7959\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.9622 - val_loss: 135.1095\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.8235 - val_loss: 135.6657\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 130.7537 - val_loss: 134.9613\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.5555 - val_loss: 135.0751\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 130.5772 - val_loss: 133.8049\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.5764 - val_loss: 135.6013\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.9299 - val_loss: 135.7743\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.5640 - val_loss: 134.6715\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.5269 - val_loss: 134.3599\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.4357 - val_loss: 134.3091\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 130.8344 - val_loss: 133.9820\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.5131 - val_loss: 135.2529\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.3300 - val_loss: 134.6308\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.4531 - val_loss: 134.3012\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.5221 - val_loss: 133.9656\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.1481 - val_loss: 134.9844\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.2045 - val_loss: 134.2258\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.0735 - val_loss: 133.9303\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.0634 - val_loss: 134.2706\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.4736 - val_loss: 133.9545\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.3072 - val_loss: 134.6279\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.6863 - val_loss: 135.2637\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.5414 - val_loss: 134.4612\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.0165 - val_loss: 134.0002\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.2003 - val_loss: 133.9142\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 128.8984 - val_loss: 134.8333\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.2608 - val_loss: 134.2784\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.8814 - val_loss: 134.8166\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.1584 - val_loss: 133.8100\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.9384 - val_loss: 133.7824\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 126.7052 - val_loss: 133.7690\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.3720 - val_loss: 136.0241\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.2308 - val_loss: 133.6232\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.0784 - val_loss: 133.7840\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.5034 - val_loss: 133.6206\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.0255 - val_loss: 133.4879\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.5657 - val_loss: 134.4568\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.3923 - val_loss: 133.5282\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.5888 - val_loss: 134.2771\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.1967 - val_loss: 133.5922\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.8182 - val_loss: 132.9736\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.4627 - val_loss: 134.1107\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.2816 - val_loss: 133.2534\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.4184 - val_loss: 134.1226\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.1921 - val_loss: 133.6272\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.2168 - val_loss: 133.9464\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.7755 - val_loss: 133.2398\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.1434 - val_loss: 134.1953\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.1363 - val_loss: 133.9281\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.0474 - val_loss: 133.1742\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 125.8807 - val_loss: 133.2725\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.1471 - val_loss: 133.8640\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.0611 - val_loss: 133.4298\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.6684 - val_loss: 134.2382\n",
      "Epoch 131/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.0430 - val_loss: 133.4837\n",
      "Epoch 132/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.6997 - val_loss: 133.4677\n",
      "Epoch 133/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.0653 - val_loss: 133.4764\n",
      "Epoch 134/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.7159 - val_loss: 133.3520\n",
      "Epoch 135/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.8868 - val_loss: 132.8505\n",
      "Epoch 136/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.5403 - val_loss: 132.8681\n",
      "Epoch 137/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.6631 - val_loss: 134.1382\n",
      "Epoch 138/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.9551 - val_loss: 133.4975\n",
      "Epoch 139/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.9348 - val_loss: 133.5961\n",
      "Epoch 140/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.9284 - val_loss: 133.6193\n",
      "Epoch 141/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 125.8949 - val_loss: 133.1726\n",
      "Epoch 142/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 125.5468 - val_loss: 132.9104\n",
      "Epoch 143/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.4757 - val_loss: 133.1176\n",
      "Epoch 144/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.6813 - val_loss: 132.8263\n",
      "Epoch 145/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 125.5208 - val_loss: 132.7356\n",
      "Epoch 146/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.9345 - val_loss: 133.4775\n",
      "Epoch 147/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.8100 - val_loss: 133.4191\n",
      "Epoch 148/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.6878 - val_loss: 133.7528\n",
      "Epoch 149/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.6229 - val_loss: 133.0078\n",
      "Epoch 150/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.7152 - val_loss: 132.9458\n",
      "Epoch 151/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.6363 - val_loss: 133.2574\n",
      "Epoch 152/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.4051 - val_loss: 133.2191\n",
      "Epoch 153/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.5197 - val_loss: 133.7285\n",
      "Epoch 154/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 125.3794 - val_loss: 133.4050\n",
      "Epoch 155/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.2592 - val_loss: 133.5431\n",
      "Epoch 156/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.2674 - val_loss: 132.7690\n",
      "Epoch 157/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.3912 - val_loss: 132.6208\n",
      "Epoch 158/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.0873 - val_loss: 132.9693\n",
      "Epoch 159/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 125.4833 - val_loss: 132.7249\n",
      "Epoch 160/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 125.6247 - val_loss: 133.4133\n",
      "Epoch 161/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.2601 - val_loss: 132.9972\n",
      "Epoch 162/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.2526 - val_loss: 133.4665\n",
      "Epoch 163/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 125.0740 - val_loss: 132.2847\n",
      "Epoch 164/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.4438 - val_loss: 133.2649\n",
      "Epoch 165/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 125.4520 - val_loss: 133.0542\n",
      "Epoch 166/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 125.2153 - val_loss: 132.9891\n",
      "Epoch 167/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.4644 - val_loss: 132.6764\n",
      "Epoch 168/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.2324 - val_loss: 133.3234\n",
      "Epoch 169/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.1020 - val_loss: 132.4610\n",
      "Epoch 170/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 125.4040 - val_loss: 133.4556\n",
      "Epoch 171/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.5863 - val_loss: 133.2599\n",
      "Epoch 172/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.3392 - val_loss: 132.7226\n",
      "Epoch 173/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.4716 - val_loss: 133.2103\n",
      "Epoch 174/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 124.9509 - val_loss: 132.2149\n",
      "Epoch 175/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.3741 - val_loss: 133.3146\n",
      "Epoch 176/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.3987 - val_loss: 133.1801\n",
      "Epoch 177/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.0202 - val_loss: 132.9388\n",
      "Epoch 178/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.1771 - val_loss: 133.1559\n",
      "Epoch 179/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.2465 - val_loss: 133.9878\n",
      "Epoch 180/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 125.7604 - val_loss: 132.5876\n",
      "Epoch 181/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.0010 - val_loss: 132.9135\n",
      "Epoch 182/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 125.3733 - val_loss: 133.6190\n",
      "Epoch 183/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.2496 - val_loss: 132.4579\n",
      "Epoch 184/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.1232 - val_loss: 133.4593\n",
      "Epoch 185/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.1657 - val_loss: 132.8974\n",
      "Epoch 186/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.0649 - val_loss: 132.7996\n",
      "Epoch 187/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 125.1810 - val_loss: 132.9192\n",
      "Epoch 188/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.0794 - val_loss: 132.9523\n",
      "Epoch 189/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.0237 - val_loss: 132.7983\n",
      "Epoch 190/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 124.9562 - val_loss: 133.0183\n",
      "Epoch 191/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 124.9126 - val_loss: 132.8516\n",
      "Epoch 192/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.9444 - val_loss: 132.8102\n",
      "Epoch 193/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.6630 - val_loss: 132.5504\n",
      "Epoch 194/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.7684 - val_loss: 132.3742\n",
      "Epoch 195/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.0194 - val_loss: 132.8398\n",
      "Epoch 196/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.0139 - val_loss: 132.8296\n",
      "Epoch 197/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.8846 - val_loss: 132.6723\n",
      "Epoch 198/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.8212 - val_loss: 132.4886\n",
      "Epoch 199/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.7156 - val_loss: 132.5530\n",
      "Epoch 200/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.7468 - val_loss: 132.5117\n",
      "Epoch 201/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.0213 - val_loss: 132.6889\n",
      "Epoch 202/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.7984 - val_loss: 132.5992\n",
      "Epoch 203/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 124.8335 - val_loss: 132.4950\n",
      "Epoch 204/300\n",
      "73/73 [==============================] - ETA: 0s - loss: 124.8086Restoring model weights from the end of the best epoch: 174.\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 124.8086 - val_loss: 132.5427\n",
      "Epoch 204: early stopping\n",
      "'########################################################Model2\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 149.9171 - val_loss: 153.1980\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 136.6287 - val_loss: 137.4714\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 134.0426 - val_loss: 135.3710\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 131.9082 - val_loss: 134.3810\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.4789 - val_loss: 133.0055\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.3185 - val_loss: 130.9257\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.2492 - val_loss: 131.6588\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.7316 - val_loss: 130.6208\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.3208 - val_loss: 135.6959\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.9973 - val_loss: 131.0110\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 127.4690 - val_loss: 130.0654\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.8008 - val_loss: 131.2194\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.4064 - val_loss: 130.7652\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.7557 - val_loss: 130.9814\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.1887 - val_loss: 130.7621\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.7082 - val_loss: 130.3524\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.2202 - val_loss: 130.5279\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.7303 - val_loss: 131.2250\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.3870 - val_loss: 130.1720\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 127.1353 - val_loss: 129.8204\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.9495 - val_loss: 130.2275\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.2020 - val_loss: 130.2260\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.6030 - val_loss: 130.2246\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.3061 - val_loss: 134.3705\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.6126 - val_loss: 130.5088\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.1576 - val_loss: 130.5823\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.7525 - val_loss: 130.9364\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.6920 - val_loss: 129.8212\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.6643 - val_loss: 129.7089\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.0679 - val_loss: 131.2974\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.5843 - val_loss: 129.7962\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.3227 - val_loss: 129.6746\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.5312 - val_loss: 129.5353\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.7933 - val_loss: 130.1283\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.5649 - val_loss: 131.9744\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.7677 - val_loss: 130.3841\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.5073 - val_loss: 131.3065\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.5295 - val_loss: 130.6123\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.5654 - val_loss: 130.0014\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.1796 - val_loss: 129.5561\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.4896 - val_loss: 129.7451\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.7651 - val_loss: 128.4520\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.9058 - val_loss: 131.7841\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.2688 - val_loss: 130.5696\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.2718 - val_loss: 129.3970\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.1641 - val_loss: 130.1192\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.5482 - val_loss: 130.2305\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.2836 - val_loss: 130.3414\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.9598 - val_loss: 129.6372\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.9545 - val_loss: 129.8383\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.0194 - val_loss: 129.1873\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 125.9295 - val_loss: 129.2848\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.4885 - val_loss: 128.9684\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.0716 - val_loss: 130.1682\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.9651 - val_loss: 129.5155\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.9497 - val_loss: 129.7098\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 125.9502 - val_loss: 131.1508\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.0848 - val_loss: 130.8900\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.5581 - val_loss: 129.1028\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.8126 - val_loss: 128.2088\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.7639 - val_loss: 129.5894\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.9053 - val_loss: 129.9043\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.9692 - val_loss: 130.1120\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.7634 - val_loss: 129.4778\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.8742 - val_loss: 130.5605\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.7747 - val_loss: 129.1526\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.8951 - val_loss: 131.0181\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.5761 - val_loss: 129.1563\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.8372 - val_loss: 130.5644\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.5723 - val_loss: 132.4045\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.0827 - val_loss: 129.8453\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.7578 - val_loss: 128.3700\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.7946 - val_loss: 130.6661\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.8213 - val_loss: 129.3216\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.4670 - val_loss: 129.6094\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.3779 - val_loss: 130.8334\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.6364 - val_loss: 129.3125\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.8941 - val_loss: 128.3395\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.1651 - val_loss: 129.6487\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.2239 - val_loss: 128.9502\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.5734 - val_loss: 129.4538\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.6822 - val_loss: 130.0458\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.2581 - val_loss: 129.0570\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.5810 - val_loss: 128.7630\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 125.3422 - val_loss: 128.6068\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.6556 - val_loss: 129.6820\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.6864 - val_loss: 129.1155\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.2604 - val_loss: 129.5884\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.2819 - val_loss: 128.9707\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - ETA: 0s - loss: 125.5115Restoring model weights from the end of the best epoch: 60.\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 125.5115 - val_loss: 128.6609\n",
      "Epoch 90: early stopping\n",
      "'########################################################Model3\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 151.8204 - val_loss: 147.2372\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 136.4895 - val_loss: 142.4694\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 135.5230 - val_loss: 140.6758\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 133.1479 - val_loss: 141.6708\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 131.6916 - val_loss: 135.9908\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.8014 - val_loss: 138.4467\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.4026 - val_loss: 133.6617\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.1833 - val_loss: 133.2778\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.0201 - val_loss: 132.3533\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.0935 - val_loss: 134.3911\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.2239 - val_loss: 135.1729\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.3524 - val_loss: 131.9453\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.6633 - val_loss: 132.4709\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.9295 - val_loss: 131.1206\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.3808 - val_loss: 130.8271\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.1327 - val_loss: 130.4743\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.0397 - val_loss: 131.3219\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.7772 - val_loss: 131.4117\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.1867 - val_loss: 130.9791\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.8894 - val_loss: 130.0616\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.5780 - val_loss: 131.1460\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.7440 - val_loss: 130.5723\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.9403 - val_loss: 132.1496\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.2210 - val_loss: 131.2826\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.8219 - val_loss: 130.6082\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.8172 - val_loss: 134.0319\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.3771 - val_loss: 131.2705\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.9843 - val_loss: 130.0313\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.7012 - val_loss: 130.4967\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.3640 - val_loss: 129.5085\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.9672 - val_loss: 130.6668\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.7361 - val_loss: 130.7871\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.7207 - val_loss: 129.4431\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.4707 - val_loss: 130.3187\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.4168 - val_loss: 130.1618\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.3725 - val_loss: 129.6233\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.3669 - val_loss: 130.4738\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.8466 - val_loss: 131.3510\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.7238 - val_loss: 129.5470\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.4867 - val_loss: 132.2471\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.9149 - val_loss: 130.1284\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.1446 - val_loss: 128.6368\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.9613 - val_loss: 130.8244\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.5557 - val_loss: 129.9278\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.0212 - val_loss: 129.7990\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.3479 - val_loss: 129.2897\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.3894 - val_loss: 129.4710\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.3218 - val_loss: 129.7926\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.9226 - val_loss: 129.6539\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.8407 - val_loss: 129.8176\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.6241 - val_loss: 128.9930\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.1555 - val_loss: 129.5678\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.5372 - val_loss: 129.3422\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.7845 - val_loss: 130.3763\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.4389 - val_loss: 128.9824\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.1517 - val_loss: 129.5496\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.6606 - val_loss: 129.0167\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.5636 - val_loss: 128.2044\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 126.0484 - val_loss: 128.1120\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.0378 - val_loss: 129.4217\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.7999 - val_loss: 129.2190\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.6051 - val_loss: 129.0323\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.7965 - val_loss: 129.0905\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.5180 - val_loss: 129.2540\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.9317 - val_loss: 129.9923\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.4440 - val_loss: 129.1251\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.5595 - val_loss: 129.2099\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.7972 - val_loss: 129.4268\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.6228 - val_loss: 129.1751\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.0915 - val_loss: 129.0945\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.6082 - val_loss: 129.7404\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.1272 - val_loss: 128.9461\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.2160 - val_loss: 129.3993\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.7048 - val_loss: 129.0683\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.4112 - val_loss: 130.5401\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.3183 - val_loss: 128.6729\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.9369 - val_loss: 129.0368\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.4359 - val_loss: 130.2777\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.3775 - val_loss: 130.0465\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.6466 - val_loss: 128.0730\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.4279 - val_loss: 129.2175\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.8229 - val_loss: 129.9186\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.6368 - val_loss: 129.2556\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.0587 - val_loss: 128.5134\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.0001 - val_loss: 129.4315\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.3812 - val_loss: 128.2142\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.2266 - val_loss: 129.6620\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.7200 - val_loss: 128.4197\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.1554 - val_loss: 129.1215\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.1595 - val_loss: 128.7510\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.8524 - val_loss: 129.8820\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.2205 - val_loss: 128.9657\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.1536 - val_loss: 128.9783\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.0293 - val_loss: 128.6571\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.3083 - val_loss: 128.9360\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.0653 - val_loss: 128.7227\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.1618 - val_loss: 128.6735\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.1175 - val_loss: 128.6716\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.0570 - val_loss: 129.1980\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.8720 - val_loss: 128.7252\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.7916 - val_loss: 129.2977\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.8465 - val_loss: 127.7627\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.1368 - val_loss: 130.5980\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.9156 - val_loss: 128.2047\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.3373 - val_loss: 128.7808\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.7559 - val_loss: 128.7226\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.0190 - val_loss: 128.6069\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.9742 - val_loss: 129.1118\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.6503 - val_loss: 128.8702\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.6479 - val_loss: 128.4691\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.7883 - val_loss: 128.9696\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.9973 - val_loss: 128.7632\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.9834 - val_loss: 127.9127\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.6647 - val_loss: 128.4731\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.2023 - val_loss: 128.4284\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.1887 - val_loss: 128.6576\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.5463 - val_loss: 128.5598\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.4502 - val_loss: 128.4286\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.0605 - val_loss: 129.0592\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.6501 - val_loss: 127.9704\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.5589 - val_loss: 128.3712\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.8596 - val_loss: 128.5367\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.0177 - val_loss: 129.6049\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.6939 - val_loss: 128.3586\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.9256 - val_loss: 129.3325\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.5315 - val_loss: 129.2267\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.9828 - val_loss: 128.6024\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.8099 - val_loss: 128.6873\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.5364 - val_loss: 128.4949\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.2985 - val_loss: 128.6158\n",
      "Epoch 131/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.2887 - val_loss: 129.6491\n",
      "Epoch 132/300\n",
      "65/73 [=========================>....] - ETA: 0s - loss: 122.7732Restoring model weights from the end of the best epoch: 102.\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 123.0752 - val_loss: 129.1044\n",
      "Epoch 132: early stopping\n",
      "'########################################################Model4\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 149.2554 - val_loss: 145.6024\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 137.0543 - val_loss: 142.9494\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 133.4937 - val_loss: 138.6315\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.7947 - val_loss: 138.1218\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 130.7173 - val_loss: 134.0509\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.0864 - val_loss: 135.3280\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.3350 - val_loss: 133.3732\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.0089 - val_loss: 133.8000\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.1298 - val_loss: 131.6471\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.2997 - val_loss: 132.0358\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.4023 - val_loss: 131.6062\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.7540 - val_loss: 130.9950\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.9045 - val_loss: 131.3402\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.8893 - val_loss: 135.3591\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.9772 - val_loss: 131.3845\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.1748 - val_loss: 135.0344\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.9367 - val_loss: 131.2350\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.1339 - val_loss: 131.2055\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.9818 - val_loss: 131.5219\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.5305 - val_loss: 130.9347\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.0328 - val_loss: 132.0598\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.8320 - val_loss: 131.0324\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.7975 - val_loss: 130.1500\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.0017 - val_loss: 130.1969\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.0945 - val_loss: 130.1633\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.9072 - val_loss: 131.3072\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.8428 - val_loss: 130.5518\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.1185 - val_loss: 130.1689\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.0007 - val_loss: 130.6136\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.0316 - val_loss: 131.2500\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.2279 - val_loss: 130.0188\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.0320 - val_loss: 130.1003\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.3508 - val_loss: 129.4342\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.7841 - val_loss: 130.3773\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.5025 - val_loss: 130.1465\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.9977 - val_loss: 129.8915\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.4844 - val_loss: 129.8448\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.2342 - val_loss: 129.7825\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.6083 - val_loss: 129.5835\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.5802 - val_loss: 129.5621\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 126.4892 - val_loss: 131.2231\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.9717 - val_loss: 132.0103\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.3530 - val_loss: 129.2422\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 126.2324 - val_loss: 128.9820\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.4868 - val_loss: 130.7718\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.6544 - val_loss: 129.6189\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.9438 - val_loss: 131.5783\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.2295 - val_loss: 129.8009\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.0905 - val_loss: 130.1677\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.3411 - val_loss: 129.9083\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.1016 - val_loss: 130.1674\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.2231 - val_loss: 132.3416\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.9512 - val_loss: 129.1721\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.9799 - val_loss: 131.4781\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.4078 - val_loss: 129.6421\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.5152 - val_loss: 132.7806\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.3914 - val_loss: 129.2016\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.0872 - val_loss: 128.8017\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.8526 - val_loss: 129.2081\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.5642 - val_loss: 128.4040\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.5348 - val_loss: 130.0818\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.9315 - val_loss: 131.1196\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.0577 - val_loss: 128.6077\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.3909 - val_loss: 130.1563\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.1531 - val_loss: 129.8350\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.0272 - val_loss: 128.4359\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.8533 - val_loss: 128.8586\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 125.3748 - val_loss: 130.0266\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.6902 - val_loss: 129.7570\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.4895 - val_loss: 129.2065\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.4401 - val_loss: 131.4169\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.1171 - val_loss: 129.4575\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.4103 - val_loss: 129.8316\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.1399 - val_loss: 129.2322\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.4927 - val_loss: 129.9928\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.8913 - val_loss: 129.4761\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.6289 - val_loss: 129.3505\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.8038 - val_loss: 128.7308\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.6892 - val_loss: 128.5557\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 124.0707 - val_loss: 128.3556\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.1592 - val_loss: 128.4906\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.8198 - val_loss: 128.3785\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.4193 - val_loss: 128.6183\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.9292 - val_loss: 128.3915\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.6955 - val_loss: 129.2557\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.5003 - val_loss: 129.5793\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.3710 - val_loss: 129.5691\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.4402 - val_loss: 128.0850\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.6349 - val_loss: 129.6279\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.4822 - val_loss: 128.0199\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.8784 - val_loss: 128.3638\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.6750 - val_loss: 128.7484\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 123.6982 - val_loss: 128.0686\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 123.6142 - val_loss: 127.7611\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.7982 - val_loss: 127.6264\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.0337 - val_loss: 128.6892\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.5053 - val_loss: 128.7278\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.3204 - val_loss: 130.3530\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.7210 - val_loss: 127.9094\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.3902 - val_loss: 127.9245\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.4521 - val_loss: 128.5435\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.2971 - val_loss: 127.8561\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.2908 - val_loss: 129.8926\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.3577 - val_loss: 128.3617\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.9203 - val_loss: 128.0155\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.9885 - val_loss: 129.2161\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.2074 - val_loss: 128.7365\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.9176 - val_loss: 128.0838\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.4136 - val_loss: 128.9776\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.0868 - val_loss: 129.7561\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.3152 - val_loss: 127.1912\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.4242 - val_loss: 132.0701\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.4741 - val_loss: 127.6060\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 122.9415 - val_loss: 128.3021\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.3462 - val_loss: 129.9376\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.9933 - val_loss: 128.8309\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 122.7681 - val_loss: 128.0185\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.9149 - val_loss: 128.1065\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.7127 - val_loss: 127.5112\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.7482 - val_loss: 127.9099\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 122.8926 - val_loss: 128.4444\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.8791 - val_loss: 128.1098\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.8537 - val_loss: 128.9582\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.7883 - val_loss: 128.0385\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.6929 - val_loss: 128.7702\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.9748 - val_loss: 128.7333\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.9384 - val_loss: 127.5946\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 122.6622 - val_loss: 127.7978\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.5842 - val_loss: 128.0677\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.6763 - val_loss: 128.4584\n",
      "Epoch 131/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.8065 - val_loss: 127.2442\n",
      "Epoch 132/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.3969 - val_loss: 128.2263\n",
      "Epoch 133/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.6200 - val_loss: 128.2872\n",
      "Epoch 134/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.7145 - val_loss: 127.9646\n",
      "Epoch 135/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.2406 - val_loss: 128.1593\n",
      "Epoch 136/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.3221 - val_loss: 127.3079\n",
      "Epoch 137/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.3871 - val_loss: 128.1774\n",
      "Epoch 138/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.1228 - val_loss: 127.9244\n",
      "Epoch 139/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.4487 - val_loss: 127.6127\n",
      "Epoch 140/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.5077 - val_loss: 127.3694\n",
      "Epoch 141/300\n",
      "73/73 [==============================] - ETA: 0s - loss: 122.2222Restoring model weights from the end of the best epoch: 111.\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 122.2222 - val_loss: 127.9594\n",
      "Epoch 141: early stopping\n",
      "'########################################################Model5\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 149.9010 - val_loss: 149.6512\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 141.4751 - val_loss: 145.4148\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 138.9287 - val_loss: 143.9497\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 137.6571 - val_loss: 141.3876\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 136.8735 - val_loss: 140.0293\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 136.8988 - val_loss: 139.5223\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 135.5727 - val_loss: 140.0590\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 135.6531 - val_loss: 141.1249\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 135.1502 - val_loss: 139.1179\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 134.0203 - val_loss: 138.3027\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 134.7410 - val_loss: 138.4617\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 134.1506 - val_loss: 138.2064\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 134.6839 - val_loss: 139.8181\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 134.0213 - val_loss: 137.8543\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 133.2183 - val_loss: 137.4986\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 132.6599 - val_loss: 137.7079\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 133.1092 - val_loss: 138.0899\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 133.7532 - val_loss: 140.5299\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 134.0822 - val_loss: 137.4494\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 133.9050 - val_loss: 138.7127\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 133.3557 - val_loss: 140.9338\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 133.7966 - val_loss: 138.0226\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 133.7832 - val_loss: 137.5799\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 133.4312 - val_loss: 138.2633\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 133.3938 - val_loss: 137.6960\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 133.7879 - val_loss: 137.2976\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 133.6667 - val_loss: 136.8967\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 133.6947 - val_loss: 139.5261\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 133.8385 - val_loss: 138.8282\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 133.7181 - val_loss: 136.3994\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 133.4673 - val_loss: 137.5673\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 133.0198 - val_loss: 137.5135\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 132.7985 - val_loss: 137.3727\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 132.7799 - val_loss: 137.7191\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 134.2384 - val_loss: 137.4015\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 133.4383 - val_loss: 137.4330\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 132.4940 - val_loss: 137.6969\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 133.0154 - val_loss: 136.9940\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 133.4690 - val_loss: 138.6020\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 133.0624 - val_loss: 137.7084\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 132.9050 - val_loss: 136.3918\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 132.4297 - val_loss: 136.2838\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.7758 - val_loss: 138.5412\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.6881 - val_loss: 137.4841\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.9103 - val_loss: 136.8808\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.6735 - val_loss: 136.3878\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.4517 - val_loss: 136.1901\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 132.2226 - val_loss: 136.1734\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 132.0086 - val_loss: 136.6951\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.1437 - val_loss: 137.3457\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 132.0028 - val_loss: 137.8650\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 133.1078 - val_loss: 136.7601\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 132.5090 - val_loss: 137.7896\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 132.3127 - val_loss: 137.8397\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 133.2409 - val_loss: 135.8910\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 132.7684 - val_loss: 135.8036\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 133.0123 - val_loss: 136.7479\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 133.4566 - val_loss: 136.6833\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 132.7683 - val_loss: 140.5953\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 132.7261 - val_loss: 137.3105\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 132.3730 - val_loss: 135.7887\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.1828 - val_loss: 136.8380\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.3408 - val_loss: 136.4417\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.9737 - val_loss: 136.3481\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 132.0726 - val_loss: 137.8521\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 132.6163 - val_loss: 135.8046\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 132.2893 - val_loss: 136.7809\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 132.3547 - val_loss: 136.7808\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 133.0693 - val_loss: 136.1998\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.9051 - val_loss: 136.3170\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 132.3608 - val_loss: 136.6228\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 132.5454 - val_loss: 137.3017\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.9840 - val_loss: 136.0338\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 132.3011 - val_loss: 135.7596\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.5265 - val_loss: 135.6528\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.5527 - val_loss: 135.3443\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.7868 - val_loss: 138.6253\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 132.4895 - val_loss: 135.5308\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.5381 - val_loss: 134.8665\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.9842 - val_loss: 136.3895\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.9447 - val_loss: 136.2882\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.6907 - val_loss: 135.9883\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.8870 - val_loss: 136.2815\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.7465 - val_loss: 135.3715\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.5428 - val_loss: 135.4054\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.1280 - val_loss: 135.9264\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.1578 - val_loss: 135.8782\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.1915 - val_loss: 135.5664\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.6086 - val_loss: 136.3148\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.2701 - val_loss: 135.4667\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.1574 - val_loss: 135.4605\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 130.5170 - val_loss: 134.7712\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.4344 - val_loss: 129.7858\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.1273 - val_loss: 128.8030\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.5435 - val_loss: 129.3476\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.8426 - val_loss: 128.7480\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.1477 - val_loss: 128.4223\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.9505 - val_loss: 128.6037\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.6576 - val_loss: 128.3990\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.8033 - val_loss: 128.6000\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.6894 - val_loss: 127.8357\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.8184 - val_loss: 128.4681\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.5348 - val_loss: 129.1941\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.9723 - val_loss: 129.3447\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.5300 - val_loss: 130.8488\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.5308 - val_loss: 127.4146\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.6180 - val_loss: 127.9324\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.2329 - val_loss: 128.7241\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.7029 - val_loss: 127.4798\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.1884 - val_loss: 128.2391\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.3894 - val_loss: 127.9087\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.1439 - val_loss: 127.8035\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.1474 - val_loss: 128.2378\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.3092 - val_loss: 128.8321\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 124.5342 - val_loss: 127.9314\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.2027 - val_loss: 127.5156\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.3010 - val_loss: 128.8972\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 124.1112 - val_loss: 128.2220\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.9750 - val_loss: 129.4764\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 124.7817 - val_loss: 127.2256\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 124.6176 - val_loss: 128.0577\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.1514 - val_loss: 127.6110\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.9260 - val_loss: 128.9849\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.0848 - val_loss: 128.5777\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.2157 - val_loss: 128.8560\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.3109 - val_loss: 127.7522\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.8774 - val_loss: 127.3931\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 123.8817 - val_loss: 127.0963\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.8670 - val_loss: 128.0004\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.9754 - val_loss: 127.8691\n",
      "Epoch 131/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.9747 - val_loss: 127.9669\n",
      "Epoch 132/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.5175 - val_loss: 127.2711\n",
      "Epoch 133/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.2804 - val_loss: 127.5117\n",
      "Epoch 134/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.6733 - val_loss: 128.1551\n",
      "Epoch 135/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 121.6648 - val_loss: 127.9338\n",
      "Epoch 136/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.0928 - val_loss: 128.1678\n",
      "Epoch 137/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.1217 - val_loss: 127.5548\n",
      "Epoch 138/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.0396 - val_loss: 126.7591\n",
      "Epoch 139/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 121.6470 - val_loss: 127.3397\n",
      "Epoch 140/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 122.0551 - val_loss: 127.4596\n",
      "Epoch 141/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 121.7231 - val_loss: 127.1670\n",
      "Epoch 142/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 121.7482 - val_loss: 127.2248\n",
      "Epoch 143/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 121.8418 - val_loss: 128.2939\n",
      "Epoch 144/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 121.9279 - val_loss: 127.2035\n",
      "Epoch 145/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 121.5717 - val_loss: 127.0708\n",
      "Epoch 146/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 121.3729 - val_loss: 127.1766\n",
      "Epoch 147/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 121.7496 - val_loss: 127.3644\n",
      "Epoch 148/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 121.2913 - val_loss: 127.0086\n",
      "Epoch 149/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 121.2900 - val_loss: 127.1847\n",
      "Epoch 150/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 121.3405 - val_loss: 127.8151\n",
      "Epoch 151/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 121.5260 - val_loss: 127.3879\n",
      "Epoch 152/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 120.9708 - val_loss: 126.2079\n",
      "Epoch 153/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 121.3292 - val_loss: 126.4998\n",
      "Epoch 154/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.8424 - val_loss: 126.7038\n",
      "Epoch 155/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.8427 - val_loss: 127.2018\n",
      "Epoch 156/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 121.5082 - val_loss: 126.6478\n",
      "Epoch 157/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 121.0637 - val_loss: 126.4266\n",
      "Epoch 158/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.9876 - val_loss: 126.9224\n",
      "Epoch 159/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 121.0956 - val_loss: 126.8106\n",
      "Epoch 160/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 121.2769 - val_loss: 126.3458\n",
      "Epoch 161/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.9685 - val_loss: 126.6986\n",
      "Epoch 162/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 121.3377 - val_loss: 127.2707\n",
      "Epoch 163/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.8329 - val_loss: 127.1653\n",
      "Epoch 164/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 121.1588 - val_loss: 126.3424\n",
      "Epoch 165/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 121.1674 - val_loss: 126.0648\n",
      "Epoch 166/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 121.0874 - val_loss: 126.8846\n",
      "Epoch 167/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.6887 - val_loss: 126.4311\n",
      "Epoch 168/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.8900 - val_loss: 127.0165\n",
      "Epoch 169/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.9831 - val_loss: 126.0008\n",
      "Epoch 170/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 121.1104 - val_loss: 127.6038\n",
      "Epoch 171/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 121.0547 - val_loss: 126.7434\n",
      "Epoch 172/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.9323 - val_loss: 127.4326\n",
      "Epoch 173/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 121.0755 - val_loss: 126.2063\n",
      "Epoch 174/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.8557 - val_loss: 126.7026\n",
      "Epoch 175/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 120.6309 - val_loss: 126.0928\n",
      "Epoch 176/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 121.0287 - val_loss: 127.3492\n",
      "Epoch 177/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 120.9233 - val_loss: 125.8840\n",
      "Epoch 178/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.6272 - val_loss: 126.4654\n",
      "Epoch 179/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.7983 - val_loss: 126.9251\n",
      "Epoch 180/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.8469 - val_loss: 125.7947\n",
      "Epoch 181/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.5671 - val_loss: 126.9013\n",
      "Epoch 182/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.4366 - val_loss: 126.0323\n",
      "Epoch 183/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.4456 - val_loss: 126.4816\n",
      "Epoch 184/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.4491 - val_loss: 127.1339\n",
      "Epoch 185/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.7115 - val_loss: 126.2896\n",
      "Epoch 186/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.6686 - val_loss: 126.6652\n",
      "Epoch 187/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.5812 - val_loss: 127.9645\n",
      "Epoch 188/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.5754 - val_loss: 125.7616\n",
      "Epoch 189/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 120.8230 - val_loss: 125.6643\n",
      "Epoch 190/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.4060 - val_loss: 125.9973\n",
      "Epoch 191/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.7146 - val_loss: 126.1061\n",
      "Epoch 192/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.4458 - val_loss: 126.2467\n",
      "Epoch 193/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.6420 - val_loss: 125.9452\n",
      "Epoch 194/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.6418 - val_loss: 126.0703\n",
      "Epoch 195/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.2655 - val_loss: 126.6412\n",
      "Epoch 196/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.4786 - val_loss: 125.8883\n",
      "Epoch 197/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.2795 - val_loss: 126.4917\n",
      "Epoch 198/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.4696 - val_loss: 125.8318\n",
      "Epoch 199/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.2682 - val_loss: 125.5456\n",
      "Epoch 200/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.2151 - val_loss: 125.8886\n",
      "Epoch 201/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.3213 - val_loss: 126.1622\n",
      "Epoch 202/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.2363 - val_loss: 126.5343\n",
      "Epoch 203/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.4327 - val_loss: 125.7949\n",
      "Epoch 204/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.4568 - val_loss: 126.6507\n",
      "Epoch 205/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 120.3830 - val_loss: 125.4744\n",
      "Epoch 206/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.9846 - val_loss: 125.4949\n",
      "Epoch 207/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.3072 - val_loss: 126.2471\n",
      "Epoch 208/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.2661 - val_loss: 125.9416\n",
      "Epoch 209/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.2343 - val_loss: 125.8660\n",
      "Epoch 210/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.8998 - val_loss: 125.5426\n",
      "Epoch 211/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.9116 - val_loss: 125.7369\n",
      "Epoch 212/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.1761 - val_loss: 125.7299\n",
      "Epoch 213/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.0895 - val_loss: 125.3128\n",
      "Epoch 214/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.9090 - val_loss: 125.5220\n",
      "Epoch 215/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.9980 - val_loss: 125.7353\n",
      "Epoch 216/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.1494 - val_loss: 125.9384\n",
      "Epoch 217/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.1579 - val_loss: 125.6201\n",
      "Epoch 218/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.0246 - val_loss: 125.9444\n",
      "Epoch 219/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.9194 - val_loss: 126.0032\n",
      "Epoch 220/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.6696 - val_loss: 125.2117\n",
      "Epoch 221/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.1264 - val_loss: 125.5491\n",
      "Epoch 222/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 120.3190 - val_loss: 125.6523\n",
      "Epoch 223/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.9841 - val_loss: 125.3316\n",
      "Epoch 224/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.0769 - val_loss: 126.5520\n",
      "Epoch 225/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.9772 - val_loss: 125.8689\n",
      "Epoch 226/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.9843 - val_loss: 125.4400\n",
      "Epoch 227/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.8962 - val_loss: 125.2712\n",
      "Epoch 228/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.8666 - val_loss: 125.5279\n",
      "Epoch 229/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.6014 - val_loss: 125.7756\n",
      "Epoch 230/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.7078 - val_loss: 125.9837\n",
      "Epoch 231/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.9563 - val_loss: 125.5387\n",
      "Epoch 232/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.9706 - val_loss: 125.3218\n",
      "Epoch 233/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.8330 - val_loss: 126.0018\n",
      "Epoch 234/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.8781 - val_loss: 125.7861\n",
      "Epoch 235/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.8414 - val_loss: 125.7112\n",
      "Epoch 236/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.9113 - val_loss: 125.5896\n",
      "Epoch 237/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.7218 - val_loss: 125.5032\n",
      "Epoch 238/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.9995 - val_loss: 125.6761\n",
      "Epoch 239/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.7322 - val_loss: 126.0297\n",
      "Epoch 240/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.9908 - val_loss: 125.1044\n",
      "Epoch 241/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 119.6915 - val_loss: 125.2537\n",
      "Epoch 242/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.6921 - val_loss: 125.3501\n",
      "Epoch 243/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.0365 - val_loss: 125.3573\n",
      "Epoch 244/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.7890 - val_loss: 125.4917\n",
      "Epoch 245/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.9028 - val_loss: 125.5217\n",
      "Epoch 246/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.5704 - val_loss: 125.8119\n",
      "Epoch 247/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.7352 - val_loss: 125.4092\n",
      "Epoch 248/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.6861 - val_loss: 125.6091\n",
      "Epoch 249/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.7686 - val_loss: 125.0327\n",
      "Epoch 250/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.8944 - val_loss: 125.3224\n",
      "Epoch 251/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.5516 - val_loss: 125.6912\n",
      "Epoch 252/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.7553 - val_loss: 125.7455\n",
      "Epoch 253/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.7404 - val_loss: 125.8801\n",
      "Epoch 254/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.0628 - val_loss: 125.1630\n",
      "Epoch 255/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.7338 - val_loss: 125.4036\n",
      "Epoch 256/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.7453 - val_loss: 125.0292\n",
      "Epoch 257/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.0635 - val_loss: 128.0873\n",
      "Epoch 258/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.2398 - val_loss: 125.1849\n",
      "Epoch 259/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.6185 - val_loss: 126.0764\n",
      "Epoch 260/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.6880 - val_loss: 126.1091\n",
      "Epoch 261/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 119.6791 - val_loss: 125.3595\n",
      "Epoch 262/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.8217 - val_loss: 126.4873\n",
      "Epoch 263/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.5479 - val_loss: 125.5238\n",
      "Epoch 264/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.6360 - val_loss: 125.2272\n",
      "Epoch 265/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 119.7950 - val_loss: 125.3785\n",
      "Epoch 266/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.5786 - val_loss: 125.2761\n",
      "Epoch 267/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.5500 - val_loss: 125.2026\n",
      "Epoch 268/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.8010 - val_loss: 125.6441\n",
      "Epoch 269/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.6677 - val_loss: 125.4763\n",
      "Epoch 270/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.7717 - val_loss: 125.3856\n",
      "Epoch 271/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.8231 - val_loss: 125.0824\n",
      "Epoch 272/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.5486 - val_loss: 125.3422\n",
      "Epoch 273/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.6545 - val_loss: 125.3480\n",
      "Epoch 274/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.2928 - val_loss: 125.5172\n",
      "Epoch 275/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.3484 - val_loss: 125.5633\n",
      "Epoch 276/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.6652 - val_loss: 125.6070\n",
      "Epoch 277/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.5338 - val_loss: 125.0111\n",
      "Epoch 278/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.5439 - val_loss: 125.4220\n",
      "Epoch 279/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.4213 - val_loss: 124.8446\n",
      "Epoch 280/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.3227 - val_loss: 125.4009\n",
      "Epoch 281/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.5860 - val_loss: 124.9575\n",
      "Epoch 282/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.5313 - val_loss: 125.6267\n",
      "Epoch 283/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.5285 - val_loss: 124.7867\n",
      "Epoch 284/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.6778 - val_loss: 125.5185\n",
      "Epoch 285/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.3469 - val_loss: 125.1893\n",
      "Epoch 286/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.1384 - val_loss: 125.0889\n",
      "Epoch 287/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.3425 - val_loss: 125.4502\n",
      "Epoch 288/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.6567 - val_loss: 125.5645\n",
      "Epoch 289/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.4600 - val_loss: 125.0733\n",
      "Epoch 290/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.4892 - val_loss: 124.7826\n",
      "Epoch 291/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.2530 - val_loss: 125.1423\n",
      "Epoch 292/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.3920 - val_loss: 125.3302\n",
      "Epoch 293/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.3771 - val_loss: 124.8730\n",
      "Epoch 294/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.3199 - val_loss: 125.1650\n",
      "Epoch 295/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.2980 - val_loss: 124.7257\n",
      "Epoch 296/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.3972 - val_loss: 125.0606\n",
      "Epoch 297/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 118.9758 - val_loss: 124.6106\n",
      "Epoch 298/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.2612 - val_loss: 124.6696\n",
      "Epoch 299/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.1296 - val_loss: 125.0630\n",
      "Epoch 300/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.1271 - val_loss: 125.3278\n",
      "'########################################################Model6\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 147.3195 - val_loss: 142.3638\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 134.9485 - val_loss: 141.3625\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 132.4794 - val_loss: 137.8856\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 131.2927 - val_loss: 135.3295\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.8787 - val_loss: 136.9774\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 129.9140 - val_loss: 134.5057\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.5052 - val_loss: 136.1437\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.8867 - val_loss: 137.4313\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.6717 - val_loss: 135.5794\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.9021 - val_loss: 136.8903\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.0608 - val_loss: 132.6139\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.7650 - val_loss: 131.9270\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.7324 - val_loss: 132.2262\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.3110 - val_loss: 131.9626\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.7173 - val_loss: 131.9195\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.8360 - val_loss: 132.6326\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.7610 - val_loss: 131.2895\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.5095 - val_loss: 130.9087\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.9427 - val_loss: 131.1675\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.2196 - val_loss: 131.5217\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.4455 - val_loss: 131.1463\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.3187 - val_loss: 130.9212\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.9134 - val_loss: 131.0871\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.3343 - val_loss: 130.8351\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.5739 - val_loss: 131.6135\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.8110 - val_loss: 131.2694\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.9718 - val_loss: 131.3929\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.3063 - val_loss: 131.0827\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.0591 - val_loss: 130.2754\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.0797 - val_loss: 130.2891\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.7240 - val_loss: 130.3266\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.4245 - val_loss: 133.5078\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.7026 - val_loss: 130.4774\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.4858 - val_loss: 130.4543\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.6770 - val_loss: 130.5582\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.5655 - val_loss: 131.3391\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.0079 - val_loss: 131.0916\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.9697 - val_loss: 130.7522\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.7287 - val_loss: 129.4197\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.5355 - val_loss: 132.0902\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.6211 - val_loss: 130.3759\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.0585 - val_loss: 130.8260\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.2526 - val_loss: 129.8562\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.2895 - val_loss: 129.5727\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.3301 - val_loss: 130.1559\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 124.9590 - val_loss: 129.3251\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.8412 - val_loss: 129.9160\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.7251 - val_loss: 129.4034\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.8761 - val_loss: 130.7121\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 126.0069 - val_loss: 129.1297\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.1531 - val_loss: 130.0209\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.9826 - val_loss: 129.5674\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.0259 - val_loss: 130.1673\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.2992 - val_loss: 129.7606\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.9066 - val_loss: 130.2191\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.9854 - val_loss: 129.4055\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.9893 - val_loss: 130.6500\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.9123 - val_loss: 129.5927\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.9460 - val_loss: 130.0380\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.4920 - val_loss: 129.6432\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.4623 - val_loss: 129.7132\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.7104 - val_loss: 128.7806\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.9890 - val_loss: 129.8428\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.7704 - val_loss: 129.8381\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 124.5471 - val_loss: 129.0996\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.4532 - val_loss: 130.1068\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.4805 - val_loss: 128.9398\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.3213 - val_loss: 129.7347\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.8988 - val_loss: 129.7510\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.1080 - val_loss: 129.3098\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.9966 - val_loss: 128.8646\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.1228 - val_loss: 128.0612\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.0711 - val_loss: 128.6670\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.1234 - val_loss: 130.2580\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.1773 - val_loss: 128.0788\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.3180 - val_loss: 129.1672\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 123.8565 - val_loss: 128.4048\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.8566 - val_loss: 130.4007\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.6258 - val_loss: 128.6381\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.4731 - val_loss: 129.3825\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.9695 - val_loss: 128.9878\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.9468 - val_loss: 129.8032\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.1585 - val_loss: 130.8361\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.4629 - val_loss: 129.6899\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.7152 - val_loss: 129.2347\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.4914 - val_loss: 129.4155\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.0493 - val_loss: 129.2642\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.1669 - val_loss: 130.6158\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.8860 - val_loss: 130.4025\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.5538 - val_loss: 130.2718\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.6462 - val_loss: 129.8454\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.3973 - val_loss: 135.7765\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.5351 - val_loss: 129.5649\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.6513 - val_loss: 129.9694\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 123.4892 - val_loss: 131.1228\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.6012 - val_loss: 130.4323\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.2150 - val_loss: 130.0220\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.5538 - val_loss: 130.6186\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.4318 - val_loss: 131.9949\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.9194 - val_loss: 129.2323\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 123.6586 - val_loss: 130.7638\n",
      "Epoch 102/300\n",
      "65/73 [=========================>....] - ETA: 0s - loss: 124.0166Restoring model weights from the end of the best epoch: 72.\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 123.6153 - val_loss: 130.0736\n",
      "Epoch 102: early stopping\n",
      "'########################################################Model7\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 151.6630 - val_loss: 152.1317\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 143.3082 - val_loss: 146.3818\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 141.3741 - val_loss: 144.2302\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 140.1072 - val_loss: 144.3196\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 139.3010 - val_loss: 144.0665\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 139.0061 - val_loss: 143.7166\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 138.0738 - val_loss: 140.5276\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 138.7809 - val_loss: 141.5003\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 138.1729 - val_loss: 140.2586\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 137.8466 - val_loss: 139.6446\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 137.8132 - val_loss: 139.9851\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 137.5601 - val_loss: 139.7096\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 136.8065 - val_loss: 139.3960\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 137.4592 - val_loss: 139.5732\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 137.1010 - val_loss: 141.2272\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 136.6673 - val_loss: 139.6974\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 137.0965 - val_loss: 140.7655\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 137.4557 - val_loss: 139.8254\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 136.8858 - val_loss: 139.9371\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 136.6407 - val_loss: 140.4806\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 136.7872 - val_loss: 139.3510\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 136.3804 - val_loss: 139.0758\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 136.5328 - val_loss: 139.1031\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 136.6772 - val_loss: 139.8447\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 136.4494 - val_loss: 139.0669\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 136.6526 - val_loss: 139.3608\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 136.4172 - val_loss: 138.8987\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 136.7222 - val_loss: 138.9267\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 136.7135 - val_loss: 139.0889\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 136.7648 - val_loss: 141.5345\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 136.5243 - val_loss: 140.1476\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 136.8288 - val_loss: 138.8831\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 136.2728 - val_loss: 138.5497\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 136.1197 - val_loss: 138.4022\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 135.8494 - val_loss: 138.3805\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 136.5108 - val_loss: 138.7749\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 136.1693 - val_loss: 138.5987\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 136.0158 - val_loss: 138.1677\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 136.0310 - val_loss: 138.6908\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 137.3451 - val_loss: 138.6491\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 135.6946 - val_loss: 139.3224\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 135.4405 - val_loss: 140.6580\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 135.5574 - val_loss: 137.6601\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 135.6134 - val_loss: 137.9815\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 135.6221 - val_loss: 138.3151\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 135.2380 - val_loss: 138.3456\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 135.5869 - val_loss: 138.0569\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 135.5925 - val_loss: 140.0006\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 135.6177 - val_loss: 138.2525\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 135.7338 - val_loss: 138.1744\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 135.4136 - val_loss: 136.9707\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 135.4825 - val_loss: 138.7836\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 135.6385 - val_loss: 139.7202\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 135.5535 - val_loss: 138.6368\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 135.3569 - val_loss: 137.9540\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 134.5428 - val_loss: 138.4336\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 135.0025 - val_loss: 138.5494\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 135.3067 - val_loss: 138.7988\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 135.4428 - val_loss: 138.6594\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 135.1464 - val_loss: 138.2041\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 135.3499 - val_loss: 137.7671\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 135.2971 - val_loss: 137.6866\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 135.0985 - val_loss: 138.5813\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 135.0587 - val_loss: 137.4659\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 135.0492 - val_loss: 138.3493\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 135.2953 - val_loss: 137.6184\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 134.8681 - val_loss: 138.3065\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 134.1599 - val_loss: 138.7595\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 135.3062 - val_loss: 138.4732\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.0536 - val_loss: 132.6904\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.6911 - val_loss: 131.2452\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.0270 - val_loss: 132.0329\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.2945 - val_loss: 131.6941\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.7842 - val_loss: 131.2584\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.8771 - val_loss: 132.0999\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.0510 - val_loss: 132.1405\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.9418 - val_loss: 130.7853\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.2725 - val_loss: 131.6585\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.3517 - val_loss: 131.4460\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.6608 - val_loss: 130.9534\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.5255 - val_loss: 130.8644\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.6412 - val_loss: 131.3585\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.8178 - val_loss: 131.7650\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.9846 - val_loss: 131.1534\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.4531 - val_loss: 130.9326\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.1850 - val_loss: 131.7172\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.2983 - val_loss: 131.5021\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.6935 - val_loss: 130.8738\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.8513 - val_loss: 131.5809\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.6023 - val_loss: 131.0516\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.3156 - val_loss: 131.2137\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.0118 - val_loss: 131.0837\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.9616 - val_loss: 131.4576\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.0730 - val_loss: 131.7929\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.3508 - val_loss: 136.9797\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.6783 - val_loss: 130.4340\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.0222 - val_loss: 131.6036\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.8796 - val_loss: 131.8943\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.8469 - val_loss: 130.9419\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.6888 - val_loss: 130.5469\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.6581 - val_loss: 130.9572\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.5006 - val_loss: 130.7959\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.3917 - val_loss: 130.2504\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.7307 - val_loss: 130.6072\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.6790 - val_loss: 129.5930\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.8205 - val_loss: 130.8920\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.0805 - val_loss: 130.4981\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.5039 - val_loss: 131.3273\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.6648 - val_loss: 130.3435\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.4305 - val_loss: 130.2837\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.0007 - val_loss: 130.6566\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.0004 - val_loss: 130.0724\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.4124 - val_loss: 130.2359\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.4096 - val_loss: 132.5167\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.1774 - val_loss: 131.0163\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.1208 - val_loss: 130.1357\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.0048 - val_loss: 129.2456\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.9111 - val_loss: 130.0589\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.8278 - val_loss: 131.8389\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.7919 - val_loss: 132.5265\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.1066 - val_loss: 130.0633\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.8792 - val_loss: 129.3929\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.8777 - val_loss: 129.7431\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.8684 - val_loss: 130.1999\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.5263 - val_loss: 129.2652\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.7651 - val_loss: 129.5269\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.9039 - val_loss: 131.1429\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.7786 - val_loss: 129.7806\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.5990 - val_loss: 130.1098\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.6046 - val_loss: 129.7774\n",
      "Epoch 131/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.3044 - val_loss: 131.8732\n",
      "Epoch 132/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.6345 - val_loss: 130.4405\n",
      "Epoch 133/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.4020 - val_loss: 129.8296\n",
      "Epoch 134/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 125.8459 - val_loss: 129.6508\n",
      "Epoch 135/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.6093 - val_loss: 129.9384\n",
      "Epoch 136/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.2308 - val_loss: 129.6807\n",
      "Epoch 137/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.2883 - val_loss: 130.4632\n",
      "Epoch 138/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.3440 - val_loss: 130.0860\n",
      "Epoch 139/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.5005 - val_loss: 129.8219\n",
      "Epoch 140/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.1740 - val_loss: 128.9532\n",
      "Epoch 141/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.3216 - val_loss: 130.5013\n",
      "Epoch 142/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.2069 - val_loss: 129.4956\n",
      "Epoch 143/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.4161 - val_loss: 129.3417\n",
      "Epoch 144/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.2740 - val_loss: 129.9344\n",
      "Epoch 145/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.1912 - val_loss: 130.0238\n",
      "Epoch 146/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.3287 - val_loss: 130.4040\n",
      "Epoch 147/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.4749 - val_loss: 129.8170\n",
      "Epoch 148/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.9549 - val_loss: 129.6880\n",
      "Epoch 149/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.0932 - val_loss: 129.6735\n",
      "Epoch 150/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.0903 - val_loss: 129.8652\n",
      "Epoch 151/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.9745 - val_loss: 129.0068\n",
      "Epoch 152/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.9499 - val_loss: 129.7369\n",
      "Epoch 153/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.8055 - val_loss: 129.2378\n",
      "Epoch 154/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 122.7964 - val_loss: 127.6134\n",
      "Epoch 155/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 121.3802 - val_loss: 128.4125\n",
      "Epoch 156/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.8711 - val_loss: 128.2018\n",
      "Epoch 157/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 121.0213 - val_loss: 127.5306\n",
      "Epoch 158/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.8050 - val_loss: 127.3041\n",
      "Epoch 159/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 121.1847 - val_loss: 127.8655\n",
      "Epoch 160/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.3617 - val_loss: 127.6273\n",
      "Epoch 161/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.5941 - val_loss: 128.0195\n",
      "Epoch 162/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.7402 - val_loss: 127.6058\n",
      "Epoch 163/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.4773 - val_loss: 127.0620\n",
      "Epoch 164/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 120.2950 - val_loss: 126.6276\n",
      "Epoch 165/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.5282 - val_loss: 126.9737\n",
      "Epoch 166/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.0293 - val_loss: 127.4831\n",
      "Epoch 167/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.0135 - val_loss: 126.8854\n",
      "Epoch 168/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.3466 - val_loss: 127.4023\n",
      "Epoch 169/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.0530 - val_loss: 127.5147\n",
      "Epoch 170/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.4678 - val_loss: 127.0039\n",
      "Epoch 171/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.0043 - val_loss: 126.9623\n",
      "Epoch 172/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.8183 - val_loss: 127.0789\n",
      "Epoch 173/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.7266 - val_loss: 126.7546\n",
      "Epoch 174/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 120.0640 - val_loss: 126.2068\n",
      "Epoch 175/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.7029 - val_loss: 126.7700\n",
      "Epoch 176/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.7675 - val_loss: 126.6680\n",
      "Epoch 177/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 119.4386 - val_loss: 126.7045\n",
      "Epoch 178/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.5166 - val_loss: 126.7353\n",
      "Epoch 179/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.6011 - val_loss: 126.7914\n",
      "Epoch 180/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.4216 - val_loss: 126.2702\n",
      "Epoch 181/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.4857 - val_loss: 127.0446\n",
      "Epoch 182/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 119.2904 - val_loss: 126.1680\n",
      "Epoch 183/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.3914 - val_loss: 126.9192\n",
      "Epoch 184/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.3022 - val_loss: 127.0337\n",
      "Epoch 185/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.5099 - val_loss: 126.8854\n",
      "Epoch 186/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.3504 - val_loss: 126.2233\n",
      "Epoch 187/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 119.3480 - val_loss: 126.7734\n",
      "Epoch 188/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.3619 - val_loss: 126.8398\n",
      "Epoch 189/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.4662 - val_loss: 126.2446\n",
      "Epoch 190/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.2883 - val_loss: 126.6456\n",
      "Epoch 191/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.0679 - val_loss: 125.9201\n",
      "Epoch 192/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 118.9975 - val_loss: 126.8045\n",
      "Epoch 193/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.2227 - val_loss: 126.3247\n",
      "Epoch 194/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.0944 - val_loss: 126.4868\n",
      "Epoch 195/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.0030 - val_loss: 126.8499\n",
      "Epoch 196/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.1531 - val_loss: 126.3248\n",
      "Epoch 197/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.4246 - val_loss: 126.7025\n",
      "Epoch 198/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.3012 - val_loss: 126.2855\n",
      "Epoch 199/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 119.4682 - val_loss: 125.8684\n",
      "Epoch 200/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.2513 - val_loss: 125.7107\n",
      "Epoch 201/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 118.9413 - val_loss: 125.8359\n",
      "Epoch 202/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.0024 - val_loss: 126.3465\n",
      "Epoch 203/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.0492 - val_loss: 125.9483\n",
      "Epoch 204/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 118.9196 - val_loss: 125.9136\n",
      "Epoch 205/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.2438 - val_loss: 126.7051\n",
      "Epoch 206/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 118.7943 - val_loss: 126.4348\n",
      "Epoch 207/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 118.8862 - val_loss: 126.5177\n",
      "Epoch 208/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 119.0607 - val_loss: 126.2162\n",
      "Epoch 209/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 118.9326 - val_loss: 126.0328\n",
      "Epoch 210/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 118.7872 - val_loss: 125.9070\n",
      "Epoch 211/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 118.9871 - val_loss: 126.0772\n",
      "Epoch 212/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 118.8693 - val_loss: 126.1764\n",
      "Epoch 213/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 118.7554 - val_loss: 125.5483\n",
      "Epoch 214/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 118.7854 - val_loss: 125.7480\n",
      "Epoch 215/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 118.5858 - val_loss: 125.7717\n",
      "Epoch 216/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 118.7638 - val_loss: 126.0048\n",
      "Epoch 217/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 118.5162 - val_loss: 125.9146\n",
      "Epoch 218/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 118.6627 - val_loss: 126.1331\n",
      "Epoch 219/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 118.7581 - val_loss: 125.5492\n",
      "Epoch 220/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 118.7082 - val_loss: 126.4573\n",
      "Epoch 221/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 118.6291 - val_loss: 126.6371\n",
      "Epoch 222/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 118.6238 - val_loss: 125.9714\n",
      "Epoch 223/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 118.6003 - val_loss: 125.7293\n",
      "Epoch 224/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 118.5886 - val_loss: 126.1593\n",
      "Epoch 225/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 118.4899 - val_loss: 126.4607\n",
      "Epoch 226/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 118.4255 - val_loss: 125.7873\n",
      "Epoch 227/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 118.7882 - val_loss: 126.4225\n",
      "Epoch 228/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 118.6050 - val_loss: 126.3603\n",
      "Epoch 229/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 118.4123 - val_loss: 126.0720\n",
      "Epoch 230/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 118.2729 - val_loss: 126.0057\n",
      "Epoch 231/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 118.5325 - val_loss: 125.8727\n",
      "Epoch 232/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 118.6250 - val_loss: 126.0362\n",
      "Epoch 233/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 118.4521 - val_loss: 125.9137\n",
      "Epoch 234/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 118.4487 - val_loss: 128.2472\n",
      "Epoch 235/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 118.7743 - val_loss: 125.9507\n",
      "Epoch 236/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 118.4676 - val_loss: 125.6650\n",
      "Epoch 237/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 118.2954 - val_loss: 125.7168\n",
      "Epoch 238/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 118.3424 - val_loss: 125.6993\n",
      "Epoch 239/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 118.5154 - val_loss: 126.4130\n",
      "Epoch 240/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 118.6332 - val_loss: 126.5303\n",
      "Epoch 241/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 118.5521 - val_loss: 125.8129\n",
      "Epoch 242/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 118.5254 - val_loss: 125.6900\n",
      "Epoch 243/300\n",
      "65/73 [=========================>....] - ETA: 0s - loss: 118.1486Restoring model weights from the end of the best epoch: 213.\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 118.3653 - val_loss: 125.6211\n",
      "Epoch 243: early stopping\n",
      "'########################################################Model8\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 153.4590 - val_loss: 152.1745\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 141.3596 - val_loss: 140.7664\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 137.3665 - val_loss: 142.3893\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 137.2867 - val_loss: 140.3535\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 135.5160 - val_loss: 138.1066\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 134.3206 - val_loss: 139.6548\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 133.8044 - val_loss: 138.0353\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 133.8788 - val_loss: 138.0436\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 133.7578 - val_loss: 138.0457\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 132.9786 - val_loss: 136.6602\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 132.1804 - val_loss: 134.8337\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.1000 - val_loss: 135.9561\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.1501 - val_loss: 135.8233\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.1268 - val_loss: 136.1737\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.1152 - val_loss: 137.1117\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.5075 - val_loss: 135.2995\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.9312 - val_loss: 135.7077\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.5473 - val_loss: 135.5940\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.7001 - val_loss: 134.8538\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.1458 - val_loss: 135.1403\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.6761 - val_loss: 136.6358\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.2370 - val_loss: 135.3094\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.8407 - val_loss: 135.1289\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.8475 - val_loss: 136.2817\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.2506 - val_loss: 134.9871\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 130.4855 - val_loss: 134.3456\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.8052 - val_loss: 134.5806\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.3724 - val_loss: 135.4205\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.8007 - val_loss: 135.1033\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.6118 - val_loss: 135.0982\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.6140 - val_loss: 135.4234\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.3027 - val_loss: 135.1295\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.2852 - val_loss: 135.2983\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.5322 - val_loss: 134.9311\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.3070 - val_loss: 135.0754\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.1482 - val_loss: 135.0406\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.2220 - val_loss: 134.8922\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.2002 - val_loss: 134.4797\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.2137 - val_loss: 134.8659\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 131.4313 - val_loss: 135.9721\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.9707 - val_loss: 134.8596\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.7945 - val_loss: 135.0050\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.1854 - val_loss: 134.2594\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.4905 - val_loss: 134.4523\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.9461 - val_loss: 135.6673\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.1181 - val_loss: 135.0323\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.3578 - val_loss: 135.0671\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.3782 - val_loss: 134.7068\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.3355 - val_loss: 134.3443\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.2660 - val_loss: 134.5060\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.2301 - val_loss: 133.3823\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.5483 - val_loss: 135.4240\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 130.5650 - val_loss: 134.5416\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.3028 - val_loss: 134.8349\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.0828 - val_loss: 134.0616\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.8738 - val_loss: 134.2347\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.0469 - val_loss: 134.2610\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.9929 - val_loss: 133.3338\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.1978 - val_loss: 135.1557\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.5361 - val_loss: 133.7176\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.6812 - val_loss: 133.8550\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.3839 - val_loss: 133.5447\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.1819 - val_loss: 133.9878\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.7031 - val_loss: 134.1062\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.6995 - val_loss: 133.9455\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.0144 - val_loss: 134.1647\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 128.6609 - val_loss: 132.9549\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 129.1090 - val_loss: 133.5635\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.8075 - val_loss: 134.8483\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.5582 - val_loss: 133.5895\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.8237 - val_loss: 133.5026\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.4172 - val_loss: 133.4634\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.5002 - val_loss: 133.8854\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.8179 - val_loss: 133.8014\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.4189 - val_loss: 133.5103\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.5563 - val_loss: 132.9807\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.8063 - val_loss: 135.9760\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.5127 - val_loss: 133.5860\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.4986 - val_loss: 134.5665\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.5686 - val_loss: 133.6255\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.4206 - val_loss: 133.6521\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.6006 - val_loss: 133.1767\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.7333 - val_loss: 133.1748\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.8226 - val_loss: 134.1589\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.4221 - val_loss: 133.6256\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.8107 - val_loss: 134.1162\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.6628 - val_loss: 133.2061\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.9904 - val_loss: 133.2681\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.5478 - val_loss: 133.3306\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.3208 - val_loss: 134.1632\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.3533 - val_loss: 132.9473\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.8409 - val_loss: 133.3508\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.2311 - val_loss: 133.8761\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.6116 - val_loss: 133.4956\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.3412 - val_loss: 134.0420\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.6197 - val_loss: 134.2920\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.0894 - val_loss: 133.0276\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.0514 - val_loss: 133.5718\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.4555 - val_loss: 132.8172\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.9945 - val_loss: 133.2229\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.4649 - val_loss: 132.9570\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.3393 - val_loss: 133.6398\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.9340 - val_loss: 133.1679\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.1899 - val_loss: 133.4192\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.0115 - val_loss: 132.5361\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.9092 - val_loss: 133.1806\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.9689 - val_loss: 132.8303\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.0108 - val_loss: 134.6063\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.9804 - val_loss: 132.5837\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.0063 - val_loss: 137.7033\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.0452 - val_loss: 133.3051\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.4210 - val_loss: 133.2241\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.1198 - val_loss: 133.6007\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.7688 - val_loss: 133.1827\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.7242 - val_loss: 133.0735\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.0465 - val_loss: 133.3343\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.2071 - val_loss: 133.6147\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.8158 - val_loss: 132.6044\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.6046 - val_loss: 132.2873\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.3155 - val_loss: 132.8807\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.2531 - val_loss: 136.6310\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 128.2989 - val_loss: 132.7732\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.4085 - val_loss: 132.5265\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.4419 - val_loss: 132.9305\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 127.1658 - val_loss: 133.0218\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.3247 - val_loss: 133.3829\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.5089 - val_loss: 134.4395\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.4836 - val_loss: 132.8855\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.5601 - val_loss: 132.9503\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.2950 - val_loss: 133.1294\n",
      "Epoch 131/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.5721 - val_loss: 133.2169\n",
      "Epoch 132/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.1179 - val_loss: 133.5782\n",
      "Epoch 133/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.5903 - val_loss: 132.4883\n",
      "Epoch 134/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.0355 - val_loss: 135.4366\n",
      "Epoch 135/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.4661 - val_loss: 133.6488\n",
      "Epoch 136/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.1688 - val_loss: 132.7637\n",
      "Epoch 137/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.1934 - val_loss: 132.1652\n",
      "Epoch 138/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.0034 - val_loss: 132.0657\n",
      "Epoch 139/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 126.2767 - val_loss: 133.9308\n",
      "Epoch 140/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 126.6174 - val_loss: 132.6250\n",
      "Epoch 141/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.2860 - val_loss: 133.2249\n",
      "Epoch 142/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.1082 - val_loss: 131.9674\n",
      "Epoch 143/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.6058 - val_loss: 132.1900\n",
      "Epoch 144/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.0694 - val_loss: 132.8059\n",
      "Epoch 145/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.8757 - val_loss: 132.2777\n",
      "Epoch 146/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.1386 - val_loss: 133.6398\n",
      "Epoch 147/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.9698 - val_loss: 132.8548\n",
      "Epoch 148/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.6973 - val_loss: 132.7306\n",
      "Epoch 149/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.3730 - val_loss: 133.1617\n",
      "Epoch 150/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.7601 - val_loss: 133.1744\n",
      "Epoch 151/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.8778 - val_loss: 132.4765\n",
      "Epoch 152/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.8812 - val_loss: 132.9243\n",
      "Epoch 153/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.8688 - val_loss: 132.5756\n",
      "Epoch 154/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 126.1294 - val_loss: 132.2106\n",
      "Epoch 155/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.6385 - val_loss: 132.5502\n",
      "Epoch 156/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.5686 - val_loss: 131.6651\n",
      "Epoch 157/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.4366 - val_loss: 132.9789\n",
      "Epoch 158/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.5144 - val_loss: 132.7499\n",
      "Epoch 159/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.5518 - val_loss: 133.1532\n",
      "Epoch 160/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.6341 - val_loss: 133.0131\n",
      "Epoch 161/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.6710 - val_loss: 132.9100\n",
      "Epoch 162/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.6523 - val_loss: 132.9997\n",
      "Epoch 163/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.9240 - val_loss: 132.3758\n",
      "Epoch 164/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 125.5807 - val_loss: 134.6307\n",
      "Epoch 165/300\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 125.9370 - val_loss: 132.4872\n",
      "Epoch 166/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.4602 - val_loss: 133.2707\n",
      "Epoch 167/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.6023 - val_loss: 132.8462\n",
      "Epoch 168/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.8821 - val_loss: 132.7860\n",
      "Epoch 169/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.5486 - val_loss: 132.3347\n",
      "Epoch 170/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.2156 - val_loss: 134.0892\n",
      "Epoch 171/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.7242 - val_loss: 132.6264\n",
      "Epoch 172/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.4065 - val_loss: 132.3565\n",
      "Epoch 173/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.0809 - val_loss: 133.0159\n",
      "Epoch 174/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.1336 - val_loss: 132.8548\n",
      "Epoch 175/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.2132 - val_loss: 132.9151\n",
      "Epoch 176/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.3881 - val_loss: 132.5959\n",
      "Epoch 177/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.2021 - val_loss: 133.7864\n",
      "Epoch 178/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.4374 - val_loss: 132.5280\n",
      "Epoch 179/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.0544 - val_loss: 132.0784\n",
      "Epoch 180/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.0860 - val_loss: 132.0863\n",
      "Epoch 181/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.3785 - val_loss: 132.4191\n",
      "Epoch 182/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.1650 - val_loss: 132.0180\n",
      "Epoch 183/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.1386 - val_loss: 132.4447\n",
      "Epoch 184/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 124.9878 - val_loss: 132.0960\n",
      "Epoch 185/300\n",
      "73/73 [==============================] - 1s 7ms/step - loss: 125.1560 - val_loss: 132.3555\n",
      "Epoch 186/300\n",
      "65/73 [=========================>....] - ETA: 0s - loss: 124.9550Restoring model weights from the end of the best epoch: 156.\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 125.1191 - val_loss: 131.8916\n",
      "Epoch 186: early stopping\n",
      "'########################################################Model9\n"
     ]
    }
   ],
   "source": [
    "model_num = 10\n",
    "\n",
    "\n",
    "mase_models = train_bagging_models(model_num, MASE(y_train,24),300,30,8)\n",
    "mape_models = train_bagging_models(model_num,'mape',300,30,8)\n",
    "smape_models = train_bagging_models(model_num, SMAPE(),300,30,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "468ad253-6a73-4a53-9d07-ad17ec4c1836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 6ms/step\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "12/12 [==============================] - 0s 6ms/step\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "12/12 [==============================] - 0s 6ms/step\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "12/12 [==============================] - 0s 8ms/step\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "12/12 [==============================] - 0s 6ms/step\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "12/12 [==============================] - 0s 6ms/step\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "12/12 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.21421507215353291, 0.23746332722336724)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred1,_=smape_models\n",
    "pred2,_=mase_models\n",
    "pred3,_=mape_models\n",
    "\n",
    "smape_predictions = bagging_predict2(pred1, test_X)\n",
    "mase_predictions = bagging_predict2(pred2, test_X)\n",
    "mape_predictions = bagging_predict2(pred3, test_X)\n",
    "concat = np.concatenate([smape_predictions, mase_predictions,mape_predictions],axis=0)\n",
    "fin_pred = np.median(concat,axis=0)\n",
    "#pd.DataFrame(fin_pred).to_csv(\"freezing_I.csv\")\n",
    "mean_squared_error(test_y.flatten(),fin_pred.flatten()),mean_absolute_error(test_y.flatten(),fin_pred.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b0204ee-8daf-431a-b391-0926f4570676",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(fin_pred).to_csv(\"../result5_new/transformer/pred_mid.csv\")\n",
    "for i in range(10):\n",
    "    pd.DataFrame(concat[i]).to_csv(f\"../result5_new/transformer/pred{i}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
