{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84526bc5-cd1a-4fac-a796-57902266c3bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "636876fb-747b-4480-8ea0-8ff0618bd573",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-29 23:54:01.304843: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-29 23:54:01.381179: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-08-29 23:54:01.381197: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-08-29 23:54:01.744715: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-08-29 23:54:01.744767: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-08-29 23:54:01.744773: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nbeats_keras.model import NBeatsNet as NBeatsKeras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "#from nbeats_pytorch.model import NBeatsNet as NBeatsPytorch\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "import time\n",
    "from keras.models import load_model\n",
    "#from target_data_electronic70_7 import target_X, target_y ,test_X, test_y\n",
    "#from m4databasis21_7 import base_domain,zt_in,zt_out,M4Meta,inputsize,train_12,train_12_y\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error,mean_absolute_percentage_error\n",
    "plt.rcParams['font.family'] ='Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] =False\n",
    "from tensorflow.keras.losses import Loss\n",
    "import tensorflow as tf\n",
    "#from m4databasis35_7_70_7 import train_35,train_35_y,train_70,train_70_y\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, LayerNormalization, MultiHeadAttention, Dropout, Add, Concatenate,Flatten,Reshape\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, TimeDistributed, Lambda\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3850e1af-7ef4-47f2-b130-6732c47014c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((723, 120), (723, 24))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_X= pd.read_csv(\"../data/solor_train_input_5.csv\").iloc[:,(1+24*0):].values\n",
    "target_y =pd.read_csv(\"../data/solor_train_output_5.csv\").iloc[:,1:].values\n",
    "test_X= pd.read_csv(\"../data/solor_val_input_5.csv\").iloc[:,(1+24*0):].values\n",
    "test_y =pd.read_csv(\"../data/solor_val_output_5.csv\").iloc[:,1:].values\n",
    "\n",
    "X_train = target_X\n",
    "y_train = target_y\n",
    "X_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3aff672-3e0d-4a08-9d95-0a0eacbdbb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "# loss SMAPE\n",
    "class SMAPE(Loss):\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_pred = tf.reshape(y_pred, tf.shape(y_true))  # 예측 값의 차원을 맞춤\n",
    "       # y_pred=tf.clip_by_value(y_pred, 1e-10, tf.reduce_max(y_pred))\n",
    "       # y_true = tf.clip_by_value(y_true, 1e-10, tf.reduce_max(y_true))\n",
    "        \n",
    "        numerator = 100 * tf.abs(y_true- y_pred )\n",
    "        denominator =  (tf.abs(y_true ) + tf.abs(y_pred))/2\n",
    "        smape =  numerator /  denominator #tf.clip_by_value(denominator, 1e-10, tf.reduce_max(denominator))\n",
    "        return tf.reduce_mean(smape)\n",
    "\n",
    "#################################################################################\n",
    "# loss MASE\n",
    "class MASE(Loss):\n",
    "    def __init__(self, training_data, period, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.scale = self.calculate_scale(training_data, period)\n",
    "    def seasonal_diff(data, period):\n",
    "        return data[period:] - data[:-period]\n",
    "\n",
    "    def calculate_scale(self, training_data, period):\n",
    "        # 주기 차분 계산\n",
    "        diff = seasonal_diff(training_data, period)\n",
    "        scale = np.mean(np.abs(diff))\n",
    "        return scale\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        y_pred = tf.reshape(y_pred, tf.shape(y_true))  # 차원 맞추기\n",
    "        error = tf.abs(y_true - y_pred)\n",
    "        return tf.reduce_mean(error / self.scale)\n",
    "\n",
    "def seasonal_diff(data, period):\n",
    "    return data[period:] - data[:-period]\n",
    "#################################################################################\n",
    "# 하이퍼파라미터 인자 설정\n",
    "def hyperparameter():\n",
    "    # 1 backcast\n",
    "    # 2 forecast\n",
    "    # 3 inputdim\n",
    "    # 4 outputdim\n",
    "    # 5 unit\n",
    "    # 6 bacth size\n",
    "    return X_train.shape[1],1,y_train.shape[1],y_train.shape[1]\n",
    "\n",
    "#################################################################################\n",
    "# nbeats 모델 생성 함수\n",
    "def build_model(input_timesteps,features,output_timesteps,unit):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(unit, return_sequences=True, input_shape=(input_timesteps, features)))\n",
    "    #model.add(LSTM(unit, return_sequences=True))\n",
    "    # Use Lambda layer to select the last 'output_timesteps' outputs\n",
    "    model.add(Lambda(lambda x: x[:, -output_timesteps:, :]))\n",
    "    model.add(TimeDistributed(Dense(1)))\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model.compile(loss='mse', optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "#################################################################################\n",
    "# 부트스트랩 샘플링\n",
    "# 배깅\n",
    "\n",
    "def train_bagging_models(num_models, loss_fn , epochs_, patience_,batch_size_,lr):\n",
    "    models = {}\n",
    "    input_timesteps,features,output_timesteps,unit = hyperparameter()\n",
    "    historys = []\n",
    "    for n in range(num_models):\n",
    "        K.clear_session()\n",
    "        model = build_model(input_timesteps,features,output_timesteps,unit)\n",
    "       # model.set_weights(pretrained_weights)  # 전이 학습 가중치 적용\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "        model.compile(optimizer=optimizer , loss=loss_fn)\n",
    "        \n",
    "        # 부트스트랩 샘플링\n",
    "        #select = np.random.choice(len(X_train), size=len(X_train), replace=True)\n",
    "        #X_bootstrap = X_train[select]\n",
    "        #y_bootstrap = y_train[select]\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience = patience_, verbose = 1, restore_best_weights=True)\n",
    "        history = model.fit(X_train, y_train, batch_size = batch_size_,\n",
    "                  epochs=epochs_, verbose=1, \n",
    "                  callbacks=[early_stop],\n",
    "                 validation_split = 0.2)\n",
    "        models[f'model_{n+1}'] = model\n",
    "        historys.append(history)\n",
    "        #models.append(model)\n",
    "        print(f\"'########################################################Model{n}\")\n",
    "    return models,historys\n",
    "\n",
    "#################################################################################\n",
    "# SMAPE 용\n",
    "def train_bagging_models_smape(num_models, loss_fn , epochs_, patience_,batch_size_):\n",
    "    models = {}\n",
    "    backcast,forecast,in_dim,out_dim,unit = hyperparameter()\n",
    "    historys = []\n",
    "    for n in range(num_models):\n",
    "        K.clear_session()\n",
    "        model = bulid_model(backcast,forecast,in_dim,out_dim,unit)\n",
    "       # model.set_weights(pretrained_weights)  # 전이 학습 가중치 적용\n",
    "        optimizer = Adam(learning_rate=0.001)\n",
    "        model.compile(optimizer=optimizer , loss=loss_fn)\n",
    "        \n",
    "        # 부트스트랩 샘플링\n",
    "        #select = np.random.choice(len(X_train), size=len(X_train), replace=True)\n",
    "        #_bootstrap = X_train[select]\n",
    "        #y_bootstrap = y_train[select]\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience = patience_, verbose = 1, restore_best_weights=True)\n",
    "        history = model.fit(X_train, y_train, batch_size = batch_size_,\n",
    "                  epochs=epochs_, verbose=1, \n",
    "                  callbacks=[early_stop],\n",
    "                 validation_split = 0.2)\n",
    "        models[f'model_{n+1}'] = model\n",
    "        historys.append(history)\n",
    "        #models.append(model)\n",
    "        print(f\"'########################################################Model{n}\")\n",
    "    return models,historys\n",
    "\n",
    "\n",
    "\n",
    "#################################################################################\n",
    "\n",
    "def bagging_predict(models, X):\n",
    "    predictions = np.array([model.predict(X) for model in models.values()])\n",
    "    return np.median(predictions, axis=0)\n",
    "\n",
    "def bagging_predict2(models, X):\n",
    "    predictions = np.array([model.predict(X) for model in models.values()])\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fce9eb03-7500-4d76-af24-72f76cc67df4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-29 23:54:02.623587: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-08-29 23:54:02.623626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ymlee2-desktop): /proc/driver/nvidia/version does not exist\n",
      "2024-08-29 23:54:02.624144: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 2s 17ms/step - loss: 1.4305 - val_loss: 1.0762\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 1.1490 - val_loss: 0.8759\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.9351 - val_loss: 0.7021\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.8393 - val_loss: 0.6734\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.8150 - val_loss: 0.6755\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.8013 - val_loss: 0.6610\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7932 - val_loss: 0.6237\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7904 - val_loss: 0.6315\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7851 - val_loss: 0.6295\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7810 - val_loss: 0.6186\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7773 - val_loss: 0.6180\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7789 - val_loss: 0.6120\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7735 - val_loss: 0.6041\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7716 - val_loss: 0.6083\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7686 - val_loss: 0.6011\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7661 - val_loss: 0.6050\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7667 - val_loss: 0.6003\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7627 - val_loss: 0.6239\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7669 - val_loss: 0.5973\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7635 - val_loss: 0.6084\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7617 - val_loss: 0.6002\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7591 - val_loss: 0.6057\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7595 - val_loss: 0.5927\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7566 - val_loss: 0.6002\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7551 - val_loss: 0.6004\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7632 - val_loss: 0.6109\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7578 - val_loss: 0.5983\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7515 - val_loss: 0.5959\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7514 - val_loss: 0.6044\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7511 - val_loss: 0.6000\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7499 - val_loss: 0.5868\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7482 - val_loss: 0.5954\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7501 - val_loss: 0.5855\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7468 - val_loss: 0.5990\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7528 - val_loss: 0.5874\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7541 - val_loss: 0.5881\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7508 - val_loss: 0.5960\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7476 - val_loss: 0.5815\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7475 - val_loss: 0.5906\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7457 - val_loss: 0.6014\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7477 - val_loss: 0.5852\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7453 - val_loss: 0.5912\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7414 - val_loss: 0.5777\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7414 - val_loss: 0.5810\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7433 - val_loss: 0.6001\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7433 - val_loss: 0.5791\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7409 - val_loss: 0.5918\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7439 - val_loss: 0.5912\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7418 - val_loss: 0.5795\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7477 - val_loss: 0.5831\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7419 - val_loss: 0.5750\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7394 - val_loss: 0.5762\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7370 - val_loss: 0.5892\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7368 - val_loss: 0.5846\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7397 - val_loss: 0.5927\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7365 - val_loss: 0.5940\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7424 - val_loss: 0.5762\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7370 - val_loss: 0.5821\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7392 - val_loss: 0.5818\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7420 - val_loss: 0.5823\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7408 - val_loss: 0.5734\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7357 - val_loss: 0.5757\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7336 - val_loss: 0.5838\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7373 - val_loss: 0.5790\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7358 - val_loss: 0.5751\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7329 - val_loss: 0.5739\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7335 - val_loss: 0.5860\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7300 - val_loss: 0.5758\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7372 - val_loss: 0.5895\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7322 - val_loss: 0.5772\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7324 - val_loss: 0.5757\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7332 - val_loss: 0.5712\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7340 - val_loss: 0.5733\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7356 - val_loss: 0.5754\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7366 - val_loss: 0.5983\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7361 - val_loss: 0.5762\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7352 - val_loss: 0.5795\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7307 - val_loss: 0.5833\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7293 - val_loss: 0.5742\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7338 - val_loss: 0.5788\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7334 - val_loss: 0.5817\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7329 - val_loss: 0.5721\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7339 - val_loss: 0.5698\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7291 - val_loss: 0.5915\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7256 - val_loss: 0.5817\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7331 - val_loss: 0.5832\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7357 - val_loss: 0.5873\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7328 - val_loss: 0.5969\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7282 - val_loss: 0.5774\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7314 - val_loss: 0.5694\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7307 - val_loss: 0.5755\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7302 - val_loss: 0.5749\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7265 - val_loss: 0.5756\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7270 - val_loss: 0.5781\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7289 - val_loss: 0.5716\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7255 - val_loss: 0.5697\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7248 - val_loss: 0.5736\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7330 - val_loss: 0.5734\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7281 - val_loss: 0.5665\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7289 - val_loss: 0.5744\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7291 - val_loss: 0.5726\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7258 - val_loss: 0.5770\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7260 - val_loss: 0.5687\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7270 - val_loss: 0.5756\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7255 - val_loss: 0.5662\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7243 - val_loss: 0.5653\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7304 - val_loss: 0.5689\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7309 - val_loss: 0.5740\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7244 - val_loss: 0.5692\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7242 - val_loss: 0.5785\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7290 - val_loss: 0.5725\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7271 - val_loss: 0.5717\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7256 - val_loss: 0.5788\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7292 - val_loss: 0.5777\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7260 - val_loss: 0.5684\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7296 - val_loss: 0.5877\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7268 - val_loss: 0.5705\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7230 - val_loss: 0.5755\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7271 - val_loss: 0.5718\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7230 - val_loss: 0.5682\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7305 - val_loss: 0.5728\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7254 - val_loss: 0.5677\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7220 - val_loss: 0.5705\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7309 - val_loss: 0.5666\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7212 - val_loss: 0.5677\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7272 - val_loss: 0.5822\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7233 - val_loss: 0.5663\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7239 - val_loss: 0.5707\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7290 - val_loss: 0.5786\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7251 - val_loss: 0.5658\n",
      "Epoch 131/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7241 - val_loss: 0.5746\n",
      "Epoch 132/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7237 - val_loss: 0.5670\n",
      "Epoch 133/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7249 - val_loss: 0.5691\n",
      "Epoch 134/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7256 - val_loss: 0.6056\n",
      "Epoch 135/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7337 - val_loss: 0.5793\n",
      "Epoch 136/300\n",
      "73/73 [==============================] - ETA: 0s - loss: 0.7236Restoring model weights from the end of the best epoch: 106.\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7236 - val_loss: 0.5679\n",
      "Epoch 136: early stopping\n",
      "'########################################################Model0\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 17ms/step - loss: 1.7277 - val_loss: 1.2557\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 1.2849 - val_loss: 0.9736\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 1.0072 - val_loss: 0.7570\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.8672 - val_loss: 0.6840\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.8187 - val_loss: 0.7063\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.8008 - val_loss: 0.6380\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7924 - val_loss: 0.6356\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7849 - val_loss: 0.6252\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7785 - val_loss: 0.6259\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7763 - val_loss: 0.6191\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7711 - val_loss: 0.6219\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7680 - val_loss: 0.6259\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7659 - val_loss: 0.6156\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7676 - val_loss: 0.6024\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7623 - val_loss: 0.6001\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7601 - val_loss: 0.6034\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7564 - val_loss: 0.5975\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7564 - val_loss: 0.5982\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7610 - val_loss: 0.6009\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7592 - val_loss: 0.6106\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7521 - val_loss: 0.5924\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7510 - val_loss: 0.5996\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7543 - val_loss: 0.5910\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7514 - val_loss: 0.5944\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7481 - val_loss: 0.6187\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7537 - val_loss: 0.5919\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7472 - val_loss: 0.5885\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7469 - val_loss: 0.5952\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7469 - val_loss: 0.6026\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7509 - val_loss: 0.5966\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7449 - val_loss: 0.5855\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7412 - val_loss: 0.6237\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7473 - val_loss: 0.5918\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7408 - val_loss: 0.5936\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7444 - val_loss: 0.5819\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7401 - val_loss: 0.5932\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7426 - val_loss: 0.5946\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7435 - val_loss: 0.5938\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7411 - val_loss: 0.5892\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7403 - val_loss: 0.5928\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7431 - val_loss: 0.5847\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7428 - val_loss: 0.5800\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7399 - val_loss: 0.5816\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7410 - val_loss: 0.5875\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7417 - val_loss: 0.6005\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7397 - val_loss: 0.5833\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7356 - val_loss: 0.5829\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7398 - val_loss: 0.5874\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7381 - val_loss: 0.5923\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7380 - val_loss: 0.5826\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7385 - val_loss: 0.5776\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7349 - val_loss: 0.5768\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7386 - val_loss: 0.5858\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7360 - val_loss: 0.5799\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7393 - val_loss: 0.5861\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7367 - val_loss: 0.5810\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7345 - val_loss: 0.5823\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7388 - val_loss: 0.5881\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7354 - val_loss: 0.5868\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7334 - val_loss: 0.5799\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7366 - val_loss: 0.6174\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7326 - val_loss: 0.5848\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7351 - val_loss: 0.5764\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7321 - val_loss: 0.5816\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7326 - val_loss: 0.5929\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7315 - val_loss: 0.5776\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7328 - val_loss: 0.5924\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7430 - val_loss: 0.5724\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7301 - val_loss: 0.5731\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7329 - val_loss: 0.5767\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7305 - val_loss: 0.5840\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7311 - val_loss: 0.5747\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7311 - val_loss: 0.5808\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7382 - val_loss: 0.5816\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7308 - val_loss: 0.5751\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7287 - val_loss: 0.6057\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7349 - val_loss: 0.5898\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7313 - val_loss: 0.5782\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7315 - val_loss: 0.5746\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7344 - val_loss: 0.5790\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7365 - val_loss: 0.6054\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7346 - val_loss: 0.5725\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7322 - val_loss: 0.5914\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7299 - val_loss: 0.5849\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7345 - val_loss: 0.5758\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7379 - val_loss: 0.5741\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7279 - val_loss: 0.5823\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7354 - val_loss: 0.5739\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7288 - val_loss: 0.5847\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7272 - val_loss: 0.5758\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7283 - val_loss: 0.5726\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7282 - val_loss: 0.5740\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7236 - val_loss: 0.5793\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7312 - val_loss: 0.5815\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7243 - val_loss: 0.5769\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7274 - val_loss: 0.5861\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7362 - val_loss: 0.5689\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7290 - val_loss: 0.5988\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7282 - val_loss: 0.5750\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7261 - val_loss: 0.5714\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7276 - val_loss: 0.5808\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7239 - val_loss: 0.5869\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7258 - val_loss: 0.5767\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7287 - val_loss: 0.5809\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7285 - val_loss: 0.5816\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7323 - val_loss: 0.5730\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7275 - val_loss: 0.5860\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7234 - val_loss: 0.5847\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7277 - val_loss: 0.5768\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7259 - val_loss: 0.5777\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7310 - val_loss: 0.5738\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7249 - val_loss: 0.5760\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7248 - val_loss: 0.5896\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7267 - val_loss: 0.5713\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7236 - val_loss: 0.5800\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7242 - val_loss: 0.5712\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7269 - val_loss: 0.5697\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7233 - val_loss: 0.5952\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7261 - val_loss: 0.5913\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7291 - val_loss: 0.5672\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7216 - val_loss: 0.5718\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7254 - val_loss: 0.5785\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7239 - val_loss: 0.5699\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7288 - val_loss: 0.5706\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7238 - val_loss: 0.5713\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7191 - val_loss: 0.5731\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7235 - val_loss: 0.5667\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7207 - val_loss: 0.5722\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7214 - val_loss: 0.5733\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7241 - val_loss: 0.5672\n",
      "Epoch 131/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7299 - val_loss: 0.5679\n",
      "Epoch 132/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7198 - val_loss: 0.5782\n",
      "Epoch 133/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7241 - val_loss: 0.5940\n",
      "Epoch 134/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7243 - val_loss: 0.5726\n",
      "Epoch 135/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7243 - val_loss: 0.5793\n",
      "Epoch 136/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7217 - val_loss: 0.5723\n",
      "Epoch 137/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7257 - val_loss: 0.5700\n",
      "Epoch 138/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7212 - val_loss: 0.5699\n",
      "Epoch 139/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7214 - val_loss: 0.5776\n",
      "Epoch 140/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7251 - val_loss: 0.5673\n",
      "Epoch 141/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7220 - val_loss: 0.5685\n",
      "Epoch 142/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7195 - val_loss: 0.5778\n",
      "Epoch 143/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7274 - val_loss: 0.5707\n",
      "Epoch 144/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7215 - val_loss: 0.5697\n",
      "Epoch 145/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7204 - val_loss: 0.5721\n",
      "Epoch 146/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7190 - val_loss: 0.5694\n",
      "Epoch 147/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7201 - val_loss: 0.5683\n",
      "Epoch 148/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7204 - val_loss: 0.5888\n",
      "Epoch 149/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7235 - val_loss: 0.5720\n",
      "Epoch 150/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7187 - val_loss: 0.5754\n",
      "Epoch 151/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7241 - val_loss: 0.5704\n",
      "Epoch 152/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7206 - val_loss: 0.5811\n",
      "Epoch 153/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7278 - val_loss: 0.5767\n",
      "Epoch 154/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7231 - val_loss: 0.5736\n",
      "Epoch 155/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7247 - val_loss: 0.5675\n",
      "Epoch 156/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7204 - val_loss: 0.5689\n",
      "Epoch 157/300\n",
      "69/73 [===========================>..] - ETA: 0s - loss: 0.7132Restoring model weights from the end of the best epoch: 127.\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7215 - val_loss: 0.5812\n",
      "Epoch 157: early stopping\n",
      "'########################################################Model1\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 15ms/step - loss: 1.7204 - val_loss: 1.2751\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 1.3754 - val_loss: 1.0537\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 1.1385 - val_loss: 0.8582\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.9070 - val_loss: 0.6690\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.8206 - val_loss: 0.6513\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.8074 - val_loss: 0.6583\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.8027 - val_loss: 0.6276\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.7950 - val_loss: 0.6256\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7911 - val_loss: 0.6465\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 0.7860 - val_loss: 0.6131\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 0.7824 - val_loss: 0.6105\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7807 - val_loss: 0.6311\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7784 - val_loss: 0.6182\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7717 - val_loss: 0.6374\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7723 - val_loss: 0.6072\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7712 - val_loss: 0.6076\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7682 - val_loss: 0.6125\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7703 - val_loss: 0.6010\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 0.7622 - val_loss: 0.5997\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7596 - val_loss: 0.5924\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7638 - val_loss: 0.5932\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7576 - val_loss: 0.5988\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7613 - val_loss: 0.5963\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7539 - val_loss: 0.5933\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.7548 - val_loss: 0.5998\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7535 - val_loss: 0.5984\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 0.7491 - val_loss: 0.5859\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 0.7525 - val_loss: 0.5841\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7528 - val_loss: 0.5833\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7460 - val_loss: 0.5867\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 21ms/step - loss: 0.7429 - val_loss: 0.5914\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7451 - val_loss: 0.5833\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7435 - val_loss: 0.6046\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7465 - val_loss: 0.5871\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7420 - val_loss: 0.5781\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 0.7415 - val_loss: 0.5829\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7371 - val_loss: 0.5802\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7429 - val_loss: 0.5896\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7399 - val_loss: 0.5864\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7391 - val_loss: 0.5786\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7394 - val_loss: 0.5745\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 0.7382 - val_loss: 0.5781\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7411 - val_loss: 0.5755\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 0.7346 - val_loss: 0.5773\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 0.7344 - val_loss: 0.5748\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7353 - val_loss: 0.5797\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7371 - val_loss: 0.5775\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7357 - val_loss: 0.5734\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7338 - val_loss: 0.5748\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7347 - val_loss: 0.5728\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7342 - val_loss: 0.5744\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7339 - val_loss: 0.5902\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 0.7352 - val_loss: 0.5725\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7293 - val_loss: 0.5736\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7320 - val_loss: 0.5936\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7319 - val_loss: 0.5843\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7376 - val_loss: 0.5900\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7316 - val_loss: 0.5861\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 0.7383 - val_loss: 0.5864\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7352 - val_loss: 0.5748\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 0.7340 - val_loss: 0.5952\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 0.7302 - val_loss: 0.5748\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7299 - val_loss: 0.5702\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7316 - val_loss: 0.5747\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7284 - val_loss: 0.5823\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 0.7309 - val_loss: 0.5706\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7353 - val_loss: 0.5711\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7287 - val_loss: 0.5783\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7263 - val_loss: 0.5798\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 0.7312 - val_loss: 0.5726\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7300 - val_loss: 0.5697\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7273 - val_loss: 0.5775\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7305 - val_loss: 0.5729\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7293 - val_loss: 0.5731\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7302 - val_loss: 0.5706\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.7304 - val_loss: 0.5740\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7262 - val_loss: 0.5798\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.7298 - val_loss: 0.5714\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 0.7272 - val_loss: 0.5697\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 1s 21ms/step - loss: 0.7246 - val_loss: 0.5674\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7267 - val_loss: 0.5689\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7256 - val_loss: 0.5651\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7255 - val_loss: 0.5826\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7292 - val_loss: 0.5746\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7284 - val_loss: 0.5720\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7239 - val_loss: 0.5673\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 0.7275 - val_loss: 0.5695\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7228 - val_loss: 0.5818\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 0.7224 - val_loss: 0.5717\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7252 - val_loss: 0.5670\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7224 - val_loss: 0.5705\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7236 - val_loss: 0.5703\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.7210 - val_loss: 0.5877\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7225 - val_loss: 0.5702\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.7277 - val_loss: 0.5652\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 0.7240 - val_loss: 0.5761\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7228 - val_loss: 0.5689\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7255 - val_loss: 0.5640\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 1s 21ms/step - loss: 0.7256 - val_loss: 0.5643\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7218 - val_loss: 0.5769\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7221 - val_loss: 0.5656\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7205 - val_loss: 0.5700\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7280 - val_loss: 0.5645\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 0.7230 - val_loss: 0.5657\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7210 - val_loss: 0.5809\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7283 - val_loss: 0.5687\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7232 - val_loss: 0.5663\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7278 - val_loss: 0.5684\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7216 - val_loss: 0.5660\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.7204 - val_loss: 0.5741\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7210 - val_loss: 0.5663\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.7230 - val_loss: 0.5654\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 0.7207 - val_loss: 0.5737\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7249 - val_loss: 0.5764\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7196 - val_loss: 0.5671\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7173 - val_loss: 0.5661\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7199 - val_loss: 0.5779\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7186 - val_loss: 0.5760\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7188 - val_loss: 0.5792\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7195 - val_loss: 0.5712\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 0.7169 - val_loss: 0.5655\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7195 - val_loss: 0.5712\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7271 - val_loss: 0.5661\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7178 - val_loss: 0.5672\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7178 - val_loss: 0.5724\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 0.7164 - val_loss: 0.5714\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 0.7165 - val_loss: 0.5664\n",
      "Epoch 128/300\n",
      "71/73 [============================>.] - ETA: 0s - loss: 0.7151Restoring model weights from the end of the best epoch: 98.\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7176 - val_loss: 0.5649\n",
      "Epoch 128: early stopping\n",
      "'########################################################Model2\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 3s 24ms/step - loss: 1.4255 - val_loss: 1.0661\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 1.1347 - val_loss: 0.8743\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.9356 - val_loss: 0.7363\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.8532 - val_loss: 0.6909\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.8284 - val_loss: 0.6619\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 0.8157 - val_loss: 0.6587\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.8098 - val_loss: 0.6450\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 0.8070 - val_loss: 0.6459\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 0.8019 - val_loss: 0.6378\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7985 - val_loss: 0.6318\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7941 - val_loss: 0.6303\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 21ms/step - loss: 0.7929 - val_loss: 0.6349\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7896 - val_loss: 0.6379\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7887 - val_loss: 0.6317\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7828 - val_loss: 0.6526\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7844 - val_loss: 0.6225\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 0.7805 - val_loss: 0.6193\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7756 - val_loss: 0.6091\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7748 - val_loss: 0.6077\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7671 - val_loss: 0.6127\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7663 - val_loss: 0.5976\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7613 - val_loss: 0.6191\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.7623 - val_loss: 0.6035\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7584 - val_loss: 0.5918\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.7559 - val_loss: 0.6059\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 0.7556 - val_loss: 0.6010\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 0.7547 - val_loss: 0.5942\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7529 - val_loss: 0.5930\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7506 - val_loss: 0.5902\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7481 - val_loss: 0.5896\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 0.7498 - val_loss: 0.5899\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7488 - val_loss: 0.5906\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7484 - val_loss: 0.5891\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 0.7449 - val_loss: 0.5839\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7450 - val_loss: 0.5923\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7446 - val_loss: 0.5869\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7462 - val_loss: 0.5851\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7430 - val_loss: 0.5916\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7446 - val_loss: 0.5922\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 0.7419 - val_loss: 0.5780\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7419 - val_loss: 0.5818\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7409 - val_loss: 0.5909\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 0.7423 - val_loss: 0.5745\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7374 - val_loss: 0.5788\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7406 - val_loss: 0.5920\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7420 - val_loss: 0.5838\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7361 - val_loss: 0.5784\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7391 - val_loss: 0.5773\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7358 - val_loss: 0.5815\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7368 - val_loss: 0.5851\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 0.7345 - val_loss: 0.5798\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7369 - val_loss: 0.5778\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7360 - val_loss: 0.5830\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 0.7349 - val_loss: 0.5739\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7370 - val_loss: 0.5781\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7346 - val_loss: 0.5781\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 0.7324 - val_loss: 0.5805\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7386 - val_loss: 0.5809\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 0.7340 - val_loss: 0.5768\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 0.7363 - val_loss: 0.5773\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7327 - val_loss: 0.5828\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7329 - val_loss: 0.5711\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7303 - val_loss: 0.5725\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7314 - val_loss: 0.5800\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7306 - val_loss: 0.5695\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7307 - val_loss: 0.5700\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7328 - val_loss: 0.5673\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 0.7295 - val_loss: 0.5700\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7303 - val_loss: 0.5709\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7293 - val_loss: 0.6020\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7305 - val_loss: 0.5681\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 0.7321 - val_loss: 0.5873\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7356 - val_loss: 0.5792\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 0.7273 - val_loss: 0.5706\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7292 - val_loss: 0.5727\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 0.7275 - val_loss: 0.5721\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 0.7286 - val_loss: 0.5923\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7340 - val_loss: 0.5725\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7292 - val_loss: 0.5731\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7261 - val_loss: 0.5824\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7318 - val_loss: 0.5694\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 0.7296 - val_loss: 0.5661\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7252 - val_loss: 0.5668\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7291 - val_loss: 0.5655\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 0.7262 - val_loss: 0.5660\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7267 - val_loss: 0.5645\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7258 - val_loss: 0.5734\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7281 - val_loss: 0.5696\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7257 - val_loss: 0.5690\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7252 - val_loss: 0.5713\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 0.7282 - val_loss: 0.5746\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7308 - val_loss: 0.5723\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7245 - val_loss: 0.5704\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 0.7238 - val_loss: 0.5670\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 1s 21ms/step - loss: 0.7278 - val_loss: 0.5654\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 1s 21ms/step - loss: 0.7259 - val_loss: 0.5755\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7255 - val_loss: 0.5891\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7261 - val_loss: 0.5680\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7254 - val_loss: 0.5790\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7234 - val_loss: 0.5726\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7234 - val_loss: 0.5683\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 0.7257 - val_loss: 0.5801\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7257 - val_loss: 0.5690\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7241 - val_loss: 0.5653\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7237 - val_loss: 0.5700\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7217 - val_loss: 0.5699\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7228 - val_loss: 0.5675\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 0.7207 - val_loss: 0.5648\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7249 - val_loss: 0.5695\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 0.7252 - val_loss: 0.6135\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 0.7252 - val_loss: 0.5709\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7245 - val_loss: 0.5656\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7221 - val_loss: 0.5737\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7218 - val_loss: 0.5662\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7207 - val_loss: 0.5651\n",
      "Epoch 116/300\n",
      "72/73 [============================>.] - ETA: 0s - loss: 0.7213Restoring model weights from the end of the best epoch: 86.\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 0.7204 - val_loss: 0.5756\n",
      "Epoch 116: early stopping\n",
      "'########################################################Model3\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 19ms/step - loss: 1.5145 - val_loss: 1.1225\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 1.2116 - val_loss: 0.9381\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 1.0161 - val_loss: 0.7926\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.8973 - val_loss: 0.7154\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.8591 - val_loss: 0.6989\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.8410 - val_loss: 0.6821\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 0.8280 - val_loss: 0.6632\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.8191 - val_loss: 0.6560\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.8144 - val_loss: 0.6626\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.8114 - val_loss: 0.6442\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.8036 - val_loss: 0.6448\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.8007 - val_loss: 0.6367\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.8004 - val_loss: 0.6339\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7943 - val_loss: 0.6417\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7930 - val_loss: 0.6403\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7909 - val_loss: 0.6263\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7864 - val_loss: 0.6214\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7850 - val_loss: 0.6195\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7796 - val_loss: 0.6171\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7780 - val_loss: 0.6110\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7763 - val_loss: 0.6212\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7735 - val_loss: 0.6069\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7706 - val_loss: 0.6052\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7701 - val_loss: 0.6054\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 0.7681 - val_loss: 0.6074\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7665 - val_loss: 0.6197\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7644 - val_loss: 0.6049\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7649 - val_loss: 0.6087\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7606 - val_loss: 0.6110\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7611 - val_loss: 0.5989\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7583 - val_loss: 0.6006\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7573 - val_loss: 0.5961\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7563 - val_loss: 0.5879\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7559 - val_loss: 0.6062\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7586 - val_loss: 0.5952\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7527 - val_loss: 0.5879\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7519 - val_loss: 0.5891\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7535 - val_loss: 0.5926\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.7505 - val_loss: 0.6075\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7526 - val_loss: 0.5872\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7504 - val_loss: 0.5899\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7488 - val_loss: 0.5850\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7483 - val_loss: 0.5857\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7476 - val_loss: 0.5846\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7477 - val_loss: 0.5830\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7442 - val_loss: 0.5929\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7442 - val_loss: 0.5902\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7439 - val_loss: 0.5996\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7411 - val_loss: 0.6009\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 0.7425 - val_loss: 0.5845\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7420 - val_loss: 0.5903\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7436 - val_loss: 0.5823\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7390 - val_loss: 0.5800\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 0.7410 - val_loss: 0.5838\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7424 - val_loss: 0.5932\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7428 - val_loss: 0.5819\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7362 - val_loss: 0.5845\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7350 - val_loss: 0.5936\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7374 - val_loss: 0.5870\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7355 - val_loss: 0.5857\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7353 - val_loss: 0.5838\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7353 - val_loss: 0.5789\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7327 - val_loss: 0.5787\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 0.7325 - val_loss: 0.5842\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7322 - val_loss: 0.5819\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7336 - val_loss: 0.5921\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7344 - val_loss: 0.5862\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 0.7284 - val_loss: 0.5792\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7312 - val_loss: 0.5866\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7306 - val_loss: 0.5772\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7300 - val_loss: 0.5923\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7270 - val_loss: 0.5781\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7295 - val_loss: 0.5792\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7380 - val_loss: 0.5933\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7315 - val_loss: 0.5775\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7298 - val_loss: 0.5845\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7276 - val_loss: 0.5747\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 0.7320 - val_loss: 0.5852\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7296 - val_loss: 0.5772\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7259 - val_loss: 0.5724\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 0.7283 - val_loss: 0.5829\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 0.7252 - val_loss: 0.5755\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7267 - val_loss: 0.5856\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7268 - val_loss: 0.5775\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7267 - val_loss: 0.5776\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7245 - val_loss: 0.5866\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7294 - val_loss: 0.5762\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7228 - val_loss: 0.5713\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7300 - val_loss: 0.5793\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7238 - val_loss: 0.5790\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7300 - val_loss: 0.5774\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.7279 - val_loss: 0.5746\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7235 - val_loss: 0.5763\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7239 - val_loss: 0.5770\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 0.7274 - val_loss: 0.5770\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7227 - val_loss: 0.5783\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7233 - val_loss: 0.5696\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7287 - val_loss: 0.5752\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7274 - val_loss: 0.5708\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7227 - val_loss: 0.5760\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7263 - val_loss: 0.5984\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7290 - val_loss: 0.5702\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7248 - val_loss: 0.5731\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7239 - val_loss: 0.5698\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7227 - val_loss: 0.5809\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7221 - val_loss: 0.5825\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7233 - val_loss: 0.5848\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7207 - val_loss: 0.5712\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.7213 - val_loss: 0.5682\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7244 - val_loss: 0.5767\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7242 - val_loss: 0.5720\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7209 - val_loss: 0.5724\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7224 - val_loss: 0.5808\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7200 - val_loss: 0.5673\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7202 - val_loss: 0.5660\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7237 - val_loss: 0.5731\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7230 - val_loss: 0.5664\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7255 - val_loss: 0.5690\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7187 - val_loss: 0.5694\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 0.7220 - val_loss: 0.5777\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7229 - val_loss: 0.5724\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7224 - val_loss: 0.5764\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 0.7225 - val_loss: 0.5699\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7176 - val_loss: 0.5730\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7206 - val_loss: 0.5732\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7192 - val_loss: 0.5672\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7176 - val_loss: 0.5671\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7244 - val_loss: 0.5804\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7224 - val_loss: 0.5968\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7209 - val_loss: 0.5681\n",
      "Epoch 131/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7206 - val_loss: 0.5666\n",
      "Epoch 132/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7193 - val_loss: 0.5803\n",
      "Epoch 133/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7220 - val_loss: 0.5665\n",
      "Epoch 134/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7196 - val_loss: 0.5707\n",
      "Epoch 135/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7187 - val_loss: 0.5752\n",
      "Epoch 136/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 0.7208 - val_loss: 0.5846\n",
      "Epoch 137/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7175 - val_loss: 0.5707\n",
      "Epoch 138/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7224 - val_loss: 0.5643\n",
      "Epoch 139/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 0.7166 - val_loss: 0.5666\n",
      "Epoch 140/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 0.7179 - val_loss: 0.5676\n",
      "Epoch 141/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7177 - val_loss: 0.5680\n",
      "Epoch 142/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7161 - val_loss: 0.5658\n",
      "Epoch 143/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7164 - val_loss: 0.5726\n",
      "Epoch 144/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7208 - val_loss: 0.5744\n",
      "Epoch 145/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7181 - val_loss: 0.5635\n",
      "Epoch 146/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7222 - val_loss: 0.5733\n",
      "Epoch 147/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7180 - val_loss: 0.5821\n",
      "Epoch 148/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7194 - val_loss: 0.5678\n",
      "Epoch 149/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7182 - val_loss: 0.5721\n",
      "Epoch 150/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7176 - val_loss: 0.5647\n",
      "Epoch 151/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7192 - val_loss: 0.5676\n",
      "Epoch 152/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7164 - val_loss: 0.5659\n",
      "Epoch 153/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7173 - val_loss: 0.5690\n",
      "Epoch 154/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.7149 - val_loss: 0.5679\n",
      "Epoch 155/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7217 - val_loss: 0.5639\n",
      "Epoch 156/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7138 - val_loss: 0.5627\n",
      "Epoch 157/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7148 - val_loss: 0.5661\n",
      "Epoch 158/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7162 - val_loss: 0.5843\n",
      "Epoch 159/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7178 - val_loss: 0.5633\n",
      "Epoch 160/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7168 - val_loss: 0.5858\n",
      "Epoch 161/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7159 - val_loss: 0.5793\n",
      "Epoch 162/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7218 - val_loss: 0.5677\n",
      "Epoch 163/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7156 - val_loss: 0.5631\n",
      "Epoch 164/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7172 - val_loss: 0.5667\n",
      "Epoch 165/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7160 - val_loss: 0.5608\n",
      "Epoch 166/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7225 - val_loss: 0.5720\n",
      "Epoch 167/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7184 - val_loss: 0.5677\n",
      "Epoch 168/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7149 - val_loss: 0.5666\n",
      "Epoch 169/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7133 - val_loss: 0.6075\n",
      "Epoch 170/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7157 - val_loss: 0.5749\n",
      "Epoch 171/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7211 - val_loss: 0.5851\n",
      "Epoch 172/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.7151 - val_loss: 0.5833\n",
      "Epoch 173/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7152 - val_loss: 0.5646\n",
      "Epoch 174/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7127 - val_loss: 0.5637\n",
      "Epoch 175/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7144 - val_loss: 0.5674\n",
      "Epoch 176/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7174 - val_loss: 0.5639\n",
      "Epoch 177/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7171 - val_loss: 0.5693\n",
      "Epoch 178/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7135 - val_loss: 0.5681\n",
      "Epoch 179/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7169 - val_loss: 0.5708\n",
      "Epoch 180/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7152 - val_loss: 0.5697\n",
      "Epoch 181/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7117 - val_loss: 0.5655\n",
      "Epoch 182/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7146 - val_loss: 0.5770\n",
      "Epoch 183/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7157 - val_loss: 0.5634\n",
      "Epoch 184/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 0.7167 - val_loss: 0.5618\n",
      "Epoch 185/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7094 - val_loss: 0.5719\n",
      "Epoch 186/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7123 - val_loss: 0.5674\n",
      "Epoch 187/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.7141 - val_loss: 0.5658\n",
      "Epoch 188/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7155 - val_loss: 0.5728\n",
      "Epoch 189/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7130 - val_loss: 0.5665\n",
      "Epoch 190/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7172 - val_loss: 0.5617\n",
      "Epoch 191/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7104 - val_loss: 0.5695\n",
      "Epoch 192/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7167 - val_loss: 0.5666\n",
      "Epoch 193/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7140 - val_loss: 0.5818\n",
      "Epoch 194/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7160 - val_loss: 0.5655\n",
      "Epoch 195/300\n",
      "72/73 [============================>.] - ETA: 0s - loss: 0.7108Restoring model weights from the end of the best epoch: 165.\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7125 - val_loss: 0.5671\n",
      "Epoch 195: early stopping\n",
      "'########################################################Model4\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 3s 23ms/step - loss: 1.6107 - val_loss: 1.1795\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 1.2477 - val_loss: 0.9562\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 1.0071 - val_loss: 0.7525\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.8593 - val_loss: 0.6652\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.8211 - val_loss: 0.6520\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.8068 - val_loss: 0.6446\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 0.7973 - val_loss: 0.6346\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 0.7924 - val_loss: 0.6353\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7887 - val_loss: 0.6440\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7819 - val_loss: 0.6181\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7807 - val_loss: 0.6253\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7786 - val_loss: 0.6320\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7767 - val_loss: 0.6150\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7738 - val_loss: 0.6032\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7725 - val_loss: 0.6229\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7735 - val_loss: 0.6162\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7699 - val_loss: 0.6104\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7687 - val_loss: 0.6251\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7698 - val_loss: 0.6048\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7660 - val_loss: 0.6024\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7658 - val_loss: 0.6054\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7608 - val_loss: 0.6252\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7636 - val_loss: 0.6054\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.7624 - val_loss: 0.6079\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7634 - val_loss: 0.5946\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7598 - val_loss: 0.5977\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7583 - val_loss: 0.6014\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7615 - val_loss: 0.5961\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7556 - val_loss: 0.5926\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7533 - val_loss: 0.5877\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 0.7517 - val_loss: 0.5938\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7516 - val_loss: 0.6002\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7505 - val_loss: 0.5949\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7476 - val_loss: 0.5867\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7493 - val_loss: 0.5869\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7473 - val_loss: 0.5882\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7476 - val_loss: 0.5924\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7469 - val_loss: 0.5818\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7457 - val_loss: 0.5858\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7430 - val_loss: 0.5818\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.7423 - val_loss: 0.5899\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7437 - val_loss: 0.5798\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7395 - val_loss: 0.5841\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7365 - val_loss: 0.5858\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7361 - val_loss: 0.5864\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7389 - val_loss: 0.5930\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7385 - val_loss: 0.5884\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7365 - val_loss: 0.5914\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7389 - val_loss: 0.5862\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7350 - val_loss: 0.5796\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7367 - val_loss: 0.5776\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7315 - val_loss: 0.5791\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.7298 - val_loss: 0.5810\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7349 - val_loss: 0.5794\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7310 - val_loss: 0.5819\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 0.7340 - val_loss: 0.5832\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7309 - val_loss: 0.5721\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7329 - val_loss: 0.5787\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7303 - val_loss: 0.5855\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7312 - val_loss: 0.5858\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7315 - val_loss: 0.5767\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7318 - val_loss: 0.5763\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7287 - val_loss: 0.5788\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7250 - val_loss: 0.5847\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7258 - val_loss: 0.5768\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7308 - val_loss: 0.6259\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7359 - val_loss: 0.5968\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7310 - val_loss: 0.5808\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7278 - val_loss: 0.5749\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7237 - val_loss: 0.5665\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7261 - val_loss: 0.5780\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7297 - val_loss: 0.5856\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 0.7247 - val_loss: 0.5910\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 0.7279 - val_loss: 0.5759\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7226 - val_loss: 0.5944\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7250 - val_loss: 0.5695\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7221 - val_loss: 0.5796\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7236 - val_loss: 0.5671\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7208 - val_loss: 0.5807\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7279 - val_loss: 0.5704\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7241 - val_loss: 0.5665\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7223 - val_loss: 0.5692\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7274 - val_loss: 0.5741\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7234 - val_loss: 0.5892\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7196 - val_loss: 0.5685\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7251 - val_loss: 0.5765\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7201 - val_loss: 0.5686\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7211 - val_loss: 0.5687\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7234 - val_loss: 0.5696\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 0.7209 - val_loss: 0.5690\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7187 - val_loss: 0.5733\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7209 - val_loss: 0.5910\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7236 - val_loss: 0.5645\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7259 - val_loss: 0.5655\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7205 - val_loss: 0.5703\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7188 - val_loss: 0.5792\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7192 - val_loss: 0.5681\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7175 - val_loss: 0.5672\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7201 - val_loss: 0.5759\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7235 - val_loss: 0.5693\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7200 - val_loss: 0.5734\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7178 - val_loss: 0.5688\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7172 - val_loss: 0.5859\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7169 - val_loss: 0.5707\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7226 - val_loss: 0.5737\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7245 - val_loss: 0.5689\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.7178 - val_loss: 0.5640\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7286 - val_loss: 0.5641\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7176 - val_loss: 0.5674\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7202 - val_loss: 0.5671\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7167 - val_loss: 0.5668\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7154 - val_loss: 0.5680\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7237 - val_loss: 0.5998\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7196 - val_loss: 0.5701\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7219 - val_loss: 0.5672\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7179 - val_loss: 0.5641\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7180 - val_loss: 0.5659\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7184 - val_loss: 0.5671\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 0.7186 - val_loss: 0.5710\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7182 - val_loss: 0.5686\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7172 - val_loss: 0.5659\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7195 - val_loss: 0.6288\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7249 - val_loss: 0.5627\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7141 - val_loss: 0.5650\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7198 - val_loss: 0.5886\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7220 - val_loss: 0.5680\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7177 - val_loss: 0.5618\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7224 - val_loss: 0.5657\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7207 - val_loss: 0.5750\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7194 - val_loss: 0.5703\n",
      "Epoch 131/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7179 - val_loss: 0.5736\n",
      "Epoch 132/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7228 - val_loss: 0.5716\n",
      "Epoch 133/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7199 - val_loss: 0.5729\n",
      "Epoch 134/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7208 - val_loss: 0.5773\n",
      "Epoch 135/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7173 - val_loss: 0.5670\n",
      "Epoch 136/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7152 - val_loss: 0.5726\n",
      "Epoch 137/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7178 - val_loss: 0.5678\n",
      "Epoch 138/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7169 - val_loss: 0.5697\n",
      "Epoch 139/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7202 - val_loss: 0.5822\n",
      "Epoch 140/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7143 - val_loss: 0.5742\n",
      "Epoch 141/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7161 - val_loss: 0.5672\n",
      "Epoch 142/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7193 - val_loss: 0.5646\n",
      "Epoch 143/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7188 - val_loss: 0.5679\n",
      "Epoch 144/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7156 - val_loss: 0.5703\n",
      "Epoch 145/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7218 - val_loss: 0.5655\n",
      "Epoch 146/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7125 - val_loss: 0.5674\n",
      "Epoch 147/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7181 - val_loss: 0.5811\n",
      "Epoch 148/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7223 - val_loss: 0.5692\n",
      "Epoch 149/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7206 - val_loss: 0.5651\n",
      "Epoch 150/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7147 - val_loss: 0.5860\n",
      "Epoch 151/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7145 - val_loss: 0.5705\n",
      "Epoch 152/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7208 - val_loss: 0.5848\n",
      "Epoch 153/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.7201 - val_loss: 0.5613\n",
      "Epoch 154/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7208 - val_loss: 0.5643\n",
      "Epoch 155/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7184 - val_loss: 0.5658\n",
      "Epoch 156/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7183 - val_loss: 0.5784\n",
      "Epoch 157/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7183 - val_loss: 0.5680\n",
      "Epoch 158/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7189 - val_loss: 0.5613\n",
      "Epoch 159/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7130 - val_loss: 0.5670\n",
      "Epoch 160/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7160 - val_loss: 0.5723\n",
      "Epoch 161/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7154 - val_loss: 0.5646\n",
      "Epoch 162/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7175 - val_loss: 0.5610\n",
      "Epoch 163/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7127 - val_loss: 0.5651\n",
      "Epoch 164/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7135 - val_loss: 0.5714\n",
      "Epoch 165/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7142 - val_loss: 0.5706\n",
      "Epoch 166/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7186 - val_loss: 0.5717\n",
      "Epoch 167/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7205 - val_loss: 0.5798\n",
      "Epoch 168/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7163 - val_loss: 0.5666\n",
      "Epoch 169/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7146 - val_loss: 0.5660\n",
      "Epoch 170/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7197 - val_loss: 0.5656\n",
      "Epoch 171/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7161 - val_loss: 0.5699\n",
      "Epoch 172/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7197 - val_loss: 0.5680\n",
      "Epoch 173/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7135 - val_loss: 0.5644\n",
      "Epoch 174/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7136 - val_loss: 0.5665\n",
      "Epoch 175/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7116 - val_loss: 0.5614\n",
      "Epoch 176/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7163 - val_loss: 0.5861\n",
      "Epoch 177/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7176 - val_loss: 0.5655\n",
      "Epoch 178/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7169 - val_loss: 0.5677\n",
      "Epoch 179/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7156 - val_loss: 0.5608\n",
      "Epoch 180/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.7171 - val_loss: 0.5632\n",
      "Epoch 181/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7178 - val_loss: 0.5672\n",
      "Epoch 182/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7155 - val_loss: 0.5633\n",
      "Epoch 183/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7129 - val_loss: 0.5661\n",
      "Epoch 184/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7133 - val_loss: 0.5634\n",
      "Epoch 185/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7120 - val_loss: 0.5614\n",
      "Epoch 186/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7149 - val_loss: 0.5627\n",
      "Epoch 187/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7122 - val_loss: 0.5719\n",
      "Epoch 188/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7148 - val_loss: 0.5672\n",
      "Epoch 189/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7141 - val_loss: 0.5747\n",
      "Epoch 190/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7136 - val_loss: 0.5682\n",
      "Epoch 191/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7133 - val_loss: 0.5620\n",
      "Epoch 192/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7146 - val_loss: 0.5679\n",
      "Epoch 193/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7148 - val_loss: 0.5685\n",
      "Epoch 194/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7104 - val_loss: 0.5625\n",
      "Epoch 195/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7169 - val_loss: 0.5829\n",
      "Epoch 196/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7121 - val_loss: 0.5614\n",
      "Epoch 197/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7108 - val_loss: 0.5714\n",
      "Epoch 198/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7158 - val_loss: 0.5700\n",
      "Epoch 199/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7159 - val_loss: 0.5778\n",
      "Epoch 200/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.7165 - val_loss: 0.5641\n",
      "Epoch 201/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7116 - val_loss: 0.5658\n",
      "Epoch 202/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7152 - val_loss: 0.5683\n",
      "Epoch 203/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7095 - val_loss: 0.5616\n",
      "Epoch 204/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7110 - val_loss: 0.5878\n",
      "Epoch 205/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7130 - val_loss: 0.5760\n",
      "Epoch 206/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7161 - val_loss: 0.5635\n",
      "Epoch 207/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7176 - val_loss: 0.5680\n",
      "Epoch 208/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7156 - val_loss: 0.5726\n",
      "Epoch 209/300\n",
      "71/73 [============================>.] - ETA: 0s - loss: 0.7167Restoring model weights from the end of the best epoch: 179.\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7171 - val_loss: 0.5663\n",
      "Epoch 209: early stopping\n",
      "'########################################################Model5\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 3s 23ms/step - loss: 1.7252 - val_loss: 1.2817\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 1.3638 - val_loss: 1.0570\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 1.1233 - val_loss: 0.8548\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.9410 - val_loss: 0.7305\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.8559 - val_loss: 0.6876\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.8300 - val_loss: 0.6493\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.8175 - val_loss: 0.6473\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.8091 - val_loss: 0.6505\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 0.8088 - val_loss: 0.6488\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.8050 - val_loss: 0.6494\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7983 - val_loss: 0.6323\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.8006 - val_loss: 0.6298\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 0.7952 - val_loss: 0.6422\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7954 - val_loss: 0.6436\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7937 - val_loss: 0.6531\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7913 - val_loss: 0.6385\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7900 - val_loss: 0.6315\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7932 - val_loss: 0.6223\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7860 - val_loss: 0.6215\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7864 - val_loss: 0.6223\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7805 - val_loss: 0.6193\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7782 - val_loss: 0.6245\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7778 - val_loss: 0.6235\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7749 - val_loss: 0.6105\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7719 - val_loss: 0.6195\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7703 - val_loss: 0.6160\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7678 - val_loss: 0.6116\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7691 - val_loss: 0.6248\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7677 - val_loss: 0.6211\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7632 - val_loss: 0.6032\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7628 - val_loss: 0.6032\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7610 - val_loss: 0.5994\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7597 - val_loss: 0.6061\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7598 - val_loss: 0.6010\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7613 - val_loss: 0.6109\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7594 - val_loss: 0.6000\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.7568 - val_loss: 0.5944\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7573 - val_loss: 0.5928\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7575 - val_loss: 0.6010\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7541 - val_loss: 0.5976\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 0.7524 - val_loss: 0.5864\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 0.7544 - val_loss: 0.5968\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7522 - val_loss: 0.5828\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7488 - val_loss: 0.5898\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7480 - val_loss: 0.5892\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7501 - val_loss: 0.6018\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7466 - val_loss: 0.6080\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7515 - val_loss: 0.5882\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7460 - val_loss: 0.5953\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7471 - val_loss: 0.6013\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7431 - val_loss: 0.5841\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7439 - val_loss: 0.5903\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7419 - val_loss: 0.5814\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7412 - val_loss: 0.6155\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7461 - val_loss: 0.5801\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7423 - val_loss: 0.5802\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7449 - val_loss: 0.5979\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7492 - val_loss: 0.6005\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7497 - val_loss: 0.5984\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7484 - val_loss: 0.5816\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7400 - val_loss: 0.6085\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7484 - val_loss: 0.6005\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7415 - val_loss: 0.5879\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7443 - val_loss: 0.5829\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7417 - val_loss: 0.5899\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7400 - val_loss: 0.5824\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7406 - val_loss: 0.5856\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7401 - val_loss: 0.5814\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7387 - val_loss: 0.6010\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.7373 - val_loss: 0.5755\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7392 - val_loss: 0.5808\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7382 - val_loss: 0.5844\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7392 - val_loss: 0.5794\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7427 - val_loss: 0.5747\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7378 - val_loss: 0.5801\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7379 - val_loss: 0.5778\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7372 - val_loss: 0.5906\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7362 - val_loss: 0.5820\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7370 - val_loss: 0.5843\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7377 - val_loss: 0.5739\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7361 - val_loss: 0.5790\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7374 - val_loss: 0.5918\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7359 - val_loss: 0.5865\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7404 - val_loss: 0.5803\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7355 - val_loss: 0.5878\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7353 - val_loss: 0.5882\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7315 - val_loss: 0.5757\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7371 - val_loss: 0.5789\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7320 - val_loss: 0.5784\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7330 - val_loss: 0.6185\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7352 - val_loss: 0.5794\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7298 - val_loss: 0.5855\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7312 - val_loss: 0.5768\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7330 - val_loss: 0.6055\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7373 - val_loss: 0.5801\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7355 - val_loss: 0.5807\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7294 - val_loss: 0.5747\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7291 - val_loss: 0.5759\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7371 - val_loss: 0.5822\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7327 - val_loss: 0.5818\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7316 - val_loss: 0.5760\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7279 - val_loss: 0.5733\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7317 - val_loss: 0.5751\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7297 - val_loss: 0.5754\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 0.7271 - val_loss: 0.5721\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7337 - val_loss: 0.5756\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7361 - val_loss: 0.5794\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 0.7270 - val_loss: 0.5749\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 0.7290 - val_loss: 0.5771\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7270 - val_loss: 0.5752\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7280 - val_loss: 0.5832\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7257 - val_loss: 0.5777\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7263 - val_loss: 0.5813\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7282 - val_loss: 0.5759\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7289 - val_loss: 0.5938\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7281 - val_loss: 0.5776\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7232 - val_loss: 0.5745\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7293 - val_loss: 0.5789\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7236 - val_loss: 0.5721\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7239 - val_loss: 0.5784\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7220 - val_loss: 0.5812\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7246 - val_loss: 0.6068\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7297 - val_loss: 0.5755\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7207 - val_loss: 0.5765\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7208 - val_loss: 0.5755\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7219 - val_loss: 0.5802\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7236 - val_loss: 0.5780\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7189 - val_loss: 0.5882\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7238 - val_loss: 0.5824\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7230 - val_loss: 0.5767\n",
      "Epoch 131/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7205 - val_loss: 0.5772\n",
      "Epoch 132/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7191 - val_loss: 0.5848\n",
      "Epoch 133/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7223 - val_loss: 0.6059\n",
      "Epoch 134/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7256 - val_loss: 0.5723\n",
      "Epoch 135/300\n",
      "71/73 [============================>.] - ETA: 0s - loss: 0.7232Restoring model weights from the end of the best epoch: 105.\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7236 - val_loss: 0.5802\n",
      "Epoch 135: early stopping\n",
      "'########################################################Model6\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 3s 23ms/step - loss: 1.4785 - val_loss: 1.1105\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 1.1805 - val_loss: 0.9119\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.9743 - val_loss: 0.7537\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.8670 - val_loss: 0.6936\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.8404 - val_loss: 0.6662\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.8228 - val_loss: 0.6567\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.8166 - val_loss: 0.6530\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.8109 - val_loss: 0.6522\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.8050 - val_loss: 0.6437\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.8016 - val_loss: 0.6445\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7990 - val_loss: 0.6407\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7971 - val_loss: 0.6347\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7939 - val_loss: 0.6311\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7936 - val_loss: 0.6324\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7910 - val_loss: 0.6244\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7899 - val_loss: 0.6328\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.7878 - val_loss: 0.6301\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7870 - val_loss: 0.6285\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7866 - val_loss: 0.6299\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7861 - val_loss: 0.6280\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7841 - val_loss: 0.6198\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7816 - val_loss: 0.6236\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7803 - val_loss: 0.6162\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7784 - val_loss: 0.6165\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7774 - val_loss: 0.6184\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7763 - val_loss: 0.6340\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7752 - val_loss: 0.6223\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7728 - val_loss: 0.6140\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7731 - val_loss: 0.6048\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7693 - val_loss: 0.6051\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7654 - val_loss: 0.6063\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7664 - val_loss: 0.6424\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7645 - val_loss: 0.6156\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7634 - val_loss: 0.6114\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7640 - val_loss: 0.5961\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7556 - val_loss: 0.6165\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7564 - val_loss: 0.6028\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7546 - val_loss: 0.5975\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7561 - val_loss: 0.6129\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7522 - val_loss: 0.6026\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7560 - val_loss: 0.5939\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7498 - val_loss: 0.6080\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7536 - val_loss: 0.5970\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7525 - val_loss: 0.5916\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7472 - val_loss: 0.5896\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7464 - val_loss: 0.6004\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7466 - val_loss: 0.5907\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7432 - val_loss: 0.5840\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.7421 - val_loss: 0.5882\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7413 - val_loss: 0.5911\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7441 - val_loss: 0.5866\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7401 - val_loss: 0.6006\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7467 - val_loss: 0.5808\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7403 - val_loss: 0.5992\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7404 - val_loss: 0.5892\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 0.7416 - val_loss: 0.5772\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7439 - val_loss: 0.5807\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7364 - val_loss: 0.5863\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7351 - val_loss: 0.5872\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 0.7401 - val_loss: 0.5834\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7373 - val_loss: 0.5762\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7395 - val_loss: 0.5780\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 0.7373 - val_loss: 0.5737\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7362 - val_loss: 0.5767\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7342 - val_loss: 0.5786\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7358 - val_loss: 0.5886\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.7333 - val_loss: 0.5750\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7427 - val_loss: 0.6029\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7381 - val_loss: 0.5773\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7326 - val_loss: 0.5745\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 0.7328 - val_loss: 0.5805\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 0.7352 - val_loss: 0.5813\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7361 - val_loss: 0.5808\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7344 - val_loss: 0.5737\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7407 - val_loss: 0.5758\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.7395 - val_loss: 0.5802\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7327 - val_loss: 0.5764\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7327 - val_loss: 0.6003\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 0.7378 - val_loss: 0.5829\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7343 - val_loss: 0.5938\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7315 - val_loss: 0.5968\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7341 - val_loss: 0.5762\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7327 - val_loss: 0.5803\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7289 - val_loss: 0.5786\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7365 - val_loss: 0.6130\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 0.7329 - val_loss: 0.5719\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.7301 - val_loss: 0.5744\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7342 - val_loss: 0.5769\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7356 - val_loss: 0.5753\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7305 - val_loss: 0.5766\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7310 - val_loss: 0.5771\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7333 - val_loss: 0.5813\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7331 - val_loss: 0.5738\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.7316 - val_loss: 0.5730\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7273 - val_loss: 0.5862\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7346 - val_loss: 0.5719\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7274 - val_loss: 0.5698\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 0.7321 - val_loss: 0.5736\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7331 - val_loss: 0.6013\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7311 - val_loss: 0.5913\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 0.7322 - val_loss: 0.5851\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7322 - val_loss: 0.5699\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7286 - val_loss: 0.5862\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7319 - val_loss: 0.5733\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7272 - val_loss: 0.5867\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 0.7316 - val_loss: 0.5724\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7276 - val_loss: 0.5742\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7334 - val_loss: 0.5682\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 0.7282 - val_loss: 0.5870\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 0.7289 - val_loss: 0.5887\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7273 - val_loss: 0.5793\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7298 - val_loss: 0.6103\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7321 - val_loss: 0.5669\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 0.7280 - val_loss: 0.5753\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7293 - val_loss: 0.5913\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7267 - val_loss: 0.5773\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.7265 - val_loss: 0.5723\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7278 - val_loss: 0.5836\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7273 - val_loss: 0.5692\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7322 - val_loss: 0.5754\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 0.7299 - val_loss: 0.5671\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7248 - val_loss: 0.5728\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7269 - val_loss: 0.5844\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.7270 - val_loss: 0.5680\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7274 - val_loss: 0.5718\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7248 - val_loss: 0.5781\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7242 - val_loss: 0.5681\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7260 - val_loss: 0.5709\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7272 - val_loss: 0.5720\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.7255 - val_loss: 0.5944\n",
      "Epoch 131/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7260 - val_loss: 0.5670\n",
      "Epoch 132/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7266 - val_loss: 0.5884\n",
      "Epoch 133/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7255 - val_loss: 0.5698\n",
      "Epoch 134/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 0.7257 - val_loss: 0.5742\n",
      "Epoch 135/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.7276 - val_loss: 0.5732\n",
      "Epoch 136/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7243 - val_loss: 0.5648\n",
      "Epoch 137/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7235 - val_loss: 0.5703\n",
      "Epoch 138/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7208 - val_loss: 0.5804\n",
      "Epoch 139/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7258 - val_loss: 0.5650\n",
      "Epoch 140/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7273 - val_loss: 0.5720\n",
      "Epoch 141/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 0.7246 - val_loss: 0.5885\n",
      "Epoch 142/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7285 - val_loss: 0.5686\n",
      "Epoch 143/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7310 - val_loss: 0.5648\n",
      "Epoch 144/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 0.7244 - val_loss: 0.5786\n",
      "Epoch 145/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7233 - val_loss: 0.5703\n",
      "Epoch 146/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7231 - val_loss: 0.5644\n",
      "Epoch 147/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7213 - val_loss: 0.5668\n",
      "Epoch 148/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7217 - val_loss: 0.5866\n",
      "Epoch 149/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7225 - val_loss: 0.5860\n",
      "Epoch 150/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7221 - val_loss: 0.5723\n",
      "Epoch 151/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7247 - val_loss: 0.5664\n",
      "Epoch 152/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7254 - val_loss: 0.5734\n",
      "Epoch 153/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.7200 - val_loss: 0.5727\n",
      "Epoch 154/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7191 - val_loss: 0.5759\n",
      "Epoch 155/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7249 - val_loss: 0.5661\n",
      "Epoch 156/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7255 - val_loss: 0.5699\n",
      "Epoch 157/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 0.7264 - val_loss: 0.5628\n",
      "Epoch 158/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7197 - val_loss: 0.5750\n",
      "Epoch 159/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7269 - val_loss: 0.5705\n",
      "Epoch 160/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 0.7256 - val_loss: 0.5828\n",
      "Epoch 161/300\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 0.7224 - val_loss: 0.5688\n",
      "Epoch 162/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7182 - val_loss: 0.5619\n",
      "Epoch 163/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7177 - val_loss: 0.5666\n",
      "Epoch 164/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7189 - val_loss: 0.5634\n",
      "Epoch 165/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7194 - val_loss: 0.5665\n",
      "Epoch 166/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7228 - val_loss: 0.5608\n",
      "Epoch 167/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 0.7189 - val_loss: 0.5606\n",
      "Epoch 168/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7197 - val_loss: 0.5637\n",
      "Epoch 169/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7148 - val_loss: 0.5629\n",
      "Epoch 170/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 0.7184 - val_loss: 0.5675\n",
      "Epoch 171/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7219 - val_loss: 0.5684\n",
      "Epoch 172/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7191 - val_loss: 0.5715\n",
      "Epoch 173/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7175 - val_loss: 0.5702\n",
      "Epoch 174/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7178 - val_loss: 0.5700\n",
      "Epoch 175/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7152 - val_loss: 0.5722\n",
      "Epoch 176/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7190 - val_loss: 0.5669\n",
      "Epoch 177/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7146 - val_loss: 0.5665\n",
      "Epoch 178/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7267 - val_loss: 0.5826\n",
      "Epoch 179/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.7201 - val_loss: 0.5603\n",
      "Epoch 180/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7175 - val_loss: 0.5703\n",
      "Epoch 181/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7203 - val_loss: 0.5872\n",
      "Epoch 182/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7185 - val_loss: 0.5686\n",
      "Epoch 183/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7120 - val_loss: 0.5701\n",
      "Epoch 184/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7150 - val_loss: 0.5633\n",
      "Epoch 185/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7141 - val_loss: 0.5679\n",
      "Epoch 186/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7173 - val_loss: 0.5789\n",
      "Epoch 187/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.7176 - val_loss: 0.5880\n",
      "Epoch 188/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7210 - val_loss: 0.5666\n",
      "Epoch 189/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7147 - val_loss: 0.5645\n",
      "Epoch 190/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 0.7108 - val_loss: 0.5648\n",
      "Epoch 191/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7108 - val_loss: 0.5671\n",
      "Epoch 192/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7196 - val_loss: 0.5842\n",
      "Epoch 193/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7174 - val_loss: 0.5686\n",
      "Epoch 194/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7163 - val_loss: 0.5781\n",
      "Epoch 195/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7184 - val_loss: 0.5696\n",
      "Epoch 196/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 0.7157 - val_loss: 0.5757\n",
      "Epoch 197/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7162 - val_loss: 0.5621\n",
      "Epoch 198/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7150 - val_loss: 0.5654\n",
      "Epoch 199/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.7127 - val_loss: 0.5617\n",
      "Epoch 200/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7118 - val_loss: 0.5730\n",
      "Epoch 201/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7146 - val_loss: 0.5656\n",
      "Epoch 202/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7108 - val_loss: 0.5643\n",
      "Epoch 203/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 0.7098 - val_loss: 0.5642\n",
      "Epoch 204/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7134 - val_loss: 0.5846\n",
      "Epoch 205/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7123 - val_loss: 0.5694\n",
      "Epoch 206/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 0.7113 - val_loss: 0.5753\n",
      "Epoch 207/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7185 - val_loss: 0.5641\n",
      "Epoch 208/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7096 - val_loss: 0.5755\n",
      "Epoch 209/300\n",
      "73/73 [==============================] - ETA: 0s - loss: 0.7114Restoring model weights from the end of the best epoch: 179.\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7114 - val_loss: 0.5736\n",
      "Epoch 209: early stopping\n",
      "'########################################################Model7\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 3s 24ms/step - loss: 1.3356 - val_loss: 1.0196\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 1.1066 - val_loss: 0.8668\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.9371 - val_loss: 0.7340\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.8610 - val_loss: 0.6874\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.8336 - val_loss: 0.6651\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.8201 - val_loss: 0.6513\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.8092 - val_loss: 0.6580\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 0.8057 - val_loss: 0.6434\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.8007 - val_loss: 0.6361\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7980 - val_loss: 0.6366\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7962 - val_loss: 0.6340\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7925 - val_loss: 0.6325\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7945 - val_loss: 0.6260\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7927 - val_loss: 0.6263\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7913 - val_loss: 0.6265\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7907 - val_loss: 0.6239\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7889 - val_loss: 0.6350\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7891 - val_loss: 0.6379\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7873 - val_loss: 0.6361\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7853 - val_loss: 0.6174\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7847 - val_loss: 0.6339\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7811 - val_loss: 0.6274\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7779 - val_loss: 0.6095\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7741 - val_loss: 0.6122\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7714 - val_loss: 0.6166\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7651 - val_loss: 0.6015\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7656 - val_loss: 0.6108\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7651 - val_loss: 0.6089\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7608 - val_loss: 0.5972\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.7601 - val_loss: 0.5987\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7578 - val_loss: 0.6073\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7549 - val_loss: 0.6115\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 0.7555 - val_loss: 0.5991\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 0.7529 - val_loss: 0.6002\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7478 - val_loss: 0.5882\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7487 - val_loss: 0.5845\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7472 - val_loss: 0.5903\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7471 - val_loss: 0.5867\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7440 - val_loss: 0.5936\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7442 - val_loss: 0.6003\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7457 - val_loss: 0.5963\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7442 - val_loss: 0.5877\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7419 - val_loss: 0.5826\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7402 - val_loss: 0.5837\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7404 - val_loss: 0.5837\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7371 - val_loss: 0.5976\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7452 - val_loss: 0.5906\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7347 - val_loss: 0.5776\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7354 - val_loss: 0.5858\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7368 - val_loss: 0.5782\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7348 - val_loss: 0.6055\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7352 - val_loss: 0.5854\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7322 - val_loss: 0.5849\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7374 - val_loss: 0.5825\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7309 - val_loss: 0.5951\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7344 - val_loss: 0.5863\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7366 - val_loss: 0.5768\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7349 - val_loss: 0.5887\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7394 - val_loss: 0.5828\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7331 - val_loss: 0.5762\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.7309 - val_loss: 0.5830\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7322 - val_loss: 0.5793\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7331 - val_loss: 0.5773\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7375 - val_loss: 0.5740\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7287 - val_loss: 0.5795\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7281 - val_loss: 0.5867\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7296 - val_loss: 0.5783\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7274 - val_loss: 0.5807\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7288 - val_loss: 0.5748\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7261 - val_loss: 0.6030\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7278 - val_loss: 0.5808\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7357 - val_loss: 0.5796\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7264 - val_loss: 0.5717\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7298 - val_loss: 0.5852\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7273 - val_loss: 0.5757\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7268 - val_loss: 0.5808\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7270 - val_loss: 0.5759\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 0.7274 - val_loss: 0.6100\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7289 - val_loss: 0.5854\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7299 - val_loss: 0.5750\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 0.7233 - val_loss: 0.5722\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7227 - val_loss: 0.5756\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7262 - val_loss: 0.5735\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7322 - val_loss: 0.5775\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7227 - val_loss: 0.5829\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7216 - val_loss: 0.5762\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7244 - val_loss: 0.5762\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7275 - val_loss: 0.5750\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7224 - val_loss: 0.5716\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7210 - val_loss: 0.5845\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7244 - val_loss: 0.5877\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7251 - val_loss: 0.5724\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7198 - val_loss: 0.5753\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7226 - val_loss: 0.5744\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7192 - val_loss: 0.5734\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7199 - val_loss: 0.5785\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7223 - val_loss: 0.5736\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7198 - val_loss: 0.5744\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7197 - val_loss: 0.5775\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.7204 - val_loss: 0.5888\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7229 - val_loss: 0.5896\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7249 - val_loss: 0.5731\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 0.7197 - val_loss: 0.5856\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7215 - val_loss: 0.5675\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7178 - val_loss: 0.5786\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7144 - val_loss: 0.5806\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7187 - val_loss: 0.5729\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7216 - val_loss: 0.5694\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7178 - val_loss: 0.5766\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7181 - val_loss: 0.5901\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7211 - val_loss: 0.5727\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7227 - val_loss: 0.5802\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7199 - val_loss: 0.5706\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7199 - val_loss: 0.5717\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7123 - val_loss: 0.5720\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7199 - val_loss: 0.5689\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7172 - val_loss: 0.5742\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7159 - val_loss: 0.5739\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7277 - val_loss: 0.5800\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7220 - val_loss: 0.5919\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7236 - val_loss: 0.5823\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7155 - val_loss: 0.5669\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7150 - val_loss: 0.5695\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7166 - val_loss: 0.5688\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7178 - val_loss: 0.5698\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7215 - val_loss: 0.5727\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7206 - val_loss: 0.5762\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7153 - val_loss: 0.5724\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.7132 - val_loss: 0.5817\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7175 - val_loss: 0.5783\n",
      "Epoch 131/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7159 - val_loss: 0.5809\n",
      "Epoch 132/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7169 - val_loss: 0.5719\n",
      "Epoch 133/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7181 - val_loss: 0.5741\n",
      "Epoch 134/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7178 - val_loss: 0.5657\n",
      "Epoch 135/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7124 - val_loss: 0.5719\n",
      "Epoch 136/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7119 - val_loss: 0.5749\n",
      "Epoch 137/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7125 - val_loss: 0.5679\n",
      "Epoch 138/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7120 - val_loss: 0.5723\n",
      "Epoch 139/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7131 - val_loss: 0.5800\n",
      "Epoch 140/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7175 - val_loss: 0.5768\n",
      "Epoch 141/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7120 - val_loss: 0.5698\n",
      "Epoch 142/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7169 - val_loss: 0.5670\n",
      "Epoch 143/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7191 - val_loss: 0.5877\n",
      "Epoch 144/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7150 - val_loss: 0.5714\n",
      "Epoch 145/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7218 - val_loss: 0.5777\n",
      "Epoch 146/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 0.7134 - val_loss: 0.5708\n",
      "Epoch 147/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7125 - val_loss: 0.5720\n",
      "Epoch 148/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7102 - val_loss: 0.5689\n",
      "Epoch 149/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7151 - val_loss: 0.5687\n",
      "Epoch 150/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7111 - val_loss: 0.5764\n",
      "Epoch 151/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7121 - val_loss: 0.5762\n",
      "Epoch 152/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7195 - val_loss: 0.5952\n",
      "Epoch 153/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7160 - val_loss: 0.5799\n",
      "Epoch 154/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7117 - val_loss: 0.5669\n",
      "Epoch 155/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7093 - val_loss: 0.5698\n",
      "Epoch 156/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7094 - val_loss: 0.5709\n",
      "Epoch 157/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7128 - val_loss: 0.5716\n",
      "Epoch 158/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7129 - val_loss: 0.5722\n",
      "Epoch 159/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7152 - val_loss: 0.5759\n",
      "Epoch 160/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7103 - val_loss: 0.5638\n",
      "Epoch 161/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7094 - val_loss: 0.5658\n",
      "Epoch 162/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7094 - val_loss: 0.5812\n",
      "Epoch 163/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7099 - val_loss: 0.5665\n",
      "Epoch 164/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7104 - val_loss: 0.5670\n",
      "Epoch 165/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7121 - val_loss: 0.5942\n",
      "Epoch 166/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7116 - val_loss: 0.5724\n",
      "Epoch 167/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7094 - val_loss: 0.5765\n",
      "Epoch 168/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7112 - val_loss: 0.5732\n",
      "Epoch 169/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7093 - val_loss: 0.5713\n",
      "Epoch 170/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7085 - val_loss: 0.5812\n",
      "Epoch 171/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7170 - val_loss: 0.5714\n",
      "Epoch 172/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7163 - val_loss: 0.5877\n",
      "Epoch 173/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7131 - val_loss: 0.5713\n",
      "Epoch 174/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7091 - val_loss: 0.5735\n",
      "Epoch 175/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7135 - val_loss: 0.5875\n",
      "Epoch 176/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7110 - val_loss: 0.5725\n",
      "Epoch 177/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7064 - val_loss: 0.5796\n",
      "Epoch 178/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7090 - val_loss: 0.5880\n",
      "Epoch 179/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7104 - val_loss: 0.5674\n",
      "Epoch 180/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7098 - val_loss: 0.5966\n",
      "Epoch 181/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7102 - val_loss: 0.5745\n",
      "Epoch 182/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.7092 - val_loss: 0.5678\n",
      "Epoch 183/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7119 - val_loss: 0.5693\n",
      "Epoch 184/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7083 - val_loss: 0.5719\n",
      "Epoch 185/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 0.7133 - val_loss: 0.5751\n",
      "Epoch 186/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7101 - val_loss: 0.5702\n",
      "Epoch 187/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7137 - val_loss: 0.5688\n",
      "Epoch 188/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7067 - val_loss: 0.5744\n",
      "Epoch 189/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7069 - val_loss: 0.5705\n",
      "Epoch 190/300\n",
      "70/73 [===========================>..] - ETA: 0s - loss: 0.7034Restoring model weights from the end of the best epoch: 160.\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7052 - val_loss: 0.5706\n",
      "Epoch 190: early stopping\n",
      "'########################################################Model8\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 3s 23ms/step - loss: 2.2491 - val_loss: 1.6204\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 1.6489 - val_loss: 1.2308\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 1.2799 - val_loss: 0.9857\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 1.0478 - val_loss: 0.8109\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.8927 - val_loss: 0.7090\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.8406 - val_loss: 0.6600\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.8235 - val_loss: 0.6673\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.8128 - val_loss: 0.6514\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.8090 - val_loss: 0.6510\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.8004 - val_loss: 0.6428\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7961 - val_loss: 0.6691\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7919 - val_loss: 0.6290\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7887 - val_loss: 0.6673\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7892 - val_loss: 0.6299\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7859 - val_loss: 0.6307\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7839 - val_loss: 0.6186\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7818 - val_loss: 0.6202\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7799 - val_loss: 0.6306\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7780 - val_loss: 0.6263\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7749 - val_loss: 0.6104\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7738 - val_loss: 0.6267\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7725 - val_loss: 0.6225\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7733 - val_loss: 0.6060\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7687 - val_loss: 0.6164\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7714 - val_loss: 0.6006\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7672 - val_loss: 0.6002\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7716 - val_loss: 0.6069\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7662 - val_loss: 0.6002\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7651 - val_loss: 0.6105\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7613 - val_loss: 0.6023\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7584 - val_loss: 0.6234\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7596 - val_loss: 0.5964\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7576 - val_loss: 0.6034\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7605 - val_loss: 0.5950\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7584 - val_loss: 0.6173\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7582 - val_loss: 0.6038\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7571 - val_loss: 0.5977\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7582 - val_loss: 0.6062\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7538 - val_loss: 0.5950\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 0.7546 - val_loss: 0.5906\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7524 - val_loss: 0.5973\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7536 - val_loss: 0.5914\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7514 - val_loss: 0.6015\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7516 - val_loss: 0.5934\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7525 - val_loss: 0.5875\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7460 - val_loss: 0.5967\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7452 - val_loss: 0.5954\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7488 - val_loss: 0.6038\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7494 - val_loss: 0.5798\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7464 - val_loss: 0.5851\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7410 - val_loss: 0.5880\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7428 - val_loss: 0.5848\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7400 - val_loss: 0.5956\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 0.7422 - val_loss: 0.5784\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7413 - val_loss: 0.5778\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7472 - val_loss: 0.5829\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 0.7399 - val_loss: 0.5993\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7546 - val_loss: 0.6151\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7424 - val_loss: 0.5854\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7385 - val_loss: 0.5839\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7390 - val_loss: 0.5760\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7364 - val_loss: 0.5740\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7373 - val_loss: 0.5768\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7408 - val_loss: 0.5815\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7434 - val_loss: 0.5839\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7364 - val_loss: 0.5828\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7355 - val_loss: 0.5994\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7343 - val_loss: 0.5758\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7399 - val_loss: 0.5912\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7341 - val_loss: 0.5896\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7381 - val_loss: 0.5837\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7378 - val_loss: 0.5739\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7381 - val_loss: 0.6187\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7366 - val_loss: 0.5909\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7336 - val_loss: 0.5716\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7352 - val_loss: 0.5887\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7357 - val_loss: 0.5725\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7349 - val_loss: 0.5865\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7293 - val_loss: 0.5719\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7325 - val_loss: 0.5741\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7361 - val_loss: 0.5863\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7303 - val_loss: 0.5785\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7322 - val_loss: 0.6029\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7359 - val_loss: 0.5733\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7298 - val_loss: 0.5805\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7345 - val_loss: 0.5770\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7287 - val_loss: 0.5790\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7357 - val_loss: 0.5782\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7339 - val_loss: 0.5859\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7356 - val_loss: 0.5794\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 0.7299 - val_loss: 0.5706\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7309 - val_loss: 0.5800\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 0.7363 - val_loss: 0.5682\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 0.7320 - val_loss: 0.5771\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7311 - val_loss: 0.5761\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7335 - val_loss: 0.5817\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7317 - val_loss: 0.5697\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7292 - val_loss: 0.5731\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7304 - val_loss: 0.5746\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7281 - val_loss: 0.5864\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7319 - val_loss: 0.5764\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7279 - val_loss: 0.5831\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7306 - val_loss: 0.5742\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7339 - val_loss: 0.5854\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7304 - val_loss: 0.5776\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7310 - val_loss: 0.5725\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7287 - val_loss: 0.5712\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7272 - val_loss: 0.5770\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7316 - val_loss: 0.5725\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7259 - val_loss: 0.5676\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7284 - val_loss: 0.5997\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7358 - val_loss: 0.5735\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7269 - val_loss: 0.5707\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7286 - val_loss: 0.5675\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7273 - val_loss: 0.5710\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7306 - val_loss: 0.5796\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7273 - val_loss: 0.5770\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7327 - val_loss: 0.5802\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7284 - val_loss: 0.5739\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7286 - val_loss: 0.5796\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7382 - val_loss: 0.5847\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7274 - val_loss: 0.5665\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7252 - val_loss: 0.5663\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7289 - val_loss: 0.5757\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7265 - val_loss: 0.5687\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7270 - val_loss: 0.5652\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7257 - val_loss: 0.5718\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7348 - val_loss: 0.5742\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7279 - val_loss: 0.5717\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7256 - val_loss: 0.5669\n",
      "Epoch 131/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7263 - val_loss: 0.5683\n",
      "Epoch 132/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7239 - val_loss: 0.5685\n",
      "Epoch 133/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7255 - val_loss: 0.5654\n",
      "Epoch 134/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7233 - val_loss: 0.5689\n",
      "Epoch 135/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7269 - val_loss: 0.5712\n",
      "Epoch 136/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7261 - val_loss: 0.5721\n",
      "Epoch 137/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7267 - val_loss: 0.5918\n",
      "Epoch 138/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7287 - val_loss: 0.5853\n",
      "Epoch 139/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7255 - val_loss: 0.5851\n",
      "Epoch 140/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7268 - val_loss: 0.5730\n",
      "Epoch 141/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7258 - val_loss: 0.5711\n",
      "Epoch 142/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7277 - val_loss: 0.5677\n",
      "Epoch 143/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7231 - val_loss: 0.5796\n",
      "Epoch 144/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7294 - val_loss: 0.5722\n",
      "Epoch 145/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7249 - val_loss: 0.5685\n",
      "Epoch 146/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7254 - val_loss: 0.5700\n",
      "Epoch 147/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7220 - val_loss: 0.5692\n",
      "Epoch 148/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7267 - val_loss: 0.5722\n",
      "Epoch 149/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7286 - val_loss: 0.5687\n",
      "Epoch 150/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7249 - val_loss: 0.5668\n",
      "Epoch 151/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7217 - val_loss: 0.5735\n",
      "Epoch 152/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7243 - val_loss: 0.5761\n",
      "Epoch 153/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7204 - val_loss: 0.5738\n",
      "Epoch 154/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7235 - val_loss: 0.5688\n",
      "Epoch 155/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7222 - val_loss: 0.6243\n",
      "Epoch 156/300\n",
      "73/73 [==============================] - ETA: 0s - loss: 0.7324Restoring model weights from the end of the best epoch: 126.\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 0.7324 - val_loss: 0.5672\n",
      "Epoch 156: early stopping\n",
      "'########################################################Model9\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 17ms/step - loss: 3859624.2500 - val_loss: 701179.2500\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 535144.0000 - val_loss: 489029.7500\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 493341.4062 - val_loss: 282286.1562\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 280728.1875 - val_loss: 488099.3125\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 360706.0625 - val_loss: 208691.1875\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 338114.0938 - val_loss: 317894.9375\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 222754.0312 - val_loss: 263795.0625\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 444208.1875 - val_loss: 159653.8281\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 247407.8594 - val_loss: 339535.1250\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 221876.1250 - val_loss: 141048.6406\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 289110.1875 - val_loss: 240200.6875\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 328315.6875 - val_loss: 541010.7500\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 239313.5000 - val_loss: 233736.1875\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 197239.2656 - val_loss: 250878.8125\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 237599.4531 - val_loss: 118390.4688\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 197620.3906 - val_loss: 174771.3594\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 205561.0781 - val_loss: 191349.7969\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 172660.6562 - val_loss: 341514.1875\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 218550.6562 - val_loss: 207553.9688\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 212191.6406 - val_loss: 160526.3281\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 274224.0625 - val_loss: 272310.9375\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 163092.9219 - val_loss: 191131.0000\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 199281.7812 - val_loss: 210384.0156\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 267926.4375 - val_loss: 315091.2500\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 232140.3750 - val_loss: 223741.1562\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 196149.8281 - val_loss: 354869.5312\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 183495.8125 - val_loss: 259771.0000\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 256343.9688 - val_loss: 395413.7188\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 177238.0000 - val_loss: 171607.3750\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 141384.0781 - val_loss: 177096.0625\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 138637.1094 - val_loss: 89179.0391\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 137727.8125 - val_loss: 120797.8750\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 213951.3438 - val_loss: 109765.8984\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 181455.9844 - val_loss: 171553.4688\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 186153.5625 - val_loss: 160246.0625\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 228838.7031 - val_loss: 121276.9922\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 156665.9375 - val_loss: 129266.4844\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 185633.1562 - val_loss: 329662.0938\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 131836.7969 - val_loss: 73652.7188\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 149552.9531 - val_loss: 122336.0000\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 278787.2500 - val_loss: 831885.0625\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 243663.6719 - val_loss: 157183.1250\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 248876.1562 - val_loss: 249012.1719\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 237217.5156 - val_loss: 149129.5156\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 232840.6719 - val_loss: 188525.8594\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 232026.9844 - val_loss: 69598.5625\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 153541.9219 - val_loss: 83114.0391\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 100641.6250 - val_loss: 59485.6211\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 190235.3594 - val_loss: 153894.5938\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 189079.7500 - val_loss: 254597.8438\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 167325.2656 - val_loss: 69610.0859\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 141176.6094 - val_loss: 219377.9375\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119269.0938 - val_loss: 225746.1875\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 212530.7969 - val_loss: 71540.1719\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 159705.8594 - val_loss: 215666.3438\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 145513.3750 - val_loss: 162050.5469\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 241429.3906 - val_loss: 486602.2188\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 146489.0156 - val_loss: 104086.8906\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 130887.7891 - val_loss: 111420.4375\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 146465.2656 - val_loss: 230508.1875\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 243204.3125 - val_loss: 93233.9375\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 90999.9766 - val_loss: 58130.1992\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 102899.5547 - val_loss: 195187.8281\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 126514.5625 - val_loss: 128600.8672\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 200645.7812 - val_loss: 297820.4375\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 151295.5156 - val_loss: 68098.8281\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 131032.0156 - val_loss: 158211.3594\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 231205.7500 - val_loss: 476676.4062\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 202540.9062 - val_loss: 183501.3281\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 214139.1562 - val_loss: 71513.2891\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 102092.8203 - val_loss: 103579.2422\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 173427.0938 - val_loss: 108844.2500\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 136273.6094 - val_loss: 70339.5938\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 198893.6562 - val_loss: 93259.4688\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 195358.4375 - val_loss: 245844.8281\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 208535.1250 - val_loss: 154116.9844\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 102711.7422 - val_loss: 149558.8281\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 117271.5703 - val_loss: 75528.1484\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 195834.3750 - val_loss: 217303.2344\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 165557.6406 - val_loss: 79711.8047\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 137881.1719 - val_loss: 58026.1641\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 137759.2188 - val_loss: 115515.3906\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 126181.7734 - val_loss: 206560.5938\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 130623.5469 - val_loss: 146978.1562\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 140591.3125 - val_loss: 82116.0078\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120070.4766 - val_loss: 364868.2500\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 211411.3750 - val_loss: 302444.8125\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 125337.3984 - val_loss: 245240.7656\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 175365.6250 - val_loss: 163966.7500\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118425.5391 - val_loss: 294939.6875\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 144109.3906 - val_loss: 179228.5469\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 177432.5781 - val_loss: 421107.3125\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123197.1250 - val_loss: 108390.6250\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 144891.2344 - val_loss: 113581.9375\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 193299.6719 - val_loss: 133871.5469\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 124888.1641 - val_loss: 96019.1641\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 74809.6953 - val_loss: 89693.5078\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 90168.4453 - val_loss: 175169.6875\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 141090.0469 - val_loss: 47872.7617\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 163054.6719 - val_loss: 269878.2500\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 199182.9688 - val_loss: 27123.9883\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 127680.4844 - val_loss: 70885.0156\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 114719.4453 - val_loss: 96590.8984\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 134063.2969 - val_loss: 58337.2422\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 124713.6641 - val_loss: 92688.7344\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 163819.9844 - val_loss: 282343.3438\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 133848.0625 - val_loss: 79397.9609\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 108957.8750 - val_loss: 156496.6094\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 129378.3281 - val_loss: 57462.1016\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 90303.7812 - val_loss: 80690.1406\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 144752.1719 - val_loss: 140940.3750\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 169957.5000 - val_loss: 203759.4688\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 182406.3125 - val_loss: 21071.2383\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 86071.5312 - val_loss: 54985.3555\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 142788.2031 - val_loss: 103638.4297\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 105686.5312 - val_loss: 130065.1328\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 111044.5859 - val_loss: 135895.4688\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 92436.9141 - val_loss: 57847.7812\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 109024.8125 - val_loss: 90545.6797\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 102706.8750 - val_loss: 116758.8828\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 140409.1719 - val_loss: 152335.9375\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 132553.1875 - val_loss: 92025.5547\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 105034.4922 - val_loss: 54303.2383\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 77825.6562 - val_loss: 239187.7031\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 112670.4375 - val_loss: 77937.7422\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 160386.8906 - val_loss: 135515.2500\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 160041.5000 - val_loss: 42731.1328\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 188364.6406 - val_loss: 33544.5781\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 153548.8750 - val_loss: 239892.2969\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 71442.8984 - val_loss: 91446.5469\n",
      "Epoch 131/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121752.4141 - val_loss: 327776.2188\n",
      "Epoch 132/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 135859.6562 - val_loss: 108413.6016\n",
      "Epoch 133/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123803.7812 - val_loss: 36725.7891\n",
      "Epoch 134/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 153144.1250 - val_loss: 137229.5312\n",
      "Epoch 135/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 99642.5078 - val_loss: 161196.8594\n",
      "Epoch 136/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 161588.3906 - val_loss: 257258.8906\n",
      "Epoch 137/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 216328.0625 - val_loss: 154035.3906\n",
      "Epoch 138/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121191.4219 - val_loss: 49421.8594\n",
      "Epoch 139/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 86312.2578 - val_loss: 191128.6562\n",
      "Epoch 140/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 100578.8672 - val_loss: 79694.5938\n",
      "Epoch 141/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 189656.2969 - val_loss: 180457.9375\n",
      "Epoch 142/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 114606.8438 - val_loss: 183287.4688\n",
      "Epoch 143/300\n",
      "73/73 [==============================] - ETA: 0s - loss: 109845.1875Restoring model weights from the end of the best epoch: 113.\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 109845.1875 - val_loss: 198431.3281\n",
      "Epoch 143: early stopping\n",
      "'########################################################Model0\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 17ms/step - loss: 4808416.0000 - val_loss: 1017461.6250\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 637977.3125 - val_loss: 518490.7500\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 413721.4375 - val_loss: 646765.8125\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 325394.5625 - val_loss: 383053.8750\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 368877.3125 - val_loss: 565575.3750\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 430510.8750 - val_loss: 442244.5000\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 378862.9062 - val_loss: 208477.0156\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 296259.9375 - val_loss: 255587.1406\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 286208.1250 - val_loss: 582964.0625\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 360962.5000 - val_loss: 424804.3125\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 375205.9688 - val_loss: 327106.9375\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 387120.0938 - val_loss: 319030.6875\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 387537.9688 - val_loss: 294690.2500\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 330531.5000 - val_loss: 356423.1875\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 192900.4375 - val_loss: 127667.3359\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 226977.0938 - val_loss: 359466.8125\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 233283.9062 - val_loss: 172156.4219\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 301460.9688 - val_loss: 190126.0469\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 199245.0312 - val_loss: 120419.8750\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 237003.9375 - val_loss: 154232.2500\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 247601.5000 - val_loss: 177354.6875\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 232204.7344 - val_loss: 387826.2812\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 260866.2188 - val_loss: 138177.9531\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 174342.7031 - val_loss: 228116.6250\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 257757.4844 - val_loss: 297512.7500\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 253458.3594 - val_loss: 88203.9062\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 235950.4531 - val_loss: 108354.8281\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 243556.1250 - val_loss: 221988.6250\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 324476.9688 - val_loss: 356639.4688\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 355366.6562 - val_loss: 158481.3594\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 263173.0625 - val_loss: 483993.0938\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 304524.0312 - val_loss: 232219.7188\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 237242.1250 - val_loss: 523581.0312\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 268010.0625 - val_loss: 510841.3750\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 355794.0938 - val_loss: 385164.2188\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 206159.2188 - val_loss: 262981.1562\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 225443.6562 - val_loss: 109586.6641\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 238370.0000 - val_loss: 92550.8516\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 184186.7500 - val_loss: 73787.5000\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 245666.8750 - val_loss: 107033.0391\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 261940.3125 - val_loss: 73415.2734\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 227458.6562 - val_loss: 609473.8125\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 287908.7188 - val_loss: 96765.5859\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 276607.7188 - val_loss: 273266.3438\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 349938.3750 - val_loss: 295692.5312\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 217690.9688 - val_loss: 238660.2812\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 234638.8438 - val_loss: 320983.5938\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 210982.9219 - val_loss: 410927.7500\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 280446.5625 - val_loss: 263038.1250\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 165448.8438 - val_loss: 65249.6328\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 137885.8125 - val_loss: 166659.7344\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 325642.5625 - val_loss: 172212.6562\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 215142.5156 - val_loss: 469972.1250\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 236636.9844 - val_loss: 296420.3125\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 255050.9688 - val_loss: 204136.8906\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 211409.3438 - val_loss: 80856.6875\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 139431.7500 - val_loss: 166949.9531\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 159327.2188 - val_loss: 154215.6875\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 291116.3750 - val_loss: 239382.4219\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 321635.5938 - val_loss: 157264.2969\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 258138.6094 - val_loss: 98006.4922\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 115188.9531 - val_loss: 209372.3281\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 160645.9219 - val_loss: 64754.5859\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 247941.2812 - val_loss: 499846.7188\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 175646.5000 - val_loss: 205091.0000\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 230481.5469 - val_loss: 400273.8750\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 320812.1875 - val_loss: 237387.9219\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 185455.2500 - val_loss: 85602.3203\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 198847.9688 - val_loss: 456122.8125\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 245450.2969 - val_loss: 183187.0000\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 154378.4844 - val_loss: 155877.6094\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 295711.9375 - val_loss: 69469.8906\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 161589.5312 - val_loss: 205628.4062\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 260559.7500 - val_loss: 130424.0703\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 390859.3125 - val_loss: 235816.2812\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 134855.3750 - val_loss: 113988.2734\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 216989.8438 - val_loss: 445757.2812\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 224575.1719 - val_loss: 104948.4922\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 215117.2969 - val_loss: 215935.3594\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 257774.3594 - val_loss: 316404.4062\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 175174.6094 - val_loss: 234127.4219\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 201463.7188 - val_loss: 498415.6562\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 254898.4844 - val_loss: 94441.2031\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 193258.3438 - val_loss: 39732.9922\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 250172.5156 - val_loss: 290883.5000\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 152584.7344 - val_loss: 191700.8750\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 184806.6875 - val_loss: 290353.5625\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 198616.2656 - val_loss: 150259.5156\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 173061.6406 - val_loss: 187160.7656\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 203714.0000 - val_loss: 151688.9844\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 283881.6562 - val_loss: 250283.5000\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 223953.7500 - val_loss: 301294.0000\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 255357.3438 - val_loss: 138864.4688\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 145858.1250 - val_loss: 268247.8750\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 188545.8750 - val_loss: 143292.3281\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 153378.0156 - val_loss: 219299.2188\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 261905.8594 - val_loss: 295034.9688\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 221094.2812 - val_loss: 324563.0000\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 307862.1250 - val_loss: 335501.6250\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 239079.7031 - val_loss: 158212.7188\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 155703.4531 - val_loss: 160195.7344\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 117551.9453 - val_loss: 361420.1562\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 149606.2812 - val_loss: 208002.1094\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 169912.0312 - val_loss: 162809.5781\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 163811.6406 - val_loss: 164921.8281\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 157155.5938 - val_loss: 132123.2500\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 174751.8125 - val_loss: 88731.6797\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 121556.6953 - val_loss: 231158.4375\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 196582.2500 - val_loss: 256792.2812\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 201380.3594 - val_loss: 169177.1406\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 148852.9062 - val_loss: 245279.3906\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 176434.0781 - val_loss: 61963.3398\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122805.2578 - val_loss: 257694.6719\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - ETA: 0s - loss: 154069.3594Restoring model weights from the end of the best epoch: 84.\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 154069.3594 - val_loss: 119101.6250\n",
      "Epoch 114: early stopping\n",
      "'########################################################Model1\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 17ms/step - loss: 1105449.5000 - val_loss: 238355.7812\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 331309.7812 - val_loss: 264209.9375\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 390559.5625 - val_loss: 591287.3125\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 269882.1562 - val_loss: 373116.3125\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 266892.2500 - val_loss: 214894.9531\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 307906.5938 - val_loss: 153159.4531\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 346281.0938 - val_loss: 111739.8281\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 282923.0312 - val_loss: 378504.9688\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 223308.2656 - val_loss: 241120.7969\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 197449.0781 - val_loss: 220942.8594\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 229173.3438 - val_loss: 165365.7500\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 223915.5469 - val_loss: 97111.7891\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 196472.7656 - val_loss: 309634.5312\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 195451.9062 - val_loss: 308661.8125\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 232652.9531 - val_loss: 154143.8281\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 151337.8906 - val_loss: 221219.3438\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 270537.5312 - val_loss: 75858.4453\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 164515.5000 - val_loss: 60577.1797\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 126219.4844 - val_loss: 320605.5312\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 230480.2969 - val_loss: 203927.4844\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 155210.9688 - val_loss: 91512.0312\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 176106.1719 - val_loss: 161360.8125\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 150169.1094 - val_loss: 68621.5234\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 273672.3750 - val_loss: 484370.7188\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 171452.9375 - val_loss: 98687.8672\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 194944.0312 - val_loss: 149515.7656\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 182443.9375 - val_loss: 90965.5312\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 196637.9062 - val_loss: 135612.0781\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 170501.4375 - val_loss: 154847.5312\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 162417.3906 - val_loss: 161871.8906\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 164644.5625 - val_loss: 108882.3438\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 248638.3906 - val_loss: 160750.7656\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 151646.4844 - val_loss: 208124.5625\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 226140.3281 - val_loss: 68826.2891\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 170439.0625 - val_loss: 203003.0781\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 132148.0156 - val_loss: 303043.6875\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 197930.8438 - val_loss: 273882.6250\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 165841.6562 - val_loss: 78419.5625\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 182225.2344 - val_loss: 351050.7188\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 183970.0000 - val_loss: 60438.6953\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 198921.9688 - val_loss: 655909.0625\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 235689.7188 - val_loss: 95331.6016\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121141.2188 - val_loss: 114238.4141\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 163220.9531 - val_loss: 351389.0938\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 144832.2188 - val_loss: 255579.9375\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 138038.7344 - val_loss: 185026.4062\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 322043.1562 - val_loss: 224275.1562\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 136092.3438 - val_loss: 139832.7969\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 246417.7969 - val_loss: 169076.7188\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 143497.7656 - val_loss: 144441.1719\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 97237.6328 - val_loss: 100746.7969\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 246545.0469 - val_loss: 252803.3125\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 185410.3594 - val_loss: 304646.0938\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 191112.5781 - val_loss: 113214.1406\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 140412.6094 - val_loss: 188527.0000\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 185775.6562 - val_loss: 156239.9375\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 110457.0938 - val_loss: 116670.8828\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 114624.1484 - val_loss: 76469.4531\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 179949.0000 - val_loss: 51527.3711\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 153231.9688 - val_loss: 167001.8594\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 136128.9844 - val_loss: 154264.2344\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122118.9375 - val_loss: 182804.6406\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 161257.5469 - val_loss: 168150.3906\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 132431.2969 - val_loss: 111176.7031\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 117147.9609 - val_loss: 61711.6133\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 127345.6172 - val_loss: 132777.5781\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 130665.5781 - val_loss: 121341.9297\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 134126.7188 - val_loss: 189475.6406\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 160419.5781 - val_loss: 213614.3438\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 143539.1094 - val_loss: 59300.4688\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 124140.8281 - val_loss: 185085.6094\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 178306.2031 - val_loss: 75521.4922\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 235228.0938 - val_loss: 152459.5312\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 192804.4688 - val_loss: 259614.7656\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 108645.0391 - val_loss: 70093.9844\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 133549.0000 - val_loss: 98200.9531\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 202413.8438 - val_loss: 246218.3750\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 131716.2031 - val_loss: 244044.3906\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122050.0312 - val_loss: 101741.4453\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 147427.4062 - val_loss: 133680.0781\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 200167.9375 - val_loss: 73020.9609\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 110421.8125 - val_loss: 102691.8438\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 132301.1406 - val_loss: 70712.7422\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 189115.9844 - val_loss: 244722.2344\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123755.6406 - val_loss: 152757.0938\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 131174.4844 - val_loss: 417430.6562\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 171225.7656 - val_loss: 118820.6328\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 113983.5938 - val_loss: 213109.5156\n",
      "Epoch 89/300\n",
      "70/73 [===========================>..] - ETA: 0s - loss: 135388.4844Restoring model weights from the end of the best epoch: 59.\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 135763.9688 - val_loss: 177813.7969\n",
      "Epoch 89: early stopping\n",
      "'########################################################Model2\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 17ms/step - loss: 9267475.0000 - val_loss: 1898154.1250\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 1299482.2500 - val_loss: 912863.8750\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 588625.8125 - val_loss: 443636.3125\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 572359.0625 - val_loss: 401571.3750\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 326323.2812 - val_loss: 405947.2500\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 289007.4062 - val_loss: 473401.4375\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 318994.0625 - val_loss: 405663.2812\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 280660.7188 - val_loss: 234617.0156\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 283287.4688 - val_loss: 243634.9219\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 223541.1562 - val_loss: 280199.4688\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 233681.1406 - val_loss: 184453.9375\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 194398.5781 - val_loss: 348677.5312\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 206357.3750 - val_loss: 354101.0938\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 200108.2969 - val_loss: 305988.9375\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 191216.2969 - val_loss: 183277.8594\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 253544.8906 - val_loss: 429714.9688\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 239220.8125 - val_loss: 110895.6406\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 179466.3906 - val_loss: 142529.2031\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 167584.7188 - val_loss: 177355.0781\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 178171.6250 - val_loss: 212392.4219\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 196874.2656 - val_loss: 303206.2500\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 169760.6719 - val_loss: 151036.0781\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 212014.4062 - val_loss: 145840.7656\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 180775.8906 - val_loss: 257162.7344\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 183919.8594 - val_loss: 213800.7812\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 147855.0156 - val_loss: 99351.5000\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 133748.5312 - val_loss: 508995.4688\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 249742.8906 - val_loss: 148236.6562\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123301.6719 - val_loss: 138983.0156\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 162264.3125 - val_loss: 132517.5156\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 187367.8125 - val_loss: 78280.1406\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 154768.9531 - val_loss: 314306.4062\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 144029.5781 - val_loss: 134142.1406\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 228293.5625 - val_loss: 52808.0234\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 127782.8516 - val_loss: 78404.6172\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 203389.1094 - val_loss: 73820.8516\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 136489.0781 - val_loss: 174133.6719\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 136407.4844 - val_loss: 197722.7656\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 128317.7266 - val_loss: 127830.4844\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 126732.5938 - val_loss: 365459.4688\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 197842.0625 - val_loss: 76139.3984\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 100407.8906 - val_loss: 253748.6094\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 155097.5312 - val_loss: 208229.5156\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 217702.4375 - val_loss: 626778.1250\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 137572.9688 - val_loss: 99962.5000\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 113293.4219 - val_loss: 78846.6797\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 126441.3438 - val_loss: 193808.1719\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 137877.8750 - val_loss: 46229.3477\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 138370.3438 - val_loss: 73777.5234\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120196.8594 - val_loss: 105246.0703\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 172330.7500 - val_loss: 313767.6562\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 114533.7266 - val_loss: 112174.7188\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 171198.1250 - val_loss: 253042.7031\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119806.6562 - val_loss: 79989.3359\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 134352.4531 - val_loss: 90668.1172\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 97773.8359 - val_loss: 115607.6094\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 96629.3828 - val_loss: 63104.3789\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 115641.6250 - val_loss: 174806.1094\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 98087.4922 - val_loss: 251469.0000\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 104954.3516 - val_loss: 252852.4375\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121722.2422 - val_loss: 149571.1719\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 143347.5000 - val_loss: 410809.7188\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 174618.2344 - val_loss: 72657.9688\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 142078.2188 - val_loss: 348149.0625\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 203042.5781 - val_loss: 127840.9219\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 105626.8438 - val_loss: 110553.3906\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 150030.9688 - val_loss: 70283.5781\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 140764.2031 - val_loss: 97098.0547\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 109597.3984 - val_loss: 255189.5781\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 93481.8750 - val_loss: 92807.3672\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 137864.5625 - val_loss: 78922.6172\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 170110.5469 - val_loss: 157290.8906\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 173011.8125 - val_loss: 138171.4688\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 101941.1172 - val_loss: 91315.6719\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 128535.0156 - val_loss: 40511.8398\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123750.8516 - val_loss: 422092.8125\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 149809.6406 - val_loss: 45462.5742\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 116832.6250 - val_loss: 127246.3750\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 98057.4531 - val_loss: 61103.6328\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 171327.9688 - val_loss: 216457.3125\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 135705.2188 - val_loss: 70165.7266\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 127955.8359 - val_loss: 402578.7188\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122804.3359 - val_loss: 85370.4219\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 99700.2969 - val_loss: 98607.7266\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 90585.6641 - val_loss: 60519.2266\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 109730.5469 - val_loss: 116386.6094\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 89341.5469 - val_loss: 53739.4258\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 126840.1094 - val_loss: 80374.0234\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 124320.3750 - val_loss: 70269.4375\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122057.1250 - val_loss: 319839.1875\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 84274.7422 - val_loss: 145927.8125\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 95390.4531 - val_loss: 125256.6094\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 125103.3203 - val_loss: 125919.4062\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 86927.0781 - val_loss: 63992.4961\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 97703.7891 - val_loss: 79282.0547\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123862.7656 - val_loss: 57420.7500\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 95908.7578 - val_loss: 96268.9688\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 76733.0625 - val_loss: 60466.5312\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118261.1484 - val_loss: 74756.4219\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 91896.0469 - val_loss: 117567.1328\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 96679.3984 - val_loss: 149178.4062\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 105673.4609 - val_loss: 104909.8984\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 104613.8125 - val_loss: 154915.4531\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 169921.3125 - val_loss: 57506.8984\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - ETA: 0s - loss: 162832.1875Restoring model weights from the end of the best epoch: 75.\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 162832.1875 - val_loss: 148084.0156\n",
      "Epoch 105: early stopping\n",
      "'########################################################Model3\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 17ms/step - loss: 1934782.0000 - val_loss: 516353.9375\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 483118.4062 - val_loss: 393882.1875\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 292272.8438 - val_loss: 202998.1562\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 226128.7344 - val_loss: 273842.5938\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 193590.2969 - val_loss: 276824.8438\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 267537.0000 - val_loss: 149218.4844\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 203787.7812 - val_loss: 409472.4062\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 256396.8438 - val_loss: 114883.7344\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 182992.6719 - val_loss: 118039.6953\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 287530.9375 - val_loss: 384649.5938\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 230263.9062 - val_loss: 434600.5938\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 216479.8594 - val_loss: 463030.0000\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 251057.1094 - val_loss: 144636.2969\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 249365.9531 - val_loss: 122649.9297\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 152610.2656 - val_loss: 147097.1406\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 134723.2188 - val_loss: 117955.3125\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 142401.2969 - val_loss: 57641.9258\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 156176.1875 - val_loss: 136927.3594\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 139066.4062 - val_loss: 308710.8125\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 221245.1875 - val_loss: 207854.1406\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 142533.9844 - val_loss: 247939.6406\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 136124.0625 - val_loss: 170186.2656\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 187522.1406 - val_loss: 79216.7656\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 146747.8594 - val_loss: 269763.3125\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 132490.6094 - val_loss: 70285.0938\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 148494.2188 - val_loss: 118418.8281\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122043.8594 - val_loss: 50867.7305\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 153410.8125 - val_loss: 161043.4844\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 162022.5625 - val_loss: 137310.1562\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 173603.5000 - val_loss: 185535.1562\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 179218.8281 - val_loss: 203548.4062\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 133785.6406 - val_loss: 312087.4062\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 172816.5156 - val_loss: 227809.3906\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 115180.8516 - val_loss: 57582.7773\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 194958.4531 - val_loss: 79411.3594\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 155220.6250 - val_loss: 188057.7031\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 117696.4141 - val_loss: 240482.6719\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 139615.6250 - val_loss: 54410.8828\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 180351.1094 - val_loss: 95880.7188\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 100852.6875 - val_loss: 120405.8594\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 134227.3750 - val_loss: 159325.2344\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 131124.5625 - val_loss: 183175.4531\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 89634.7891 - val_loss: 112004.6016\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 106018.2266 - val_loss: 134806.7812\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 224828.2344 - val_loss: 408318.2188\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 130174.0469 - val_loss: 89120.9609\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 191366.1250 - val_loss: 336172.5312\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 180491.6719 - val_loss: 91740.9297\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 106669.0000 - val_loss: 177019.5938\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 120730.7266 - val_loss: 52844.1523\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119483.6953 - val_loss: 117754.1641\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 174872.0938 - val_loss: 72706.0156\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 137076.1406 - val_loss: 91555.2500\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 114969.4219 - val_loss: 195588.1406\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 134225.5469 - val_loss: 177794.6094\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 103827.5859 - val_loss: 112950.7891\n",
      "Epoch 57/300\n",
      "69/73 [===========================>..] - ETA: 0s - loss: 91266.5156Restoring model weights from the end of the best epoch: 27.\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 91775.5703 - val_loss: 110846.0078\n",
      "Epoch 57: early stopping\n",
      "'########################################################Model4\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 17ms/step - loss: 8405625.0000 - val_loss: 1550797.7500\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 943342.6250 - val_loss: 680636.0625\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 547731.8125 - val_loss: 313736.6562\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 550470.0625 - val_loss: 498039.5625\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 378137.0938 - val_loss: 213470.7500\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 350587.7500 - val_loss: 211036.1719\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 355389.7500 - val_loss: 352119.4688\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 316814.4375 - val_loss: 282081.5312\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 303747.9375 - val_loss: 329630.1250\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 352279.4062 - val_loss: 601113.1875\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 262381.3125 - val_loss: 370475.0312\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 249240.1719 - val_loss: 368558.6250\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 223154.4688 - val_loss: 248985.8750\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 230124.6719 - val_loss: 224078.4375\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 229004.3750 - val_loss: 560651.6250\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 213860.7969 - val_loss: 98689.4922\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 274361.7500 - val_loss: 564278.3750\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 243808.9062 - val_loss: 217931.6562\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 205252.6719 - val_loss: 255719.4219\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 215114.3594 - val_loss: 332814.5000\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 367287.6250 - val_loss: 323186.1875\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 157844.8750 - val_loss: 73200.8203\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 213894.4688 - val_loss: 120971.3125\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 258193.8281 - val_loss: 206007.2188\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 290765.1875 - val_loss: 113572.2109\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 227328.2969 - val_loss: 216653.5156\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 188768.6719 - val_loss: 128423.2969\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 195818.2812 - val_loss: 137944.2188\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 244251.9375 - val_loss: 343172.7500\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 217119.4062 - val_loss: 428495.6562\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 268197.0938 - val_loss: 90521.2891\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 158863.9844 - val_loss: 216746.7500\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 289850.0625 - val_loss: 250343.1719\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 147811.3281 - val_loss: 189313.0469\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 188402.3594 - val_loss: 282839.4062\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 184894.6406 - val_loss: 235946.2969\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 157141.0469 - val_loss: 131772.4375\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 168977.4688 - val_loss: 224924.6094\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 277728.7500 - val_loss: 215417.9531\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 163417.1406 - val_loss: 232839.5312\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 150510.0469 - val_loss: 99917.1328\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 140356.2031 - val_loss: 237251.4688\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 182370.3438 - val_loss: 104891.0859\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 203601.7969 - val_loss: 154745.6875\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 165317.2656 - val_loss: 111774.9766\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 136864.0625 - val_loss: 65653.8906\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120974.3125 - val_loss: 86298.1797\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 157337.8281 - val_loss: 104199.9219\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 131511.9375 - val_loss: 259651.7500\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 143282.7031 - val_loss: 185970.2031\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 172485.7656 - val_loss: 749467.5625\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 202139.7188 - val_loss: 248203.3125\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 148653.4062 - val_loss: 64565.5781\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 173561.6875 - val_loss: 385038.5000\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 220926.8750 - val_loss: 117115.9844\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 123277.9219 - val_loss: 221979.8125\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 150428.7969 - val_loss: 77638.3984\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 126416.4453 - val_loss: 66616.2031\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 144824.7188 - val_loss: 161996.7969\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 167197.4375 - val_loss: 77789.6172\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 164885.9688 - val_loss: 102154.2734\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 139423.7500 - val_loss: 87323.6719\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 95679.6953 - val_loss: 146012.7031\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 162267.9844 - val_loss: 169167.1875\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 156481.3125 - val_loss: 110876.1406\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 116372.3438 - val_loss: 223482.0938\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 161776.6406 - val_loss: 92033.2891\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 176867.0938 - val_loss: 147886.5781\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120568.6328 - val_loss: 154287.2031\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 163134.4844 - val_loss: 174404.1562\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 205734.7344 - val_loss: 238313.8750\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 155507.5781 - val_loss: 146171.1719\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 133344.0938 - val_loss: 132247.2344\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 163327.0000 - val_loss: 482041.8750\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 192825.2188 - val_loss: 102784.6719\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 148914.9531 - val_loss: 179006.2969\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 135577.4531 - val_loss: 251903.3438\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 137857.3281 - val_loss: 180128.6406\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 109625.4453 - val_loss: 124978.2734\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 191044.4531 - val_loss: 149654.8906\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 214417.1406 - val_loss: 200335.8281\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 132418.0625 - val_loss: 229979.0938\n",
      "Epoch 83/300\n",
      "71/73 [============================>.] - ETA: 0s - loss: 150714.5938Restoring model weights from the end of the best epoch: 53.\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 151528.1250 - val_loss: 73551.6172\n",
      "Epoch 83: early stopping\n",
      "'########################################################Model5\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 18ms/step - loss: 3957848.5000 - val_loss: 1622072.3750\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 822139.4375 - val_loss: 595450.9375\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 463660.6562 - val_loss: 360778.0000\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 397086.0000 - val_loss: 254124.0781\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 333942.0312 - val_loss: 388857.3438\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 342395.2500 - val_loss: 247582.7656\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 276274.8125 - val_loss: 274426.9062\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 332110.3438 - val_loss: 868770.8125\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 728079.5000 - val_loss: 1013945.3750\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 340716.2500 - val_loss: 195672.5938\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 262177.2188 - val_loss: 275539.3750\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 325437.2500 - val_loss: 424098.4062\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 275564.7812 - val_loss: 263204.9688\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 229262.1250 - val_loss: 171633.4688\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 429233.5625 - val_loss: 437611.7188\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 401074.9375 - val_loss: 931429.0625\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 233022.1719 - val_loss: 120699.2266\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 370380.8438 - val_loss: 240134.7031\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 316529.0938 - val_loss: 238532.5469\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 152441.7500 - val_loss: 229903.1250\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 254816.4375 - val_loss: 423062.6250\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 303158.9062 - val_loss: 716471.3750\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 325328.0312 - val_loss: 224829.7031\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 197908.1875 - val_loss: 336379.4688\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 191501.5938 - val_loss: 472368.5000\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 235821.8125 - val_loss: 144273.5156\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 290502.3438 - val_loss: 612474.6875\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 255228.8750 - val_loss: 222932.7031\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 279945.8125 - val_loss: 389586.7500\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 214281.6250 - val_loss: 180034.9219\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 177550.3594 - val_loss: 304494.9375\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 189319.2344 - val_loss: 367955.1875\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 261478.0000 - val_loss: 301145.5000\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 191926.3750 - val_loss: 415712.1875\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 207182.2344 - val_loss: 240800.3906\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 164837.7812 - val_loss: 122934.4844\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 229041.1562 - val_loss: 240480.4375\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 182948.5938 - val_loss: 143780.8750\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 223719.3125 - val_loss: 121692.6172\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 169587.2344 - val_loss: 199593.3281\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 151946.0000 - val_loss: 452514.6562\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 207034.3281 - val_loss: 388907.0000\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 198717.2969 - val_loss: 165257.6719\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 171317.8594 - val_loss: 655748.6875\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 360634.9375 - val_loss: 407252.5312\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 234791.8594 - val_loss: 237418.2969\n",
      "Epoch 47/300\n",
      "72/73 [============================>.] - ETA: 0s - loss: 186039.4531Restoring model weights from the end of the best epoch: 17.\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 185946.9219 - val_loss: 193851.0156\n",
      "Epoch 47: early stopping\n",
      "'########################################################Model6\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 17ms/step - loss: 4377710.5000 - val_loss: 469300.3438\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 287162.6250 - val_loss: 249857.4688\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 280284.4375 - val_loss: 315670.4688\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 245398.1406 - val_loss: 963214.2500\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 302586.3438 - val_loss: 590275.9375\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 320667.0312 - val_loss: 705531.5000\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 297932.3750 - val_loss: 223750.2031\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 193469.5469 - val_loss: 339674.1562\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 276315.1875 - val_loss: 220644.0000\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 377774.9375 - val_loss: 324035.0312\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 210924.8594 - val_loss: 228276.0000\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 173610.2500 - val_loss: 80883.5859\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 272946.1250 - val_loss: 205161.4062\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 258482.4062 - val_loss: 88064.1719\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 224136.0938 - val_loss: 345864.2812\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 226723.3281 - val_loss: 241082.2656\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 170543.1250 - val_loss: 233251.8125\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 231292.7812 - val_loss: 221868.5469\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 219159.2500 - val_loss: 296297.5000\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 223168.8281 - val_loss: 333047.6250\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 165770.1406 - val_loss: 226220.1094\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 155555.5938 - val_loss: 136516.2188\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 254471.6094 - val_loss: 317384.9375\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 241936.3906 - val_loss: 129468.6797\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 155645.3125 - val_loss: 115450.6094\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 179938.9688 - val_loss: 149201.4844\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120972.4531 - val_loss: 319659.2812\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 130409.6641 - val_loss: 95444.2500\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 175921.6094 - val_loss: 188826.6875\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 130720.5781 - val_loss: 291866.0312\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 275921.4688 - val_loss: 469464.1562\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 164495.4844 - val_loss: 172346.2656\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 152093.0312 - val_loss: 43527.8086\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 161075.4219 - val_loss: 425495.5000\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 220767.5781 - val_loss: 184963.0938\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123881.5234 - val_loss: 74581.6797\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 145988.8906 - val_loss: 73443.8516\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 147615.2500 - val_loss: 465312.2188\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 216606.8594 - val_loss: 345527.3438\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 172769.0625 - val_loss: 198121.7188\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 113709.3828 - val_loss: 79076.6719\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 179247.5938 - val_loss: 43845.1367\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 124517.6328 - val_loss: 56905.9844\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 105376.5781 - val_loss: 123739.4766\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 186619.0156 - val_loss: 74218.1250\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 116824.6641 - val_loss: 53402.7578\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 357676.9375 - val_loss: 580969.1250\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 241048.2812 - val_loss: 58725.6562\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 149413.0000 - val_loss: 279017.1250\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 249412.0625 - val_loss: 95499.8828\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 252710.0938 - val_loss: 98287.5391\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 153569.8750 - val_loss: 134840.6250\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 110529.3281 - val_loss: 68733.0078\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 163888.6875 - val_loss: 177334.2500\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 134966.2656 - val_loss: 413847.8750\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 164373.1875 - val_loss: 303713.1562\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 160821.8594 - val_loss: 67687.8281\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 173370.9375 - val_loss: 36742.9727\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 161922.5312 - val_loss: 271132.4375\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 171715.3906 - val_loss: 195982.1875\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 99904.5391 - val_loss: 140292.7656\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 131501.0781 - val_loss: 410036.3438\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 262918.8125 - val_loss: 199594.1250\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 127864.9688 - val_loss: 54489.3594\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 115803.0625 - val_loss: 237606.3750\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 152583.0469 - val_loss: 168908.4219\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 166107.5156 - val_loss: 127714.8984\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 127174.4766 - val_loss: 104699.8359\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 160910.7188 - val_loss: 134637.4844\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 113264.6328 - val_loss: 73212.9375\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 168744.7812 - val_loss: 107336.1016\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 232819.2656 - val_loss: 310605.4688\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 194022.3594 - val_loss: 125468.5547\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 128394.3906 - val_loss: 104464.5234\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 164441.5312 - val_loss: 202243.4062\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 153809.2188 - val_loss: 203961.0156\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 130932.9375 - val_loss: 229834.5469\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 129811.4297 - val_loss: 102662.1328\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 104352.1797 - val_loss: 221322.1719\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 178427.8438 - val_loss: 50342.3516\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 127324.3906 - val_loss: 168946.8750\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 138901.6094 - val_loss: 38653.6406\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 136107.2500 - val_loss: 211665.2969\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 150245.8594 - val_loss: 129333.7656\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122715.5000 - val_loss: 68036.1172\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 94505.5859 - val_loss: 83251.3438\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 137212.7812 - val_loss: 62482.3867\n",
      "Epoch 88/300\n",
      "69/73 [===========================>..] - ETA: 0s - loss: 115250.8281Restoring model weights from the end of the best epoch: 58.\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 116494.2422 - val_loss: 62640.2539\n",
      "Epoch 88: early stopping\n",
      "'########################################################Model7\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 17ms/step - loss: 1627070.0000 - val_loss: 481816.2812\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 415066.0312 - val_loss: 552438.3125\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 362958.5938 - val_loss: 337100.2188\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 225299.4062 - val_loss: 244657.5156\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 228146.9062 - val_loss: 167720.2969\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 263903.3750 - val_loss: 124876.3203\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 211978.0000 - val_loss: 376380.8750\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 306590.5938 - val_loss: 137777.5312\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 224256.6875 - val_loss: 284467.5938\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 300886.0625 - val_loss: 400703.8125\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 328385.7812 - val_loss: 604984.8750\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 243176.1719 - val_loss: 166020.9531\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 301915.2500 - val_loss: 207873.2656\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 163382.6094 - val_loss: 100356.7656\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 262359.6562 - val_loss: 327202.2812\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 195532.8594 - val_loss: 125580.9219\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 137130.5781 - val_loss: 147807.5781\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 169399.3125 - val_loss: 152610.9219\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 185086.9531 - val_loss: 121532.5547\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 248635.7031 - val_loss: 505630.9062\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 190700.0312 - val_loss: 136270.2969\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 188885.7500 - val_loss: 130123.1172\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 194837.2656 - val_loss: 79579.0625\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 153403.2344 - val_loss: 277413.7500\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 155841.5938 - val_loss: 77265.8203\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 188750.0312 - val_loss: 131896.3750\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 193479.1094 - val_loss: 156940.5781\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 112066.2422 - val_loss: 284079.8125\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 188813.1094 - val_loss: 146068.0625\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 140764.7969 - val_loss: 104787.6641\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 195660.4062 - val_loss: 169946.5781\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118401.7734 - val_loss: 196361.0000\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 145466.8438 - val_loss: 310428.0000\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 168521.1562 - val_loss: 261208.6094\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 204526.9688 - val_loss: 196764.7656\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 158999.4688 - val_loss: 434411.0625\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 231083.2344 - val_loss: 421809.5312\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 165050.6406 - val_loss: 283798.7188\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 135850.4062 - val_loss: 474970.1562\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 165017.4375 - val_loss: 157104.4062\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 177026.0781 - val_loss: 188117.2656\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 201824.0938 - val_loss: 39348.7422\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 196318.3438 - val_loss: 195097.6094\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 157114.8438 - val_loss: 91760.5156\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 136996.0625 - val_loss: 133296.2031\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 134090.1094 - val_loss: 208481.9062\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 140680.7969 - val_loss: 130458.9141\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 130059.1953 - val_loss: 75162.7344\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 124511.3672 - val_loss: 120776.2031\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 126397.3672 - val_loss: 89140.7500\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 93244.6953 - val_loss: 246173.0469\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 146605.3281 - val_loss: 126142.7344\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 129667.1562 - val_loss: 241900.4688\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 183929.8594 - val_loss: 128142.5078\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 146522.8438 - val_loss: 310905.6250\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 129892.6953 - val_loss: 105819.4297\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 115755.1562 - val_loss: 203259.6094\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 192818.4219 - val_loss: 398814.2500\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 161078.9688 - val_loss: 194244.1719\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 129653.6719 - val_loss: 159167.6094\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 116012.6016 - val_loss: 54967.8086\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 102026.5156 - val_loss: 60313.2617\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 116837.7969 - val_loss: 128196.8281\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 92247.5469 - val_loss: 54704.8359\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120530.7578 - val_loss: 156914.1562\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 135951.7969 - val_loss: 150838.7656\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 139824.9219 - val_loss: 134886.3438\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 168029.2500 - val_loss: 64153.9375\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 180549.9375 - val_loss: 314119.0000\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 133502.9688 - val_loss: 171132.8438\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 169141.6406 - val_loss: 174705.8125\n",
      "Epoch 72/300\n",
      "71/73 [============================>.] - ETA: 0s - loss: 125547.8984Restoring model weights from the end of the best epoch: 42.\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 124736.8750 - val_loss: 93943.1172\n",
      "Epoch 72: early stopping\n",
      "'########################################################Model8\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 18ms/step - loss: 2950687.0000 - val_loss: 798820.1875\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 357280.5625 - val_loss: 222063.0938\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 323946.9375 - val_loss: 109026.5625\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 371044.0312 - val_loss: 330212.3438\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 168672.5156 - val_loss: 110586.6484\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 173742.5469 - val_loss: 451320.4375\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 244225.2656 - val_loss: 512870.4688\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 234740.1875 - val_loss: 285537.7500\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 177657.2656 - val_loss: 132332.2188\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 227252.6250 - val_loss: 228385.1406\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 147298.5000 - val_loss: 136700.5625\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 138915.9688 - val_loss: 398185.0625\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 216137.7500 - val_loss: 116001.5703\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 162770.8906 - val_loss: 110837.7031\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 170575.9531 - val_loss: 171215.8281\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 156797.7500 - val_loss: 136672.5625\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 213560.0469 - val_loss: 160095.5625\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 178246.7031 - val_loss: 180999.3438\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 243565.3438 - val_loss: 57436.4688\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 280281.8438 - val_loss: 341049.9688\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 149334.4062 - val_loss: 83507.9141\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 173223.4531 - val_loss: 95263.1484\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 132443.5781 - val_loss: 114250.2812\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 100296.6172 - val_loss: 125678.1641\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 148763.5625 - val_loss: 100098.7656\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 222378.4375 - val_loss: 100658.2188\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 141446.4375 - val_loss: 162389.7656\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 155425.8438 - val_loss: 212994.8750\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 133519.5781 - val_loss: 101773.3984\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 151432.4062 - val_loss: 171438.2500\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119725.3125 - val_loss: 299220.5938\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 189460.9219 - val_loss: 95500.6250\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 111019.2109 - val_loss: 102849.3906\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 133369.1562 - val_loss: 520208.5000\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 244826.2656 - val_loss: 438257.7812\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 184432.3906 - val_loss: 99161.4062\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 138060.2188 - val_loss: 88056.8203\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 180964.9375 - val_loss: 85670.7812\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 165408.4688 - val_loss: 95318.2188\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 205632.8750 - val_loss: 64974.9102\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 82289.0000 - val_loss: 225327.8438\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119205.4141 - val_loss: 67550.5781\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 303906.5312 - val_loss: 158498.0000\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 136403.1562 - val_loss: 121516.4375\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 152100.2344 - val_loss: 61917.8477\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 112355.1875 - val_loss: 80282.9766\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 136433.0312 - val_loss: 144575.3281\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 130110.1328 - val_loss: 111677.6328\n",
      "Epoch 49/300\n",
      "70/73 [===========================>..] - ETA: 0s - loss: 230662.2188Restoring model weights from the end of the best epoch: 19.\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 226001.2031 - val_loss: 83224.7188\n",
      "Epoch 49: early stopping\n",
      "'########################################################Model9\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 18ms/step - loss: 142.9445 - val_loss: 141.0432\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 135.7836 - val_loss: 139.8152\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 133.5753 - val_loss: 136.8133\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 129.2096 - val_loss: 133.6319\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 128.2973 - val_loss: 133.5784\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 127.1645 - val_loss: 132.3651\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 126.8879 - val_loss: 133.2697\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 126.2217 - val_loss: 131.5258\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 125.9312 - val_loss: 131.6972\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 125.4811 - val_loss: 131.0056\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 124.9763 - val_loss: 131.2080\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 124.8485 - val_loss: 130.4878\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 124.3926 - val_loss: 129.7976\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.7552 - val_loss: 129.8581\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.2777 - val_loss: 129.0879\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.3344 - val_loss: 128.8692\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.4393 - val_loss: 129.0478\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.4914 - val_loss: 129.2254\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.8363 - val_loss: 129.6891\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.6304 - val_loss: 128.4041\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.5348 - val_loss: 128.3841\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.7625 - val_loss: 128.6369\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.5826 - val_loss: 128.8198\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.1115 - val_loss: 127.9952\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.9817 - val_loss: 129.3387\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.0643 - val_loss: 128.6288\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 121.9775 - val_loss: 127.3930\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.9083 - val_loss: 128.9409\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.7677 - val_loss: 127.4149\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.7213 - val_loss: 128.3279\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 121.9263 - val_loss: 126.7889\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.8471 - val_loss: 128.0028\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.6293 - val_loss: 127.2289\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.0616 - val_loss: 130.8601\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 122.2680 - val_loss: 127.6371\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.2956 - val_loss: 127.8110\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 121.1872 - val_loss: 127.8677\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.2681 - val_loss: 127.3744\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.2087 - val_loss: 126.7891\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.2856 - val_loss: 128.2532\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.0989 - val_loss: 126.9762\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.4319 - val_loss: 127.4620\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.2121 - val_loss: 126.4307\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.9077 - val_loss: 126.6617\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.8428 - val_loss: 127.5762\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.7424 - val_loss: 127.2047\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.6666 - val_loss: 127.4904\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.2634 - val_loss: 126.8667\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.6577 - val_loss: 126.3265\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.6321 - val_loss: 126.5992\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.5280 - val_loss: 126.4274\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.5090 - val_loss: 127.2375\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.5451 - val_loss: 126.4783\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.5112 - val_loss: 126.7049\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.5249 - val_loss: 127.6530\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.6317 - val_loss: 126.1432\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.2638 - val_loss: 126.0471\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.3096 - val_loss: 125.7633\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.1406 - val_loss: 126.0779\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.2920 - val_loss: 126.2302\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.2908 - val_loss: 125.9051\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.3654 - val_loss: 126.6363\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.5778 - val_loss: 127.0817\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.6675 - val_loss: 126.4617\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.7514 - val_loss: 126.0014\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.0937 - val_loss: 125.6377\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.1760 - val_loss: 126.0455\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.4247 - val_loss: 125.9692\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.1419 - val_loss: 126.8023\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 121.2404 - val_loss: 126.0023\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.1816 - val_loss: 126.2124\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 119.9296 - val_loss: 125.7433\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.2809 - val_loss: 125.5007\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 120.1320 - val_loss: 125.6468\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.0639 - val_loss: 127.3647\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.9176 - val_loss: 126.1571\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.0355 - val_loss: 126.3995\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.8245 - val_loss: 125.6609\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.9073 - val_loss: 125.5126\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.8403 - val_loss: 126.1740\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.6878 - val_loss: 125.5527\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.1072 - val_loss: 125.0544\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.9650 - val_loss: 125.6814\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.9776 - val_loss: 126.1891\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.0428 - val_loss: 125.2792\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 119.6001 - val_loss: 125.8689\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7989 - val_loss: 125.6701\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.6681 - val_loss: 125.4027\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.9147 - val_loss: 125.5428\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.0579 - val_loss: 126.3948\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 119.8264 - val_loss: 126.1936\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.0612 - val_loss: 124.9233\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 120.1432 - val_loss: 125.9054\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.6699 - val_loss: 126.3556\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.9415 - val_loss: 125.1269\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.8657 - val_loss: 124.8886\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.6332 - val_loss: 125.2178\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7038 - val_loss: 125.7617\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.8202 - val_loss: 125.4854\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.5566 - val_loss: 125.1140\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.8961 - val_loss: 125.3732\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.8501 - val_loss: 125.5498\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.9099 - val_loss: 124.7421\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.6552 - val_loss: 125.9622\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.9789 - val_loss: 125.1258\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.6086 - val_loss: 126.1650\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.6475 - val_loss: 125.6768\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.6993 - val_loss: 125.0621\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.5424 - val_loss: 125.3588\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.5795 - val_loss: 126.8036\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.6312 - val_loss: 124.9717\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.4672 - val_loss: 124.9689\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.1725 - val_loss: 126.2605\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.8840 - val_loss: 124.9767\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.5468 - val_loss: 125.2996\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3689 - val_loss: 124.9253\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 119.5241 - val_loss: 124.4352\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7387 - val_loss: 125.5114\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.6736 - val_loss: 125.2785\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.6283 - val_loss: 126.0353\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7127 - val_loss: 125.4336\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.4559 - val_loss: 125.7267\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7616 - val_loss: 124.9902\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.9065 - val_loss: 124.7661\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.6248 - val_loss: 124.8930\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.5167 - val_loss: 124.5043\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.6014 - val_loss: 124.5307\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.5096 - val_loss: 126.1802\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 119.5303 - val_loss: 124.4974\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.5826 - val_loss: 125.9725\n",
      "Epoch 131/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 119.8551 - val_loss: 124.5072\n",
      "Epoch 132/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.5532 - val_loss: 124.6577\n",
      "Epoch 133/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.5457 - val_loss: 124.7990\n",
      "Epoch 134/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7922 - val_loss: 124.9447\n",
      "Epoch 135/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.4148 - val_loss: 125.7515\n",
      "Epoch 136/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.6442 - val_loss: 125.9122\n",
      "Epoch 137/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 119.7897 - val_loss: 125.1440\n",
      "Epoch 138/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.4298 - val_loss: 125.3505\n",
      "Epoch 139/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7449 - val_loss: 124.6044\n",
      "Epoch 140/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.2849 - val_loss: 124.5770\n",
      "Epoch 141/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3739 - val_loss: 124.4336\n",
      "Epoch 142/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.2220 - val_loss: 125.0222\n",
      "Epoch 143/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3469 - val_loss: 124.9308\n",
      "Epoch 144/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.6201 - val_loss: 125.4209\n",
      "Epoch 145/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.2233 - val_loss: 125.0318\n",
      "Epoch 146/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 119.6263 - val_loss: 124.6503\n",
      "Epoch 147/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3815 - val_loss: 124.6605\n",
      "Epoch 148/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.9553 - val_loss: 126.4284\n",
      "Epoch 149/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7962 - val_loss: 124.9509\n",
      "Epoch 150/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.4752 - val_loss: 125.4836\n",
      "Epoch 151/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.4063 - val_loss: 125.2847\n",
      "Epoch 152/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.2020 - val_loss: 125.1566\n",
      "Epoch 153/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3761 - val_loss: 125.3516\n",
      "Epoch 154/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3608 - val_loss: 124.7092\n",
      "Epoch 155/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.1646 - val_loss: 125.2343\n",
      "Epoch 156/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3078 - val_loss: 124.3291\n",
      "Epoch 157/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.0824 - val_loss: 124.3101\n",
      "Epoch 158/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 119.5138 - val_loss: 125.2324\n",
      "Epoch 159/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3900 - val_loss: 126.7527\n",
      "Epoch 160/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.4309 - val_loss: 125.0909\n",
      "Epoch 161/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.2967 - val_loss: 124.4130\n",
      "Epoch 162/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.4098 - val_loss: 124.1536\n",
      "Epoch 163/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3184 - val_loss: 124.9210\n",
      "Epoch 164/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3868 - val_loss: 126.2172\n",
      "Epoch 165/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.2592 - val_loss: 124.3874\n",
      "Epoch 166/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.1643 - val_loss: 124.7016\n",
      "Epoch 167/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.2039 - val_loss: 125.2114\n",
      "Epoch 168/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.1554 - val_loss: 124.1724\n",
      "Epoch 169/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.2728 - val_loss: 125.6270\n",
      "Epoch 170/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3900 - val_loss: 125.8145\n",
      "Epoch 171/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.2729 - val_loss: 124.7371\n",
      "Epoch 172/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.4844 - val_loss: 125.2699\n",
      "Epoch 173/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.4759 - val_loss: 124.1247\n",
      "Epoch 174/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 119.1710 - val_loss: 124.3995\n",
      "Epoch 175/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3227 - val_loss: 125.6272\n",
      "Epoch 176/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.2044 - val_loss: 125.7967\n",
      "Epoch 177/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3092 - val_loss: 124.9270\n",
      "Epoch 178/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.0852 - val_loss: 125.1054\n",
      "Epoch 179/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.0248 - val_loss: 124.8493\n",
      "Epoch 180/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 119.0591 - val_loss: 124.9752\n",
      "Epoch 181/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.2039 - val_loss: 124.9109\n",
      "Epoch 182/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3283 - val_loss: 124.8807\n",
      "Epoch 183/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.4165 - val_loss: 125.1098\n",
      "Epoch 184/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.2336 - val_loss: 125.0475\n",
      "Epoch 185/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.2863 - val_loss: 125.1344\n",
      "Epoch 186/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.2602 - val_loss: 124.4636\n",
      "Epoch 187/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.1551 - val_loss: 125.2853\n",
      "Epoch 188/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 119.7897 - val_loss: 124.7823\n",
      "Epoch 189/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.1537 - val_loss: 125.0794\n",
      "Epoch 190/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 119.4361 - val_loss: 124.7549\n",
      "Epoch 191/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 119.2856 - val_loss: 126.2062\n",
      "Epoch 192/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 119.4892 - val_loss: 124.6480\n",
      "Epoch 193/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.0966 - val_loss: 124.5364\n",
      "Epoch 194/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 119.4600 - val_loss: 124.9645\n",
      "Epoch 195/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 119.1590 - val_loss: 124.7556\n",
      "Epoch 196/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 119.0626 - val_loss: 124.6559\n",
      "Epoch 197/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.1170 - val_loss: 124.4565\n",
      "Epoch 198/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 119.1518 - val_loss: 125.3712\n",
      "Epoch 199/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 119.1632 - val_loss: 125.3274\n",
      "Epoch 200/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 119.2718 - val_loss: 126.3929\n",
      "Epoch 201/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.1606 - val_loss: 124.3883\n",
      "Epoch 202/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.0887 - val_loss: 124.5134\n",
      "Epoch 203/300\n",
      "73/73 [==============================] - ETA: 0s - loss: 118.9499Restoring model weights from the end of the best epoch: 173.\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.9499 - val_loss: 124.9903\n",
      "Epoch 203: early stopping\n",
      "'########################################################Model0\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 18ms/step - loss: 145.1722 - val_loss: 140.7588\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 135.6700 - val_loss: 139.8418\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 134.1626 - val_loss: 138.2848\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 131.1189 - val_loss: 133.7881\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 127.2660 - val_loss: 132.5012\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 126.5020 - val_loss: 133.3400\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 125.8713 - val_loss: 131.2024\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 125.9324 - val_loss: 131.3284\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 125.3693 - val_loss: 130.8660\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 124.7224 - val_loss: 129.5991\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 124.9739 - val_loss: 130.0820\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 124.3494 - val_loss: 130.1203\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 124.6530 - val_loss: 129.3847\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.9467 - val_loss: 129.2507\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.6653 - val_loss: 130.0930\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 124.0997 - val_loss: 129.3032\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.6356 - val_loss: 128.8234\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.4984 - val_loss: 128.5845\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.2261 - val_loss: 129.5157\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.4215 - val_loss: 128.9279\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.3312 - val_loss: 128.9700\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 123.7638 - val_loss: 128.3099\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.1660 - val_loss: 128.8107\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.6952 - val_loss: 128.8736\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.9053 - val_loss: 128.6861\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.6148 - val_loss: 128.2510\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.6894 - val_loss: 129.3697\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.3304 - val_loss: 128.6161\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.5007 - val_loss: 128.1404\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.5891 - val_loss: 128.6336\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.4823 - val_loss: 128.0514\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.6936 - val_loss: 128.0024\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.3903 - val_loss: 127.7163\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.2752 - val_loss: 129.1246\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.4718 - val_loss: 128.1844\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.3223 - val_loss: 128.0098\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.7318 - val_loss: 127.5384\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.0684 - val_loss: 128.7535\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.9983 - val_loss: 128.9978\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.2747 - val_loss: 127.8345\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.8560 - val_loss: 127.4608\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 122.0834 - val_loss: 127.7712\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.2938 - val_loss: 127.6802\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.0026 - val_loss: 127.2245\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.1701 - val_loss: 127.3650\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.7080 - val_loss: 128.1664\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.9717 - val_loss: 129.0119\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.1498 - val_loss: 127.0901\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.2747 - val_loss: 127.4025\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.4459 - val_loss: 129.2266\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.3118 - val_loss: 127.5501\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.8819 - val_loss: 128.0145\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.6198 - val_loss: 127.1496\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 121.4495 - val_loss: 127.3974\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.6040 - val_loss: 127.1859\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.6943 - val_loss: 127.9141\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.6660 - val_loss: 128.2759\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.5828 - val_loss: 127.3632\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.4472 - val_loss: 127.6942\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.3740 - val_loss: 126.9633\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.5105 - val_loss: 127.4849\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.0014 - val_loss: 128.0685\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.5561 - val_loss: 127.5577\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.6003 - val_loss: 127.4772\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.2685 - val_loss: 127.0563\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.3396 - val_loss: 127.2105\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 121.2946 - val_loss: 127.1814\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.3367 - val_loss: 127.3344\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.0037 - val_loss: 127.3198\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.5369 - val_loss: 128.6550\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 121.8210 - val_loss: 128.6350\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.4947 - val_loss: 126.7546\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.0803 - val_loss: 126.9782\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 121.2907 - val_loss: 127.0980\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.3648 - val_loss: 127.3837\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.2677 - val_loss: 126.9336\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.7300 - val_loss: 127.0491\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.6064 - val_loss: 127.8295\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.0471 - val_loss: 127.9935\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.0673 - val_loss: 126.6254\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.7017 - val_loss: 127.2739\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.0787 - val_loss: 126.6639\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.1932 - val_loss: 127.5943\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.2697 - val_loss: 126.3954\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.5621 - val_loss: 127.0865\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.0627 - val_loss: 126.7861\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.9083 - val_loss: 127.1494\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.2899 - val_loss: 127.2990\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.2264 - val_loss: 126.8053\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.3292 - val_loss: 126.5071\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.9216 - val_loss: 126.2159\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.0921 - val_loss: 127.2714\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.0626 - val_loss: 126.7534\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.6925 - val_loss: 126.5757\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.9391 - val_loss: 126.7003\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.9025 - val_loss: 126.5453\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.9858 - val_loss: 126.1034\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.6869 - val_loss: 126.3736\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.8526 - val_loss: 126.6593\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.7099 - val_loss: 125.9593\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 120.8168 - val_loss: 127.2239\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.6716 - val_loss: 125.9282\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.9450 - val_loss: 126.4584\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.3170 - val_loss: 126.2046\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.8087 - val_loss: 127.1491\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.8988 - val_loss: 127.0417\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.0751 - val_loss: 127.1527\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.7492 - val_loss: 126.9542\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.7906 - val_loss: 126.1858\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.6188 - val_loss: 126.0643\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.8532 - val_loss: 127.1424\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.9870 - val_loss: 126.4549\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.5536 - val_loss: 126.0203\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.6371 - val_loss: 126.1752\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.6727 - val_loss: 126.2955\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 120.6434 - val_loss: 125.9174\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.4676 - val_loss: 126.1040\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.9163 - val_loss: 127.1350\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.6829 - val_loss: 127.1158\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.9527 - val_loss: 126.0524\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.6895 - val_loss: 126.4867\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.9489 - val_loss: 127.3328\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 120.7822 - val_loss: 126.3933\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.7999 - val_loss: 125.8755\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.5404 - val_loss: 127.1181\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.5810 - val_loss: 126.9887\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.6152 - val_loss: 126.7592\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.7619 - val_loss: 126.3345\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.0084 - val_loss: 125.9265\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.6554 - val_loss: 127.6574\n",
      "Epoch 131/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.5197 - val_loss: 126.3090\n",
      "Epoch 132/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.7282 - val_loss: 126.4228\n",
      "Epoch 133/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.7587 - val_loss: 126.5928\n",
      "Epoch 134/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 121.2444 - val_loss: 126.7949\n",
      "Epoch 135/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.0257 - val_loss: 126.0751\n",
      "Epoch 136/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.7781 - val_loss: 126.0711\n",
      "Epoch 137/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.4217 - val_loss: 126.5957\n",
      "Epoch 138/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.8132 - val_loss: 127.7490\n",
      "Epoch 139/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.4601 - val_loss: 125.8980\n",
      "Epoch 140/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.5295 - val_loss: 126.9389\n",
      "Epoch 141/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.6701 - val_loss: 125.8830\n",
      "Epoch 142/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.4319 - val_loss: 126.0398\n",
      "Epoch 143/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.5019 - val_loss: 125.5718\n",
      "Epoch 144/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.4897 - val_loss: 126.3677\n",
      "Epoch 145/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 120.5617 - val_loss: 125.9496\n",
      "Epoch 146/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.4002 - val_loss: 126.0856\n",
      "Epoch 147/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.3155 - val_loss: 125.9067\n",
      "Epoch 148/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.2803 - val_loss: 126.1925\n",
      "Epoch 149/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.2099 - val_loss: 126.5785\n",
      "Epoch 150/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.5301 - val_loss: 126.2298\n",
      "Epoch 151/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.2455 - val_loss: 126.0241\n",
      "Epoch 152/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.7511 - val_loss: 125.9272\n",
      "Epoch 153/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.5613 - val_loss: 125.5130\n",
      "Epoch 154/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.5995 - val_loss: 125.6326\n",
      "Epoch 155/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.4936 - val_loss: 126.1274\n",
      "Epoch 156/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.6107 - val_loss: 125.7467\n",
      "Epoch 157/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.5077 - val_loss: 126.4386\n",
      "Epoch 158/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.2912 - val_loss: 125.9686\n",
      "Epoch 159/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.4212 - val_loss: 125.8723\n",
      "Epoch 160/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.5457 - val_loss: 126.0456\n",
      "Epoch 161/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 120.2595 - val_loss: 125.5255\n",
      "Epoch 162/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.3649 - val_loss: 126.9798\n",
      "Epoch 163/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.1974 - val_loss: 125.7782\n",
      "Epoch 164/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.1702 - val_loss: 125.5294\n",
      "Epoch 165/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.1829 - val_loss: 125.7795\n",
      "Epoch 166/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.3034 - val_loss: 125.5444\n",
      "Epoch 167/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.5926 - val_loss: 125.6145\n",
      "Epoch 168/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.2693 - val_loss: 125.5696\n",
      "Epoch 169/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.2817 - val_loss: 125.8542\n",
      "Epoch 170/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.5025 - val_loss: 126.6746\n",
      "Epoch 171/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.2763 - val_loss: 125.6180\n",
      "Epoch 172/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.1374 - val_loss: 126.2652\n",
      "Epoch 173/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.5709 - val_loss: 126.2362\n",
      "Epoch 174/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.3164 - val_loss: 125.7446\n",
      "Epoch 175/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.4236 - val_loss: 125.5670\n",
      "Epoch 176/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.3937 - val_loss: 126.0986\n",
      "Epoch 177/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.5017 - val_loss: 125.5519\n",
      "Epoch 178/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.3593 - val_loss: 125.3928\n",
      "Epoch 179/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.0735 - val_loss: 125.9708\n",
      "Epoch 180/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.1160 - val_loss: 125.2497\n",
      "Epoch 181/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.2083 - val_loss: 125.6610\n",
      "Epoch 182/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.4202 - val_loss: 126.1982\n",
      "Epoch 183/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.3606 - val_loss: 125.3867\n",
      "Epoch 184/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.0831 - val_loss: 125.4384\n",
      "Epoch 185/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.0605 - val_loss: 125.3873\n",
      "Epoch 186/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.1152 - val_loss: 125.6037\n",
      "Epoch 187/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.1259 - val_loss: 126.3088\n",
      "Epoch 188/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.1068 - val_loss: 126.4596\n",
      "Epoch 189/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.1241 - val_loss: 125.3975\n",
      "Epoch 190/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.5455 - val_loss: 125.6344\n",
      "Epoch 191/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.0745 - val_loss: 125.9552\n",
      "Epoch 192/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.1003 - val_loss: 125.5766\n",
      "Epoch 193/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 120.0313 - val_loss: 125.3380\n",
      "Epoch 194/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 120.1993 - val_loss: 125.5382\n",
      "Epoch 195/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.2128 - val_loss: 126.1729\n",
      "Epoch 196/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.2188 - val_loss: 125.6362\n",
      "Epoch 197/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.0509 - val_loss: 125.8137\n",
      "Epoch 198/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.5018 - val_loss: 125.3293\n",
      "Epoch 199/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.0677 - val_loss: 126.4329\n",
      "Epoch 200/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.1384 - val_loss: 127.0345\n",
      "Epoch 201/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.3190 - val_loss: 125.2602\n",
      "Epoch 202/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.3089 - val_loss: 125.6546\n",
      "Epoch 203/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.2862 - val_loss: 125.7893\n",
      "Epoch 204/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.0278 - val_loss: 125.4996\n",
      "Epoch 205/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.9008 - val_loss: 126.1547\n",
      "Epoch 206/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.1349 - val_loss: 125.8863\n",
      "Epoch 207/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.3815 - val_loss: 125.9908\n",
      "Epoch 208/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.9013 - val_loss: 125.7635\n",
      "Epoch 209/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.0742 - val_loss: 125.5535\n",
      "Epoch 210/300\n",
      "72/73 [============================>.] - ETA: 0s - loss: 119.9742Restoring model weights from the end of the best epoch: 180.\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.8883 - val_loss: 125.8658\n",
      "Epoch 210: early stopping\n",
      "'########################################################Model1\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 18ms/step - loss: 149.8909 - val_loss: 141.6812\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 136.8653 - val_loss: 140.8781\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 135.8025 - val_loss: 139.9203\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 134.5646 - val_loss: 138.8879\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 133.0461 - val_loss: 137.4054\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 130.6603 - val_loss: 133.8611\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 128.7239 - val_loss: 134.0130\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 126.9299 - val_loss: 135.1602\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 126.9457 - val_loss: 132.8570\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 125.4926 - val_loss: 131.8053\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 125.0173 - val_loss: 130.2040\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 124.8625 - val_loss: 130.0997\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 124.1746 - val_loss: 129.5753\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 124.5864 - val_loss: 130.7998\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.9741 - val_loss: 129.2719\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.4535 - val_loss: 129.1794\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.6106 - val_loss: 131.1071\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 124.0233 - val_loss: 128.6586\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.9318 - val_loss: 131.1759\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.8608 - val_loss: 128.5113\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 124.0465 - val_loss: 128.5232\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 123.0815 - val_loss: 128.6908\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.7328 - val_loss: 128.2694\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.7774 - val_loss: 129.9020\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.5491 - val_loss: 128.2567\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.3573 - val_loss: 128.5327\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.9957 - val_loss: 128.9899\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.5042 - val_loss: 128.5726\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.7949 - val_loss: 128.9240\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 122.0922 - val_loss: 127.6086\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.0109 - val_loss: 127.3757\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.2711 - val_loss: 128.3715\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 122.2240 - val_loss: 130.9891\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 122.4382 - val_loss: 128.3389\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 121.8024 - val_loss: 127.3718\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 121.5924 - val_loss: 127.8816\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.5656 - val_loss: 127.6611\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.0631 - val_loss: 127.8899\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.7629 - val_loss: 128.3134\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 122.4499 - val_loss: 127.3379\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.5453 - val_loss: 126.9700\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.6006 - val_loss: 127.7886\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.3218 - val_loss: 127.0584\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 121.3953 - val_loss: 126.8479\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 121.2711 - val_loss: 127.0942\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 121.2094 - val_loss: 126.5094\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 121.2602 - val_loss: 127.5674\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.4396 - val_loss: 128.3646\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.4309 - val_loss: 127.3921\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.8387 - val_loss: 126.8304\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 121.0392 - val_loss: 127.8738\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 121.0270 - val_loss: 126.6774\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 121.1965 - val_loss: 126.5072\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 121.3269 - val_loss: 126.7289\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.7845 - val_loss: 126.9536\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 121.0290 - val_loss: 127.7037\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 120.9304 - val_loss: 126.9000\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 120.9024 - val_loss: 126.8453\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 121.1993 - val_loss: 127.2468\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.3950 - val_loss: 126.7547\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 121.3791 - val_loss: 126.5428\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 121.1090 - val_loss: 127.1983\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 121.2615 - val_loss: 126.4022\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 120.9167 - val_loss: 125.9932\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 120.7589 - val_loss: 126.5355\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.7027 - val_loss: 125.8351\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 121.3841 - val_loss: 126.6257\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 120.6294 - val_loss: 126.6183\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 120.7051 - val_loss: 127.4454\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.7494 - val_loss: 125.9141\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.4413 - val_loss: 126.4463\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 120.8422 - val_loss: 126.1970\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 120.6351 - val_loss: 125.9489\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.6139 - val_loss: 126.0077\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.1747 - val_loss: 126.2011\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 120.6421 - val_loss: 125.9640\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 121.0105 - val_loss: 127.2067\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 120.4597 - val_loss: 127.2006\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.6363 - val_loss: 126.0989\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.6770 - val_loss: 126.2452\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 1s 21ms/step - loss: 121.1595 - val_loss: 127.1628\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 120.7745 - val_loss: 126.7343\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.6161 - val_loss: 126.2585\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 120.4725 - val_loss: 126.0910\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 120.9238 - val_loss: 126.2099\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 120.4411 - val_loss: 125.9797\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.2850 - val_loss: 126.0242\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 120.4139 - val_loss: 126.1652\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.6983 - val_loss: 126.0901\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 120.8277 - val_loss: 126.0698\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 120.2092 - val_loss: 127.5292\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 120.4012 - val_loss: 126.0649\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 120.2954 - val_loss: 125.6288\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 120.2748 - val_loss: 126.5494\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 121.1399 - val_loss: 126.5958\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 120.9625 - val_loss: 126.7565\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.5476 - val_loss: 127.4290\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 1s 21ms/step - loss: 120.6477 - val_loss: 126.1882\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 120.4209 - val_loss: 125.8358\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 120.3371 - val_loss: 127.4292\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.3838 - val_loss: 125.4937\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 120.4915 - val_loss: 125.3800\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 120.6072 - val_loss: 126.4260\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.4047 - val_loss: 125.6400\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 120.6354 - val_loss: 125.8828\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 120.3729 - val_loss: 126.2015\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.5933 - val_loss: 125.9490\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.2853 - val_loss: 126.2762\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 120.4135 - val_loss: 126.7291\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 120.7567 - val_loss: 125.6085\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 120.3958 - val_loss: 125.6132\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 120.3435 - val_loss: 125.6982\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 120.5337 - val_loss: 127.1124\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 120.5734 - val_loss: 126.2151\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 120.5871 - val_loss: 126.2321\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.5191 - val_loss: 125.5922\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 120.2923 - val_loss: 125.6730\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 120.5802 - val_loss: 126.6131\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 120.3570 - val_loss: 125.5152\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 120.3427 - val_loss: 126.4759\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.3224 - val_loss: 125.3660\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 1s 21ms/step - loss: 120.6783 - val_loss: 125.3898\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.3380 - val_loss: 126.4192\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.2253 - val_loss: 126.2962\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 120.1510 - val_loss: 125.8564\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 120.2065 - val_loss: 125.8073\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.2454 - val_loss: 125.9210\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 120.4965 - val_loss: 125.5787\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 120.1881 - val_loss: 125.7656\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 120.2923 - val_loss: 125.5310\n",
      "Epoch 131/300\n",
      "73/73 [==============================] - 2s 22ms/step - loss: 120.0208 - val_loss: 125.5263\n",
      "Epoch 132/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 120.7090 - val_loss: 125.6055\n",
      "Epoch 133/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 120.1342 - val_loss: 125.9437\n",
      "Epoch 134/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.0322 - val_loss: 125.3492\n",
      "Epoch 135/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 120.2501 - val_loss: 126.5499\n",
      "Epoch 136/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 120.5458 - val_loss: 125.9283\n",
      "Epoch 137/300\n",
      "73/73 [==============================] - 1s 21ms/step - loss: 119.9656 - val_loss: 125.9073\n",
      "Epoch 138/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 121.2103 - val_loss: 125.7281\n",
      "Epoch 139/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 120.0984 - val_loss: 126.0898\n",
      "Epoch 140/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 120.2442 - val_loss: 126.2692\n",
      "Epoch 141/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 120.1615 - val_loss: 125.8166\n",
      "Epoch 142/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.0839 - val_loss: 125.6327\n",
      "Epoch 143/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 120.0390 - val_loss: 125.5971\n",
      "Epoch 144/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 119.9661 - val_loss: 125.4714\n",
      "Epoch 145/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 119.9766 - val_loss: 125.5792\n",
      "Epoch 146/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 120.2913 - val_loss: 125.2554\n",
      "Epoch 147/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.6087 - val_loss: 126.4825\n",
      "Epoch 148/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.0583 - val_loss: 125.4223\n",
      "Epoch 149/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 120.2062 - val_loss: 125.3610\n",
      "Epoch 150/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 120.0030 - val_loss: 125.2720\n",
      "Epoch 151/300\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 120.2557 - val_loss: 125.9499\n",
      "Epoch 152/300\n",
      "73/73 [==============================] - 1s 21ms/step - loss: 119.8986 - val_loss: 126.0258\n",
      "Epoch 153/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.4635 - val_loss: 127.3293\n",
      "Epoch 154/300\n",
      "73/73 [==============================] - 1s 21ms/step - loss: 120.5823 - val_loss: 125.7245\n",
      "Epoch 155/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.2596 - val_loss: 126.2667\n",
      "Epoch 156/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 120.2057 - val_loss: 125.0591\n",
      "Epoch 157/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 120.0265 - val_loss: 126.0001\n",
      "Epoch 158/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 120.1178 - val_loss: 126.8560\n",
      "Epoch 159/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 120.6018 - val_loss: 125.4482\n",
      "Epoch 160/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 120.2270 - val_loss: 125.6735\n",
      "Epoch 161/300\n",
      "73/73 [==============================] - 1s 21ms/step - loss: 120.1476 - val_loss: 126.8209\n",
      "Epoch 162/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.2882 - val_loss: 125.2601\n",
      "Epoch 163/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 120.1755 - val_loss: 125.2573\n",
      "Epoch 164/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.8760 - val_loss: 125.7346\n",
      "Epoch 165/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 119.9315 - val_loss: 125.5649\n",
      "Epoch 166/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 120.1040 - val_loss: 126.1570\n",
      "Epoch 167/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 120.1951 - val_loss: 125.5685\n",
      "Epoch 168/300\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 120.4818 - val_loss: 126.8030\n",
      "Epoch 169/300\n",
      "73/73 [==============================] - 1s 21ms/step - loss: 120.2450 - val_loss: 126.3434\n",
      "Epoch 170/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.2819 - val_loss: 127.9783\n",
      "Epoch 171/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.1967 - val_loss: 126.2260\n",
      "Epoch 172/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 120.1650 - val_loss: 125.3063\n",
      "Epoch 173/300\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 120.3575 - val_loss: 126.5286\n",
      "Epoch 174/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 120.8480 - val_loss: 127.5810\n",
      "Epoch 175/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.1964 - val_loss: 125.4907\n",
      "Epoch 176/300\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 120.1326 - val_loss: 125.1305\n",
      "Epoch 177/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.1734 - val_loss: 127.4922\n",
      "Epoch 178/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.8424 - val_loss: 126.4478\n",
      "Epoch 179/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 120.0682 - val_loss: 125.9342\n",
      "Epoch 180/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 120.1060 - val_loss: 126.2652\n",
      "Epoch 181/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.3691 - val_loss: 125.2163\n",
      "Epoch 182/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 120.1803 - val_loss: 126.2951\n",
      "Epoch 183/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 120.0627 - val_loss: 126.6106\n",
      "Epoch 184/300\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 119.9364 - val_loss: 125.7178\n",
      "Epoch 185/300\n",
      "73/73 [==============================] - 2s 22ms/step - loss: 119.9113 - val_loss: 125.8507\n",
      "Epoch 186/300\n",
      "71/73 [============================>.] - ETA: 0s - loss: 120.4073Restoring model weights from the end of the best epoch: 156.\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 120.0817 - val_loss: 125.7625\n",
      "Epoch 186: early stopping\n",
      "'########################################################Model2\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 3s 25ms/step - loss: 150.1168 - val_loss: 142.7041\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 137.4979 - val_loss: 141.3643\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 136.2730 - val_loss: 140.3622\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 134.9410 - val_loss: 139.0614\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 133.1678 - val_loss: 137.2296\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 130.0723 - val_loss: 132.5041\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 21ms/step - loss: 126.6629 - val_loss: 131.5226\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 125.9715 - val_loss: 131.3081\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 125.6654 - val_loss: 130.2323\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 125.6203 - val_loss: 131.1413\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 125.2634 - val_loss: 131.6540\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 124.7621 - val_loss: 131.6885\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 124.5834 - val_loss: 130.4635\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 124.1932 - val_loss: 129.4031\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 125.3008 - val_loss: 130.1956\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 123.8643 - val_loss: 130.4360\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 123.8607 - val_loss: 130.2025\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 124.1762 - val_loss: 130.2118\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 123.7412 - val_loss: 129.7600\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 123.5188 - val_loss: 129.5137\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 123.3994 - val_loss: 128.7099\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 123.1011 - val_loss: 128.7746\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 123.3482 - val_loss: 129.7137\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 123.4119 - val_loss: 129.0622\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 21ms/step - loss: 123.1270 - val_loss: 129.0247\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 122.8237 - val_loss: 128.0839\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 122.5368 - val_loss: 128.5755\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 122.8562 - val_loss: 128.3758\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 123.1510 - val_loss: 128.7603\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 122.4978 - val_loss: 128.0932\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 122.0781 - val_loss: 127.7271\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 122.5339 - val_loss: 127.4917\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 122.0589 - val_loss: 128.1811\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 21ms/step - loss: 122.2384 - val_loss: 128.4361\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 122.8488 - val_loss: 128.0338\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 121.9901 - val_loss: 127.5761\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 122.1239 - val_loss: 127.7215\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 121.9362 - val_loss: 127.3478\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 121.8054 - val_loss: 127.3375\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 122.1406 - val_loss: 128.3590\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 121.7033 - val_loss: 128.2453\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 1s 21ms/step - loss: 121.7341 - val_loss: 128.3528\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 122.1251 - val_loss: 127.2152\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 121.6564 - val_loss: 127.9284\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 121.6896 - val_loss: 129.1954\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 122.3379 - val_loss: 128.0940\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 121.4889 - val_loss: 126.9846\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 121.2638 - val_loss: 128.2423\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 1s 21ms/step - loss: 121.5761 - val_loss: 127.0304\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 121.4067 - val_loss: 127.6948\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 121.3680 - val_loss: 126.7551\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 121.3129 - val_loss: 127.1139\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 121.0478 - val_loss: 127.7720\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 121.2057 - val_loss: 127.2299\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 121.2880 - val_loss: 127.4005\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 121.8063 - val_loss: 126.9176\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 121.9008 - val_loss: 126.8175\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 121.5424 - val_loss: 127.8508\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 121.0320 - val_loss: 127.3903\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 121.7310 - val_loss: 127.0470\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 121.2226 - val_loss: 127.8656\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 121.0013 - val_loss: 127.9582\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 122.2374 - val_loss: 126.4704\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 121.1743 - val_loss: 126.5223\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 121.1699 - val_loss: 126.4266\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 121.0163 - val_loss: 126.1259\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 120.5454 - val_loss: 126.9923\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.7609 - val_loss: 126.5071\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 121.6136 - val_loss: 126.0953\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.6473 - val_loss: 128.1354\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 121.2976 - val_loss: 126.1273\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.8159 - val_loss: 128.3593\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 121.4157 - val_loss: 126.8920\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 121.2321 - val_loss: 126.9853\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 1s 21ms/step - loss: 120.5985 - val_loss: 126.8029\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 120.6329 - val_loss: 126.7033\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 120.5400 - val_loss: 125.7632\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.7254 - val_loss: 125.8439\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 120.3607 - val_loss: 126.4076\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.8142 - val_loss: 127.0525\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 1s 21ms/step - loss: 120.9522 - val_loss: 126.4427\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.2103 - val_loss: 125.8076\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 120.2093 - val_loss: 126.6475\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.5503 - val_loss: 126.0938\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 120.1705 - val_loss: 125.7489\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 120.5750 - val_loss: 127.1231\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 120.4042 - val_loss: 126.1400\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.2777 - val_loss: 125.9953\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 120.5829 - val_loss: 126.0604\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 121.0697 - val_loss: 126.6760\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.3337 - val_loss: 126.1417\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.4634 - val_loss: 126.5036\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 120.4540 - val_loss: 126.8552\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 120.5376 - val_loss: 125.6558\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 120.6253 - val_loss: 127.1111\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 1s 21ms/step - loss: 120.7508 - val_loss: 126.2500\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 120.4928 - val_loss: 126.1294\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.3869 - val_loss: 126.0624\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 120.5398 - val_loss: 125.3627\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.1307 - val_loss: 127.0878\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.6661 - val_loss: 127.8736\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 121.2458 - val_loss: 125.9694\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 120.1917 - val_loss: 125.9796\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.1794 - val_loss: 125.6038\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.1422 - val_loss: 125.4479\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 120.5276 - val_loss: 126.2044\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 1s 21ms/step - loss: 120.6686 - val_loss: 126.1926\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.6973 - val_loss: 125.9034\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 120.4240 - val_loss: 125.8117\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 120.4107 - val_loss: 126.7367\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.2215 - val_loss: 126.7951\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 120.4261 - val_loss: 125.6973\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.2061 - val_loss: 126.8272\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.9952 - val_loss: 126.0830\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.4687 - val_loss: 125.8515\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 120.0611 - val_loss: 126.2755\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 120.1219 - val_loss: 125.1987\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 120.6034 - val_loss: 125.8421\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.2728 - val_loss: 126.3328\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 119.9969 - val_loss: 125.7988\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.2769 - val_loss: 126.0169\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.4835 - val_loss: 126.7320\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.2389 - val_loss: 125.4415\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.0538 - val_loss: 125.2287\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 120.4734 - val_loss: 125.9799\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.3035 - val_loss: 125.5046\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 120.0150 - val_loss: 125.7060\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.7543 - val_loss: 126.2601\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.1163 - val_loss: 125.4962\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.9591 - val_loss: 126.1428\n",
      "Epoch 131/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.2265 - val_loss: 125.2435\n",
      "Epoch 132/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 120.5912 - val_loss: 125.5165\n",
      "Epoch 133/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 120.2174 - val_loss: 125.3176\n",
      "Epoch 134/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.1545 - val_loss: 126.4542\n",
      "Epoch 135/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 120.2873 - val_loss: 125.6770\n",
      "Epoch 136/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.9953 - val_loss: 125.5979\n",
      "Epoch 137/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.9652 - val_loss: 126.0804\n",
      "Epoch 138/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.1807 - val_loss: 125.2212\n",
      "Epoch 139/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 120.2759 - val_loss: 125.4261\n",
      "Epoch 140/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 119.9675 - val_loss: 125.1604\n",
      "Epoch 141/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 120.1956 - val_loss: 125.9754\n",
      "Epoch 142/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.0373 - val_loss: 126.1316\n",
      "Epoch 143/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 120.2849 - val_loss: 126.2643\n",
      "Epoch 144/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.2544 - val_loss: 126.5857\n",
      "Epoch 145/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.6712 - val_loss: 125.8460\n",
      "Epoch 146/300\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 120.2707 - val_loss: 126.4115\n",
      "Epoch 147/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 120.8596 - val_loss: 125.5551\n",
      "Epoch 148/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 119.9132 - val_loss: 125.6496\n",
      "Epoch 149/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.2318 - val_loss: 124.9510\n",
      "Epoch 150/300\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 120.1059 - val_loss: 126.6042\n",
      "Epoch 151/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.2076 - val_loss: 124.8686\n",
      "Epoch 152/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.8166 - val_loss: 125.1037\n",
      "Epoch 153/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.2981 - val_loss: 125.0516\n",
      "Epoch 154/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 119.8816 - val_loss: 125.5948\n",
      "Epoch 155/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 120.2692 - val_loss: 125.2465\n",
      "Epoch 156/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 120.0947 - val_loss: 126.7175\n",
      "Epoch 157/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 120.2358 - val_loss: 125.4753\n",
      "Epoch 158/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.8044 - val_loss: 124.9935\n",
      "Epoch 159/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.0135 - val_loss: 125.7603\n",
      "Epoch 160/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.9943 - val_loss: 126.0829\n",
      "Epoch 161/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.0874 - val_loss: 124.9787\n",
      "Epoch 162/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 119.9951 - val_loss: 125.0261\n",
      "Epoch 163/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 120.2108 - val_loss: 126.7059\n",
      "Epoch 164/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 120.1480 - val_loss: 126.8178\n",
      "Epoch 165/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 120.3496 - val_loss: 125.7158\n",
      "Epoch 166/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.7521 - val_loss: 125.4218\n",
      "Epoch 167/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.9096 - val_loss: 126.9158\n",
      "Epoch 168/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.3842 - val_loss: 127.0854\n",
      "Epoch 169/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.9792 - val_loss: 125.8438\n",
      "Epoch 170/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 119.8549 - val_loss: 125.7868\n",
      "Epoch 171/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.1269 - val_loss: 127.1923\n",
      "Epoch 172/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7095 - val_loss: 124.9048\n",
      "Epoch 173/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 119.8471 - val_loss: 125.6966\n",
      "Epoch 174/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 119.8257 - val_loss: 125.2688\n",
      "Epoch 175/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.0551 - val_loss: 125.1402\n",
      "Epoch 176/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 120.2081 - val_loss: 126.5504\n",
      "Epoch 177/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.2130 - val_loss: 125.4917\n",
      "Epoch 178/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 119.8773 - val_loss: 125.2821\n",
      "Epoch 179/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 119.8641 - val_loss: 125.4128\n",
      "Epoch 180/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 119.8971 - val_loss: 125.3917\n",
      "Epoch 181/300\n",
      "71/73 [============================>.] - ETA: 0s - loss: 119.9662Restoring model weights from the end of the best epoch: 151.\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 119.8511 - val_loss: 124.8854\n",
      "Epoch 181: early stopping\n",
      "'########################################################Model3\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 3s 24ms/step - loss: 159.6304 - val_loss: 143.1340\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 136.2744 - val_loss: 140.0992\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 134.9419 - val_loss: 139.3478\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 133.6419 - val_loss: 137.8755\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 130.7092 - val_loss: 133.5963\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 127.1957 - val_loss: 131.7977\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 126.5254 - val_loss: 131.2558\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 125.7508 - val_loss: 132.8089\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 124.9714 - val_loss: 131.7606\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 124.7994 - val_loss: 131.0080\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 124.8650 - val_loss: 129.7985\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 124.5584 - val_loss: 129.9362\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 124.4200 - val_loss: 129.9342\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 123.9392 - val_loss: 129.4697\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 123.6406 - val_loss: 129.6805\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 123.5480 - val_loss: 128.7052\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 123.3159 - val_loss: 129.4096\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 123.6989 - val_loss: 128.5552\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 122.9580 - val_loss: 128.6537\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 122.8889 - val_loss: 128.6593\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 122.8678 - val_loss: 128.5887\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.0134 - val_loss: 128.9470\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 122.7023 - val_loss: 128.2708\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.4178 - val_loss: 129.1725\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 122.8254 - val_loss: 129.9459\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 122.5949 - val_loss: 128.3446\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 122.4875 - val_loss: 127.7275\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 122.2965 - val_loss: 128.1568\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 122.1247 - val_loss: 128.7770\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.2571 - val_loss: 128.0880\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 121.9009 - val_loss: 127.7379\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 122.3904 - val_loss: 128.1533\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 122.0191 - val_loss: 127.9310\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 122.1698 - val_loss: 127.3537\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 122.1785 - val_loss: 127.8962\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 122.1679 - val_loss: 127.4528\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 121.8096 - val_loss: 128.6496\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 121.8162 - val_loss: 128.9950\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.2393 - val_loss: 127.1496\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 121.7146 - val_loss: 127.5301\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.8935 - val_loss: 127.5883\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 122.1411 - val_loss: 127.4075\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 121.6687 - val_loss: 126.8997\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 121.6996 - val_loss: 127.7050\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 121.5142 - val_loss: 128.9667\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 122.1299 - val_loss: 128.1116\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 121.3267 - val_loss: 127.7896\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 121.6951 - val_loss: 128.3166\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 121.2187 - val_loss: 127.4348\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 121.2885 - val_loss: 128.0102\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 121.2897 - val_loss: 127.3612\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 121.4768 - val_loss: 127.0987\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 121.1774 - val_loss: 128.3700\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 121.4876 - val_loss: 129.6647\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 121.5190 - val_loss: 127.7570\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 121.7228 - val_loss: 127.7397\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 122.0335 - val_loss: 127.9775\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 121.6888 - val_loss: 126.6759\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 120.9363 - val_loss: 127.5148\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 121.4628 - val_loss: 127.0681\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.9570 - val_loss: 127.0784\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 120.8343 - val_loss: 127.8821\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 121.3674 - val_loss: 127.7298\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 121.2417 - val_loss: 127.4496\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 121.1219 - val_loss: 126.9407\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 121.0188 - val_loss: 127.7037\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.9527 - val_loss: 126.9602\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 121.0377 - val_loss: 126.6662\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 121.0163 - val_loss: 126.7877\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 120.9940 - val_loss: 127.2308\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 120.8922 - val_loss: 126.5876\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 120.9417 - val_loss: 128.0882\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 121.1740 - val_loss: 126.3738\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.6606 - val_loss: 127.9746\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 121.2395 - val_loss: 126.6922\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 120.9121 - val_loss: 127.4997\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 120.6832 - val_loss: 126.8302\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 120.7062 - val_loss: 126.5037\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 120.9874 - val_loss: 127.4864\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.7655 - val_loss: 126.9970\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 120.6527 - val_loss: 126.5784\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.6598 - val_loss: 126.8643\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.6306 - val_loss: 126.0431\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 120.6127 - val_loss: 127.3203\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.9957 - val_loss: 126.6759\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.3939 - val_loss: 126.6843\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.5408 - val_loss: 126.9956\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 121.4976 - val_loss: 128.1776\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 120.7377 - val_loss: 126.6683\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.5000 - val_loss: 126.9759\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 120.7368 - val_loss: 126.9789\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 120.4400 - val_loss: 126.4425\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 120.6236 - val_loss: 126.3415\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.3488 - val_loss: 126.5702\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.3916 - val_loss: 126.5243\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.6803 - val_loss: 126.5832\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.4974 - val_loss: 127.3119\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.7967 - val_loss: 126.0153\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 121.1005 - val_loss: 126.6618\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 120.4861 - val_loss: 126.2962\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 120.5718 - val_loss: 125.9349\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.2777 - val_loss: 127.5339\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 120.5540 - val_loss: 126.3600\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 120.7231 - val_loss: 126.3712\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.3351 - val_loss: 126.0398\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.2169 - val_loss: 127.3428\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.4442 - val_loss: 126.1286\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.2646 - val_loss: 125.9390\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.6409 - val_loss: 125.8629\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.1153 - val_loss: 125.7754\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.2677 - val_loss: 126.2903\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.1422 - val_loss: 126.7457\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 120.3630 - val_loss: 126.0575\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.5323 - val_loss: 126.3768\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.6523 - val_loss: 126.6532\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.2023 - val_loss: 125.5898\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.0141 - val_loss: 127.2322\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.2827 - val_loss: 125.3326\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 120.0519 - val_loss: 126.1315\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.9268 - val_loss: 125.6211\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 120.6689 - val_loss: 125.6884\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.4350 - val_loss: 126.4758\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 120.4031 - val_loss: 125.5050\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.1531 - val_loss: 125.9475\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 120.1223 - val_loss: 125.8708\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 120.2607 - val_loss: 126.3753\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.4912 - val_loss: 126.0811\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.4735 - val_loss: 126.4025\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.5009 - val_loss: 125.6641\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.2343 - val_loss: 125.8301\n",
      "Epoch 131/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 120.1911 - val_loss: 126.9959\n",
      "Epoch 132/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.3786 - val_loss: 125.5486\n",
      "Epoch 133/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.1305 - val_loss: 125.2223\n",
      "Epoch 134/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.1370 - val_loss: 126.0293\n",
      "Epoch 135/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.9988 - val_loss: 125.3930\n",
      "Epoch 136/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.7877 - val_loss: 125.5333\n",
      "Epoch 137/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.7917 - val_loss: 126.0900\n",
      "Epoch 138/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.0603 - val_loss: 125.5538\n",
      "Epoch 139/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.8696 - val_loss: 125.2580\n",
      "Epoch 140/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.5166 - val_loss: 128.7091\n",
      "Epoch 141/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.1167 - val_loss: 125.3209\n",
      "Epoch 142/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.8372 - val_loss: 126.3133\n",
      "Epoch 143/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.5947 - val_loss: 127.5254\n",
      "Epoch 144/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 119.9487 - val_loss: 125.4490\n",
      "Epoch 145/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 119.8302 - val_loss: 125.8710\n",
      "Epoch 146/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 120.0130 - val_loss: 126.4398\n",
      "Epoch 147/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.2737 - val_loss: 125.5604\n",
      "Epoch 148/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.9628 - val_loss: 125.7098\n",
      "Epoch 149/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 121.9232 - val_loss: 125.7869\n",
      "Epoch 150/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.9247 - val_loss: 125.0570\n",
      "Epoch 151/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.9456 - val_loss: 125.6528\n",
      "Epoch 152/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.9858 - val_loss: 125.6362\n",
      "Epoch 153/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.7488 - val_loss: 125.4989\n",
      "Epoch 154/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.5268 - val_loss: 125.0491\n",
      "Epoch 155/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.9123 - val_loss: 127.1330\n",
      "Epoch 156/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.9832 - val_loss: 125.5235\n",
      "Epoch 157/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.6119 - val_loss: 125.6062\n",
      "Epoch 158/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.9071 - val_loss: 126.3155\n",
      "Epoch 159/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.0042 - val_loss: 125.4882\n",
      "Epoch 160/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.0571 - val_loss: 126.1839\n",
      "Epoch 161/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 119.8904 - val_loss: 125.1634\n",
      "Epoch 162/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.6048 - val_loss: 126.5991\n",
      "Epoch 163/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.7242 - val_loss: 126.5325\n",
      "Epoch 164/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.4940 - val_loss: 125.4100\n",
      "Epoch 165/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.6315 - val_loss: 126.5440\n",
      "Epoch 166/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 119.7626 - val_loss: 125.0183\n",
      "Epoch 167/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 119.6025 - val_loss: 126.8343\n",
      "Epoch 168/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 119.9361 - val_loss: 125.5347\n",
      "Epoch 169/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 119.9844 - val_loss: 126.5327\n",
      "Epoch 170/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.4312 - val_loss: 125.5446\n",
      "Epoch 171/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.5571 - val_loss: 125.3774\n",
      "Epoch 172/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.4923 - val_loss: 125.3692\n",
      "Epoch 173/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 119.6794 - val_loss: 124.9696\n",
      "Epoch 174/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.7762 - val_loss: 126.7850\n",
      "Epoch 175/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.8798 - val_loss: 126.6977\n",
      "Epoch 176/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.8798 - val_loss: 126.0257\n",
      "Epoch 177/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 119.8984 - val_loss: 125.3755\n",
      "Epoch 178/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 120.2109 - val_loss: 124.8433\n",
      "Epoch 179/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.3345 - val_loss: 124.8344\n",
      "Epoch 180/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.4304 - val_loss: 124.7864\n",
      "Epoch 181/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.4062 - val_loss: 125.2525\n",
      "Epoch 182/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 119.3491 - val_loss: 125.1206\n",
      "Epoch 183/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.5010 - val_loss: 125.5727\n",
      "Epoch 184/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.5128 - val_loss: 126.0042\n",
      "Epoch 185/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.8652 - val_loss: 124.8636\n",
      "Epoch 186/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.3658 - val_loss: 125.7546\n",
      "Epoch 187/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.4164 - val_loss: 124.7506\n",
      "Epoch 188/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.3030 - val_loss: 125.8969\n",
      "Epoch 189/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.5368 - val_loss: 124.8478\n",
      "Epoch 190/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.5579 - val_loss: 125.2006\n",
      "Epoch 191/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 119.3897 - val_loss: 125.8138\n",
      "Epoch 192/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 119.9878 - val_loss: 125.6937\n",
      "Epoch 193/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 119.3710 - val_loss: 126.5049\n",
      "Epoch 194/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 119.4422 - val_loss: 125.3807\n",
      "Epoch 195/300\n",
      "73/73 [==============================] - 1s 18ms/step - loss: 119.4168 - val_loss: 125.9838\n",
      "Epoch 196/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.5995 - val_loss: 124.6555\n",
      "Epoch 197/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.3076 - val_loss: 124.8630\n",
      "Epoch 198/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 119.3797 - val_loss: 125.1000\n",
      "Epoch 199/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.1492 - val_loss: 124.9218\n",
      "Epoch 200/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.6411 - val_loss: 125.4249\n",
      "Epoch 201/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.1753 - val_loss: 124.6171\n",
      "Epoch 202/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 119.2654 - val_loss: 126.3210\n",
      "Epoch 203/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.3254 - val_loss: 125.5049\n",
      "Epoch 204/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.9517 - val_loss: 124.7928\n",
      "Epoch 205/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.1496 - val_loss: 125.4871\n",
      "Epoch 206/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 118.9588 - val_loss: 125.4738\n",
      "Epoch 207/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 119.2344 - val_loss: 125.5159\n",
      "Epoch 208/300\n",
      "73/73 [==============================] - 2s 21ms/step - loss: 119.2818 - val_loss: 126.0923\n",
      "Epoch 209/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 119.0654 - val_loss: 125.1097\n",
      "Epoch 210/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.2117 - val_loss: 124.9961\n",
      "Epoch 211/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.3493 - val_loss: 125.4211\n",
      "Epoch 212/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.2718 - val_loss: 124.5322\n",
      "Epoch 213/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.0531 - val_loss: 125.8778\n",
      "Epoch 214/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.2538 - val_loss: 124.5051\n",
      "Epoch 215/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.4727 - val_loss: 124.6035\n",
      "Epoch 216/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 119.1252 - val_loss: 124.6849\n",
      "Epoch 217/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 119.3827 - val_loss: 125.2289\n",
      "Epoch 218/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 119.3857 - val_loss: 126.2774\n",
      "Epoch 219/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 119.3776 - val_loss: 124.8658\n",
      "Epoch 220/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 119.0132 - val_loss: 124.9501\n",
      "Epoch 221/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 119.3344 - val_loss: 125.0605\n",
      "Epoch 222/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.1023 - val_loss: 125.2035\n",
      "Epoch 223/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 118.9360 - val_loss: 125.3129\n",
      "Epoch 224/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 119.0763 - val_loss: 124.8304\n",
      "Epoch 225/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 118.9190 - val_loss: 126.1655\n",
      "Epoch 226/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 119.3512 - val_loss: 125.4697\n",
      "Epoch 227/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 118.9045 - val_loss: 124.5457\n",
      "Epoch 228/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 119.2782 - val_loss: 125.4548\n",
      "Epoch 229/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 118.9324 - val_loss: 125.1411\n",
      "Epoch 230/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 118.8857 - val_loss: 124.9249\n",
      "Epoch 231/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 118.6826 - val_loss: 125.3558\n",
      "Epoch 232/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 118.9108 - val_loss: 124.8228\n",
      "Epoch 233/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 118.7017 - val_loss: 125.0901\n",
      "Epoch 234/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 119.3648 - val_loss: 125.8908\n",
      "Epoch 235/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 119.0009 - val_loss: 125.0777\n",
      "Epoch 236/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 118.7124 - val_loss: 125.0784\n",
      "Epoch 237/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 118.8624 - val_loss: 124.9987\n",
      "Epoch 238/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 118.9344 - val_loss: 125.1094\n",
      "Epoch 239/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 118.9586 - val_loss: 124.8485\n",
      "Epoch 240/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 119.0402 - val_loss: 124.9985\n",
      "Epoch 241/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 118.8670 - val_loss: 125.7937\n",
      "Epoch 242/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 119.3717 - val_loss: 125.9893\n",
      "Epoch 243/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.0757 - val_loss: 126.0626\n",
      "Epoch 244/300\n",
      "71/73 [============================>.] - ETA: 0s - loss: 118.9440Restoring model weights from the end of the best epoch: 214.\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 118.9118 - val_loss: 124.6954\n",
      "Epoch 244: early stopping\n",
      "'########################################################Model4\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 3s 23ms/step - loss: 154.4066 - val_loss: 144.6507\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 137.7624 - val_loss: 141.9822\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 137.1308 - val_loss: 141.3245\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 136.4441 - val_loss: 140.7155\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 135.6553 - val_loss: 139.8849\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 134.2782 - val_loss: 138.4709\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 132.2652 - val_loss: 136.4636\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 129.7838 - val_loss: 134.3146\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 127.5583 - val_loss: 132.4101\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 126.5964 - val_loss: 132.7038\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 126.0800 - val_loss: 131.1914\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 125.3177 - val_loss: 131.7314\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 125.3532 - val_loss: 129.8208\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 125.1041 - val_loss: 129.9542\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 125.0227 - val_loss: 133.2760\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 125.3857 - val_loss: 133.2573\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 124.9422 - val_loss: 129.4734\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 124.3796 - val_loss: 128.9283\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 123.9433 - val_loss: 131.1458\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 124.5730 - val_loss: 131.8109\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 124.2324 - val_loss: 128.5694\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 123.6177 - val_loss: 131.2948\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.3073 - val_loss: 128.6830\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 16ms/step - loss: 123.1166 - val_loss: 128.8172\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 123.3669 - val_loss: 128.3769\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 123.0810 - val_loss: 128.0882\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 122.8844 - val_loss: 128.1457\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 122.7995 - val_loss: 128.7339\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 122.9454 - val_loss: 128.5660\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 123.5009 - val_loss: 127.9771\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 122.5766 - val_loss: 127.8937\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 122.4858 - val_loss: 128.2312\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 122.5584 - val_loss: 127.6045\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 123.1095 - val_loss: 127.9740\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 122.1823 - val_loss: 127.9553\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 122.5011 - val_loss: 127.4142\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 122.0496 - val_loss: 127.5219\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 122.6311 - val_loss: 127.4229\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 122.4728 - val_loss: 128.3102\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 121.8239 - val_loss: 127.8409\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 121.8210 - val_loss: 127.0350\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 121.5526 - val_loss: 127.4686\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 121.6425 - val_loss: 127.1081\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 121.6467 - val_loss: 128.6924\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 122.0758 - val_loss: 127.8412\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 121.4804 - val_loss: 128.2796\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 121.8220 - val_loss: 126.9220\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 121.7427 - val_loss: 127.7954\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 121.3718 - val_loss: 127.1328\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 121.3621 - val_loss: 127.9537\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 121.7600 - val_loss: 127.5102\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 121.6650 - val_loss: 127.5420\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 121.6968 - val_loss: 126.8569\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.4949 - val_loss: 127.2072\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 121.4468 - val_loss: 126.5748\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.3909 - val_loss: 127.5171\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 121.4619 - val_loss: 127.5279\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 121.1595 - val_loss: 127.0866\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 121.1842 - val_loss: 127.6697\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 121.4261 - val_loss: 129.4655\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 121.5783 - val_loss: 126.7847\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 121.8677 - val_loss: 126.7511\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 121.0225 - val_loss: 126.6739\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.9648 - val_loss: 126.4827\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 120.9597 - val_loss: 127.0057\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 121.1679 - val_loss: 127.5636\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 121.2001 - val_loss: 126.8818\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.8217 - val_loss: 126.2619\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.8291 - val_loss: 126.9515\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 121.2601 - val_loss: 126.6635\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.8189 - val_loss: 126.7545\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.5741 - val_loss: 126.6330\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 1s 17ms/step - loss: 120.7688 - val_loss: 126.1352\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 120.6386 - val_loss: 125.8525\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 121.1357 - val_loss: 126.3821\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.7211 - val_loss: 127.6328\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 120.6979 - val_loss: 127.5491\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 121.1895 - val_loss: 127.3772\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.6817 - val_loss: 125.8811\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 120.5802 - val_loss: 125.9282\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.8459 - val_loss: 125.9581\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.5471 - val_loss: 126.0802\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 1s 19ms/step - loss: 120.3490 - val_loss: 125.7814\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.6278 - val_loss: 126.7531\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.7010 - val_loss: 126.1580\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.5902 - val_loss: 125.6217\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.8590 - val_loss: 126.6274\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.8648 - val_loss: 128.0678\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.6519 - val_loss: 125.8708\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.8607 - val_loss: 126.4402\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.3995 - val_loss: 125.6739\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.4214 - val_loss: 125.8376\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.1939 - val_loss: 126.4523\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.3636 - val_loss: 127.0266\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.5841 - val_loss: 128.0260\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 1s 20ms/step - loss: 120.5598 - val_loss: 125.8673\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.4868 - val_loss: 125.7775\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.2739 - val_loss: 126.8109\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.5389 - val_loss: 125.8285\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.4829 - val_loss: 126.6207\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.2553 - val_loss: 125.1403\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.7230 - val_loss: 125.4688\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.6122 - val_loss: 125.4959\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.7036 - val_loss: 126.9514\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.4196 - val_loss: 125.6001\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.4058 - val_loss: 126.0602\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.2576 - val_loss: 125.8622\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.4282 - val_loss: 126.4158\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.6437 - val_loss: 126.3873\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.4031 - val_loss: 126.4349\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.3210 - val_loss: 125.9058\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.8246 - val_loss: 125.8351\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.5245 - val_loss: 127.2727\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.7788 - val_loss: 125.7582\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.0451 - val_loss: 125.2499\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.1781 - val_loss: 125.9901\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 131/300\n",
      "71/73 [============================>.] - ETA: 0s - loss: nanRestoring model weights from the end of the best epoch: 101.\n",
      "73/73 [==============================] - 1s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 131: early stopping\n",
      "'########################################################Model5\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 18ms/step - loss: 162.8306 - val_loss: 146.1060\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 138.2047 - val_loss: 141.6020\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 136.7862 - val_loss: 140.7166\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 135.5489 - val_loss: 139.6424\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 133.9831 - val_loss: 138.2390\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 132.3810 - val_loss: 136.8943\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 130.7137 - val_loss: 135.0081\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 127.8876 - val_loss: 134.1187\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 126.7903 - val_loss: 130.9964\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 125.8102 - val_loss: 131.4265\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 125.1633 - val_loss: 131.2436\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 124.9927 - val_loss: 131.3022\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 124.7212 - val_loss: 130.2983\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 124.9562 - val_loss: 129.6615\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 124.6134 - val_loss: 129.9791\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 124.1725 - val_loss: 129.7978\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 124.0077 - val_loss: 129.1353\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.5510 - val_loss: 129.2130\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 123.3898 - val_loss: 129.1384\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.3063 - val_loss: 128.9667\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.2568 - val_loss: 128.3583\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.0095 - val_loss: 128.2902\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.2949 - val_loss: 128.0853\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.8979 - val_loss: 128.2938\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.8846 - val_loss: 130.3768\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.3342 - val_loss: 128.6711\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.0479 - val_loss: 127.8507\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.9288 - val_loss: 128.7712\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.0523 - val_loss: 127.7794\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.7628 - val_loss: 128.2300\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 123.0300 - val_loss: 127.5595\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.8331 - val_loss: 128.8260\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.8693 - val_loss: 128.3226\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.7380 - val_loss: 127.6539\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.0750 - val_loss: 129.5268\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.8430 - val_loss: 127.7546\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.1146 - val_loss: 130.2621\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.7931 - val_loss: 128.2220\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 122.5821 - val_loss: 127.9500\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.6248 - val_loss: 128.5801\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.6700 - val_loss: 128.2170\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 122.4227 - val_loss: 127.7023\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.7134 - val_loss: 127.2938\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 122.4124 - val_loss: 127.4352\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.4561 - val_loss: 127.9924\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.4086 - val_loss: 127.5588\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 122.3872 - val_loss: 127.4101\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.2644 - val_loss: 127.8859\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.3761 - val_loss: 127.7153\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.1534 - val_loss: 127.6078\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.4561 - val_loss: 127.4043\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.6236 - val_loss: 127.5330\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 122.3801 - val_loss: 127.8601\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.3370 - val_loss: 127.7794\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.4081 - val_loss: 127.6880\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.1347 - val_loss: 129.0381\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.2444 - val_loss: 127.7883\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.2166 - val_loss: 127.7942\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.4509 - val_loss: 127.5093\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.2733 - val_loss: 127.5728\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 122.7432 - val_loss: 127.4682\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.2299 - val_loss: 127.1541\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.0012 - val_loss: 128.3364\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.2787 - val_loss: 128.0878\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.0582 - val_loss: 127.4940\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.0465 - val_loss: 127.0928\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.8667 - val_loss: 127.0719\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.8328 - val_loss: 127.5779\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.7915 - val_loss: 127.5584\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.6602 - val_loss: 126.9918\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.1261 - val_loss: 128.9777\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.6849 - val_loss: 127.6328\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 121.7896 - val_loss: 126.8144\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 121.5395 - val_loss: 126.8952\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.9130 - val_loss: 127.3609\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.6030 - val_loss: 127.1908\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.9634 - val_loss: 127.2744\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.6502 - val_loss: 126.9506\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.3833 - val_loss: 127.4087\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.4532 - val_loss: 127.0767\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.7656 - val_loss: 127.5774\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 121.6391 - val_loss: 126.8781\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 121.2674 - val_loss: 126.7330\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.5931 - val_loss: 126.6473\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.1229 - val_loss: 126.7576\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.1712 - val_loss: 128.0433\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.3733 - val_loss: 126.8546\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.4948 - val_loss: 126.7852\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.1072 - val_loss: 126.7018\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.1525 - val_loss: 126.6440\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.3481 - val_loss: 126.6562\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.1073 - val_loss: 126.4338\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.4862 - val_loss: 127.2417\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.0646 - val_loss: 126.6328\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.3101 - val_loss: 127.7076\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.4941 - val_loss: 127.3788\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.0069 - val_loss: 128.3134\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.8141 - val_loss: 128.1698\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.0658 - val_loss: 126.6819\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.1182 - val_loss: 126.7252\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.1082 - val_loss: 127.0760\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.1323 - val_loss: 127.7858\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.9603 - val_loss: 127.5317\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.1445 - val_loss: 126.7703\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.7730 - val_loss: 126.3816\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.8380 - val_loss: 126.8161\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.8191 - val_loss: 126.5230\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.1435 - val_loss: 126.7758\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.3661 - val_loss: 126.8909\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.6643 - val_loss: 126.7744\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.7387 - val_loss: 126.2702\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.7287 - val_loss: 126.7759\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.5085 - val_loss: 127.3420\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.7291 - val_loss: 126.5649\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.8371 - val_loss: 126.2786\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.4855 - val_loss: 126.3293\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.7643 - val_loss: 126.8109\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.6180 - val_loss: 126.1581\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.5724 - val_loss: 126.2778\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.9392 - val_loss: 125.8278\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.5335 - val_loss: 126.2899\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.1710 - val_loss: 127.9561\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.6801 - val_loss: 125.9374\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.4374 - val_loss: 126.6069\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.9001 - val_loss: 127.8691\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.4017 - val_loss: 126.6172\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.6884 - val_loss: 126.0677\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.7239 - val_loss: 127.4937\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.6763 - val_loss: 126.4612\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.3797 - val_loss: 126.4691\n",
      "Epoch 131/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.0711 - val_loss: 126.8443\n",
      "Epoch 132/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.1375 - val_loss: 125.9663\n",
      "Epoch 133/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.7647 - val_loss: 125.6802\n",
      "Epoch 134/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.5666 - val_loss: 126.1946\n",
      "Epoch 135/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.1333 - val_loss: 126.5031\n",
      "Epoch 136/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.7216 - val_loss: 125.9705\n",
      "Epoch 137/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.2808 - val_loss: 125.7140\n",
      "Epoch 138/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.5409 - val_loss: 125.6367\n",
      "Epoch 139/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.4183 - val_loss: 125.4495\n",
      "Epoch 140/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.0539 - val_loss: 125.3065\n",
      "Epoch 141/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.2532 - val_loss: 127.0185\n",
      "Epoch 142/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.0022 - val_loss: 125.9414\n",
      "Epoch 143/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.2950 - val_loss: 125.1367\n",
      "Epoch 144/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 119.7191 - val_loss: 124.8420\n",
      "Epoch 145/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7506 - val_loss: 125.1493\n",
      "Epoch 146/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7389 - val_loss: 125.7875\n",
      "Epoch 147/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.9766 - val_loss: 125.6370\n",
      "Epoch 148/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7792 - val_loss: 124.7734\n",
      "Epoch 149/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.9069 - val_loss: 125.0751\n",
      "Epoch 150/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.8195 - val_loss: 125.9791\n",
      "Epoch 151/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.1351 - val_loss: 126.1017\n",
      "Epoch 152/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.5912 - val_loss: 126.1423\n",
      "Epoch 153/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.8986 - val_loss: 124.9854\n",
      "Epoch 154/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7489 - val_loss: 124.9545\n",
      "Epoch 155/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.6904 - val_loss: 125.5154\n",
      "Epoch 156/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.6785 - val_loss: 125.2062\n",
      "Epoch 157/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7320 - val_loss: 124.9835\n",
      "Epoch 158/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.5635 - val_loss: 125.2112\n",
      "Epoch 159/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.8118 - val_loss: 125.1188\n",
      "Epoch 160/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3311 - val_loss: 124.8434\n",
      "Epoch 161/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.9044 - val_loss: 125.1412\n",
      "Epoch 162/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 119.8251 - val_loss: 124.7970\n",
      "Epoch 163/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.2560 - val_loss: 126.2301\n",
      "Epoch 164/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 119.8671 - val_loss: 126.8863\n",
      "Epoch 165/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 119.8409 - val_loss: 124.6887\n",
      "Epoch 166/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3727 - val_loss: 125.2220\n",
      "Epoch 167/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.4209 - val_loss: 125.5389\n",
      "Epoch 168/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.8783 - val_loss: 126.5260\n",
      "Epoch 169/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7697 - val_loss: 125.1765\n",
      "Epoch 170/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.5519 - val_loss: 125.0301\n",
      "Epoch 171/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3926 - val_loss: 124.9404\n",
      "Epoch 172/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 119.7188 - val_loss: 125.9153\n",
      "Epoch 173/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.8388 - val_loss: 126.3669\n",
      "Epoch 174/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.5849 - val_loss: 125.6311\n",
      "Epoch 175/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.0992 - val_loss: 126.3780\n",
      "Epoch 176/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.9680 - val_loss: 126.7739\n",
      "Epoch 177/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3855 - val_loss: 125.0793\n",
      "Epoch 178/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 119.4066 - val_loss: 125.4766\n",
      "Epoch 179/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.6102 - val_loss: 124.9928\n",
      "Epoch 180/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.5147 - val_loss: 124.9292\n",
      "Epoch 181/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.2117 - val_loss: 124.8486\n",
      "Epoch 182/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3504 - val_loss: 125.5211\n",
      "Epoch 183/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.5268 - val_loss: 124.6116\n",
      "Epoch 184/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.1733 - val_loss: 127.4886\n",
      "Epoch 185/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 119.3772 - val_loss: 124.8467\n",
      "Epoch 186/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.1706 - val_loss: 125.5768\n",
      "Epoch 187/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.2218 - val_loss: 124.8926\n",
      "Epoch 188/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3689 - val_loss: 125.8485\n",
      "Epoch 189/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 119.6499 - val_loss: 126.9648\n",
      "Epoch 190/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7702 - val_loss: 126.0060\n",
      "Epoch 191/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 119.2692 - val_loss: 124.5032\n",
      "Epoch 192/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3731 - val_loss: 125.1982\n",
      "Epoch 193/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3760 - val_loss: 124.8137\n",
      "Epoch 194/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.1604 - val_loss: 125.6968\n",
      "Epoch 195/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3401 - val_loss: 124.3572\n",
      "Epoch 196/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.4232 - val_loss: 125.3798\n",
      "Epoch 197/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.2118 - val_loss: 125.7400\n",
      "Epoch 198/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.4648 - val_loss: 124.7226\n",
      "Epoch 199/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.4107 - val_loss: 125.4268\n",
      "Epoch 200/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3142 - val_loss: 124.8384\n",
      "Epoch 201/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7218 - val_loss: 124.7488\n",
      "Epoch 202/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.4976 - val_loss: 125.2079\n",
      "Epoch 203/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 119.3787 - val_loss: 124.7847\n",
      "Epoch 204/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.2255 - val_loss: 124.5968\n",
      "Epoch 205/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.4249 - val_loss: 125.0846\n",
      "Epoch 206/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.2750 - val_loss: 126.7000\n",
      "Epoch 207/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.6939 - val_loss: 125.6347\n",
      "Epoch 208/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.2391 - val_loss: 124.9500\n",
      "Epoch 209/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 119.2956 - val_loss: 125.3730\n",
      "Epoch 210/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3757 - val_loss: 125.0698\n",
      "Epoch 211/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.2676 - val_loss: 124.7854\n",
      "Epoch 212/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.0837 - val_loss: 124.6495\n",
      "Epoch 213/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.0798 - val_loss: 124.5911\n",
      "Epoch 214/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.1003 - val_loss: 125.6966\n",
      "Epoch 215/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.2051 - val_loss: 124.3802\n",
      "Epoch 216/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3832 - val_loss: 124.4843\n",
      "Epoch 217/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3093 - val_loss: 125.3950\n",
      "Epoch 218/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.2708 - val_loss: 125.1372\n",
      "Epoch 219/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.1533 - val_loss: 124.2414\n",
      "Epoch 220/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.1519 - val_loss: 125.2115\n",
      "Epoch 221/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 119.0537 - val_loss: 124.9719\n",
      "Epoch 222/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 119.1746 - val_loss: 125.0224\n",
      "Epoch 223/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.2409 - val_loss: 124.9414\n",
      "Epoch 224/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 119.0231 - val_loss: 124.4199\n",
      "Epoch 225/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.0844 - val_loss: 126.1427\n",
      "Epoch 226/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.2638 - val_loss: 124.5012\n",
      "Epoch 227/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.1331 - val_loss: 126.2583\n",
      "Epoch 228/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3501 - val_loss: 124.6009\n",
      "Epoch 229/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.0318 - val_loss: 124.6871\n",
      "Epoch 230/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.0788 - val_loss: 124.6553\n",
      "Epoch 231/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.4566 - val_loss: 124.6158\n",
      "Epoch 232/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.2359 - val_loss: 125.8294\n",
      "Epoch 233/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.1350 - val_loss: 124.4150\n",
      "Epoch 234/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3197 - val_loss: 124.5655\n",
      "Epoch 235/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 119.3027 - val_loss: 124.1766\n",
      "Epoch 236/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.2352 - val_loss: 125.3825\n",
      "Epoch 237/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.0210 - val_loss: 125.7602\n",
      "Epoch 238/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.1764 - val_loss: 124.2120\n",
      "Epoch 239/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.1392 - val_loss: 125.2547\n",
      "Epoch 240/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.8957 - val_loss: 124.3778\n",
      "Epoch 241/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.8194 - val_loss: 125.2922\n",
      "Epoch 242/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.9594 - val_loss: 126.1197\n",
      "Epoch 243/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.1628 - val_loss: 124.3403\n",
      "Epoch 244/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3401 - val_loss: 124.8194\n",
      "Epoch 245/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 119.1353 - val_loss: 124.1889\n",
      "Epoch 246/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.9405 - val_loss: 125.6763\n",
      "Epoch 247/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.9281 - val_loss: 124.6690\n",
      "Epoch 248/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.2997 - val_loss: 124.4605\n",
      "Epoch 249/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.2294 - val_loss: 124.7452\n",
      "Epoch 250/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.0495 - val_loss: 125.7869\n",
      "Epoch 251/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.9567 - val_loss: 124.5249\n",
      "Epoch 252/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.0969 - val_loss: 125.0830\n",
      "Epoch 253/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.9931 - val_loss: 124.9929\n",
      "Epoch 254/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.2173 - val_loss: 124.5497\n",
      "Epoch 255/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.9177 - val_loss: 124.2845\n",
      "Epoch 256/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.9073 - val_loss: 124.9166\n",
      "Epoch 257/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.9488 - val_loss: 124.7169\n",
      "Epoch 258/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.8983 - val_loss: 124.6564\n",
      "Epoch 259/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.9149 - val_loss: 124.6933\n",
      "Epoch 260/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 119.0538 - val_loss: 124.9412\n",
      "Epoch 261/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.0069 - val_loss: 124.6410\n",
      "Epoch 262/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.8888 - val_loss: 125.0294\n",
      "Epoch 263/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.1134 - val_loss: 124.6287\n",
      "Epoch 264/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.8276 - val_loss: 124.2253\n",
      "Epoch 265/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.7853 - val_loss: 124.1271\n",
      "Epoch 266/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 118.8241 - val_loss: 124.0582\n",
      "Epoch 267/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.8256 - val_loss: 124.3367\n",
      "Epoch 268/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.8223 - val_loss: 124.0005\n",
      "Epoch 269/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.0103 - val_loss: 123.8779\n",
      "Epoch 270/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.7786 - val_loss: 123.7909\n",
      "Epoch 271/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.8689 - val_loss: 124.6946\n",
      "Epoch 272/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.6946 - val_loss: 125.0469\n",
      "Epoch 273/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.9883 - val_loss: 123.8461\n",
      "Epoch 274/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 118.8554 - val_loss: 124.4136\n",
      "Epoch 275/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.8499 - val_loss: 125.8401\n",
      "Epoch 276/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 118.7022 - val_loss: 124.4449\n",
      "Epoch 277/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.7616 - val_loss: 124.7927\n",
      "Epoch 278/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.0288 - val_loss: 126.0700\n",
      "Epoch 279/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.8641 - val_loss: 124.0718\n",
      "Epoch 280/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.0422 - val_loss: 125.6363\n",
      "Epoch 281/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.5370 - val_loss: 125.0499\n",
      "Epoch 282/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 118.8087 - val_loss: 124.4357\n",
      "Epoch 283/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.8461 - val_loss: 124.3921\n",
      "Epoch 284/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.9407 - val_loss: 124.6164\n",
      "Epoch 285/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.1109 - val_loss: 125.1509\n",
      "Epoch 286/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.8428 - val_loss: 124.2489\n",
      "Epoch 287/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.8198 - val_loss: 124.0343\n",
      "Epoch 288/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.9367 - val_loss: 124.1079\n",
      "Epoch 289/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.6949 - val_loss: 124.3967\n",
      "Epoch 290/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.7922 - val_loss: 124.2165\n",
      "Epoch 291/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.9162 - val_loss: 125.1747\n",
      "Epoch 292/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.7961 - val_loss: 124.2565\n",
      "Epoch 293/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.8355 - val_loss: 125.2569\n",
      "Epoch 294/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.0863 - val_loss: 124.4591\n",
      "Epoch 295/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 118.8112 - val_loss: 124.4576\n",
      "Epoch 296/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.9339 - val_loss: 124.1119\n",
      "Epoch 297/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.9322 - val_loss: 124.0006\n",
      "Epoch 298/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.8861 - val_loss: 124.7964\n",
      "Epoch 299/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.7710 - val_loss: 124.9715\n",
      "Epoch 300/300\n",
      "70/73 [===========================>..] - ETA: 0s - loss: nanRestoring model weights from the end of the best epoch: 270.\n",
      "73/73 [==============================] - 1s 15ms/step - loss: nan - val_loss: nan\n",
      "Epoch 300: early stopping\n",
      "'########################################################Model6\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 18ms/step - loss: 147.7051 - val_loss: 142.8960\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 136.8617 - val_loss: 140.6741\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 135.2379 - val_loss: 139.0413\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 131.9625 - val_loss: 135.3522\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 128.0691 - val_loss: 133.2803\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 127.1160 - val_loss: 134.1437\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 126.5754 - val_loss: 132.2473\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 125.7811 - val_loss: 131.8949\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 125.3226 - val_loss: 130.9604\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 124.7830 - val_loss: 130.5559\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 124.9324 - val_loss: 131.5413\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.8748 - val_loss: 130.1356\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.9930 - val_loss: 129.6202\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.4717 - val_loss: 129.4686\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 123.4950 - val_loss: 128.6889\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.1810 - val_loss: 129.0596\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.8521 - val_loss: 130.6029\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.6489 - val_loss: 129.9805\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.9312 - val_loss: 129.1725\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.0338 - val_loss: 130.1621\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.3076 - val_loss: 128.9562\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.8857 - val_loss: 128.0971\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.1641 - val_loss: 128.1350\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.3757 - val_loss: 127.9276\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.3762 - val_loss: 128.4072\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.2741 - val_loss: 128.5099\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.3722 - val_loss: 130.5167\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.0490 - val_loss: 127.7821\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.3955 - val_loss: 127.3158\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.7148 - val_loss: 127.7738\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.4352 - val_loss: 128.7443\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.4933 - val_loss: 127.5622\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.7193 - val_loss: 128.0895\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.0723 - val_loss: 127.7566\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.0486 - val_loss: 127.6598\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.0799 - val_loss: 128.4555\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.9629 - val_loss: 129.0628\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.3059 - val_loss: 127.8146\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.0916 - val_loss: 127.3997\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.9504 - val_loss: 127.0608\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 121.9507 - val_loss: 127.3201\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.7342 - val_loss: 127.6434\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.7569 - val_loss: 127.3799\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.8331 - val_loss: 127.2414\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.7571 - val_loss: 127.6322\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.8355 - val_loss: 127.9943\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.6547 - val_loss: 127.9027\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.7875 - val_loss: 127.9488\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.7480 - val_loss: 127.5263\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.6108 - val_loss: 127.1115\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.8916 - val_loss: 126.8100\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.5317 - val_loss: 127.5644\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.2510 - val_loss: 127.9361\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.7053 - val_loss: 128.2217\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.6669 - val_loss: 126.9667\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.0539 - val_loss: 127.7540\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.7451 - val_loss: 127.6627\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.5690 - val_loss: 127.4708\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.6186 - val_loss: 128.7950\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.6716 - val_loss: 126.7836\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.3770 - val_loss: 126.7209\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.5622 - val_loss: 127.0845\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.9422 - val_loss: 126.9812\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.3450 - val_loss: 127.7191\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.2577 - val_loss: 126.7311\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.3612 - val_loss: 127.1862\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.2212 - val_loss: 127.2440\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.1683 - val_loss: 126.6022\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.7852 - val_loss: 126.8977\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.0068 - val_loss: 127.0265\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.3832 - val_loss: 128.7946\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.7611 - val_loss: 126.6963\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.1156 - val_loss: 127.2177\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.4164 - val_loss: 126.9868\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.4373 - val_loss: 127.2531\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.2399 - val_loss: 126.8908\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.0471 - val_loss: 127.3468\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.2378 - val_loss: 129.3933\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.1690 - val_loss: 126.7284\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.0350 - val_loss: 126.8047\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.1709 - val_loss: 126.8172\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.8944 - val_loss: 126.5129\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.9995 - val_loss: 126.3792\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.3879 - val_loss: 126.6580\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.9184 - val_loss: 127.0336\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.3447 - val_loss: 126.3526\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.7977 - val_loss: 126.7402\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.9154 - val_loss: 126.2612\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.9509 - val_loss: 128.1533\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.8943 - val_loss: 126.7410\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.4715 - val_loss: 126.8189\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.9738 - val_loss: 129.2848\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.9255 - val_loss: 126.0076\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.6903 - val_loss: 126.8771\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.8204 - val_loss: 126.3127\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.6299 - val_loss: 126.7181\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.4548 - val_loss: 126.7643\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.1132 - val_loss: 127.8431\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.7546 - val_loss: 126.4741\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.3892 - val_loss: 126.2708\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.4593 - val_loss: 126.3807\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.4466 - val_loss: 126.5912\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.6325 - val_loss: 126.2961\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.8299 - val_loss: 127.3221\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.6302 - val_loss: 126.4907\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.4958 - val_loss: 127.2184\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.4640 - val_loss: 126.1210\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.5762 - val_loss: 126.1304\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.9416 - val_loss: 126.1311\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.4439 - val_loss: 125.7739\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.3749 - val_loss: 126.1202\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.3068 - val_loss: 125.5585\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.7810 - val_loss: 126.2353\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.2869 - val_loss: 125.5663\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.0660 - val_loss: 126.0914\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.4896 - val_loss: 126.8633\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.3734 - val_loss: 126.2976\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.4910 - val_loss: 125.5879\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.3170 - val_loss: 126.2300\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.2034 - val_loss: 125.8624\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.2891 - val_loss: 127.2840\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.7734 - val_loss: 125.8897\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.5294 - val_loss: 127.0647\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.3553 - val_loss: 125.4684\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.7136 - val_loss: 126.2541\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.0792 - val_loss: 125.9500\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.6572 - val_loss: 125.8576\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.2068 - val_loss: 125.4339\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.5819 - val_loss: 127.8156\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.3576 - val_loss: 126.2334\n",
      "Epoch 131/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.1411 - val_loss: 126.4051\n",
      "Epoch 132/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.4818 - val_loss: 128.4698\n",
      "Epoch 133/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.7808 - val_loss: 125.4515\n",
      "Epoch 134/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.8691 - val_loss: 125.6046\n",
      "Epoch 135/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.9216 - val_loss: 126.5112\n",
      "Epoch 136/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.9583 - val_loss: 125.3845\n",
      "Epoch 137/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7562 - val_loss: 126.4123\n",
      "Epoch 138/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.2763 - val_loss: 125.6648\n",
      "Epoch 139/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.3834 - val_loss: 125.6856\n",
      "Epoch 140/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.9013 - val_loss: 125.4107\n",
      "Epoch 141/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7256 - val_loss: 127.7220\n",
      "Epoch 142/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.5564 - val_loss: 125.9456\n",
      "Epoch 143/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.9065 - val_loss: 125.5380\n",
      "Epoch 144/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.0393 - val_loss: 125.8422\n",
      "Epoch 145/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.1773 - val_loss: 126.2428\n",
      "Epoch 146/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7684 - val_loss: 125.3034\n",
      "Epoch 147/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.9989 - val_loss: 125.2897\n",
      "Epoch 148/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.8698 - val_loss: 125.2738\n",
      "Epoch 149/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.5951 - val_loss: 125.9872\n",
      "Epoch 150/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.0962 - val_loss: 125.6488\n",
      "Epoch 151/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.0725 - val_loss: 124.7644\n",
      "Epoch 152/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7477 - val_loss: 126.1332\n",
      "Epoch 153/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.1015 - val_loss: 125.5290\n",
      "Epoch 154/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.9172 - val_loss: 124.7299\n",
      "Epoch 155/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.6913 - val_loss: 125.4406\n",
      "Epoch 156/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.8725 - val_loss: 125.9449\n",
      "Epoch 157/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.9346 - val_loss: 124.8987\n",
      "Epoch 158/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7609 - val_loss: 127.0130\n",
      "Epoch 159/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.3589 - val_loss: 125.9718\n",
      "Epoch 160/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.9811 - val_loss: 126.1146\n",
      "Epoch 161/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.0169 - val_loss: 125.3366\n",
      "Epoch 162/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.5875 - val_loss: 125.9340\n",
      "Epoch 163/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.8842 - val_loss: 127.1075\n",
      "Epoch 164/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.0731 - val_loss: 125.5398\n",
      "Epoch 165/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7921 - val_loss: 124.9876\n",
      "Epoch 166/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7567 - val_loss: 125.7421\n",
      "Epoch 167/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7380 - val_loss: 126.1024\n",
      "Epoch 168/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.0716 - val_loss: 126.1091\n",
      "Epoch 169/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.5615 - val_loss: 124.8528\n",
      "Epoch 170/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7475 - val_loss: 125.9844\n",
      "Epoch 171/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7476 - val_loss: 125.2287\n",
      "Epoch 172/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.6214 - val_loss: 126.2196\n",
      "Epoch 173/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.4610 - val_loss: 126.1510\n",
      "Epoch 174/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.5332 - val_loss: 125.4226\n",
      "Epoch 175/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.4865 - val_loss: 124.6383\n",
      "Epoch 176/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7812 - val_loss: 124.7082\n",
      "Epoch 177/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.4308 - val_loss: 124.7886\n",
      "Epoch 178/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.6183 - val_loss: 125.3780\n",
      "Epoch 179/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.0792 - val_loss: 125.4090\n",
      "Epoch 180/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.5075 - val_loss: 125.7320\n",
      "Epoch 181/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.2212 - val_loss: 125.1637\n",
      "Epoch 182/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.4403 - val_loss: 124.8017\n",
      "Epoch 183/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.4535 - val_loss: 125.2356\n",
      "Epoch 184/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.5702 - val_loss: 127.7094\n",
      "Epoch 185/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.8509 - val_loss: 125.2704\n",
      "Epoch 186/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7358 - val_loss: 124.5702\n",
      "Epoch 187/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.3052 - val_loss: 124.8969\n",
      "Epoch 188/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3590 - val_loss: 124.4043\n",
      "Epoch 189/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7993 - val_loss: 126.0523\n",
      "Epoch 190/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.0696 - val_loss: 125.2683\n",
      "Epoch 191/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.9770 - val_loss: 124.8920\n",
      "Epoch 192/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.6570 - val_loss: 124.9534\n",
      "Epoch 193/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.5570 - val_loss: 124.5719\n",
      "Epoch 194/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.4708 - val_loss: 125.6270\n",
      "Epoch 195/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.2944 - val_loss: 125.2432\n",
      "Epoch 196/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.5589 - val_loss: 125.7295\n",
      "Epoch 197/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.5819 - val_loss: 125.6089\n",
      "Epoch 198/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.5384 - val_loss: 125.7225\n",
      "Epoch 199/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 119.5568 - val_loss: 125.7515\n",
      "Epoch 200/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 119.5031 - val_loss: 125.0372\n",
      "Epoch 201/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3434 - val_loss: 124.7230\n",
      "Epoch 202/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.6978 - val_loss: 124.6202\n",
      "Epoch 203/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 120.1388 - val_loss: 125.3542\n",
      "Epoch 204/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.4679 - val_loss: 126.0404\n",
      "Epoch 205/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.4613 - val_loss: 124.7663\n",
      "Epoch 206/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3702 - val_loss: 124.3404\n",
      "Epoch 207/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.5928 - val_loss: 125.8011\n",
      "Epoch 208/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.9584 - val_loss: 124.8004\n",
      "Epoch 209/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3344 - val_loss: 125.2007\n",
      "Epoch 210/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3134 - val_loss: 124.9733\n",
      "Epoch 211/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3030 - val_loss: 125.9370\n",
      "Epoch 212/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 119.3977 - val_loss: 125.7765\n",
      "Epoch 213/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.4104 - val_loss: 126.3460\n",
      "Epoch 214/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.5685 - val_loss: 125.6872\n",
      "Epoch 215/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.4581 - val_loss: 125.6630\n",
      "Epoch 216/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.4839 - val_loss: 126.9328\n",
      "Epoch 217/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.1191 - val_loss: 126.8587\n",
      "Epoch 218/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.6818 - val_loss: 124.5864\n",
      "Epoch 219/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.5827 - val_loss: 126.1192\n",
      "Epoch 220/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.5293 - val_loss: 125.3949\n",
      "Epoch 221/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.6615 - val_loss: 125.0752\n",
      "Epoch 222/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3734 - val_loss: 125.8204\n",
      "Epoch 223/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.2707 - val_loss: 124.4929\n",
      "Epoch 224/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.4802 - val_loss: 125.2792\n",
      "Epoch 225/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7427 - val_loss: 125.4259\n",
      "Epoch 226/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.5694 - val_loss: 124.9364\n",
      "Epoch 227/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.1938 - val_loss: 124.5230\n",
      "Epoch 228/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.4431 - val_loss: 126.8520\n",
      "Epoch 229/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.9609 - val_loss: 125.2536\n",
      "Epoch 230/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7761 - val_loss: 126.0279\n",
      "Epoch 231/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.4200 - val_loss: 124.9291\n",
      "Epoch 232/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.2944 - val_loss: 126.2447\n",
      "Epoch 233/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.4798 - val_loss: 124.3618\n",
      "Epoch 234/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.5982 - val_loss: 126.0673\n",
      "Epoch 235/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.6415 - val_loss: 125.2226\n",
      "Epoch 236/300\n",
      "70/73 [===========================>..] - ETA: 0s - loss: 119.4884Restoring model weights from the end of the best epoch: 206.\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3923 - val_loss: 126.4726\n",
      "Epoch 236: early stopping\n",
      "'########################################################Model7\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 18ms/step - loss: 197.8070 - val_loss: 183.9364\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 148.3400 - val_loss: 142.1068\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 137.1452 - val_loss: 140.9909\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 135.8497 - val_loss: 139.8823\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 134.2818 - val_loss: 138.4545\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 131.8912 - val_loss: 135.5063\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 128.2063 - val_loss: 132.8195\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 126.6631 - val_loss: 132.2323\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 125.8514 - val_loss: 131.7555\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 125.2860 - val_loss: 130.5582\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 124.9830 - val_loss: 130.1655\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 124.4674 - val_loss: 129.9516\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 124.4013 - val_loss: 130.5352\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.7376 - val_loss: 129.2098\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.7619 - val_loss: 128.9909\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.6534 - val_loss: 129.6222\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 124.0957 - val_loss: 128.8600\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.3704 - val_loss: 128.8539\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.4660 - val_loss: 128.3396\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 122.8948 - val_loss: 128.7179\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 123.0716 - val_loss: 128.4579\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.8055 - val_loss: 128.0449\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.1009 - val_loss: 128.6447\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.3044 - val_loss: 128.1522\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.8697 - val_loss: 128.9052\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.9068 - val_loss: 129.2120\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 122.3335 - val_loss: 127.9786\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 122.9759 - val_loss: 127.7525\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.5349 - val_loss: 128.4194\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 122.3518 - val_loss: 128.9949\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 122.2344 - val_loss: 128.0284\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.8991 - val_loss: 127.4252\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.1491 - val_loss: 127.2593\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 121.8127 - val_loss: 127.2676\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.0779 - val_loss: 127.6202\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.5924 - val_loss: 128.2823\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 121.9048 - val_loss: 128.9121\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.9357 - val_loss: 126.9364\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.2677 - val_loss: 126.9436\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.4194 - val_loss: 126.4600\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.7808 - val_loss: 127.8080\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 121.1855 - val_loss: 127.2718\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.1578 - val_loss: 127.0128\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.2741 - val_loss: 127.3766\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 121.2523 - val_loss: 126.9104\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 121.3570 - val_loss: 127.2491\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.2491 - val_loss: 127.2095\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 121.1621 - val_loss: 126.4608\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.3697 - val_loss: 126.7627\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.9644 - val_loss: 127.1791\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 121.1159 - val_loss: 126.9183\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.8613 - val_loss: 126.5096\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.9528 - val_loss: 126.4113\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.2540 - val_loss: 126.3100\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.7921 - val_loss: 126.6849\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.5876 - val_loss: 126.6458\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.3789 - val_loss: 127.4824\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.8913 - val_loss: 128.1798\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 121.1849 - val_loss: 126.8608\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.8065 - val_loss: 127.4491\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.9929 - val_loss: 128.4344\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.0285 - val_loss: 126.4458\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.8282 - val_loss: 127.0138\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.6330 - val_loss: 126.1548\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.9491 - val_loss: 126.2148\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.8921 - val_loss: 126.5919\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.6162 - val_loss: 126.2413\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.3398 - val_loss: 126.1699\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.7157 - val_loss: 126.1049\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.5397 - val_loss: 126.1843\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.6901 - val_loss: 126.4026\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.9424 - val_loss: 126.5715\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.4874 - val_loss: 126.4178\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.9751 - val_loss: 126.0675\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 121.3264 - val_loss: 126.9034\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.5410 - val_loss: 126.7597\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.2905 - val_loss: 126.6541\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.8729 - val_loss: 126.2520\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.5737 - val_loss: 126.7307\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.7983 - val_loss: 126.7608\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.3323 - val_loss: 126.5864\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.6103 - val_loss: 126.2194\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.5982 - val_loss: 125.5411\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.1466 - val_loss: 126.9388\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.5482 - val_loss: 126.1702\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.4266 - val_loss: 125.7442\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.2108 - val_loss: 126.2539\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.3798 - val_loss: 125.6472\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.4630 - val_loss: 126.7723\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.3740 - val_loss: 126.5506\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.1071 - val_loss: 125.7858\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.4984 - val_loss: 127.0681\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.0398 - val_loss: 126.1860\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.1128 - val_loss: 126.7063\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.4445 - val_loss: 126.8991\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.5846 - val_loss: 125.4301\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.5027 - val_loss: 126.2899\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.3287 - val_loss: 126.3489\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.0877 - val_loss: 125.6055\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.2034 - val_loss: 125.7227\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.1343 - val_loss: 126.6415\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.9725 - val_loss: 126.0525\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.0521 - val_loss: 125.7843\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.2412 - val_loss: 125.9683\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.0799 - val_loss: 125.5331\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.9945 - val_loss: 127.0781\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.4562 - val_loss: 126.9454\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.8837 - val_loss: 126.8397\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.3806 - val_loss: 126.2590\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.0549 - val_loss: 125.9148\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.9291 - val_loss: 126.5617\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.2315 - val_loss: 125.4569\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.7988 - val_loss: 126.5029\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7799 - val_loss: 125.3903\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 119.9746 - val_loss: 125.4212\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.9155 - val_loss: 126.0990\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.0445 - val_loss: 126.9994\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.3348 - val_loss: 125.2334\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.2442 - val_loss: 126.3688\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7319 - val_loss: 126.1031\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.1576 - val_loss: 126.5791\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 119.6171 - val_loss: 126.1423\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 119.8174 - val_loss: 124.6567\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.9253 - val_loss: 125.7684\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.0017 - val_loss: 128.0873\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.2747 - val_loss: 126.7745\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.9452 - val_loss: 124.6879\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.8490 - val_loss: 128.2952\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.1368 - val_loss: 126.6013\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 119.9189 - val_loss: 125.6514\n",
      "Epoch 131/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.5744 - val_loss: 126.4110\n",
      "Epoch 132/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.3926 - val_loss: 126.3437\n",
      "Epoch 133/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.6835 - val_loss: 124.8864\n",
      "Epoch 134/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 119.6617 - val_loss: 126.9357\n",
      "Epoch 135/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 119.6252 - val_loss: 126.0370\n",
      "Epoch 136/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 119.5657 - val_loss: 124.7197\n",
      "Epoch 137/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.3219 - val_loss: 126.2803\n",
      "Epoch 138/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 119.7406 - val_loss: 125.5698\n",
      "Epoch 139/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.6204 - val_loss: 125.4433\n",
      "Epoch 140/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 119.6624 - val_loss: 126.3507\n",
      "Epoch 141/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.8139 - val_loss: 126.1865\n",
      "Epoch 142/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.5433 - val_loss: 125.7687\n",
      "Epoch 143/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7918 - val_loss: 124.7001\n",
      "Epoch 144/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 119.2578 - val_loss: 125.7139\n",
      "Epoch 145/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.6636 - val_loss: 125.2253\n",
      "Epoch 146/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.0844 - val_loss: 124.6166\n",
      "Epoch 147/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3653 - val_loss: 125.6044\n",
      "Epoch 148/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 119.4469 - val_loss: 124.5808\n",
      "Epoch 149/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.9995 - val_loss: 127.3417\n",
      "Epoch 150/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 119.6354 - val_loss: 125.0821\n",
      "Epoch 151/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.5085 - val_loss: 125.0313\n",
      "Epoch 152/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.6106 - val_loss: 125.0874\n",
      "Epoch 153/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.5305 - val_loss: 125.7118\n",
      "Epoch 154/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.5572 - val_loss: 124.8646\n",
      "Epoch 155/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3010 - val_loss: 124.9270\n",
      "Epoch 156/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3508 - val_loss: 125.1465\n",
      "Epoch 157/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.2868 - val_loss: 125.6511\n",
      "Epoch 158/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.6854 - val_loss: 124.7757\n",
      "Epoch 159/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.2278 - val_loss: 125.6867\n",
      "Epoch 160/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.9698 - val_loss: 126.3986\n",
      "Epoch 161/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 119.5935 - val_loss: 125.4338\n",
      "Epoch 162/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.2378 - val_loss: 124.6400\n",
      "Epoch 163/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 119.5029 - val_loss: 126.1104\n",
      "Epoch 164/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3471 - val_loss: 124.4220\n",
      "Epoch 165/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.9384 - val_loss: 125.6639\n",
      "Epoch 166/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.8833 - val_loss: 125.0473\n",
      "Epoch 167/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.4984 - val_loss: 125.2273\n",
      "Epoch 168/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.6418 - val_loss: 124.8582\n",
      "Epoch 169/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.5703 - val_loss: 127.5322\n",
      "Epoch 170/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.5136 - val_loss: 125.0659\n",
      "Epoch 171/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.6783 - val_loss: 125.1825\n",
      "Epoch 172/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7927 - val_loss: 124.6883\n",
      "Epoch 173/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3235 - val_loss: 126.3325\n",
      "Epoch 174/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7007 - val_loss: 125.6471\n",
      "Epoch 175/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.0541 - val_loss: 126.3632\n",
      "Epoch 176/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 119.3335 - val_loss: 125.9634\n",
      "Epoch 177/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.4739 - val_loss: 124.9346\n",
      "Epoch 178/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3614 - val_loss: 124.9888\n",
      "Epoch 179/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.5098 - val_loss: 125.2666\n",
      "Epoch 180/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.5043 - val_loss: 126.3893\n",
      "Epoch 181/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 119.2824 - val_loss: 124.7723\n",
      "Epoch 182/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.2344 - val_loss: 125.2290\n",
      "Epoch 183/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 119.5270 - val_loss: 124.7063\n",
      "Epoch 184/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7703 - val_loss: 124.7629\n",
      "Epoch 185/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7940 - val_loss: 126.0881\n",
      "Epoch 186/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.6562 - val_loss: 126.3569\n",
      "Epoch 187/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.8408 - val_loss: 125.5801\n",
      "Epoch 188/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.5397 - val_loss: 124.5318\n",
      "Epoch 189/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.6095 - val_loss: 125.5422\n",
      "Epoch 190/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 119.5986 - val_loss: 126.0183\n",
      "Epoch 191/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.2528 - val_loss: 125.4920\n",
      "Epoch 192/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 119.4418 - val_loss: 125.7819\n",
      "Epoch 193/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.5079 - val_loss: 128.1354\n",
      "Epoch 194/300\n",
      "73/73 [==============================] - ETA: 0s - loss: 119.7470Restoring model weights from the end of the best epoch: 164.\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7470 - val_loss: 125.3010\n",
      "Epoch 194: early stopping\n",
      "'########################################################Model8\n",
      "Epoch 1/300\n",
      "73/73 [==============================] - 2s 18ms/step - loss: 153.7705 - val_loss: 143.4153\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 137.1648 - val_loss: 141.2112\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 136.4217 - val_loss: 140.6765\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 135.6187 - val_loss: 139.8768\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 134.4700 - val_loss: 138.8146\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 132.5440 - val_loss: 136.7063\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 128.9736 - val_loss: 132.6769\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 128.5347 - val_loss: 131.3112\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 126.4851 - val_loss: 135.7615\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 126.2736 - val_loss: 130.5883\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 125.3669 - val_loss: 130.1224\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 124.7689 - val_loss: 130.3692\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 125.0626 - val_loss: 129.3763\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 124.5505 - val_loss: 130.8269\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 124.2150 - val_loss: 131.6791\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 124.3305 - val_loss: 129.7891\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.7585 - val_loss: 130.0579\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 124.2854 - val_loss: 129.9318\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 124.1355 - val_loss: 130.8297\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 124.0361 - val_loss: 128.1741\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.7003 - val_loss: 129.6245\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.5983 - val_loss: 128.9154\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.3847 - val_loss: 128.8350\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.4423 - val_loss: 129.2386\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.9588 - val_loss: 128.3202\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.0191 - val_loss: 128.1656\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.0977 - val_loss: 128.6446\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.1080 - val_loss: 127.6402\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.0885 - val_loss: 128.8226\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.7632 - val_loss: 128.9635\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.6286 - val_loss: 127.5828\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.6451 - val_loss: 128.5366\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.8601 - val_loss: 127.5578\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.7650 - val_loss: 127.6488\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.1141 - val_loss: 131.1033\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 123.2976 - val_loss: 127.5621\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.4204 - val_loss: 127.4034\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.3420 - val_loss: 128.9316\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.5240 - val_loss: 128.2590\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.4218 - val_loss: 130.2201\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.4768 - val_loss: 127.8076\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.0965 - val_loss: 129.0660\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.4667 - val_loss: 129.1387\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.1732 - val_loss: 128.2262\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.1441 - val_loss: 127.2197\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.0872 - val_loss: 127.7424\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.1135 - val_loss: 127.0273\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.8950 - val_loss: 128.1139\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.3221 - val_loss: 127.5719\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.0816 - val_loss: 127.6101\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.8140 - val_loss: 127.2872\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.5985 - val_loss: 127.4156\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.7270 - val_loss: 127.1131\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 122.2737 - val_loss: 127.5220\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.3681 - val_loss: 126.7415\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.6900 - val_loss: 127.3605\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.2139 - val_loss: 126.6302\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.1339 - val_loss: 127.2888\n",
      "Epoch 59/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.1150 - val_loss: 127.6762\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.5185 - val_loss: 127.9599\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.7901 - val_loss: 126.5027\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 121.4881 - val_loss: 126.6730\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.3296 - val_loss: 126.9660\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.2775 - val_loss: 127.9413\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.2411 - val_loss: 127.4311\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.2315 - val_loss: 127.1062\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.0613 - val_loss: 126.4152\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.7373 - val_loss: 126.6731\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.1132 - val_loss: 128.4958\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.9488 - val_loss: 126.7059\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.8424 - val_loss: 126.5621\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.9856 - val_loss: 125.8216\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.0695 - val_loss: 126.7351\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.7587 - val_loss: 125.9547\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.0019 - val_loss: 126.8793\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.4772 - val_loss: 127.3665\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.6454 - val_loss: 126.2949\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.7266 - val_loss: 126.5582\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.7377 - val_loss: 126.5067\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.7673 - val_loss: 126.4751\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.8747 - val_loss: 126.1874\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.6529 - val_loss: 127.7920\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.5391 - val_loss: 125.8595\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.0296 - val_loss: 126.7650\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.7798 - val_loss: 128.0833\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 121.3411 - val_loss: 126.4463\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.5674 - val_loss: 126.3987\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.5085 - val_loss: 127.3602\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.5402 - val_loss: 126.1226\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.5191 - val_loss: 127.1307\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.9371 - val_loss: 127.5315\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.7015 - val_loss: 126.5737\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.5260 - val_loss: 126.3128\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.4143 - val_loss: 125.9243\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.2856 - val_loss: 125.8582\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 120.1347 - val_loss: 127.0787\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.5255 - val_loss: 125.7689\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.3930 - val_loss: 126.3564\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.2564 - val_loss: 126.3885\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.2418 - val_loss: 125.9126\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.7204 - val_loss: 126.4599\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.2130 - val_loss: 125.2465\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.4577 - val_loss: 127.3034\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.6473 - val_loss: 125.9419\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.0540 - val_loss: 125.8490\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.4033 - val_loss: 127.1720\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.4150 - val_loss: 127.0098\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.5744 - val_loss: 126.0343\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.0693 - val_loss: 126.1876\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.6554 - val_loss: 125.6735\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.2314 - val_loss: 125.3936\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.4553 - val_loss: 125.8053\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.2560 - val_loss: 126.5111\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.2904 - val_loss: 126.8368\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.1857 - val_loss: 125.7089\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.3074 - val_loss: 125.3279\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.0779 - val_loss: 126.8786\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.5939 - val_loss: 126.0347\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.1776 - val_loss: 125.7912\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.0206 - val_loss: 125.1513\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.9780 - val_loss: 125.5778\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.2245 - val_loss: 126.1950\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.3607 - val_loss: 125.3502\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.9329 - val_loss: 126.3439\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.9012 - val_loss: 125.3375\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.8626 - val_loss: 125.5178\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.9296 - val_loss: 125.5723\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.2571 - val_loss: 127.8961\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.2470 - val_loss: 127.2058\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 120.4269 - val_loss: 125.4459\n",
      "Epoch 131/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.1486 - val_loss: 126.3050\n",
      "Epoch 132/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.2830 - val_loss: 126.0838\n",
      "Epoch 133/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.2033 - val_loss: 125.3038\n",
      "Epoch 134/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.9247 - val_loss: 126.4467\n",
      "Epoch 135/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.2925 - val_loss: 126.6571\n",
      "Epoch 136/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.1715 - val_loss: 125.1509\n",
      "Epoch 137/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.0863 - val_loss: 126.4021\n",
      "Epoch 138/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.2187 - val_loss: 126.8426\n",
      "Epoch 139/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.1054 - val_loss: 125.3098\n",
      "Epoch 140/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 119.9643 - val_loss: 126.7078\n",
      "Epoch 141/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.9494 - val_loss: 127.1271\n",
      "Epoch 142/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.1604 - val_loss: 126.4387\n",
      "Epoch 143/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.9491 - val_loss: 125.5947\n",
      "Epoch 144/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.0434 - val_loss: 125.1621\n",
      "Epoch 145/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7795 - val_loss: 126.1066\n",
      "Epoch 146/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.7399 - val_loss: 126.5785\n",
      "Epoch 147/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.4243 - val_loss: 125.6878\n",
      "Epoch 148/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7963 - val_loss: 125.0100\n",
      "Epoch 149/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7552 - val_loss: 126.2771\n",
      "Epoch 150/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.8396 - val_loss: 125.1155\n",
      "Epoch 151/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 119.7761 - val_loss: 126.1223\n",
      "Epoch 152/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.1396 - val_loss: 125.9631\n",
      "Epoch 153/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.9888 - val_loss: 125.0632\n",
      "Epoch 154/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.8291 - val_loss: 125.1674\n",
      "Epoch 155/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.0283 - val_loss: 125.9630\n",
      "Epoch 156/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7333 - val_loss: 126.6738\n",
      "Epoch 157/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7855 - val_loss: 125.3819\n",
      "Epoch 158/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7829 - val_loss: 125.7194\n",
      "Epoch 159/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7331 - val_loss: 125.1902\n",
      "Epoch 160/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.6380 - val_loss: 125.0965\n",
      "Epoch 161/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7907 - val_loss: 127.2567\n",
      "Epoch 162/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7393 - val_loss: 125.3537\n",
      "Epoch 163/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7937 - val_loss: 126.1390\n",
      "Epoch 164/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.8032 - val_loss: 126.0650\n",
      "Epoch 165/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.9354 - val_loss: 125.3144\n",
      "Epoch 166/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.1300 - val_loss: 125.0829\n",
      "Epoch 167/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.9241 - val_loss: 126.2234\n",
      "Epoch 168/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.8752 - val_loss: 125.7763\n",
      "Epoch 169/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.6140 - val_loss: 125.7028\n",
      "Epoch 170/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 119.7951 - val_loss: 125.1330\n",
      "Epoch 171/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.6216 - val_loss: 126.9404\n",
      "Epoch 172/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.8907 - val_loss: 128.2099\n",
      "Epoch 173/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.6401 - val_loss: 125.7494\n",
      "Epoch 174/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.6874 - val_loss: 125.1019\n",
      "Epoch 175/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.4816 - val_loss: 124.7836\n",
      "Epoch 176/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.5742 - val_loss: 126.4946\n",
      "Epoch 177/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.0697 - val_loss: 125.5972\n",
      "Epoch 178/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7316 - val_loss: 125.3662\n",
      "Epoch 179/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 119.7706 - val_loss: 124.9705\n",
      "Epoch 180/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.4227 - val_loss: 125.8108\n",
      "Epoch 181/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7830 - val_loss: 125.5805\n",
      "Epoch 182/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3339 - val_loss: 126.5253\n",
      "Epoch 183/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7785 - val_loss: 125.0671\n",
      "Epoch 184/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.2756 - val_loss: 126.0772\n",
      "Epoch 185/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.4591 - val_loss: 125.2001\n",
      "Epoch 186/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.5162 - val_loss: 126.1021\n",
      "Epoch 187/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.9377 - val_loss: 124.9750\n",
      "Epoch 188/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.6712 - val_loss: 124.6322\n",
      "Epoch 189/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.4079 - val_loss: 124.6532\n",
      "Epoch 190/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.5300 - val_loss: 125.3779\n",
      "Epoch 191/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.5431 - val_loss: 125.8968\n",
      "Epoch 192/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.4720 - val_loss: 125.2828\n",
      "Epoch 193/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3468 - val_loss: 124.7957\n",
      "Epoch 194/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3844 - val_loss: 125.7089\n",
      "Epoch 195/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.4356 - val_loss: 125.3286\n",
      "Epoch 196/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 119.6155 - val_loss: 124.6851\n",
      "Epoch 197/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.5133 - val_loss: 124.7543\n",
      "Epoch 198/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.2118 - val_loss: 127.3757\n",
      "Epoch 199/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.8514 - val_loss: 125.4347\n",
      "Epoch 200/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.6748 - val_loss: 124.6034\n",
      "Epoch 201/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.6522 - val_loss: 124.1722\n",
      "Epoch 202/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.2608 - val_loss: 124.2854\n",
      "Epoch 203/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.5647 - val_loss: 125.7815\n",
      "Epoch 204/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3820 - val_loss: 125.2495\n",
      "Epoch 205/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3309 - val_loss: 125.8707\n",
      "Epoch 206/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.6087 - val_loss: 125.8798\n",
      "Epoch 207/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.2647 - val_loss: 125.1844\n",
      "Epoch 208/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.2240 - val_loss: 124.1256\n",
      "Epoch 209/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.2222 - val_loss: 124.8690\n",
      "Epoch 210/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.4515 - val_loss: 124.2730\n",
      "Epoch 211/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.1701 - val_loss: 125.3257\n",
      "Epoch 212/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3972 - val_loss: 124.2809\n",
      "Epoch 213/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.5050 - val_loss: 126.3132\n",
      "Epoch 214/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.4089 - val_loss: 126.9085\n",
      "Epoch 215/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3225 - val_loss: 125.3512\n",
      "Epoch 216/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7072 - val_loss: 126.6052\n",
      "Epoch 217/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.2271 - val_loss: 124.8961\n",
      "Epoch 218/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3034 - val_loss: 125.2611\n",
      "Epoch 219/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3474 - val_loss: 124.4177\n",
      "Epoch 220/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.2031 - val_loss: 126.4814\n",
      "Epoch 221/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7070 - val_loss: 125.4571\n",
      "Epoch 222/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3363 - val_loss: 124.6011\n",
      "Epoch 223/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.9237 - val_loss: 124.4263\n",
      "Epoch 224/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 119.4761 - val_loss: 125.4351\n",
      "Epoch 225/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.2832 - val_loss: 124.9054\n",
      "Epoch 226/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.4231 - val_loss: 125.0655\n",
      "Epoch 227/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 120.3643 - val_loss: 124.4904\n",
      "Epoch 228/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.2004 - val_loss: 124.4172\n",
      "Epoch 229/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3372 - val_loss: 125.2315\n",
      "Epoch 230/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.8912 - val_loss: 124.4436\n",
      "Epoch 231/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.9649 - val_loss: 124.0489\n",
      "Epoch 232/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.8532 - val_loss: 124.3686\n",
      "Epoch 233/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3876 - val_loss: 125.5732\n",
      "Epoch 234/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.0409 - val_loss: 124.6562\n",
      "Epoch 235/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 119.2659 - val_loss: 124.2952\n",
      "Epoch 236/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.5905 - val_loss: 124.9110\n",
      "Epoch 237/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.1763 - val_loss: 124.4390\n",
      "Epoch 238/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.0762 - val_loss: 125.5243\n",
      "Epoch 239/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.0227 - val_loss: 124.7185\n",
      "Epoch 240/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.8492 - val_loss: 125.7627\n",
      "Epoch 241/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.1764 - val_loss: 124.6964\n",
      "Epoch 242/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.1854 - val_loss: 124.5900\n",
      "Epoch 243/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 118.9615 - val_loss: 124.1049\n",
      "Epoch 244/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.0403 - val_loss: 124.1277\n",
      "Epoch 245/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.1777 - val_loss: 123.9778\n",
      "Epoch 246/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.8975 - val_loss: 125.1366\n",
      "Epoch 247/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.6108 - val_loss: 124.7956\n",
      "Epoch 248/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.7834 - val_loss: 125.0455\n",
      "Epoch 249/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.9914 - val_loss: 124.6345\n",
      "Epoch 250/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.2475 - val_loss: 124.4586\n",
      "Epoch 251/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.9040 - val_loss: 125.7008\n",
      "Epoch 252/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.0894 - val_loss: 124.4419\n",
      "Epoch 253/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 118.7561 - val_loss: 124.0684\n",
      "Epoch 254/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.0369 - val_loss: 124.2971\n",
      "Epoch 255/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.8268 - val_loss: 124.7056\n",
      "Epoch 256/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.7547 - val_loss: 124.7432\n",
      "Epoch 257/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.3416 - val_loss: 125.0439\n",
      "Epoch 258/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.1206 - val_loss: 124.2535\n",
      "Epoch 259/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.8941 - val_loss: 124.6705\n",
      "Epoch 260/300\n",
      "73/73 [==============================] - 1s 15ms/step - loss: 118.9205 - val_loss: 124.7573\n",
      "Epoch 261/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.8497 - val_loss: 124.4891\n",
      "Epoch 262/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.2598 - val_loss: 125.7155\n",
      "Epoch 263/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.1721 - val_loss: 125.0222\n",
      "Epoch 264/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.9285 - val_loss: 124.5195\n",
      "Epoch 265/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.0876 - val_loss: 124.3209\n",
      "Epoch 266/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.9449 - val_loss: 124.3391\n",
      "Epoch 267/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.7143 - val_loss: 124.5482\n",
      "Epoch 268/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.0281 - val_loss: 124.5595\n",
      "Epoch 269/300\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 118.9648 - val_loss: 124.8021\n",
      "Epoch 270/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.9173 - val_loss: 124.7120\n",
      "Epoch 271/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.9262 - val_loss: 125.1630\n",
      "Epoch 272/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.1344 - val_loss: 124.1701\n",
      "Epoch 273/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.8842 - val_loss: 125.6025\n",
      "Epoch 274/300\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 119.1913 - val_loss: 125.1292\n",
      "Epoch 275/300\n",
      "72/73 [============================>.] - ETA: 0s - loss: 118.8155Restoring model weights from the end of the best epoch: 245.\n",
      "73/73 [==============================] - 1s 14ms/step - loss: 118.9005 - val_loss: 124.3444\n",
      "Epoch 275: early stopping\n",
      "'########################################################Model9\n"
     ]
    }
   ],
   "source": [
    "model_num = 10\n",
    "\n",
    "\n",
    "mase_models = train_bagging_models(model_num, MASE(y_train,24),300,30,8,0.0005)\n",
    "mape_models = train_bagging_models(model_num,'mape',300,30,8,0.0005)\n",
    "smape_models = train_bagging_models(model_num, SMAPE(),300,30,8,0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b35de203-07f8-48f9-8ede-0a0bcba1ea27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 4ms/step\n",
      "12/12 [==============================] - 0s 5ms/step\n",
      "12/12 [==============================] - 0s 5ms/step\n",
      "12/12 [==============================] - 0s 5ms/step\n",
      "12/12 [==============================] - 0s 5ms/step\n",
      "12/12 [==============================] - 0s 5ms/step\n",
      "12/12 [==============================] - 0s 5ms/step\n",
      "12/12 [==============================] - 0s 5ms/step\n",
      "12/12 [==============================] - 0s 5ms/step\n",
      "12/12 [==============================] - 0s 5ms/step\n",
      "12/12 [==============================] - 0s 5ms/step\n",
      "12/12 [==============================] - 0s 5ms/step\n",
      "12/12 [==============================] - 0s 5ms/step\n",
      "12/12 [==============================] - 0s 5ms/step\n",
      "12/12 [==============================] - 0s 5ms/step\n",
      "12/12 [==============================] - 0s 5ms/step\n",
      "12/12 [==============================] - 0s 5ms/step\n",
      "12/12 [==============================] - 0s 4ms/step\n",
      "12/12 [==============================] - 0s 5ms/step\n",
      "12/12 [==============================] - 0s 5ms/step\n",
      "12/12 [==============================] - 0s 5ms/step\n",
      "12/12 [==============================] - 0s 5ms/step\n",
      "12/12 [==============================] - 1s 5ms/step\n",
      "12/12 [==============================] - 0s 5ms/step\n",
      "12/12 [==============================] - 0s 5ms/step\n",
      "12/12 [==============================] - 0s 5ms/step\n",
      "12/12 [==============================] - 0s 5ms/step\n",
      "12/12 [==============================] - 0s 5ms/step\n",
      "12/12 [==============================] - 0s 5ms/step\n",
      "12/12 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.23174375712714193, 0.2363225466259961)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred1,_=smape_models\n",
    "pred2,_=mase_models\n",
    "pred3,_=mape_models\n",
    "\n",
    "smape_predictions = bagging_predict2(pred1, test_X)\n",
    "mase_predictions = bagging_predict2(pred2, test_X)\n",
    "mape_predictions = bagging_predict2(pred3, test_X)\n",
    "concat = np.concatenate([smape_predictions, mase_predictions,mape_predictions],axis=0)\n",
    "fin_pred = np.median(concat,axis=0)\n",
    "#pd.DataFrame(fin_pred).to_csv(\"freezing_I.csv\")\n",
    "mean_squared_error(test_y.flatten(),fin_pred.flatten()),mean_absolute_error(test_y.flatten(),fin_pred.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c80efe85-f798-42c9-b7c2-9756f51cf6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(fin_pred.reshape(-1,24)).to_csv(\"../result5_new/LSTM/pred_mid.csv\")\n",
    "for i in range(10):\n",
    "    pd.DataFrame(concat[i].reshape(-1,24)).to_csv(f\"../result5_new/LSTM/pred{i}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
