{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e097566-30f2-4f57-b3a2-2ae3b7d02005",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-30 14:51:45.690357: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-30 14:51:45.761509: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-08-30 14:51:45.761526: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-08-30 14:51:46.104600: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-08-30 14:51:46.104650: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-08-30 14:51:46.104656: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nbeats_keras.model import NBeatsNet as NBeatsKeras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "#from nbeats_pytorch.model import NBeatsNet as NBeatsPytorch\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "import time\n",
    "from keras.models import load_model\n",
    "#from target_data_electronic70_7 import target_X, target_y ,test_X, test_y\n",
    "#from m4databasis21_7 import base_domain,zt_in,zt_out,M4Meta,inputsize,train_12,train_12_y\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error,mean_absolute_percentage_error\n",
    "plt.rcParams['font.family'] ='Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] =False\n",
    "from tensorflow.keras.losses import Loss\n",
    "import tensorflow as tf\n",
    "#from m4databasis35_7_70_7 import train_35,train_35_y,train_70,train_70_y\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, LayerNormalization, MultiHeadAttention, Dropout, Add, Concatenate,Flatten,Reshape\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31c74fd4-9d10-4b7d-9c83-4da3c7f1871f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 24)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "target_X= pd.read_csv(\"../data/solor_train_input_3.csv\").iloc[:,(1+24*0):].values\n",
    "target_y =pd.read_csv(\"../data/solor_train_output_3.csv\").iloc[:,1:].values\n",
    "test_X= pd.read_csv(\"../data/solor_val_input_3.csv\").iloc[:,(1+24*0):].values\n",
    "test_y =pd.read_csv(\"../data/solor_val_output_3.csv\").iloc[:,1:].values\n",
    "\n",
    "X_train=target_X\n",
    "y_train=target_y\n",
    "\n",
    "backcast_length = X_train.shape[1]\n",
    "forecast_length = y_train.shape[1]\n",
    "backcast_length,forecast_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475bd839-0f9e-49d3-96a8-f1fe23500d97",
   "metadata": {},
   "source": [
    "# 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "117869af-8623-4129-aa35-bcc7ee3da674",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "# loss SMAPE\n",
    "class SMAPE(Loss):\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_pred = tf.reshape(y_pred, tf.shape(y_true))  # 예측 값의 차원을 맞춤\n",
    "       # y_pred=tf.clip_by_value(y_pred, 1e-10, tf.reduce_max(y_pred))\n",
    "       # y_true = tf.clip_by_value(y_true, 1e-10, tf.reduce_max(y_true))\n",
    "        \n",
    "        numerator = 100 * tf.abs(y_true- y_pred )\n",
    "        denominator =  (tf.abs(y_true ) + tf.abs(y_pred))/2\n",
    "        smape =  numerator /  denominator #tf.clip_by_value(denominator, 1e-10, tf.reduce_max(denominator))\n",
    "        return tf.reduce_mean(smape)\n",
    "\n",
    "#################################################################################\n",
    "# loss MASE\n",
    "class MASE(Loss):\n",
    "    def __init__(self, training_data, period, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.scale = self.calculate_scale(training_data, period)\n",
    "    def seasonal_diff(data, period):\n",
    "        return data[period:] - data[:-period]\n",
    "\n",
    "    def calculate_scale(self, training_data, period):\n",
    "        # 주기 차분 계산\n",
    "        diff = seasonal_diff(training_data, period)\n",
    "        scale = np.mean(np.abs(diff))\n",
    "        return scale\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        y_pred = tf.reshape(y_pred, tf.shape(y_true))  # 차원 맞추기\n",
    "        error = tf.abs(y_true - y_pred)\n",
    "        return tf.reduce_mean(error / self.scale)\n",
    "\n",
    "def seasonal_diff(data, period):\n",
    "    return data[period:] - data[:-period]\n",
    "\n",
    "#################################################################################\n",
    "#################################################################################\n",
    "# 하이퍼파라미터 인자 설정\n",
    "def hyperparameter():\n",
    "    # 1 backcast\n",
    "    # 2 forecast\n",
    "    # 3 inputdim\n",
    "    # 4 outputdim\n",
    "    # 5 unit\n",
    "    # 6 bacth size\n",
    "    return X_train.shape[1],y_train.shape[1],1,1,128\n",
    "\n",
    "#################################################################################\n",
    "# nbeats + I모델 생성 함수\n",
    "def bulid_model(backcast_,forecast_,input_dim,output_dim,unit):\n",
    "    model= NBeatsKeras(backcast_length=backcast_, \n",
    "                       forecast_length=forecast_,\n",
    "                       input_dim=input_dim,\n",
    "                       output_dim=output_dim,\n",
    "                       stack_types=(NBeatsKeras.TREND_BLOCK,\n",
    "                                    NBeatsKeras.TREND_BLOCK,\n",
    "                                    NBeatsKeras.SEASONALITY_BLOCK,\n",
    "                                    NBeatsKeras.SEASONALITY_BLOCK)\n",
    "                   ,nb_blocks_per_stack=1, thetas_dim=(1,2,4,4),\n",
    "                   share_weights_in_stack=True, hidden_layer_units=unit)\n",
    "    return model \n",
    "#################################################################################\n",
    "# nbeats + G모델 생성 함수    \n",
    "def bulid_model_G(backcast_,forecast_,input_dim,output_dim,unit):\n",
    "    model= NBeatsKeras(backcast_length=backcast_, \n",
    "                       forecast_length=forecast_,\n",
    "                       input_dim=input_dim,\n",
    "                       output_dim=output_dim,\n",
    "                       stack_types=(NBeatsKeras.GENERIC_BLOCK,NBeatsKeras.GENERIC_BLOCK)\n",
    "                   ,nb_blocks_per_stack=5, thetas_dim=(4,4),\n",
    "                   share_weights_in_stack=False, hidden_layer_units=unit)\n",
    "    return model \n",
    "#################################################################################\n",
    "# nbeats + I모델 부트스트랩 샘플링 배깅\n",
    "\n",
    "def train_bagging_models(num_models, loss_fn , epochs_, patience_,batch_size_,lr):\n",
    "    models = {}\n",
    "    backcast,forecast,in_dim,out_dim,unit = hyperparameter()\n",
    "    historys = []\n",
    "    for n in range(num_models):\n",
    "        K.clear_session()\n",
    "        model = bulid_model(backcast,forecast,in_dim,out_dim,unit)\n",
    "       # model.set_weights(pretrained_weights)  # 전이 학습 가중치 적용\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "        model.compile(optimizer=optimizer , loss=loss_fn)\n",
    "        \n",
    "        # 부트스트랩 샘플링\n",
    "        #select = np.random.choice(len(X_train), size=len(X_train), replace=True)\n",
    "        #X_bootstrap = X_train[select]\n",
    "        #y_bootstrap = y_train[select]\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience = patience_, verbose = 0, restore_best_weights=True)\n",
    "        history = model.fit(X_train,y_train, batch_size = batch_size_,\n",
    "                  epochs=epochs_, verbose=1, \n",
    "                  callbacks=[early_stop],\n",
    "                 validation_split = 0.2)\n",
    "        models[f'model_{n+1}'] = model\n",
    "        historys.append(history)\n",
    "        #models.append(model)\n",
    "        print(f\"'########################################################Model{n}\")\n",
    "    return models,historys\n",
    "#################################################################################\n",
    "# nbeats + I모델 부트스트랩 샘플링 배깅\n",
    "\n",
    "def train_bagging_models_G(num_models, loss_fn , epochs_, patience_,batch_size_,lr):\n",
    "    models = {}\n",
    "    backcast,forecast,in_dim,out_dim,unit = hyperparameter()\n",
    "    historys = []\n",
    "    for n in range(num_models):\n",
    "        K.clear_session()\n",
    "        model = bulid_model_G(backcast,forecast,in_dim,out_dim,unit)\n",
    "       # model.set_weights(pretrained_weights)  # 전이 학습 가중치 적용\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "        model.compile(optimizer=optimizer , loss=loss_fn)\n",
    "        \n",
    "        # 부트스트랩 샘플링\n",
    "        #select = np.random.choice(len(X_train), size=len(X_train), replace=True)\n",
    "        #X_bootstrap = X_train[select]\n",
    "        #y_bootstrap = y_train[select]\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience = patience_, verbose = 0, restore_best_weights=True)\n",
    "        history = model.fit(X_train, y_train, batch_size = batch_size_,\n",
    "                  epochs=epochs_, verbose=1, \n",
    "                  callbacks=[early_stop],\n",
    "                 validation_split = 0.2)\n",
    "        models[f'model_{n+1}'] = model\n",
    "        historys.append(history)\n",
    "        #models.append(model)\n",
    "        print(f\"'########################################################Model{n}\")\n",
    "    return models,historys\n",
    "\n",
    "#################################################################################\n",
    "# SMAPE 용\n",
    "def train_bagging_models_smape(num_models, loss_fn , epochs_, patience_,batch_size_,lr):\n",
    "    models = {}\n",
    "    backcast,forecast,in_dim,out_dim,unit = hyperparameter()\n",
    "    historys = []\n",
    "    for n in range(num_models):\n",
    "        K.clear_session()\n",
    "        model = bulid_model(backcast,forecast,in_dim,out_dim,unit)\n",
    "       # model.set_weights(pretrained_weights)  # 전이 학습 가중치 적용\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "        model.compile(optimizer=optimizer , loss=loss_fn)\n",
    "        \n",
    "        # 부트스트랩 샘플링\n",
    "        #select = np.random.choice(len(X_train), size=len(X_train), replace=True)\n",
    "        #X_bootstrap = X_train[select]\n",
    "        #y_bootstrap = y_train[select]\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience = patience_, verbose = 0, restore_best_weights=True)\n",
    "        history = model.fit(X_bootstrap, y_bootstrap, batch_size = batch_size_,\n",
    "                  epochs=epochs_, verbose=1, \n",
    "                  callbacks=[early_stop],\n",
    "                 validation_split = 0.2)\n",
    "        models[f'model_{n+1}'] = model\n",
    "        historys.append(history)\n",
    "        #models.append(model)\n",
    "        print(f\"'########################################################Model{n}\")\n",
    "    return models,historys\n",
    "\n",
    "##########################################################################################\n",
    "# 트랜스퍼 레이어\n",
    "class PositionalEncoding(layers.Layer):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = layers.Dropout(rate=dropout)\n",
    "\n",
    "        position = np.arange(max_len)[:, np.newaxis]\n",
    "        div_term = np.exp(np.arange(0, d_model, 2) * (-np.log(10000.0) / d_model))\n",
    "        pe = np.zeros((max_len, d_model))\n",
    "        pe[:, 0::2] = np.sin(position * div_term)\n",
    "        pe[:, 1::2] = np.cos(position * div_term)\n",
    "        pe = pe[np.newaxis, ...]\n",
    "\n",
    "        self.pe = tf.constant(pe, dtype=tf.float32)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = x + self.pe[:, :tf.shape(x)[1], :]\n",
    "        return self.dropout(x)\n",
    "##########################################################################################\n",
    "# 트랜스퍼 레이어\n",
    "def create_model(fn,d_model, nlayers, nhead, dropout, iw, ow,lr):\n",
    "    \n",
    "    \n",
    "    x = layers.Dense(d_model // 2, activation='relu')(pretrained_output_reshaped)\n",
    "    x = layers.Dense(d_model, activation='relu')(x)\n",
    "    \n",
    "    pos_encoding = PositionalEncoding(d_model, dropout)\n",
    "    x = pos_encoding(x)\n",
    "    \n",
    "    for _ in range(nlayers):\n",
    "        attn_output = layers.MultiHeadAttention(num_heads=nhead, key_dim=d_model, dropout=dropout)(x, x)\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x + attn_output)\n",
    "        ffn_output = layers.Dense(d_model, activation='relu')(x)\n",
    "        ffn_output = layers.Dense(d_model)(ffn_output)\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x + ffn_output)\n",
    "    \n",
    "    x = layers.Dense(d_model // 2, activation='relu')(x)\n",
    "    x = layers.Dense(1)(x)\n",
    "    x = tf.squeeze(x, axis=-1)\n",
    "    \n",
    "    outputs = layers.Dense((iw + ow) // 2, activation='relu')(x)\n",
    "    outputs = layers.Dense(ow)(outputs)\n",
    "    \n",
    "    optimizer = Adam(learning_rate=lr)\n",
    "    target_model = Model(inputs=inputs, outputs=outputs)\n",
    "    target_model.compile(optimizer=optimizer, loss=fn)\n",
    "    \n",
    "    return target_model\n",
    "#################################################################################\n",
    "# 예측\n",
    "\n",
    "def bagging_predict(models, X):\n",
    "    predictions = np.array([model.predict(X) for model in models.values()])\n",
    "    return np.median(predictions, axis=0)\n",
    "\n",
    "def bagging_predict2(models, X):\n",
    "    predictions = np.array([model.predict(X) for model in models.values()])\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa4c593-18a3-4fa1-be2e-8894dc7d453f",
   "metadata": {},
   "source": [
    "# 모형적합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99f13c2f-9812-460b-9269-22aa352bfc7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-30 15:01:53.686170: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-08-30 15:01:53.686203: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ymlee2-desktop): /proc/driver/nvidia/version does not exist\n",
      "2024-08-30 15:01:53.686794: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 5ms/step - loss: 1.1672 - val_loss: 0.7404\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.8489 - val_loss: 0.7270\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.8007 - val_loss: 0.6846\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7656 - val_loss: 0.6695\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7597 - val_loss: 0.6449\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7437 - val_loss: 0.7015\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7312 - val_loss: 0.6758\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7287 - val_loss: 0.6519\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7075 - val_loss: 0.6777\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7133 - val_loss: 0.6551\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6937 - val_loss: 0.6469\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6777 - val_loss: 0.6849\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6684 - val_loss: 0.6553\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6676 - val_loss: 0.6483\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6662 - val_loss: 0.6445\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6429 - val_loss: 0.6785\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6426 - val_loss: 0.6647\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6355 - val_loss: 0.6712\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6288 - val_loss: 0.6699\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6471 - val_loss: 0.6680\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6102 - val_loss: 0.6278\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5949 - val_loss: 0.6534\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5875 - val_loss: 0.6479\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5873 - val_loss: 0.6676\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5655 - val_loss: 0.6528\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5661 - val_loss: 0.6467\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5616 - val_loss: 0.6343\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5615 - val_loss: 0.6337\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5338 - val_loss: 0.6491\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5428 - val_loss: 0.6289\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5336 - val_loss: 0.6679\n",
      "'########################################################Model0\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 5ms/step - loss: 1.2195 - val_loss: 0.7427\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.8404 - val_loss: 0.7021\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.8050 - val_loss: 0.6763\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7903 - val_loss: 0.6732\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7546 - val_loss: 0.6646\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7404 - val_loss: 0.6437\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7275 - val_loss: 0.6727\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7162 - val_loss: 0.6698\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6977 - val_loss: 0.6821\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6918 - val_loss: 0.7056\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7010 - val_loss: 0.6572\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6634 - val_loss: 0.6376\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6626 - val_loss: 0.6881\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6708 - val_loss: 0.7047\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6320 - val_loss: 0.7072\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6691 - val_loss: 0.6769\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6417 - val_loss: 0.6730\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6227 - val_loss: 0.6615\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5980 - val_loss: 0.6840\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6014 - val_loss: 0.6798\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6029 - val_loss: 0.6785\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5912 - val_loss: 0.6653\n",
      "'########################################################Model1\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 5ms/step - loss: 1.1453 - val_loss: 0.8087\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.8685 - val_loss: 0.7114\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.8018 - val_loss: 0.7774\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.8066 - val_loss: 0.6950\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7668 - val_loss: 0.6640\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7511 - val_loss: 0.6656\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7347 - val_loss: 0.6730\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7221 - val_loss: 0.6477\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7040 - val_loss: 0.6868\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6915 - val_loss: 0.6609\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6847 - val_loss: 0.6425\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6732 - val_loss: 0.6440\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6509 - val_loss: 0.7055\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6525 - val_loss: 0.7229\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6846 - val_loss: 0.6467\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6193 - val_loss: 0.6385\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6043 - val_loss: 0.6596\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6086 - val_loss: 0.6430\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6169 - val_loss: 0.6437\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5866 - val_loss: 0.6789\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5825 - val_loss: 0.6179\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5741 - val_loss: 0.6685\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5658 - val_loss: 0.6641\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5494 - val_loss: 0.6342\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5557 - val_loss: 0.6402\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5255 - val_loss: 0.6620\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5302 - val_loss: 0.6917\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5176 - val_loss: 0.6893\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.4953 - val_loss: 0.6944\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5100 - val_loss: 0.7179\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.4919 - val_loss: 0.7083\n",
      "'########################################################Model2\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 5ms/step - loss: 1.1890 - val_loss: 0.7755\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.8477 - val_loss: 0.7406\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.8208 - val_loss: 0.7227\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7789 - val_loss: 0.6730\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7557 - val_loss: 0.6622\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7701 - val_loss: 0.6623\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7370 - val_loss: 0.6792\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7141 - val_loss: 0.6678\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7070 - val_loss: 0.6763\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7020 - val_loss: 0.6824\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7013 - val_loss: 0.6571\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6769 - val_loss: 0.6588\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6850 - val_loss: 0.6411\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6527 - val_loss: 0.6362\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6550 - val_loss: 0.6251\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6694 - val_loss: 0.6465\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6392 - val_loss: 0.6519\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6197 - val_loss: 0.6434\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6133 - val_loss: 0.6662\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6025 - val_loss: 0.6644\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6032 - val_loss: 0.6314\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5914 - val_loss: 0.6483\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5729 - val_loss: 0.6238\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5572 - val_loss: 0.6680\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5509 - val_loss: 0.6300\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5460 - val_loss: 0.6610\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5480 - val_loss: 0.6522\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5077 - val_loss: 0.6407\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5320 - val_loss: 0.6255\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.4962 - val_loss: 0.6253\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.4929 - val_loss: 0.6793\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.4644 - val_loss: 0.6859\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.4869 - val_loss: 0.6615\n",
      "'########################################################Model3\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 5ms/step - loss: 1.1974 - val_loss: 0.8141\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.8822 - val_loss: 0.7293\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.8263 - val_loss: 0.7209\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7786 - val_loss: 0.6958\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7620 - val_loss: 0.6372\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7236 - val_loss: 0.6544\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7150 - val_loss: 0.6853\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7169 - val_loss: 0.6660\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6865 - val_loss: 0.6709\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6759 - val_loss: 0.6727\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6663 - val_loss: 0.6414\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6566 - val_loss: 0.6701\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6543 - val_loss: 0.6530\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6276 - val_loss: 0.6604\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6189 - val_loss: 0.6662\n",
      "'########################################################Model4\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 5ms/step - loss: 1.0883 - val_loss: 0.7279\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.8438 - val_loss: 0.7447\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7946 - val_loss: 0.6758\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7612 - val_loss: 0.6773\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7536 - val_loss: 0.6496\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7407 - val_loss: 0.6699\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7275 - val_loss: 0.6587\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7173 - val_loss: 0.6621\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6974 - val_loss: 0.6550\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6888 - val_loss: 0.6397\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7023 - val_loss: 0.6572\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6656 - val_loss: 0.6423\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6633 - val_loss: 0.7080\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6602 - val_loss: 0.6783\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6447 - val_loss: 0.6654\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6341 - val_loss: 0.6625\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6120 - val_loss: 0.6617\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6112 - val_loss: 0.6616\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5943 - val_loss: 0.6497\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5913 - val_loss: 0.7177\n",
      "'########################################################Model5\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 5ms/step - loss: 1.1827 - val_loss: 0.7791\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.8611 - val_loss: 0.7127\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.8047 - val_loss: 0.7010\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7783 - val_loss: 0.7159\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7822 - val_loss: 0.6940\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7626 - val_loss: 0.6501\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7301 - val_loss: 0.6530\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7247 - val_loss: 0.6865\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7077 - val_loss: 0.6687\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7007 - val_loss: 0.6545\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6957 - val_loss: 0.6458\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6705 - val_loss: 0.6486\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6788 - val_loss: 0.6431\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6514 - val_loss: 0.6374\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6474 - val_loss: 0.6626\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6277 - val_loss: 0.6439\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6259 - val_loss: 0.6725\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6351 - val_loss: 0.6314\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6172 - val_loss: 0.6412\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6155 - val_loss: 0.6699\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5965 - val_loss: 0.6159\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6028 - val_loss: 0.6179\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5852 - val_loss: 0.6453\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5742 - val_loss: 0.6352\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5534 - val_loss: 0.6489\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5590 - val_loss: 0.6302\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5622 - val_loss: 0.6572\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5402 - val_loss: 0.6524\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5484 - val_loss: 0.6468\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5122 - val_loss: 0.6767\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.4988 - val_loss: 0.6355\n",
      "'########################################################Model6\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 5ms/step - loss: 1.2079 - val_loss: 0.7749\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.8468 - val_loss: 0.7275\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.8023 - val_loss: 0.7310\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7858 - val_loss: 0.6723\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7540 - val_loss: 0.6498\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7516 - val_loss: 0.6625\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7206 - val_loss: 0.6528\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7220 - val_loss: 0.6709\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7174 - val_loss: 0.6619\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7051 - val_loss: 0.6794\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6973 - val_loss: 0.6559\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6909 - val_loss: 0.6520\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6594 - val_loss: 0.6709\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6620 - val_loss: 0.6556\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6712 - val_loss: 0.6538\n",
      "'########################################################Model7\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 5ms/step - loss: 1.1701 - val_loss: 0.7584\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.8423 - val_loss: 0.6999\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.8130 - val_loss: 0.6869\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7782 - val_loss: 0.6629\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7480 - val_loss: 0.6881\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7439 - val_loss: 0.6799\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7357 - val_loss: 0.6552\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7165 - val_loss: 0.6583\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7147 - val_loss: 0.6295\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6941 - val_loss: 0.6506\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6977 - val_loss: 0.7181\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6865 - val_loss: 0.6312\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6683 - val_loss: 0.6035\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6575 - val_loss: 0.6501\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6606 - val_loss: 0.6566\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6762 - val_loss: 0.6561\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6460 - val_loss: 0.6245\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6307 - val_loss: 0.6490\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6324 - val_loss: 0.6254\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6135 - val_loss: 0.6330\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6133 - val_loss: 0.6260\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5952 - val_loss: 0.6315\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5847 - val_loss: 0.6456\n",
      "'########################################################Model8\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 5ms/step - loss: 1.1378 - val_loss: 0.7465\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.8572 - val_loss: 0.7182\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7942 - val_loss: 0.7136\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7641 - val_loss: 0.6803\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7622 - val_loss: 0.6428\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7494 - val_loss: 0.6699\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7309 - val_loss: 0.6755\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7214 - val_loss: 0.6941\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7069 - val_loss: 0.6371\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6983 - val_loss: 0.6695\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6822 - val_loss: 0.6450\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6819 - val_loss: 0.6900\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6690 - val_loss: 0.7092\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6472 - val_loss: 0.6740\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6416 - val_loss: 0.6696\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6208 - val_loss: 0.6782\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6214 - val_loss: 0.6397\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6074 - val_loss: 0.6722\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5849 - val_loss: 0.6729\n",
      "'########################################################Model9\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 5ms/step - loss: 80062248.0000 - val_loss: 36201608.0000\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 27163166.0000 - val_loss: 20569328.0000\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 17362212.0000 - val_loss: 13475888.0000\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 13468648.0000 - val_loss: 12057595.0000\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 11333470.0000 - val_loss: 10078523.0000\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 8560404.0000 - val_loss: 7907527.5000\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 7880721.5000 - val_loss: 7075335.0000\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 6671290.0000 - val_loss: 6028490.5000\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 5516384.0000 - val_loss: 5497357.0000\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 5037758.0000 - val_loss: 4879684.0000\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 5138501.5000 - val_loss: 5148712.0000\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 4480456.0000 - val_loss: 4471610.5000\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 4027270.5000 - val_loss: 3966156.2500\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3468966.5000 - val_loss: 3498504.2500\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2858709.7500 - val_loss: 3162348.7500\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2752594.7500 - val_loss: 3081376.7500\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2918872.0000 - val_loss: 2550717.5000\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2440254.2500 - val_loss: 2675329.0000\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2687230.7500 - val_loss: 2573104.0000\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2170309.7500 - val_loss: 3203384.2500\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2415368.5000 - val_loss: 2699499.2500\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2286589.5000 - val_loss: 1819041.6250\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2313441.7500 - val_loss: 2305865.2500\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1953679.2500 - val_loss: 2939313.7500\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2018909.1250 - val_loss: 2204078.2500\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1963511.8750 - val_loss: 2164172.5000\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1596494.8750 - val_loss: 1976777.0000\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1920970.1250 - val_loss: 2284643.2500\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1659249.1250 - val_loss: 1534165.1250\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1553972.6250 - val_loss: 2492061.0000\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1700891.0000 - val_loss: 1501955.8750\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2003589.2500 - val_loss: 3393442.7500\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2159617.0000 - val_loss: 1487215.3750\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1864721.8750 - val_loss: 1766409.0000\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1432731.1250 - val_loss: 1404562.2500\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1518065.1250 - val_loss: 1063714.3750\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1198327.0000 - val_loss: 1146350.0000\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1182388.2500 - val_loss: 971546.2500\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1207375.5000 - val_loss: 2049923.5000\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1301876.2500 - val_loss: 1174268.2500\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 932568.6875 - val_loss: 930051.6250\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 916261.8750 - val_loss: 1267211.8750\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1027440.7500 - val_loss: 920713.8750\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 942745.6250 - val_loss: 892390.4375\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1282841.3750 - val_loss: 1038598.3750\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 949822.4375 - val_loss: 695896.5000\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1121831.0000 - val_loss: 1983125.3750\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 993244.3750 - val_loss: 894652.5000\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 996758.0625 - val_loss: 750572.0000\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 839038.8125 - val_loss: 1342422.6250\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 635330.6875 - val_loss: 855180.1875\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 866141.3750 - val_loss: 581485.8750\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 581878.9375 - val_loss: 678710.4375\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 528897.0000 - val_loss: 543563.1250\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 569547.1250 - val_loss: 359303.8750\n",
      "Epoch 56/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 441304.9375 - val_loss: 697286.3125\n",
      "Epoch 57/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 388484.1250 - val_loss: 319750.5938\n",
      "Epoch 58/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 350344.8438 - val_loss: 288406.2188\n",
      "Epoch 59/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 366597.6875 - val_loss: 414271.4062\n",
      "Epoch 60/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 283972.7812 - val_loss: 352401.6562\n",
      "Epoch 61/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 267084.7188 - val_loss: 279728.8438\n",
      "Epoch 62/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 228201.7656 - val_loss: 402324.9062\n",
      "Epoch 63/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 235839.3906 - val_loss: 213998.4688\n",
      "Epoch 64/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 204753.1875 - val_loss: 467024.1250\n",
      "Epoch 65/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 293901.4688 - val_loss: 362742.1250\n",
      "Epoch 66/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 172333.2031 - val_loss: 180941.4375\n",
      "Epoch 67/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 146310.8281 - val_loss: 178468.8906\n",
      "Epoch 68/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 169216.7656 - val_loss: 180626.2500\n",
      "Epoch 69/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 221017.2031 - val_loss: 126636.7344\n",
      "Epoch 70/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 130439.7969 - val_loss: 201868.0312\n",
      "Epoch 71/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 163026.7344 - val_loss: 89916.2422\n",
      "Epoch 72/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 136971.2500 - val_loss: 241846.2969\n",
      "Epoch 73/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 128878.0938 - val_loss: 129831.0859\n",
      "Epoch 74/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 89200.1250 - val_loss: 118083.4922\n",
      "Epoch 75/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126535.1719 - val_loss: 177264.8281\n",
      "Epoch 76/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 106607.8594 - val_loss: 134485.7500\n",
      "Epoch 77/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 209206.5312 - val_loss: 222592.9531\n",
      "Epoch 78/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 173809.7031 - val_loss: 145686.0781\n",
      "Epoch 79/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 107281.4844 - val_loss: 93059.1719\n",
      "Epoch 80/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 102241.3359 - val_loss: 140843.7188\n",
      "Epoch 81/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 116298.2734 - val_loss: 84456.4297\n",
      "Epoch 82/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 84184.5703 - val_loss: 80156.1719\n",
      "Epoch 83/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 75236.3984 - val_loss: 117663.1328\n",
      "Epoch 84/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 96597.7031 - val_loss: 177373.4688\n",
      "Epoch 85/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 177315.8750 - val_loss: 230909.7344\n",
      "Epoch 86/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 105477.7109 - val_loss: 101939.8984\n",
      "Epoch 87/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 106944.4375 - val_loss: 112124.4922\n",
      "Epoch 88/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 98683.2422 - val_loss: 96428.4375\n",
      "Epoch 89/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 48794.6094 - val_loss: 39582.6250\n",
      "Epoch 90/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 80721.1094 - val_loss: 106821.1484\n",
      "Epoch 91/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 53242.4766 - val_loss: 47674.6992\n",
      "Epoch 92/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 63633.4336 - val_loss: 100976.2969\n",
      "Epoch 93/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 110891.5625 - val_loss: 55897.6211\n",
      "Epoch 94/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 34417.4570 - val_loss: 30609.2031\n",
      "Epoch 95/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 40976.6680 - val_loss: 94804.4062\n",
      "Epoch 96/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 51422.2891 - val_loss: 136212.6094\n",
      "Epoch 97/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 75310.2188 - val_loss: 67917.7812\n",
      "Epoch 98/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 35045.3984 - val_loss: 35873.8047\n",
      "Epoch 99/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 45061.8477 - val_loss: 6137.3843\n",
      "Epoch 100/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 41870.8906 - val_loss: 53432.2656\n",
      "'########################################################Model0\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 5ms/step - loss: 90184632.0000 - val_loss: 35414072.0000\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 30117984.0000 - val_loss: 20825562.0000\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 18973482.0000 - val_loss: 19270540.0000\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 14527868.0000 - val_loss: 13527096.0000\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 12248156.0000 - val_loss: 11997790.0000\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 9737104.0000 - val_loss: 10170576.0000\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 9030516.0000 - val_loss: 8020942.5000\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 8765392.0000 - val_loss: 9430643.0000\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 6460890.5000 - val_loss: 7468463.5000\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 6709070.0000 - val_loss: 7037326.5000\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 5758127.0000 - val_loss: 5181774.0000\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 4888585.5000 - val_loss: 5055512.5000\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 4136463.5000 - val_loss: 4810836.5000\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 4469182.0000 - val_loss: 6529286.5000\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3843621.5000 - val_loss: 4022411.5000\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3997054.7500 - val_loss: 3668642.2500\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3518867.5000 - val_loss: 3822184.2500\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3630918.5000 - val_loss: 4395033.5000\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3317026.7500 - val_loss: 3185656.2500\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3322231.5000 - val_loss: 7034373.5000\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2904801.2500 - val_loss: 2864238.5000\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2295411.7500 - val_loss: 3025586.5000\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2341785.2500 - val_loss: 2632559.5000\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2565584.7500 - val_loss: 2514668.2500\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2649570.2500 - val_loss: 2560581.7500\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2226092.5000 - val_loss: 2254009.5000\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2222233.5000 - val_loss: 3601717.2500\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1940455.0000 - val_loss: 2072278.7500\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2076345.3750 - val_loss: 2063003.3750\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1640913.7500 - val_loss: 1976890.8750\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1897477.7500 - val_loss: 2773646.7500\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2322059.2500 - val_loss: 2255046.0000\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1747915.7500 - val_loss: 1856736.6250\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2045473.3750 - val_loss: 3513233.0000\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1724017.5000 - val_loss: 2462398.2500\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1724858.2500 - val_loss: 3292033.0000\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1780801.3750 - val_loss: 1501124.6250\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1306824.3750 - val_loss: 1948911.8750\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1357390.6250 - val_loss: 1298491.2500\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1413546.7500 - val_loss: 1227805.8750\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1428927.5000 - val_loss: 1247818.8750\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1187285.1250 - val_loss: 1151308.7500\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1263830.8750 - val_loss: 1824156.8750\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1240989.2500 - val_loss: 1108512.0000\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1237611.6250 - val_loss: 2218743.5000\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1085424.3750 - val_loss: 983548.1250\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1021947.2500 - val_loss: 1019442.3125\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1172201.0000 - val_loss: 1761045.2500\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1050724.2500 - val_loss: 965786.0625\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 882434.5625 - val_loss: 1044433.6250\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1091721.3750 - val_loss: 1474149.5000\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1053417.2500 - val_loss: 1892308.2500\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 923789.9375 - val_loss: 925436.8125\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1049817.8750 - val_loss: 1022368.0000\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 912992.3125 - val_loss: 1186419.0000\n",
      "Epoch 56/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 824856.8750 - val_loss: 1255952.1250\n",
      "Epoch 57/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1188653.6250 - val_loss: 1072538.3750\n",
      "Epoch 58/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 977818.3750 - val_loss: 1051066.7500\n",
      "Epoch 59/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 810353.1875 - val_loss: 1013235.0625\n",
      "Epoch 60/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 859359.6875 - val_loss: 1063289.5000\n",
      "Epoch 61/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 980442.1250 - val_loss: 968537.0625\n",
      "Epoch 62/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1040037.6250 - val_loss: 1043667.7500\n",
      "Epoch 63/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 935934.6875 - val_loss: 1233302.3750\n",
      "'########################################################Model1\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 5ms/step - loss: 93135264.0000 - val_loss: 34407104.0000\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 27587674.0000 - val_loss: 26187072.0000\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 19440934.0000 - val_loss: 17066172.0000\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 13375445.0000 - val_loss: 13091525.0000\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 11028395.0000 - val_loss: 16317917.0000\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 9443715.0000 - val_loss: 11706765.0000\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 8535388.0000 - val_loss: 9219821.0000\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 7288571.5000 - val_loss: 7407550.0000\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 5378888.5000 - val_loss: 7234135.5000\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 5023835.0000 - val_loss: 5430165.5000\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 4399885.0000 - val_loss: 5235548.0000\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3933127.5000 - val_loss: 4123909.7500\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3897656.0000 - val_loss: 4670864.5000\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 4368478.5000 - val_loss: 3825772.2500\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3120776.7500 - val_loss: 3255901.2500\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3561124.2500 - val_loss: 4098529.5000\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3312788.5000 - val_loss: 3442676.0000\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2868507.5000 - val_loss: 3446819.7500\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2997894.2500 - val_loss: 3297309.5000\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2940908.0000 - val_loss: 2897391.2500\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2162501.7500 - val_loss: 2417576.0000\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2484898.7500 - val_loss: 3133449.5000\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1906665.7500 - val_loss: 1936337.0000\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2106816.5000 - val_loss: 1846989.2500\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2256702.2500 - val_loss: 5196865.0000\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1975480.0000 - val_loss: 3945556.7500\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2016032.8750 - val_loss: 1638175.1250\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1440363.2500 - val_loss: 1462389.0000\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1760508.2500 - val_loss: 1827842.3750\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1409171.2500 - val_loss: 1469864.2500\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1055281.8750 - val_loss: 1865544.1250\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1004983.9375 - val_loss: 1303589.5000\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 944310.9375 - val_loss: 1223656.1250\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 795424.8125 - val_loss: 814706.1250\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 715386.3125 - val_loss: 712891.1875\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 731447.6875 - val_loss: 716605.9375\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 657611.8125 - val_loss: 833555.5000\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 576060.6250 - val_loss: 674367.1875\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 507139.3750 - val_loss: 849725.1875\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 596915.8125 - val_loss: 529647.3125\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 534059.3125 - val_loss: 684385.8125\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 418064.8750 - val_loss: 381281.7812\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 275747.4688 - val_loss: 390982.0000\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 349525.6875 - val_loss: 382408.4375\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 328037.5000 - val_loss: 393020.2500\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 286069.6562 - val_loss: 727617.3125\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 308182.3438 - val_loss: 291301.6875\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 226751.7344 - val_loss: 317160.3750\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 262278.6250 - val_loss: 320981.7500\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 245395.4688 - val_loss: 235342.9531\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 212604.0938 - val_loss: 353064.2500\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 239682.0625 - val_loss: 251486.4844\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 211852.5781 - val_loss: 442238.0000\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 225134.5312 - val_loss: 239110.4219\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 191965.6094 - val_loss: 427092.8125\n",
      "Epoch 56/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 205681.9688 - val_loss: 187852.2188\n",
      "Epoch 57/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 328128.6250 - val_loss: 269261.6875\n",
      "Epoch 58/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 213059.9531 - val_loss: 329120.9688\n",
      "Epoch 59/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 195535.6875 - val_loss: 331486.6875\n",
      "Epoch 60/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 190162.7656 - val_loss: 185610.0156\n",
      "Epoch 61/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 195978.7812 - val_loss: 102804.8750\n",
      "Epoch 62/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 173728.1406 - val_loss: 179324.0312\n",
      "Epoch 63/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 277524.8438 - val_loss: 523144.7188\n",
      "Epoch 64/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 197077.0469 - val_loss: 283878.4375\n",
      "Epoch 65/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 220127.2188 - val_loss: 151228.9219\n",
      "Epoch 66/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 240967.2344 - val_loss: 119724.6094\n",
      "Epoch 67/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 182665.9688 - val_loss: 116898.1250\n",
      "Epoch 68/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 129829.2812 - val_loss: 200310.5156\n",
      "Epoch 69/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 167491.0312 - val_loss: 129823.0469\n",
      "Epoch 70/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 173783.1250 - val_loss: 345276.8750\n",
      "Epoch 71/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 148771.4219 - val_loss: 108295.2969\n",
      "'########################################################Model2\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 6ms/step - loss: 83337424.0000 - val_loss: 30422838.0000\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 25249138.0000 - val_loss: 19772062.0000\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 16882500.0000 - val_loss: 14037115.0000\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 13051517.0000 - val_loss: 11535501.0000\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 9675272.0000 - val_loss: 10017668.0000\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 8827909.0000 - val_loss: 10901106.0000\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 7557645.0000 - val_loss: 6163596.5000\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 6181843.0000 - val_loss: 5682543.0000\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 5011487.5000 - val_loss: 7232547.0000\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 4907506.0000 - val_loss: 4887322.0000\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 4506829.0000 - val_loss: 4708935.5000\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 4896837.5000 - val_loss: 5989758.5000\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 4358676.5000 - val_loss: 4219844.5000\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3876682.5000 - val_loss: 3308295.2500\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2922986.2500 - val_loss: 3119952.2500\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2623528.0000 - val_loss: 3127867.2500\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2853464.2500 - val_loss: 2612178.7500\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2975444.5000 - val_loss: 3200434.0000\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2777879.5000 - val_loss: 5004959.0000\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2950382.2500 - val_loss: 3688670.0000\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3176947.7500 - val_loss: 2585885.0000\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2149438.5000 - val_loss: 2229765.7500\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1824325.2500 - val_loss: 2153304.2500\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1770827.3750 - val_loss: 1801091.8750\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1787335.0000 - val_loss: 2009999.8750\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1629246.6250 - val_loss: 2101124.5000\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1964284.7500 - val_loss: 1890523.1250\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1447723.3750 - val_loss: 1626423.1250\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1857467.1250 - val_loss: 2543106.2500\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1939261.1250 - val_loss: 1800578.1250\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1536456.6250 - val_loss: 1418601.6250\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1398044.7500 - val_loss: 2034639.2500\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1296905.0000 - val_loss: 1372452.7500\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1634789.8750 - val_loss: 2243441.0000\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1457366.2500 - val_loss: 1014012.6875\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1642714.8750 - val_loss: 1400836.7500\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1440620.6250 - val_loss: 1150711.0000\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1389755.7500 - val_loss: 1129895.7500\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1194393.8750 - val_loss: 906569.1875\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 967224.1875 - val_loss: 870270.9375\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 907913.3750 - val_loss: 948945.6250\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1024865.4375 - val_loss: 769951.0000\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 754061.8125 - val_loss: 659795.5625\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 681983.0000 - val_loss: 1164133.1250\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 744243.3125 - val_loss: 1025194.6875\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 889339.5625 - val_loss: 615681.1875\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 772612.0625 - val_loss: 682292.6875\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 782136.7500 - val_loss: 626430.7500\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 762864.8125 - val_loss: 818516.6875\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 673257.4375 - val_loss: 464647.8750\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 405727.6875 - val_loss: 510559.6562\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 384486.4688 - val_loss: 474238.2812\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 303586.0625 - val_loss: 296975.2500\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 363705.5312 - val_loss: 307417.5938\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 261638.3750 - val_loss: 381832.7812\n",
      "Epoch 56/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 266984.5000 - val_loss: 216765.8594\n",
      "Epoch 57/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 234326.5156 - val_loss: 244580.1094\n",
      "Epoch 58/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 251732.3594 - val_loss: 278820.4688\n",
      "Epoch 59/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 235281.9531 - val_loss: 376822.9375\n",
      "Epoch 60/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 209008.1406 - val_loss: 245149.6562\n",
      "Epoch 61/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 164550.9688 - val_loss: 197795.5312\n",
      "Epoch 62/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 158544.5312 - val_loss: 149641.4062\n",
      "Epoch 63/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 172108.6719 - val_loss: 182938.7031\n",
      "Epoch 64/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 150295.0156 - val_loss: 150288.9062\n",
      "Epoch 65/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 147864.1250 - val_loss: 147503.3594\n",
      "Epoch 66/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 173192.2812 - val_loss: 119294.3828\n",
      "Epoch 67/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 101610.4688 - val_loss: 181701.3125\n",
      "Epoch 68/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 155755.2031 - val_loss: 207788.4219\n",
      "Epoch 69/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124673.9688 - val_loss: 155986.2969\n",
      "Epoch 70/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126254.1953 - val_loss: 125771.7656\n",
      "Epoch 71/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 116816.6797 - val_loss: 149071.8125\n",
      "Epoch 72/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 163218.7344 - val_loss: 259074.1562\n",
      "Epoch 73/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 191247.5312 - val_loss: 196144.3125\n",
      "Epoch 74/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 110766.6562 - val_loss: 151083.4688\n",
      "Epoch 75/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125349.2578 - val_loss: 89240.1719\n",
      "Epoch 76/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 87375.1797 - val_loss: 101326.8672\n",
      "Epoch 77/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123737.9141 - val_loss: 86085.6328\n",
      "Epoch 78/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125193.5703 - val_loss: 158420.0625\n",
      "Epoch 79/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 94672.8125 - val_loss: 224971.0000\n",
      "Epoch 80/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 114990.8047 - val_loss: 86843.3906\n",
      "Epoch 81/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 72247.7109 - val_loss: 99405.7969\n",
      "Epoch 82/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 87915.1484 - val_loss: 79560.5000\n",
      "Epoch 83/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 90992.0547 - val_loss: 103589.3984\n",
      "Epoch 84/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 69187.2500 - val_loss: 95945.9219\n",
      "Epoch 85/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 84046.4219 - val_loss: 67901.9609\n",
      "Epoch 86/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 63784.5508 - val_loss: 72683.3203\n",
      "Epoch 87/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 40615.8125 - val_loss: 81562.4141\n",
      "Epoch 88/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 63196.8672 - val_loss: 72116.1719\n",
      "Epoch 89/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 44365.5234 - val_loss: 84238.3047\n",
      "Epoch 90/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 56570.6250 - val_loss: 29643.9316\n",
      "Epoch 91/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 42838.7031 - val_loss: 24843.0664\n",
      "Epoch 92/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 29406.4648 - val_loss: 146983.3906\n",
      "Epoch 93/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 55057.7617 - val_loss: 11114.2666\n",
      "Epoch 94/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 42825.7305 - val_loss: 138919.6250\n",
      "Epoch 95/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 37762.9258 - val_loss: 47251.7305\n",
      "Epoch 96/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 29166.3906 - val_loss: 40750.2188\n",
      "Epoch 97/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 39741.8906 - val_loss: 28456.1602\n",
      "Epoch 98/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 25714.1934 - val_loss: 14544.4375\n",
      "Epoch 99/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 32708.8867 - val_loss: 60495.7812\n",
      "Epoch 100/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 27274.9277 - val_loss: 19548.2246\n",
      "'########################################################Model3\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 5ms/step - loss: 94991288.0000 - val_loss: 35589244.0000\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 29668278.0000 - val_loss: 18966098.0000\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 18498746.0000 - val_loss: 16871736.0000\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 15333450.0000 - val_loss: 13014148.0000\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 11924820.0000 - val_loss: 9562156.0000\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 10032133.0000 - val_loss: 13540960.0000\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 9756849.0000 - val_loss: 7693595.5000\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 7192744.0000 - val_loss: 9928143.0000\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 8404392.0000 - val_loss: 6156127.0000\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 5883372.0000 - val_loss: 5255850.0000\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 4576942.5000 - val_loss: 6070727.0000\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 5041914.5000 - val_loss: 5177146.5000\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 4563173.0000 - val_loss: 5344076.5000\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 4597937.0000 - val_loss: 6112833.5000\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 4235982.0000 - val_loss: 3514211.0000\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3310500.7500 - val_loss: 3015538.2500\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3151530.2500 - val_loss: 3081556.2500\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3772005.5000 - val_loss: 3639565.7500\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3304711.0000 - val_loss: 5335746.0000\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2486178.2500 - val_loss: 3048298.0000\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2666696.0000 - val_loss: 2137449.7500\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1908004.0000 - val_loss: 2277609.7500\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2147253.0000 - val_loss: 5599375.0000\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2130970.5000 - val_loss: 3569377.5000\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2076992.8750 - val_loss: 2848926.0000\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1937120.0000 - val_loss: 3120920.7500\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2143499.2500 - val_loss: 3291285.7500\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1890811.6250 - val_loss: 1700439.5000\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1591224.3750 - val_loss: 1210702.6250\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1500522.8750 - val_loss: 1377138.1250\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1838624.5000 - val_loss: 2122894.5000\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1113197.3750 - val_loss: 1062130.5000\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1204571.6250 - val_loss: 1236690.6250\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1224527.2500 - val_loss: 1021654.3750\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1145007.5000 - val_loss: 1051829.3750\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1116836.8750 - val_loss: 1530736.2500\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 903340.0000 - val_loss: 871596.5000\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 788921.4375 - val_loss: 723933.4375\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 746322.3125 - val_loss: 713619.5000\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 776248.6875 - val_loss: 874498.5625\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 802671.1875 - val_loss: 1106162.2500\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 621048.5625 - val_loss: 714443.1875\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 736653.6250 - val_loss: 493326.2812\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 514813.7812 - val_loss: 536004.4375\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 454540.0312 - val_loss: 623630.2500\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 485730.6562 - val_loss: 581927.7500\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 411110.2812 - val_loss: 573179.3750\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 384949.5312 - val_loss: 412473.2812\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 332661.5312 - val_loss: 416737.0625\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 303639.6875 - val_loss: 373270.1562\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 331031.3125 - val_loss: 309163.2812\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 313828.1875 - val_loss: 331656.9688\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 250259.1406 - val_loss: 513873.5000\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 403194.2812 - val_loss: 626570.5625\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 355576.2188 - val_loss: 459564.3438\n",
      "Epoch 56/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 315794.2500 - val_loss: 299880.7188\n",
      "Epoch 57/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 346476.1875 - val_loss: 347629.9688\n",
      "Epoch 58/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 277234.9375 - val_loss: 354933.8125\n",
      "Epoch 59/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 244707.6094 - val_loss: 226897.0156\n",
      "Epoch 60/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 259315.4219 - val_loss: 372881.9375\n",
      "Epoch 61/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 219270.2656 - val_loss: 330235.1875\n",
      "Epoch 62/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 272291.7500 - val_loss: 233748.0000\n",
      "Epoch 63/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 223195.8750 - val_loss: 304959.7500\n",
      "Epoch 64/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 265250.2812 - val_loss: 339770.2500\n",
      "Epoch 65/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 242914.1250 - val_loss: 350267.1250\n",
      "Epoch 66/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 258080.7500 - val_loss: 332866.0000\n",
      "Epoch 67/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 280789.2188 - val_loss: 165662.9688\n",
      "Epoch 68/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 195999.3281 - val_loss: 353565.9375\n",
      "Epoch 69/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 248043.1250 - val_loss: 189931.2969\n",
      "Epoch 70/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 228518.7188 - val_loss: 181260.5938\n",
      "Epoch 71/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 242631.3438 - val_loss: 316238.9062\n",
      "Epoch 72/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 245066.7344 - val_loss: 242832.3594\n",
      "Epoch 73/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 193970.6562 - val_loss: 373623.5625\n",
      "Epoch 74/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 198553.0156 - val_loss: 159102.8125\n",
      "Epoch 75/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 200530.0000 - val_loss: 191468.8906\n",
      "Epoch 76/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 220090.3125 - val_loss: 214464.6250\n",
      "Epoch 77/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 208163.7188 - val_loss: 218895.5469\n",
      "Epoch 78/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 209793.4062 - val_loss: 224662.2344\n",
      "Epoch 79/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 191384.2500 - val_loss: 242470.2031\n",
      "Epoch 80/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 198777.7031 - val_loss: 126781.1172\n",
      "Epoch 81/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 181978.0469 - val_loss: 339387.3438\n",
      "Epoch 82/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 213314.9375 - val_loss: 171962.5469\n",
      "Epoch 83/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 153858.1719 - val_loss: 229263.8125\n",
      "Epoch 84/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 189525.8438 - val_loss: 174750.1094\n",
      "Epoch 85/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 224951.2344 - val_loss: 103716.9609\n",
      "Epoch 86/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 171153.5781 - val_loss: 940553.5000\n",
      "Epoch 87/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 192937.3438 - val_loss: 150714.8750\n",
      "Epoch 88/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 149869.7656 - val_loss: 162563.7188\n",
      "Epoch 89/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 208908.1094 - val_loss: 594979.3750\n",
      "Epoch 90/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 250622.1250 - val_loss: 108672.9297\n",
      "Epoch 91/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 135002.6406 - val_loss: 67994.9297\n",
      "Epoch 92/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 112221.8203 - val_loss: 100023.4453\n",
      "Epoch 93/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127912.6875 - val_loss: 121405.7109\n",
      "Epoch 94/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 146960.0469 - val_loss: 229056.7656\n",
      "Epoch 95/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 116245.2812 - val_loss: 40730.9023\n",
      "Epoch 96/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 108218.0859 - val_loss: 128210.6328\n",
      "Epoch 97/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 191260.8750 - val_loss: 164340.7344\n",
      "Epoch 98/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 113403.4453 - val_loss: 153843.4531\n",
      "Epoch 99/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 170561.9531 - val_loss: 381071.6562\n",
      "Epoch 100/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 101994.8672 - val_loss: 79414.1953\n",
      "'########################################################Model4\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 6ms/step - loss: 79644152.0000 - val_loss: 31586036.0000\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 27469452.0000 - val_loss: 21743220.0000\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 16925158.0000 - val_loss: 15647170.0000\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 13581014.0000 - val_loss: 11199354.0000\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 12298931.0000 - val_loss: 10662543.0000\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 10171885.0000 - val_loss: 9338930.0000\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 9022517.0000 - val_loss: 8342813.0000\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 7767032.0000 - val_loss: 8115422.5000\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 7478733.5000 - val_loss: 7013025.0000\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 6518404.5000 - val_loss: 7303486.0000\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 5399715.5000 - val_loss: 5243197.5000\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 5261131.5000 - val_loss: 7023259.0000\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 5343481.5000 - val_loss: 5130870.5000\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 4835543.0000 - val_loss: 7097719.5000\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 4205736.5000 - val_loss: 4478421.5000\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 4859170.5000 - val_loss: 4419364.0000\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3332891.2500 - val_loss: 4151053.2500\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3212562.0000 - val_loss: 4008027.2500\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3536327.0000 - val_loss: 3033930.5000\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2782984.2500 - val_loss: 3136109.0000\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3319333.2500 - val_loss: 3581470.0000\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2523932.0000 - val_loss: 4596418.0000\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2819794.0000 - val_loss: 2683980.2500\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2771169.2500 - val_loss: 2413264.2500\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2326922.2500 - val_loss: 2451647.2500\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2073054.5000 - val_loss: 1996475.3750\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2042666.1250 - val_loss: 3585704.0000\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2358340.5000 - val_loss: 2022301.7500\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1842500.3750 - val_loss: 1773182.6250\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1827229.5000 - val_loss: 1621149.6250\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1683814.1250 - val_loss: 2326256.0000\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1799573.8750 - val_loss: 2356434.0000\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1870032.5000 - val_loss: 1744265.0000\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1834307.0000 - val_loss: 2248737.5000\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2006743.3750 - val_loss: 1892059.7500\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1983494.8750 - val_loss: 1911371.2500\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1441393.1250 - val_loss: 2243676.7500\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2148856.0000 - val_loss: 1597805.6250\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1605130.8750 - val_loss: 1380886.7500\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1583894.2500 - val_loss: 1804307.6250\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1316957.8750 - val_loss: 1392430.5000\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1301398.6250 - val_loss: 1633400.0000\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1286440.7500 - val_loss: 1567635.7500\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1800816.2500 - val_loss: 1250697.8750\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1649569.8750 - val_loss: 2130450.5000\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1419571.7500 - val_loss: 1526851.0000\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1480115.5000 - val_loss: 1464077.6250\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1030953.2500 - val_loss: 1236249.1250\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1006211.3125 - val_loss: 1455444.0000\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1328937.0000 - val_loss: 1293556.1250\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1182179.5000 - val_loss: 968216.6250\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1311821.1250 - val_loss: 1032114.5625\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1038897.0000 - val_loss: 1235081.2500\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 928941.0000 - val_loss: 1038295.5000\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1239672.5000 - val_loss: 1606855.2500\n",
      "Epoch 56/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1354611.2500 - val_loss: 1242429.1250\n",
      "Epoch 57/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1103641.0000 - val_loss: 1376407.8750\n",
      "Epoch 58/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1123324.5000 - val_loss: 878347.0000\n",
      "Epoch 59/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 989863.9375 - val_loss: 1094461.8750\n",
      "Epoch 60/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 766417.7500 - val_loss: 804573.4375\n",
      "Epoch 61/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 952805.7500 - val_loss: 969986.7500\n",
      "Epoch 62/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 747083.0625 - val_loss: 796249.9375\n",
      "Epoch 63/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 779365.1250 - val_loss: 1227114.8750\n",
      "Epoch 64/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 832062.8750 - val_loss: 833643.1250\n",
      "Epoch 65/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 747662.6875 - val_loss: 801085.6875\n",
      "Epoch 66/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 876305.4375 - val_loss: 1196557.0000\n",
      "Epoch 67/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 836252.8125 - val_loss: 763178.8750\n",
      "Epoch 68/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 718939.0625 - val_loss: 1003459.4375\n",
      "Epoch 69/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 614802.5625 - val_loss: 626476.1875\n",
      "Epoch 70/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 573280.3125 - val_loss: 603991.3750\n",
      "Epoch 71/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 599437.5000 - val_loss: 747662.8125\n",
      "Epoch 72/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 639590.8125 - val_loss: 640177.6250\n",
      "Epoch 73/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 565221.3750 - val_loss: 526275.5000\n",
      "Epoch 74/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 388544.0938 - val_loss: 458342.4688\n",
      "Epoch 75/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 415534.7812 - val_loss: 514142.6875\n",
      "Epoch 76/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 399393.8438 - val_loss: 901660.4375\n",
      "Epoch 77/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 439661.2500 - val_loss: 388891.9688\n",
      "Epoch 78/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 332541.3125 - val_loss: 339378.2188\n",
      "Epoch 79/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 409626.1250 - val_loss: 627775.7500\n",
      "Epoch 80/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 395088.9688 - val_loss: 328082.1562\n",
      "Epoch 81/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 357069.9062 - val_loss: 343180.3438\n",
      "Epoch 82/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 264601.6562 - val_loss: 362483.9688\n",
      "Epoch 83/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 274365.1562 - val_loss: 507187.8750\n",
      "Epoch 84/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 296642.9375 - val_loss: 402513.5938\n",
      "Epoch 85/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 247520.7188 - val_loss: 383697.2500\n",
      "Epoch 86/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 223063.0000 - val_loss: 417212.2812\n",
      "Epoch 87/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 240773.7656 - val_loss: 416604.3750\n",
      "Epoch 88/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 217229.7031 - val_loss: 221844.8438\n",
      "Epoch 89/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 182405.4531 - val_loss: 305710.4688\n",
      "Epoch 90/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 216331.6719 - val_loss: 349225.0625\n",
      "Epoch 91/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 241777.8438 - val_loss: 210640.0938\n",
      "Epoch 92/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 190220.1562 - val_loss: 403026.3438\n",
      "Epoch 93/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 211664.2188 - val_loss: 334470.6875\n",
      "Epoch 94/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 187498.0625 - val_loss: 534117.5000\n",
      "Epoch 95/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 179439.0781 - val_loss: 132453.3281\n",
      "Epoch 96/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126245.9141 - val_loss: 150674.2812\n",
      "Epoch 97/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 137084.2500 - val_loss: 120877.2266\n",
      "Epoch 98/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 146992.4844 - val_loss: 128035.2656\n",
      "Epoch 99/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 133199.8594 - val_loss: 256472.9375\n",
      "Epoch 100/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 133989.8750 - val_loss: 114684.6172\n",
      "'########################################################Model5\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 5ms/step - loss: 80586936.0000 - val_loss: 31404596.0000\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 28035512.0000 - val_loss: 23963104.0000\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 20733514.0000 - val_loss: 18122734.0000\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 14419857.0000 - val_loss: 12603373.0000\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 11615205.0000 - val_loss: 10361280.0000\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 9524511.0000 - val_loss: 9312442.0000\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 8905366.0000 - val_loss: 11941612.0000\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 7894893.5000 - val_loss: 7310018.0000\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 7674265.5000 - val_loss: 8671787.0000\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 5620991.5000 - val_loss: 8886900.0000\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 5230328.0000 - val_loss: 6010238.5000\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 5078227.5000 - val_loss: 6877603.0000\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 5270490.0000 - val_loss: 5383926.0000\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3930596.2500 - val_loss: 4287962.5000\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 4269142.0000 - val_loss: 5929842.5000\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3653640.5000 - val_loss: 3848062.2500\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3193535.2500 - val_loss: 3951187.7500\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3324278.7500 - val_loss: 3392189.0000\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2879546.2500 - val_loss: 4222742.0000\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3274693.0000 - val_loss: 3380420.7500\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2824464.0000 - val_loss: 3104195.7500\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2441815.2500 - val_loss: 2508519.0000\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2787047.5000 - val_loss: 2201134.2500\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1995385.3750 - val_loss: 2302704.7500\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2151159.0000 - val_loss: 2782986.2500\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2218355.5000 - val_loss: 2185670.5000\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1950102.5000 - val_loss: 2423993.5000\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2101516.0000 - val_loss: 4033034.5000\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2192614.7500 - val_loss: 1901741.5000\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1769969.0000 - val_loss: 1905077.3750\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1505766.7500 - val_loss: 1684247.7500\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1506138.3750 - val_loss: 2646121.2500\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1781634.2500 - val_loss: 1272368.1250\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1640483.7500 - val_loss: 2427434.2500\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1480092.7500 - val_loss: 1236556.6250\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1298382.0000 - val_loss: 3220130.7500\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1777451.0000 - val_loss: 2001176.0000\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1420818.8750 - val_loss: 1439582.6250\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1239000.1250 - val_loss: 2769154.7500\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1355631.2500 - val_loss: 1222068.6250\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1347183.5000 - val_loss: 1127254.8750\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1102697.1250 - val_loss: 875235.3750\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1131128.7500 - val_loss: 985427.0000\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1190943.5000 - val_loss: 1305497.0000\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1006911.5625 - val_loss: 1293991.3750\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1229137.6250 - val_loss: 904441.4375\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 896645.5000 - val_loss: 848835.4375\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 845436.0000 - val_loss: 1280937.0000\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 772955.8125 - val_loss: 1078168.8750\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 924181.0625 - val_loss: 774308.1875\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 856434.4375 - val_loss: 919929.1875\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 781735.5000 - val_loss: 648966.7500\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 786064.4375 - val_loss: 889312.8750\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 721643.1875 - val_loss: 709467.8750\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 887392.0625 - val_loss: 611107.8125\n",
      "Epoch 56/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 747680.9375 - val_loss: 1096665.8750\n",
      "Epoch 57/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 683775.3125 - val_loss: 1449095.8750\n",
      "Epoch 58/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 769826.6250 - val_loss: 497896.6562\n",
      "Epoch 59/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 511791.7188 - val_loss: 621475.3125\n",
      "Epoch 60/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 566901.4375 - val_loss: 914118.6875\n",
      "Epoch 61/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 517977.0625 - val_loss: 1153747.0000\n",
      "Epoch 62/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 576011.5000 - val_loss: 470552.4375\n",
      "Epoch 63/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 537983.3125 - val_loss: 435301.0938\n",
      "Epoch 64/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 408194.0625 - val_loss: 464528.6562\n",
      "Epoch 65/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 388954.3438 - val_loss: 377201.8750\n",
      "Epoch 66/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 391977.9375 - val_loss: 372634.0312\n",
      "Epoch 67/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 377976.1250 - val_loss: 333120.7500\n",
      "Epoch 68/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 245622.7031 - val_loss: 292408.6562\n",
      "Epoch 69/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 344105.9688 - val_loss: 489089.0938\n",
      "Epoch 70/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 314743.7500 - val_loss: 263185.4375\n",
      "Epoch 71/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 270981.7188 - val_loss: 323117.7188\n",
      "Epoch 72/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 358833.2812 - val_loss: 155486.7188\n",
      "Epoch 73/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 332863.5000 - val_loss: 220411.2031\n",
      "Epoch 74/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 223416.2031 - val_loss: 332615.4375\n",
      "Epoch 75/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 386977.9062 - val_loss: 246643.7031\n",
      "Epoch 76/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 296695.1875 - val_loss: 434688.8125\n",
      "Epoch 77/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 194005.5938 - val_loss: 204537.7031\n",
      "Epoch 78/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 274547.6562 - val_loss: 233186.9219\n",
      "Epoch 79/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 165136.8438 - val_loss: 132678.5000\n",
      "Epoch 80/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 197339.1250 - val_loss: 261024.8750\n",
      "Epoch 81/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 208907.8125 - val_loss: 216585.8750\n",
      "Epoch 82/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 183876.7031 - val_loss: 193012.4375\n",
      "Epoch 83/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 245574.7031 - val_loss: 253104.1875\n",
      "Epoch 84/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 256798.2656 - val_loss: 164025.0000\n",
      "Epoch 85/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 182171.8594 - val_loss: 278453.3438\n",
      "Epoch 86/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 210610.7969 - val_loss: 268814.4062\n",
      "Epoch 87/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 151898.4062 - val_loss: 321114.0000\n",
      "Epoch 88/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 200866.5312 - val_loss: 301758.7500\n",
      "Epoch 89/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 267159.8438 - val_loss: 345730.6562\n",
      "'########################################################Model6\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 6ms/step - loss: 95577328.0000 - val_loss: 35062096.0000\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 29661696.0000 - val_loss: 22853252.0000\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 18710344.0000 - val_loss: 18659502.0000\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 15887909.0000 - val_loss: 17734196.0000\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 13374986.0000 - val_loss: 12970206.0000\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 11432863.0000 - val_loss: 11472305.0000\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 9337222.0000 - val_loss: 9672230.0000\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 9253193.0000 - val_loss: 8399394.0000\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 7707639.0000 - val_loss: 8253622.5000\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 6620207.0000 - val_loss: 8449528.0000\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 6847592.0000 - val_loss: 7312768.0000\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 6228305.0000 - val_loss: 8548944.0000\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 6714917.0000 - val_loss: 5672785.5000\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 5717408.0000 - val_loss: 5673603.5000\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 5008536.5000 - val_loss: 4658189.0000\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 4899810.0000 - val_loss: 10001108.0000\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 4688645.0000 - val_loss: 6580555.5000\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 4676336.0000 - val_loss: 3747790.5000\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3970875.2500 - val_loss: 3817930.5000\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3362305.7500 - val_loss: 5319332.5000\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3683674.2500 - val_loss: 4389389.5000\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3066460.7500 - val_loss: 3162286.0000\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3103852.2500 - val_loss: 3141482.7500\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3030142.7500 - val_loss: 3298474.5000\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2910354.5000 - val_loss: 3315671.0000\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2828123.2500 - val_loss: 3294366.2500\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2743599.7500 - val_loss: 2588849.2500\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3083336.0000 - val_loss: 4340062.0000\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2359802.0000 - val_loss: 2630519.7500\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1974180.6250 - val_loss: 2247460.0000\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2166312.5000 - val_loss: 6613665.5000\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2541185.7500 - val_loss: 2137004.2500\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2005591.0000 - val_loss: 3080208.5000\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2168373.5000 - val_loss: 2061766.1250\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2178981.2500 - val_loss: 1963119.2500\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1867812.8750 - val_loss: 1995847.0000\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2267359.7500 - val_loss: 3629561.7500\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2220774.2500 - val_loss: 2338578.0000\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1470015.1250 - val_loss: 2073443.2500\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1285973.8750 - val_loss: 1325104.5000\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1289820.8750 - val_loss: 2301347.5000\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1320179.6250 - val_loss: 1284740.0000\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1433366.1250 - val_loss: 2120678.2500\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1545737.0000 - val_loss: 1292938.8750\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1169686.8750 - val_loss: 1197369.6250\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1301193.0000 - val_loss: 1120336.6250\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1062407.5000 - val_loss: 1450421.1250\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1065846.5000 - val_loss: 1341412.3750\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1070989.8750 - val_loss: 958745.2500\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1155789.8750 - val_loss: 930907.5625\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 917685.5625 - val_loss: 1678989.1250\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 843858.3750 - val_loss: 1106096.5000\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 831572.3750 - val_loss: 764855.4375\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 743417.1875 - val_loss: 586897.8125\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 690394.6875 - val_loss: 947153.1875\n",
      "Epoch 56/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 627147.3750 - val_loss: 610625.0000\n",
      "Epoch 57/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 527402.6250 - val_loss: 581273.7500\n",
      "Epoch 58/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 477706.5938 - val_loss: 479081.3125\n",
      "Epoch 59/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 564284.7500 - val_loss: 817031.1875\n",
      "Epoch 60/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 429736.5312 - val_loss: 635701.7500\n",
      "Epoch 61/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 457920.5938 - val_loss: 510566.5000\n",
      "Epoch 62/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 397209.2812 - val_loss: 244242.1250\n",
      "Epoch 63/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 370033.9688 - val_loss: 369134.5312\n",
      "Epoch 64/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 310422.4688 - val_loss: 298969.7500\n",
      "Epoch 65/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 288649.8125 - val_loss: 296544.0312\n",
      "Epoch 66/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 314893.6875 - val_loss: 369206.9375\n",
      "Epoch 67/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 269239.5312 - val_loss: 291866.7188\n",
      "Epoch 68/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 259310.4062 - val_loss: 263921.9688\n",
      "Epoch 69/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 352456.7188 - val_loss: 324706.8438\n",
      "Epoch 70/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 304014.1875 - val_loss: 319143.1875\n",
      "Epoch 71/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 234255.5938 - val_loss: 191589.4844\n",
      "Epoch 72/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 217291.9844 - val_loss: 258815.6094\n",
      "Epoch 73/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 230248.7656 - val_loss: 247336.9375\n",
      "Epoch 74/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 275231.2188 - val_loss: 229165.0000\n",
      "Epoch 75/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 246113.1875 - val_loss: 355235.2812\n",
      "Epoch 76/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 246452.5781 - val_loss: 268917.0000\n",
      "Epoch 77/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 227262.8125 - val_loss: 638292.0625\n",
      "Epoch 78/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 286858.2500 - val_loss: 638864.0625\n",
      "Epoch 79/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 242602.2344 - val_loss: 195949.2344\n",
      "Epoch 80/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 221408.0469 - val_loss: 301031.9062\n",
      "Epoch 81/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 197138.2188 - val_loss: 189561.5000\n",
      "Epoch 82/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 250645.3281 - val_loss: 299195.9375\n",
      "Epoch 83/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 282398.4688 - val_loss: 270052.3438\n",
      "Epoch 84/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 181064.9844 - val_loss: 338282.7188\n",
      "Epoch 85/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 220177.0781 - val_loss: 196256.4688\n",
      "Epoch 86/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 164875.2031 - val_loss: 266142.5312\n",
      "Epoch 87/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 196207.4219 - val_loss: 257684.4062\n",
      "Epoch 88/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 165562.9219 - val_loss: 244785.3594\n",
      "Epoch 89/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 165188.5156 - val_loss: 222353.6875\n",
      "Epoch 90/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 195818.0156 - val_loss: 217393.2656\n",
      "Epoch 91/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 204718.2344 - val_loss: 125426.3438\n",
      "Epoch 92/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 156058.6875 - val_loss: 116829.5859\n",
      "Epoch 93/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 130697.8359 - val_loss: 102337.8047\n",
      "Epoch 94/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 188117.8906 - val_loss: 206668.8750\n",
      "Epoch 95/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 147278.6094 - val_loss: 139999.1094\n",
      "Epoch 96/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 162535.7500 - val_loss: 116494.3047\n",
      "Epoch 97/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 107937.5156 - val_loss: 140011.9375\n",
      "Epoch 98/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 140286.7500 - val_loss: 183184.6406\n",
      "Epoch 99/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 157565.0312 - val_loss: 310336.2188\n",
      "Epoch 100/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 187359.7031 - val_loss: 223934.1250\n",
      "'########################################################Model7\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 5ms/step - loss: 86919536.0000 - val_loss: 34155704.0000\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 28046824.0000 - val_loss: 21575192.0000\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 17534278.0000 - val_loss: 14862539.0000\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 13383706.0000 - val_loss: 13085842.0000\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 10349040.0000 - val_loss: 8289913.0000\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 9452382.0000 - val_loss: 7856781.0000\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 6729093.5000 - val_loss: 7035263.5000\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 6461719.5000 - val_loss: 7779483.5000\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 5460440.0000 - val_loss: 7620394.5000\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 5312327.5000 - val_loss: 6462197.0000\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 4377793.0000 - val_loss: 4822586.5000\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 4035729.2500 - val_loss: 3539849.2500\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3554543.2500 - val_loss: 3650211.0000\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3261972.5000 - val_loss: 3408613.2500\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3364269.7500 - val_loss: 2953216.0000\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2514201.5000 - val_loss: 2708476.7500\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2378152.5000 - val_loss: 2836022.2500\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2887957.2500 - val_loss: 2915803.0000\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2152568.0000 - val_loss: 1929660.2500\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1813319.6250 - val_loss: 2489660.2500\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1856371.3750 - val_loss: 1834326.1250\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1967509.6250 - val_loss: 1733986.1250\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1451836.5000 - val_loss: 1380564.8750\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1646589.2500 - val_loss: 1833367.2500\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1327529.6250 - val_loss: 1884040.3750\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1255426.3750 - val_loss: 1069961.2500\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 907717.2500 - val_loss: 1375149.6250\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1189993.0000 - val_loss: 1487274.8750\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 920253.5000 - val_loss: 721114.5000\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 608627.5625 - val_loss: 495027.3750\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 639939.6250 - val_loss: 385146.7812\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 514574.1250 - val_loss: 320678.9688\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 291437.2812 - val_loss: 510319.1250\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 357968.7812 - val_loss: 389831.6562\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 255477.1094 - val_loss: 229039.4844\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 205321.3906 - val_loss: 409233.5625\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 173190.8281 - val_loss: 171683.1250\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 211847.5938 - val_loss: 579671.3125\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 261896.8750 - val_loss: 120991.8750\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 205946.8906 - val_loss: 578462.0000\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 267810.1562 - val_loss: 361608.8125\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 166991.5625 - val_loss: 88097.1484\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 151044.4688 - val_loss: 235755.0625\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 179546.9844 - val_loss: 254169.9844\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 194175.1562 - val_loss: 93020.2266\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 143854.6406 - val_loss: 78679.8750\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 144834.4062 - val_loss: 176120.9844\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 102405.3281 - val_loss: 46316.3945\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124022.6172 - val_loss: 151592.5000\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 112531.6797 - val_loss: 203203.7969\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 87779.2422 - val_loss: 308075.5938\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 147566.2031 - val_loss: 90847.6953\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 114347.6094 - val_loss: 126806.6328\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 118199.9141 - val_loss: 50613.3789\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 155316.3906 - val_loss: 499967.8750\n",
      "Epoch 56/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 160640.2656 - val_loss: 162899.9688\n",
      "Epoch 57/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125468.7422 - val_loss: 62086.6914\n",
      "Epoch 58/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 115861.0781 - val_loss: 113850.9219\n",
      "'########################################################Model8\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 5ms/step - loss: 86389392.0000 - val_loss: 37370288.0000\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 26920008.0000 - val_loss: 18497168.0000\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 16791464.0000 - val_loss: 16070220.0000\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 13497183.0000 - val_loss: 12086531.0000\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 11657408.0000 - val_loss: 11230452.0000\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 9934974.0000 - val_loss: 9236043.0000\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 8408855.0000 - val_loss: 8531201.0000\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 7253067.5000 - val_loss: 9169041.0000\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 5846993.0000 - val_loss: 5717699.5000\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 4968457.0000 - val_loss: 6827826.5000\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 5159725.0000 - val_loss: 6867693.5000\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 4902538.5000 - val_loss: 4859105.5000\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3919510.5000 - val_loss: 4428276.0000\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3946056.7500 - val_loss: 3683118.0000\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3566818.5000 - val_loss: 3059565.2500\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2970212.5000 - val_loss: 3159404.2500\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2627310.0000 - val_loss: 4851706.5000\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3233914.7500 - val_loss: 3402035.2500\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2834110.2500 - val_loss: 5103998.5000\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 3009109.0000 - val_loss: 2754937.7500\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2354041.5000 - val_loss: 2491088.2500\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2481921.0000 - val_loss: 2434375.2500\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2175838.2500 - val_loss: 2427665.2500\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2141268.2500 - val_loss: 1958550.5000\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2652979.2500 - val_loss: 3313575.0000\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2463668.2500 - val_loss: 2093815.0000\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1844542.8750 - val_loss: 1927954.5000\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 2123736.5000 - val_loss: 1631226.8750\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1632246.5000 - val_loss: 1829578.8750\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1416984.2500 - val_loss: 2162263.2500\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1573179.7500 - val_loss: 1775167.3750\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1708943.5000 - val_loss: 1374978.8750\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1603998.2500 - val_loss: 1517488.0000\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1898077.6250 - val_loss: 1643073.1250\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1415178.8750 - val_loss: 1532836.5000\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1212651.8750 - val_loss: 1810600.5000\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1397818.7500 - val_loss: 2811211.0000\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1741890.2500 - val_loss: 1266672.2500\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1165223.1250 - val_loss: 1165525.6250\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1572215.7500 - val_loss: 1666589.5000\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1274277.3750 - val_loss: 1178121.3750\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1155041.6250 - val_loss: 1073772.5000\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1090860.5000 - val_loss: 1219764.2500\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 945011.3125 - val_loss: 1134608.8750\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1021903.1250 - val_loss: 907998.6250\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1063850.7500 - val_loss: 1308468.2500\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 961394.6250 - val_loss: 972014.8750\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1137275.7500 - val_loss: 856983.4375\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 950591.7500 - val_loss: 1082367.5000\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1079665.8750 - val_loss: 798218.5000\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1003841.1250 - val_loss: 896457.0000\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 685940.6875 - val_loss: 770711.5625\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 648627.1250 - val_loss: 775757.0625\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 568644.8750 - val_loss: 834845.1250\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 668006.1250 - val_loss: 563775.3125\n",
      "Epoch 56/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 522296.5000 - val_loss: 603756.0000\n",
      "Epoch 57/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 816260.7500 - val_loss: 606077.8125\n",
      "Epoch 58/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 429995.6250 - val_loss: 525620.0625\n",
      "Epoch 59/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 629388.3125 - val_loss: 612899.2500\n",
      "Epoch 60/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 502546.4688 - val_loss: 520554.0938\n",
      "Epoch 61/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 436167.0000 - val_loss: 347954.1562\n",
      "Epoch 62/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 351524.2188 - val_loss: 392537.0000\n",
      "Epoch 63/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 255177.4844 - val_loss: 322066.3750\n",
      "Epoch 64/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 294755.1875 - val_loss: 284102.9375\n",
      "Epoch 65/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 277688.3750 - val_loss: 341090.7500\n",
      "Epoch 66/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 315221.0938 - val_loss: 412797.8125\n",
      "Epoch 67/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 269677.3438 - val_loss: 365241.0625\n",
      "Epoch 68/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 269584.2500 - val_loss: 280271.5312\n",
      "Epoch 69/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 227841.3125 - val_loss: 330100.8125\n",
      "Epoch 70/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 257635.7031 - val_loss: 260420.5469\n",
      "Epoch 71/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 288331.1875 - val_loss: 259108.2500\n",
      "Epoch 72/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 180100.5781 - val_loss: 283101.7500\n",
      "Epoch 73/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 197824.8750 - val_loss: 163821.0312\n",
      "Epoch 74/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 170089.2656 - val_loss: 145274.4375\n",
      "Epoch 75/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 288764.5938 - val_loss: 212577.4688\n",
      "Epoch 76/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 177001.5312 - val_loss: 340085.0312\n",
      "Epoch 77/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 207436.0312 - val_loss: 277329.1875\n",
      "Epoch 78/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 158632.0625 - val_loss: 194706.9688\n",
      "Epoch 79/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 158943.8594 - val_loss: 202156.1875\n",
      "Epoch 80/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 197479.5312 - val_loss: 368770.4688\n",
      "Epoch 81/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 228779.4062 - val_loss: 380344.6250\n",
      "Epoch 82/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 220819.1719 - val_loss: 217088.2969\n",
      "Epoch 83/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 142256.6250 - val_loss: 207262.0000\n",
      "Epoch 84/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 176868.2969 - val_loss: 167621.9375\n",
      "'########################################################Model9\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 6ms/step - loss: 148.3569 - val_loss: 137.8873\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 133.5712 - val_loss: 134.5982\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 133.4371 - val_loss: 138.9611\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 133.7744 - val_loss: 135.7667\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 133.5797 - val_loss: 133.4495\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 134.4397 - val_loss: 136.2792\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 130.7149 - val_loss: 132.6231\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 130.7141 - val_loss: 134.1522\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 128.8101 - val_loss: 133.1672\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 129.1302 - val_loss: 135.6876\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.9249 - val_loss: 132.4384\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 129.6389 - val_loss: 131.1314\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.6846 - val_loss: 133.5154\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.8043 - val_loss: 131.4125\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.5101 - val_loss: 130.4874\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.4090 - val_loss: 133.0321\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.4110 - val_loss: 130.4529\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.5811 - val_loss: 131.2600\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.1087 - val_loss: 130.7481\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.6323 - val_loss: 133.8721\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.6287 - val_loss: 131.4712\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.3826 - val_loss: 131.0725\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 128.1013 - val_loss: 130.3177\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.3638 - val_loss: 130.7191\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.6712 - val_loss: 129.2937\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.9097 - val_loss: 129.5333\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.8307 - val_loss: 131.3253\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.5581 - val_loss: 130.0743\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.4042 - val_loss: 129.2488\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.6326 - val_loss: 129.9910\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.7498 - val_loss: 130.9651\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.3094 - val_loss: 130.7192\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.7782 - val_loss: 130.6328\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.4995 - val_loss: 129.1810\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.0957 - val_loss: 129.6475\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.4275 - val_loss: 127.6907\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.1608 - val_loss: 129.7844\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.2558 - val_loss: 129.4599\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.3007 - val_loss: 131.7833\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.6987 - val_loss: 132.9806\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.6790 - val_loss: 130.2778\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.6278 - val_loss: 129.2906\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.6289 - val_loss: 130.7539\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.2305 - val_loss: 129.1615\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 121.8311 - val_loss: 129.0819\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.3086 - val_loss: 129.2744\n",
      "'########################################################Model0\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 5ms/step - loss: 147.9247 - val_loss: 140.9617\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 136.1300 - val_loss: 137.6918\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 133.4019 - val_loss: 136.2858\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 133.1826 - val_loss: 135.5215\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 131.4649 - val_loss: 135.5967\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 128.6005 - val_loss: 132.3544\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 130.0171 - val_loss: 134.8446\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 130.7021 - val_loss: 130.0841\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 131.1095 - val_loss: 137.5969\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 133.0566 - val_loss: 134.0477\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.9022 - val_loss: 132.4371\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.3073 - val_loss: 133.0991\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.9055 - val_loss: 130.7798\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.7430 - val_loss: 131.7642\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.2582 - val_loss: 130.4191\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.2567 - val_loss: 129.4376\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.4520 - val_loss: 131.7369\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.1862 - val_loss: 131.3180\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.1787 - val_loss: 129.8677\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.0568 - val_loss: 130.8350\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.4175 - val_loss: 130.1616\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.7649 - val_loss: 131.2327\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.2368 - val_loss: 131.4484\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.9974 - val_loss: 131.2175\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.0882 - val_loss: 131.0373\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.3931 - val_loss: 132.9548\n",
      "'########################################################Model1\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 6ms/step - loss: 142.1911 - val_loss: 140.1086\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 133.7304 - val_loss: 138.8615\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 132.8840 - val_loss: 135.4096\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 131.4498 - val_loss: 134.2961\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 128.6990 - val_loss: 134.0474\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 130.7772 - val_loss: 133.6763\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 132.2132 - val_loss: 134.4218\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 130.5147 - val_loss: 133.1202\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 129.0686 - val_loss: 134.3127\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 137.6145 - val_loss: 136.8610\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 129.6957 - val_loss: 131.7511\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 129.0588 - val_loss: 134.1703\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 128.8636 - val_loss: 131.7255\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 129.4131 - val_loss: 133.0506\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 128.2911 - val_loss: 132.9355\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 130.0522 - val_loss: 133.9872\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 128.6575 - val_loss: 130.8142\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.9105 - val_loss: 133.5137\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.5003 - val_loss: 132.6474\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.2445 - val_loss: 131.6786\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.7212 - val_loss: 132.0156\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.9470 - val_loss: 132.3694\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.1145 - val_loss: 130.2790\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.3474 - val_loss: 131.3441\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.2776 - val_loss: 131.7825\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.2493 - val_loss: 130.7837\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.9475 - val_loss: 130.1629\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.0697 - val_loss: 131.2155\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.9425 - val_loss: 130.4533\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.0717 - val_loss: 129.3616\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.6911 - val_loss: 132.4065\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.2142 - val_loss: 130.1785\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.6342 - val_loss: 132.6085\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.5835 - val_loss: 131.3145\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.8095 - val_loss: 129.4460\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.7127 - val_loss: 131.1720\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.2275 - val_loss: 130.0003\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.3272 - val_loss: 130.6383\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.4883 - val_loss: 128.3500\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.7021 - val_loss: 130.3167\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.9717 - val_loss: 130.1978\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.8078 - val_loss: 131.4322\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.5730 - val_loss: 128.4644\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.1453 - val_loss: 128.4637\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.4463 - val_loss: 128.4508\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 121.7492 - val_loss: 129.2870\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 121.4483 - val_loss: 129.1644\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.1197 - val_loss: 131.2021\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.0650 - val_loss: 128.4302\n",
      "'########################################################Model2\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 6ms/step - loss: 142.1521 - val_loss: 140.2592\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 137.5568 - val_loss: 144.2224\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 136.8802 - val_loss: 138.9015\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 132.4664 - val_loss: 136.6329\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 133.8834 - val_loss: 133.4003\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 132.4949 - val_loss: 134.2408\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 133.2745 - val_loss: 135.0136\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 132.1259 - val_loss: 133.8007\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 130.5888 - val_loss: 133.6725\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 128.8207 - val_loss: 136.7796\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 128.7663 - val_loss: 132.7412\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.6249 - val_loss: 132.0108\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.9470 - val_loss: 131.5519\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.4229 - val_loss: 133.5337\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 128.3206 - val_loss: 132.7168\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.5186 - val_loss: 130.7856\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 130.1489 - val_loss: 135.7908\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 128.6709 - val_loss: 132.1501\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 128.1517 - val_loss: 134.0017\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.9156 - val_loss: 131.4149\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.5179 - val_loss: 130.2964\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.0216 - val_loss: 131.3320\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.3224 - val_loss: 130.7875\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.0451 - val_loss: 132.9101\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.2053 - val_loss: 128.2157\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.0163 - val_loss: 130.8027\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.8011 - val_loss: 130.3896\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.0412 - val_loss: 130.0713\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.6973 - val_loss: 131.0493\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.2773 - val_loss: 128.5600\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.0102 - val_loss: 128.6552\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.7115 - val_loss: 131.6498\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.7897 - val_loss: 130.4563\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.9614 - val_loss: 129.8076\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.9182 - val_loss: 129.7998\n",
      "'########################################################Model3\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 5ms/step - loss: 145.1452 - val_loss: 139.0819\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 134.7184 - val_loss: 138.6782\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 133.1348 - val_loss: 137.0717\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 134.5758 - val_loss: 137.3862\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 132.1564 - val_loss: 133.6572\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 131.5277 - val_loss: 134.8950\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 129.9286 - val_loss: 133.8184\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 129.9788 - val_loss: 133.0245\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 128.3011 - val_loss: 134.1625\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 133.9231 - val_loss: 133.2230\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 129.5096 - val_loss: 133.6321\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 128.1288 - val_loss: 132.0298\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.5212 - val_loss: 132.9665\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.2723 - val_loss: 130.4663\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.1506 - val_loss: 130.3516\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.1509 - val_loss: 131.2564\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.8049 - val_loss: 131.3065\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.2192 - val_loss: 131.8104\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.6766 - val_loss: 133.1230\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.2256 - val_loss: 130.2940\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.6307 - val_loss: 130.4028\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.5425 - val_loss: 131.4339\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.3230 - val_loss: 129.6413\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.0912 - val_loss: 129.2427\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.6543 - val_loss: 130.9654\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.8326 - val_loss: 129.6065\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.2517 - val_loss: 130.9453\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.0219 - val_loss: 128.8358\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.6990 - val_loss: 131.3236\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.9529 - val_loss: 129.2955\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.5222 - val_loss: 130.1491\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.8796 - val_loss: 128.1334\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.5156 - val_loss: 131.1900\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.9506 - val_loss: 130.7908\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.8120 - val_loss: 129.9601\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.1632 - val_loss: 129.8069\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.7127 - val_loss: 129.5614\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.9157 - val_loss: 129.4287\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.3035 - val_loss: 129.5641\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.3129 - val_loss: 130.1029\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.5467 - val_loss: 128.8868\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.3367 - val_loss: 130.7201\n",
      "'########################################################Model4\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 6ms/step - loss: 140.3362 - val_loss: 139.8264\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 137.3431 - val_loss: 140.7041\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 137.8727 - val_loss: 136.8701\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 133.5947 - val_loss: 137.7276\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 133.7076 - val_loss: 134.0772\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 130.2266 - val_loss: 134.1951\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 131.4738 - val_loss: 134.3270\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 132.2919 - val_loss: 138.1795\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 133.0182 - val_loss: 136.4347\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 130.3073 - val_loss: 133.6503\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 129.0770 - val_loss: 136.9902\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 132.5746 - val_loss: 134.6097\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 129.7938 - val_loss: 131.5515\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 128.1804 - val_loss: 130.7767\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.8275 - val_loss: 131.1077\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.0059 - val_loss: 132.2502\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.8778 - val_loss: 130.1550\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.6293 - val_loss: 132.7119\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.8843 - val_loss: 131.1805\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.7015 - val_loss: 133.0275\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.0933 - val_loss: 131.0742\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.9376 - val_loss: 133.0642\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.6454 - val_loss: 135.5533\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.9789 - val_loss: 130.0644\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.9313 - val_loss: 128.1294\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.6983 - val_loss: 130.3121\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.3565 - val_loss: 131.2516\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.3004 - val_loss: 130.0061\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.2794 - val_loss: 130.4686\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.8145 - val_loss: 130.7565\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.8587 - val_loss: 129.8111\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.4662 - val_loss: 128.9464\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.1644 - val_loss: 129.2773\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.6611 - val_loss: 129.2806\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.2598 - val_loss: 129.0667\n",
      "'########################################################Model5\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 6ms/step - loss: 150.9737 - val_loss: 150.8297\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 147.2582 - val_loss: 141.7616\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 137.8621 - val_loss: 139.6342\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 135.8035 - val_loss: 139.6523\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 138.0097 - val_loss: 137.3952\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 133.2348 - val_loss: 133.9185\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 130.5755 - val_loss: 133.8654\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 129.4334 - val_loss: 133.1441\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 130.9962 - val_loss: 134.4457\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 129.9463 - val_loss: 132.9838\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 129.7942 - val_loss: 133.8931\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.9597 - val_loss: 131.0836\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.5224 - val_loss: 133.3504\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 128.2430 - val_loss: 133.7764\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.8356 - val_loss: 131.3259\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.8911 - val_loss: 130.7099\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.3135 - val_loss: 129.9653\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.9865 - val_loss: 130.1934\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.9461 - val_loss: 129.1817\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.6316 - val_loss: 131.5631\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.3191 - val_loss: 129.4453\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.0813 - val_loss: 132.0325\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.9883 - val_loss: 130.3460\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.8246 - val_loss: 129.5319\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.1534 - val_loss: 131.1631\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.7058 - val_loss: 131.1214\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.3361 - val_loss: 130.5147\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.4417 - val_loss: 131.0739\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.4201 - val_loss: 129.4748\n",
      "'########################################################Model6\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 4ms/step - loss: 144.2659 - val_loss: 139.9272\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 138.8492 - val_loss: 139.8602\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 133.7928 - val_loss: 137.0613\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 131.2329 - val_loss: 134.5105\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 132.9793 - val_loss: 135.0321\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 132.6270 - val_loss: 138.6365\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 134.2296 - val_loss: 136.0192\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 132.9762 - val_loss: 134.8644\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 132.3071 - val_loss: 134.3307\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 131.3703 - val_loss: 132.5033\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 129.8624 - val_loss: 136.1966\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 130.4410 - val_loss: 133.5411\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 129.3002 - val_loss: 131.3243\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 128.9406 - val_loss: 132.2997\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.4710 - val_loss: 130.4058\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.2772 - val_loss: 137.2491\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 129.4494 - val_loss: 131.9763\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 128.3322 - val_loss: 132.8623\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.4676 - val_loss: 130.7731\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.8478 - val_loss: 131.5123\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 130.4944 - val_loss: 132.5083\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 128.3622 - val_loss: 134.0117\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.4257 - val_loss: 130.9725\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.6455 - val_loss: 134.5658\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.3432 - val_loss: 130.0042\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.8569 - val_loss: 129.7149\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.9189 - val_loss: 131.5530\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.9520 - val_loss: 129.8747\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.7032 - val_loss: 129.3729\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.3518 - val_loss: 130.4411\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.8216 - val_loss: 130.4742\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.4771 - val_loss: 131.8516\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.2814 - val_loss: 131.2517\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.8901 - val_loss: 129.1867\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.8856 - val_loss: 131.7893\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.7258 - val_loss: 130.3375\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.8416 - val_loss: 130.4870\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.9308 - val_loss: 131.5364\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.9257 - val_loss: 129.6853\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.9141 - val_loss: 130.4710\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.9592 - val_loss: 129.6112\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.8909 - val_loss: 130.1028\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.5546 - val_loss: 128.5026\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.8076 - val_loss: 131.2904\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.1335 - val_loss: 131.1961\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.1743 - val_loss: 129.1330\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.7695 - val_loss: 129.3961\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.3635 - val_loss: 130.4863\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.2217 - val_loss: 129.0272\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.7562 - val_loss: 129.5483\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 121.7681 - val_loss: 130.1087\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.3425 - val_loss: 129.9039\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 121.3670 - val_loss: 131.0399\n",
      "'########################################################Model7\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 5ms/step - loss: 147.6537 - val_loss: 140.5455\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 139.3444 - val_loss: 141.4840\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 137.4315 - val_loss: 137.1978\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 134.4826 - val_loss: 139.6444\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 136.6431 - val_loss: 138.9182\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 131.9589 - val_loss: 137.7945\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 134.2856 - val_loss: 136.8434\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 129.8050 - val_loss: 134.4744\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 129.0342 - val_loss: 134.3647\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 128.2324 - val_loss: 133.4652\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.1433 - val_loss: 131.1546\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.0223 - val_loss: 133.8221\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.8716 - val_loss: 131.5698\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.4759 - val_loss: 131.5209\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.9187 - val_loss: 132.4570\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.3909 - val_loss: 131.2215\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.9329 - val_loss: 132.6325\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.3787 - val_loss: 129.6385\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.7386 - val_loss: 131.6052\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.8077 - val_loss: 131.9967\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.4633 - val_loss: 131.0956\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.1494 - val_loss: 131.0823\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.7488 - val_loss: 130.3169\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.8157 - val_loss: 132.4846\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.5995 - val_loss: 131.4069\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.7688 - val_loss: 130.6058\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.9269 - val_loss: 129.9283\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.9761 - val_loss: 129.1067\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.3823 - val_loss: 129.1643\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.9283 - val_loss: 129.9053\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.9538 - val_loss: 129.6498\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.3900 - val_loss: 129.8431\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.2883 - val_loss: 129.5992\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.7060 - val_loss: 129.8969\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.6306 - val_loss: 129.0405\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.6760 - val_loss: 129.1918\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.5237 - val_loss: 128.6709\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.5227 - val_loss: 129.9560\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 123.8737 - val_loss: 129.8644\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.7604 - val_loss: 130.2322\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.8076 - val_loss: 129.9813\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.2450 - val_loss: 129.9394\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 121.8604 - val_loss: 129.8282\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 121.6079 - val_loss: 130.6028\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 122.1453 - val_loss: 129.1340\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 121.7277 - val_loss: 129.2539\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 121.1147 - val_loss: 129.2220\n",
      "'########################################################Model8\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 1s 6ms/step - loss: 141.8553 - val_loss: 142.7277\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 136.6301 - val_loss: 143.3320\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 134.3072 - val_loss: 136.2968\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 132.4628 - val_loss: 135.5454\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 131.6786 - val_loss: 140.0981\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 132.0407 - val_loss: 136.5099\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 130.7807 - val_loss: 133.5094\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 129.4832 - val_loss: 131.7699\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 128.1683 - val_loss: 133.2888\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.7166 - val_loss: 130.2569\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.7213 - val_loss: 133.0160\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 127.4832 - val_loss: 132.4758\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.7636 - val_loss: 129.5010\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.3053 - val_loss: 130.4631\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.7120 - val_loss: 130.3496\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.4908 - val_loss: 131.3370\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.2300 - val_loss: 131.7907\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.7282 - val_loss: 130.0125\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.1165 - val_loss: 130.9598\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.3375 - val_loss: 131.8791\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 126.8068 - val_loss: 131.1969\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 124.6982 - val_loss: 131.7207\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.4047 - val_loss: 131.9529\n",
      "'########################################################Model9\n"
     ]
    }
   ],
   "source": [
    "model_num = 10\n",
    "\n",
    "mase_models = train_bagging_models(model_num, MASE(y_train,24),100,10,8,0.001)\n",
    "mape_models = train_bagging_models(model_num,'mape',100,10,8,0.001)\n",
    "smape_models = train_bagging_models(model_num, SMAPE(),100,10,8,0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c961ec8-129c-4f36-a2dc-04b0b9661a19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 889us/step\n",
      "12/12 [==============================] - 0s 925us/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 924us/step\n",
      "12/12 [==============================] - 0s 903us/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 863us/step\n",
      "12/12 [==============================] - 0s 958us/step\n",
      "12/12 [==============================] - 0s 757us/step\n",
      "12/12 [==============================] - 0s 927us/step\n",
      "12/12 [==============================] - 0s 993us/step\n",
      "12/12 [==============================] - 0s 777us/step\n",
      "12/12 [==============================] - 0s 780us/step\n",
      "12/12 [==============================] - 0s 758us/step\n",
      "12/12 [==============================] - 0s 731us/step\n",
      "12/12 [==============================] - 0s 797us/step\n",
      "12/12 [==============================] - 0s 738us/step\n",
      "12/12 [==============================] - 0s 772us/step\n",
      "12/12 [==============================] - 0s 744us/step\n",
      "12/12 [==============================] - 0s 781us/step\n",
      "12/12 [==============================] - 0s 775us/step\n",
      "12/12 [==============================] - 0s 710us/step\n",
      "12/12 [==============================] - 0s 727us/step\n",
      "12/12 [==============================] - 1s 733us/step\n",
      "12/12 [==============================] - 0s 960us/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 771us/step\n",
      "12/12 [==============================] - 0s 843us/step\n",
      "12/12 [==============================] - 0s 979us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.21251175272052902, 0.2353601182253664)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred1,_=smape_models\n",
    "pred2,_=mase_models\n",
    "pred3,_=mape_models\n",
    "\n",
    "smape_predictions = bagging_predict2(pred1, test_X)\n",
    "mase_predictions = bagging_predict2(pred2, test_X)\n",
    "mape_predictions = bagging_predict2(pred3, test_X)\n",
    "concat_I = np.concatenate([smape_predictions, mase_predictions,mape_predictions],axis=0)\n",
    "fin_pred_I = np.median(concat_I,axis=0)\n",
    "#pd.DataFrame(fin_pred).to_csv(\"freezing_I.csv\")\n",
    "mean_squared_error(test_y.flatten(),fin_pred_I.flatten()),mean_absolute_error(test_y.flatten(),fin_pred_I.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02005ee4-9b13-4a5a-a2c3-d25441395630",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(fin_pred_I.reshape(-1,24)).to_csv(\"../result3_new/NBEATs/pred_mid_I.csv\")\n",
    "for i in range(10):\n",
    "    pd.DataFrame(concat_I[i].reshape(-1,24)).to_csv(f\"../result3_new/NBEATs/pred_I{i}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a104b3-22fb-46e4-855e-ca5e5202a204",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 일반블락"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df7fa618-a25e-48c5-9544-ca3e091f28ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 9ms/step - loss: 1.0319 - val_loss: 0.7067\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.8152 - val_loss: 0.6753\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7874 - val_loss: 0.6690\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7625 - val_loss: 0.6569\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7396 - val_loss: 0.7347\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7528 - val_loss: 0.6243\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7304 - val_loss: 0.6276\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7071 - val_loss: 0.6427\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7006 - val_loss: 0.6371\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7090 - val_loss: 0.6302\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6915 - val_loss: 0.6344\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6720 - val_loss: 0.6731\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6597 - val_loss: 0.6499\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6826 - val_loss: 0.6225\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6487 - val_loss: 0.6359\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6311 - val_loss: 0.6807\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6432 - val_loss: 0.6358\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6106 - val_loss: 0.6530\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6069 - val_loss: 0.7018\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5974 - val_loss: 0.6295\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5831 - val_loss: 0.6838\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5761 - val_loss: 0.6475\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5668 - val_loss: 0.6567\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.5564 - val_loss: 0.6357\n",
      "'########################################################Model0\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 7ms/step - loss: 1.0393 - val_loss: 0.7127\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.8152 - val_loss: 0.6819\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7856 - val_loss: 0.6475\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7574 - val_loss: 0.6485\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7509 - val_loss: 0.6435\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7424 - val_loss: 0.6720\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7247 - val_loss: 0.6453\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7158 - val_loss: 0.6463\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7348 - val_loss: 0.6388\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6942 - val_loss: 0.6562\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6925 - val_loss: 0.6528\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6772 - val_loss: 0.6417\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6679 - val_loss: 0.6416\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6558 - val_loss: 0.6498\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6547 - val_loss: 0.6349\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6418 - val_loss: 0.6680\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6306 - val_loss: 0.6331\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6192 - val_loss: 0.6526\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6009 - val_loss: 0.6499\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.5845 - val_loss: 0.6523\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5894 - val_loss: 0.6706\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.5707 - val_loss: 0.6363\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5376 - val_loss: 0.6618\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5701 - val_loss: 0.6680\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.5430 - val_loss: 0.6758\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5457 - val_loss: 0.6674\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.5214 - val_loss: 0.6807\n",
      "'########################################################Model1\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 7ms/step - loss: 0.9670 - val_loss: 0.7321\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.8245 - val_loss: 0.7133\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7914 - val_loss: 0.6494\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7587 - val_loss: 0.6478\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7640 - val_loss: 0.6805\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.7537 - val_loss: 0.6447\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7235 - val_loss: 0.6491\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7147 - val_loss: 0.6613\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7250 - val_loss: 0.6373\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7035 - val_loss: 0.6749\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7016 - val_loss: 0.6544\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6811 - val_loss: 0.6465\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6808 - val_loss: 0.6644\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6702 - val_loss: 0.6850\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6528 - val_loss: 0.6411\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6366 - val_loss: 0.6520\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6304 - val_loss: 0.6361\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6138 - val_loss: 0.6823\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6314 - val_loss: 0.6851\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5773 - val_loss: 0.6365\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5762 - val_loss: 0.7025\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.5831 - val_loss: 0.6630\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5604 - val_loss: 0.6724\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5378 - val_loss: 0.6557\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.5150 - val_loss: 0.7010\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5136 - val_loss: 0.6670\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5076 - val_loss: 0.6917\n",
      "'########################################################Model2\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 7ms/step - loss: 1.0195 - val_loss: 0.7401\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.8165 - val_loss: 0.6983\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7732 - val_loss: 0.6769\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.7635 - val_loss: 0.6529\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.7487 - val_loss: 0.6417\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.7336 - val_loss: 0.6380\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.7273 - val_loss: 0.6292\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.7296 - val_loss: 0.6690\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.7100 - val_loss: 0.6657\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6991 - val_loss: 0.6426\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6976 - val_loss: 0.6418\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6713 - val_loss: 0.6284\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6709 - val_loss: 0.6611\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6695 - val_loss: 0.6497\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6500 - val_loss: 0.6696\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6465 - val_loss: 0.6512\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6278 - val_loss: 0.6556\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6392 - val_loss: 0.6814\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6027 - val_loss: 0.6428\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5801 - val_loss: 0.6992\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5792 - val_loss: 0.6730\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5789 - val_loss: 0.6508\n",
      "'########################################################Model3\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 9ms/step - loss: 1.0265 - val_loss: 0.7319\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.8000 - val_loss: 0.6462\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7958 - val_loss: 0.6798\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7514 - val_loss: 0.6307\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7333 - val_loss: 0.6391\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7322 - val_loss: 0.6318\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7126 - val_loss: 0.6207\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7053 - val_loss: 0.6503\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7031 - val_loss: 0.6253\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6890 - val_loss: 0.6541\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6848 - val_loss: 0.6394\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6644 - val_loss: 0.6456\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6488 - val_loss: 0.6681\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6377 - val_loss: 0.6494\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6272 - val_loss: 0.6663\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6433 - val_loss: 0.6440\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6180 - val_loss: 0.6245\n",
      "'########################################################Model4\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 7ms/step - loss: 1.0068 - val_loss: 0.7564\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.8224 - val_loss: 0.7511\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7910 - val_loss: 0.6695\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7878 - val_loss: 0.6934\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7428 - val_loss: 0.6381\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7348 - val_loss: 0.6376\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7269 - val_loss: 0.6294\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7106 - val_loss: 0.6825\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7144 - val_loss: 0.6429\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7023 - val_loss: 0.6211\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6857 - val_loss: 0.6424\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6715 - val_loss: 0.6466\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6676 - val_loss: 0.6574\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6538 - val_loss: 0.6316\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6453 - val_loss: 0.6603\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6359 - val_loss: 0.6642\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6440 - val_loss: 0.6473\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6181 - val_loss: 0.6542\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.5924 - val_loss: 0.6664\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5801 - val_loss: 0.6565\n",
      "'########################################################Model5\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 9ms/step - loss: 1.0001 - val_loss: 0.7024\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.8160 - val_loss: 0.6672\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7907 - val_loss: 0.6467\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7734 - val_loss: 0.6514\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7480 - val_loss: 0.6545\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7317 - val_loss: 0.6458\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7205 - val_loss: 0.6326\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7127 - val_loss: 0.6370\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6975 - val_loss: 0.6544\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6888 - val_loss: 0.6346\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6907 - val_loss: 0.7008\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6946 - val_loss: 0.6475\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6767 - val_loss: 0.7157\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6693 - val_loss: 0.6508\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6490 - val_loss: 0.6408\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6271 - val_loss: 0.6539\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6256 - val_loss: 0.6197\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6089 - val_loss: 0.6630\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6289 - val_loss: 0.6586\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6097 - val_loss: 0.6587\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5771 - val_loss: 0.6487\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5685 - val_loss: 0.6555\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5771 - val_loss: 0.6491\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5424 - val_loss: 0.6943\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5400 - val_loss: 0.6638\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5274 - val_loss: 0.6602\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5026 - val_loss: 0.6732\n",
      "'########################################################Model6\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 7ms/step - loss: 1.0168 - val_loss: 0.6987\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.8084 - val_loss: 0.7125\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.7875 - val_loss: 0.6750\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.7644 - val_loss: 0.6812\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7631 - val_loss: 0.6494\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7375 - val_loss: 0.6260\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.7233 - val_loss: 0.6347\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.7161 - val_loss: 0.6393\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6980 - val_loss: 0.6574\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7082 - val_loss: 0.6417\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6813 - val_loss: 0.6320\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6782 - val_loss: 0.6279\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6706 - val_loss: 0.6616\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6677 - val_loss: 0.6533\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6641 - val_loss: 0.6202\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6372 - val_loss: 0.6490\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6238 - val_loss: 0.6557\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6225 - val_loss: 0.6475\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6132 - val_loss: 0.6360\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6224 - val_loss: 0.6457\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5793 - val_loss: 0.6534\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5788 - val_loss: 0.6427\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5716 - val_loss: 0.6489\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5528 - val_loss: 0.6417\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5272 - val_loss: 0.6449\n",
      "'########################################################Model7\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 9ms/step - loss: 1.0126 - val_loss: 0.7300\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.8158 - val_loss: 0.6662\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7791 - val_loss: 0.6655\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7584 - val_loss: 0.6846\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7422 - val_loss: 0.6410\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7389 - val_loss: 0.6296\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7179 - val_loss: 0.6384\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7164 - val_loss: 0.6442\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7042 - val_loss: 0.6506\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7045 - val_loss: 0.6325\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6968 - val_loss: 0.6631\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6776 - val_loss: 0.6568\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6761 - val_loss: 0.6295\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6539 - val_loss: 0.6286\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6503 - val_loss: 0.6826\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6398 - val_loss: 0.6315\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6255 - val_loss: 0.6635\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.6061 - val_loss: 0.6354\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6055 - val_loss: 0.6711\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5916 - val_loss: 0.6507\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5761 - val_loss: 0.6593\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5841 - val_loss: 0.7101\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5636 - val_loss: 0.6544\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5438 - val_loss: 0.6513\n",
      "'########################################################Model8\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 8ms/step - loss: 0.9638 - val_loss: 0.6886\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.8121 - val_loss: 0.7403\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7893 - val_loss: 0.6578\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7603 - val_loss: 0.6620\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7540 - val_loss: 0.6577\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7236 - val_loss: 0.6330\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7253 - val_loss: 0.6599\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7161 - val_loss: 0.6315\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7073 - val_loss: 0.6952\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7124 - val_loss: 0.6719\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.7080 - val_loss: 0.6280\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6753 - val_loss: 0.6374\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6596 - val_loss: 0.6379\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6766 - val_loss: 0.6487\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6502 - val_loss: 0.6436\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 0.6381 - val_loss: 0.6582\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6372 - val_loss: 0.6792\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6216 - val_loss: 0.6372\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.6102 - val_loss: 0.6420\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5959 - val_loss: 0.6531\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 0.5801 - val_loss: 0.6564\n",
      "'########################################################Model9\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 9ms/step - loss: 50553508.0000 - val_loss: 13341336.0000\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 13822364.0000 - val_loss: 12258458.0000\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 10031863.0000 - val_loss: 8583134.0000\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 7607020.5000 - val_loss: 7580320.5000\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 6192743.5000 - val_loss: 5846988.5000\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 4581208.0000 - val_loss: 5079692.5000\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 4038744.2500 - val_loss: 3635603.7500\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3371177.2500 - val_loss: 3253294.2500\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2976224.7500 - val_loss: 3100290.5000\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2667415.7500 - val_loss: 3033176.5000\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2337067.5000 - val_loss: 3492594.0000\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2151029.7500 - val_loss: 2144359.7500\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1972294.6250 - val_loss: 2335756.2500\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1794998.5000 - val_loss: 2113900.5000\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1507510.5000 - val_loss: 1969878.7500\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1527692.3750 - val_loss: 2482988.0000\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1346957.6250 - val_loss: 1469488.2500\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1284150.1250 - val_loss: 1812818.2500\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1165803.0000 - val_loss: 1283607.8750\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1077471.5000 - val_loss: 1907327.1250\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1143273.2500 - val_loss: 1330345.1250\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1033851.3750 - val_loss: 1224305.3750\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 922595.3750 - val_loss: 1234363.2500\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 949665.6250 - val_loss: 1007634.8750\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 797592.6875 - val_loss: 1234002.8750\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 778170.5625 - val_loss: 1146195.5000\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 746685.6250 - val_loss: 1245687.8750\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 792142.5625 - val_loss: 1100234.7500\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 699244.8750 - val_loss: 1014079.1250\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 671993.6250 - val_loss: 1269374.1250\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 719203.0625 - val_loss: 989092.4375\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 677901.4375 - val_loss: 946966.3125\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 642144.6875 - val_loss: 977799.0625\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 690369.1875 - val_loss: 1029963.1250\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 644266.1250 - val_loss: 776296.7500\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 675087.6875 - val_loss: 1093754.8750\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 628199.5000 - val_loss: 860849.3125\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 703088.8125 - val_loss: 1038921.2500\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 640044.1250 - val_loss: 863291.1875\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 685153.1250 - val_loss: 1021723.9375\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 679102.8125 - val_loss: 946475.3750\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 656472.2500 - val_loss: 877233.6875\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 547668.0000 - val_loss: 800196.5000\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 668257.9375 - val_loss: 820325.6875\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 621852.3750 - val_loss: 923376.9375\n",
      "'########################################################Model0\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 9ms/step - loss: 50215800.0000 - val_loss: 22360704.0000\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 15822968.0000 - val_loss: 12431922.0000\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 10724012.0000 - val_loss: 10593808.0000\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 7885281.0000 - val_loss: 6802055.0000\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 6421493.5000 - val_loss: 6058049.5000\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 5016557.0000 - val_loss: 4267051.0000\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 4096022.0000 - val_loss: 4843995.5000\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3478136.2500 - val_loss: 4226033.5000\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3038999.5000 - val_loss: 3268480.7500\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2438876.2500 - val_loss: 3557759.5000\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2476288.0000 - val_loss: 2602570.2500\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2134802.2500 - val_loss: 2054567.7500\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1813100.7500 - val_loss: 1777116.3750\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1591837.5000 - val_loss: 1728759.5000\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1509087.7500 - val_loss: 1757594.7500\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1338988.7500 - val_loss: 1785658.8750\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1396272.6250 - val_loss: 1932986.5000\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1262436.2500 - val_loss: 1493825.1250\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1086057.2500 - val_loss: 1189751.8750\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1051780.3750 - val_loss: 1263660.6250\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1042177.0000 - val_loss: 1190326.0000\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 967803.9375 - val_loss: 1033926.0625\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 897537.3125 - val_loss: 1111385.0000\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 772300.8750 - val_loss: 1006247.9375\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 790949.8750 - val_loss: 908837.4375\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 771750.8125 - val_loss: 951721.3750\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 709670.8125 - val_loss: 1161985.6250\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 719125.6875 - val_loss: 1027081.9375\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 734169.6250 - val_loss: 906583.6875\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 644202.7500 - val_loss: 1236975.7500\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 674918.0000 - val_loss: 1423419.0000\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 652686.4375 - val_loss: 825622.8750\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 630108.1250 - val_loss: 1055457.3750\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 708387.0000 - val_loss: 958688.2500\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 623115.1250 - val_loss: 728468.3125\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 601913.9375 - val_loss: 851155.8750\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 576091.4375 - val_loss: 742446.8125\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 619513.8750 - val_loss: 1167225.1250\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 564182.2500 - val_loss: 988129.1875\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 627188.2500 - val_loss: 875609.6875\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 561611.2500 - val_loss: 1200595.8750\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 687404.5625 - val_loss: 1104280.3750\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 633428.4375 - val_loss: 1043887.8750\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 663057.5625 - val_loss: 799326.4375\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 560053.4375 - val_loss: 988680.6250\n",
      "'########################################################Model1\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 3s 9ms/step - loss: 43209116.0000 - val_loss: 14029228.0000\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 15152287.0000 - val_loss: 12723549.0000\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 9507789.0000 - val_loss: 8767590.0000\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 6904870.5000 - val_loss: 5236855.0000\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 5271941.5000 - val_loss: 5338107.5000\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 4618104.0000 - val_loss: 5324414.5000\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3772233.7500 - val_loss: 3420655.7500\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3241887.0000 - val_loss: 3070910.0000\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2770684.0000 - val_loss: 2622051.7500\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2308288.5000 - val_loss: 2796351.7500\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1897176.2500 - val_loss: 2601490.5000\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1785712.5000 - val_loss: 1731796.2500\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1554304.8750 - val_loss: 1528636.1250\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1485718.1250 - val_loss: 2053489.0000\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1434559.5000 - val_loss: 1886756.2500\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1207011.2500 - val_loss: 1469866.1250\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1249292.7500 - val_loss: 1540406.5000\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1121318.3750 - val_loss: 1463433.0000\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1091438.7500 - val_loss: 1619503.3750\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1138482.1250 - val_loss: 1283383.7500\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 839943.8125 - val_loss: 1193135.5000\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 840482.8125 - val_loss: 874816.8125\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 907395.3750 - val_loss: 1255148.0000\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 750318.7500 - val_loss: 949274.5000\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 863908.5000 - val_loss: 785006.0000\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 673439.7500 - val_loss: 885372.6875\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 701578.1250 - val_loss: 1127997.8750\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 762031.5625 - val_loss: 1063863.6250\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 588893.0625 - val_loss: 1194304.2500\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 713036.5000 - val_loss: 1109489.1250\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 671708.9375 - val_loss: 954836.0625\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 647483.8125 - val_loss: 1072905.0000\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 650790.1250 - val_loss: 1124783.8750\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 596232.0000 - val_loss: 729899.9375\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 673791.5625 - val_loss: 845814.8750\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 635245.4375 - val_loss: 879815.5625\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 625172.6875 - val_loss: 820711.3750\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 676150.0000 - val_loss: 1162466.7500\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 733495.1875 - val_loss: 1040589.1250\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 809516.1250 - val_loss: 986374.0625\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 841686.8125 - val_loss: 746199.3125\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 669157.6250 - val_loss: 980968.8125\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 697229.0000 - val_loss: 922474.6250\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 685426.4375 - val_loss: 711488.5000\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 662113.8125 - val_loss: 884973.1250\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 784027.6875 - val_loss: 901874.1875\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 589951.7500 - val_loss: 766567.1250\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 679414.3125 - val_loss: 1405165.0000\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 797286.8125 - val_loss: 807935.0000\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 681992.7500 - val_loss: 960132.1875\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 733480.3125 - val_loss: 1043427.8750\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 793810.7500 - val_loss: 862078.6250\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 671247.1250 - val_loss: 892159.9375\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 684602.1250 - val_loss: 1132893.1250\n",
      "'########################################################Model2\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 9ms/step - loss: 47222528.0000 - val_loss: 15765922.0000\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 15374168.0000 - val_loss: 14830200.0000\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 11046175.0000 - val_loss: 10090727.0000\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 7214894.5000 - val_loss: 6592107.5000\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 5900701.5000 - val_loss: 4683180.0000\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 4530019.5000 - val_loss: 5033978.5000\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 4190377.0000 - val_loss: 4315475.0000\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3398824.7500 - val_loss: 3141153.0000\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2884640.2500 - val_loss: 2912156.0000\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2304108.7500 - val_loss: 3228386.5000\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2288042.7500 - val_loss: 2456627.7500\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2057007.6250 - val_loss: 2528136.0000\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1828789.7500 - val_loss: 2240294.0000\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1715609.2500 - val_loss: 2210410.0000\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1648415.5000 - val_loss: 1735955.0000\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1408658.5000 - val_loss: 2060263.5000\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1293120.6250 - val_loss: 1318495.7500\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1229470.1250 - val_loss: 1640522.1250\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1027590.3750 - val_loss: 1347606.2500\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1041399.1875 - val_loss: 1472743.6250\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1110352.5000 - val_loss: 1332810.3750\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1068032.8750 - val_loss: 1361327.3750\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 912114.6250 - val_loss: 1080901.5000\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 876522.8125 - val_loss: 1336478.1250\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 846344.6875 - val_loss: 885110.9375\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 747320.2500 - val_loss: 931819.9375\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 764843.1250 - val_loss: 972499.7500\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 735236.5625 - val_loss: 1195406.8750\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 772012.0000 - val_loss: 901149.8750\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 730638.3750 - val_loss: 961482.5625\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 584107.0625 - val_loss: 1003500.5625\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 754169.6875 - val_loss: 941740.0000\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 629674.0000 - val_loss: 950175.7500\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 681197.2500 - val_loss: 1012986.2500\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 604418.1250 - val_loss: 852300.5000\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 674249.8125 - val_loss: 999795.5000\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 594179.5625 - val_loss: 863403.5000\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 653736.6875 - val_loss: 821446.8125\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 682655.2500 - val_loss: 848973.9375\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 574618.3750 - val_loss: 867752.5000\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 610511.5000 - val_loss: 885011.3125\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 696698.0000 - val_loss: 1130424.7500\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 651525.2500 - val_loss: 777948.4375\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 706795.0625 - val_loss: 1127130.3750\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 650268.0000 - val_loss: 980561.5625\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 573046.5000 - val_loss: 1120309.0000\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 699567.8750 - val_loss: 946147.0625\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 657694.0625 - val_loss: 1382928.3750\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 856900.6875 - val_loss: 1340363.7500\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 687376.1250 - val_loss: 1050288.2500\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 742661.1875 - val_loss: 1000847.1250\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 766048.2500 - val_loss: 1057412.1250\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 653004.3750 - val_loss: 1188705.2500\n",
      "'########################################################Model3\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 9ms/step - loss: 50129876.0000 - val_loss: 18859814.0000\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 15325611.0000 - val_loss: 11937822.0000\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 10696958.0000 - val_loss: 10673734.0000\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 8214688.0000 - val_loss: 6707209.5000\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 6515506.0000 - val_loss: 7469738.5000\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 4953142.5000 - val_loss: 4280221.0000\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 4037467.2500 - val_loss: 4118308.7500\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3670173.2500 - val_loss: 4213974.0000\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3141716.0000 - val_loss: 3195153.0000\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2791639.7500 - val_loss: 3000220.0000\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2398158.2500 - val_loss: 2929528.7500\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2207613.5000 - val_loss: 2509822.5000\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1865424.1250 - val_loss: 2133094.2500\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1773399.0000 - val_loss: 2251401.2500\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1683769.8750 - val_loss: 1840172.5000\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1429422.3750 - val_loss: 1637412.0000\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1303599.2500 - val_loss: 1703393.8750\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1151240.6250 - val_loss: 1313050.0000\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1088426.7500 - val_loss: 1363754.7500\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1149207.0000 - val_loss: 1266167.2500\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1011729.4375 - val_loss: 1378516.8750\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1004998.0625 - val_loss: 1358068.8750\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 987531.6875 - val_loss: 1434107.6250\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 923086.0000 - val_loss: 1064004.1250\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 856267.8750 - val_loss: 1310406.5000\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 870725.5000 - val_loss: 1318295.0000\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 775612.1250 - val_loss: 1308076.6250\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 857538.8125 - val_loss: 1355914.2500\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 652157.1875 - val_loss: 1067574.6250\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 649262.1250 - val_loss: 822988.0625\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 657205.9375 - val_loss: 1065634.0000\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 691476.4375 - val_loss: 1118889.8750\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 685122.5625 - val_loss: 826762.0000\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 727933.4375 - val_loss: 910592.6875\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 684412.7500 - val_loss: 1185157.1250\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 685570.5625 - val_loss: 771743.1250\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 732755.3750 - val_loss: 899858.1875\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 750290.1250 - val_loss: 829170.1250\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 651380.9375 - val_loss: 1033453.1250\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 710827.1250 - val_loss: 1011040.0000\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 763055.6875 - val_loss: 1346112.1250\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 773482.1250 - val_loss: 1160145.3750\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 808616.1250 - val_loss: 992975.8750\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 679484.8125 - val_loss: 1086090.5000\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 736121.9375 - val_loss: 963684.9375\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 772693.0625 - val_loss: 1480040.8750\n",
      "'########################################################Model4\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 9ms/step - loss: 42325936.0000 - val_loss: 17223814.0000\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 12446510.0000 - val_loss: 8318209.0000\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 9126658.0000 - val_loss: 7625811.0000\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 6575887.0000 - val_loss: 5444114.5000\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 5239158.5000 - val_loss: 4507585.5000\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 4322338.5000 - val_loss: 4223718.5000\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3527584.7500 - val_loss: 3239571.5000\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3433206.5000 - val_loss: 3518134.0000\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2783733.5000 - val_loss: 3450484.7500\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2411582.5000 - val_loss: 2528590.7500\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2122950.2500 - val_loss: 2396814.2500\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2173381.2500 - val_loss: 2032189.6250\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1817802.6250 - val_loss: 2092883.0000\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1546469.7500 - val_loss: 1876093.3750\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1483147.0000 - val_loss: 1818489.0000\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1364881.8750 - val_loss: 1851072.1250\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1298167.8750 - val_loss: 1259392.0000\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1192441.1250 - val_loss: 1383647.6250\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1034422.6250 - val_loss: 1452416.5000\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1097305.1250 - val_loss: 1338032.0000\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 910136.1250 - val_loss: 1154153.7500\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 955859.0625 - val_loss: 1203978.6250\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 973494.7500 - val_loss: 1291394.3750\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 824587.3750 - val_loss: 1458527.5000\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 834281.8750 - val_loss: 863136.5625\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 774878.9375 - val_loss: 876646.3750\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 799260.0625 - val_loss: 1036886.3125\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 724115.6250 - val_loss: 824309.4375\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 711225.8750 - val_loss: 1022560.8750\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 794613.8750 - val_loss: 1228564.1250\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 752734.6875 - val_loss: 956769.7500\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 731192.7500 - val_loss: 902759.0625\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 732080.3125 - val_loss: 1019523.1875\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 687229.5000 - val_loss: 1165637.1250\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 791424.6250 - val_loss: 1373138.3750\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 718453.8750 - val_loss: 812540.0000\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 709064.8750 - val_loss: 808935.3125\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 644489.6250 - val_loss: 731332.8750\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 629067.5000 - val_loss: 777855.3125\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 616518.1250 - val_loss: 1005007.2500\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 570918.5000 - val_loss: 792630.0625\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 526089.7500 - val_loss: 1132339.2500\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 641992.6250 - val_loss: 844604.8750\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 693936.6250 - val_loss: 1017122.3125\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 571931.1250 - val_loss: 927236.7500\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 621495.1250 - val_loss: 1117594.3750\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 698013.1250 - val_loss: 741023.1875\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 614824.8125 - val_loss: 682716.8750\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 584006.3125 - val_loss: 746636.6250\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 611497.9375 - val_loss: 768860.3125\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 601010.5625 - val_loss: 772189.7500\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 709700.3750 - val_loss: 844352.0625\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 640118.3750 - val_loss: 967026.8750\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 652350.1875 - val_loss: 950694.0625\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 642265.2500 - val_loss: 925499.5000\n",
      "Epoch 56/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 637375.3125 - val_loss: 1076594.1250\n",
      "Epoch 57/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 654000.1875 - val_loss: 948308.6250\n",
      "Epoch 58/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 646836.1250 - val_loss: 729550.1250\n",
      "'########################################################Model5\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 9ms/step - loss: 43884708.0000 - val_loss: 20772636.0000\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 15146863.0000 - val_loss: 13058077.0000\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 10695728.0000 - val_loss: 8239532.0000\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 7815580.0000 - val_loss: 6568535.0000\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 5988871.5000 - val_loss: 5535083.5000\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 4895365.5000 - val_loss: 5472248.0000\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 4244770.0000 - val_loss: 4842073.0000\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3708136.5000 - val_loss: 3654735.2500\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3036542.2500 - val_loss: 3146145.5000\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2438515.2500 - val_loss: 2638666.7500\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2264422.5000 - val_loss: 2567681.0000\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1953261.8750 - val_loss: 2786696.5000\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1940346.8750 - val_loss: 2210985.5000\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1687655.3750 - val_loss: 1832112.7500\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1656118.5000 - val_loss: 2169686.5000\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1559936.7500 - val_loss: 1977763.7500\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1310363.2500 - val_loss: 1836425.7500\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1204872.2500 - val_loss: 1230814.3750\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1191457.8750 - val_loss: 1508334.6250\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1156847.8750 - val_loss: 1544542.7500\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1059497.1250 - val_loss: 1513359.7500\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 929465.8125 - val_loss: 1002105.3750\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 822134.1875 - val_loss: 1151194.6250\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 827553.1875 - val_loss: 934358.7500\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 801064.5625 - val_loss: 1048119.8125\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 761877.9375 - val_loss: 1066218.8750\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 810855.1875 - val_loss: 1042023.7500\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 761988.0000 - val_loss: 1215036.1250\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 672627.8750 - val_loss: 981082.1250\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 778798.1250 - val_loss: 680184.2500\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 776346.3125 - val_loss: 1132583.2500\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 690462.7500 - val_loss: 837692.4375\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 657640.6875 - val_loss: 761522.6875\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 701524.5000 - val_loss: 863633.1875\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 622790.0000 - val_loss: 915260.9375\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 742963.1875 - val_loss: 857743.3750\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 701836.1250 - val_loss: 866114.1250\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 694136.0625 - val_loss: 1051345.6250\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 771916.3750 - val_loss: 1008940.2500\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 687076.1250 - val_loss: 1122847.7500\n",
      "'########################################################Model6\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 9ms/step - loss: 43270040.0000 - val_loss: 18763754.0000\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 13565102.0000 - val_loss: 15867071.0000\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 10151954.0000 - val_loss: 9472428.0000\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 7309127.0000 - val_loss: 6318382.0000\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 5644322.5000 - val_loss: 4968024.5000\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 4837734.0000 - val_loss: 4736788.0000\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3880730.0000 - val_loss: 3726345.7500\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3176163.5000 - val_loss: 3498792.5000\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2629807.5000 - val_loss: 3081676.2500\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2524888.2500 - val_loss: 2832345.0000\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2158999.5000 - val_loss: 2370421.0000\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1705757.6250 - val_loss: 1845857.5000\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1714607.5000 - val_loss: 2062376.3750\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1388209.3750 - val_loss: 1664031.1250\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1504273.5000 - val_loss: 1370732.5000\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1092368.7500 - val_loss: 1474029.5000\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1249808.7500 - val_loss: 1274229.2500\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1087325.7500 - val_loss: 1563980.0000\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 984573.2500 - val_loss: 1455445.6250\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 912136.2500 - val_loss: 1051612.2500\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 796150.1875 - val_loss: 1357068.1250\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 839366.0000 - val_loss: 1106556.7500\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 820160.3750 - val_loss: 1314975.1250\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 718020.6875 - val_loss: 1069388.8750\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 832527.7500 - val_loss: 1162705.5000\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 723044.8750 - val_loss: 1076756.2500\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 800587.2500 - val_loss: 1010650.3750\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 674644.1250 - val_loss: 851852.8125\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 703004.4375 - val_loss: 870462.7500\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 736528.5625 - val_loss: 961485.2500\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 737058.7500 - val_loss: 1150152.0000\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 665152.3125 - val_loss: 1010630.6250\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 536544.5625 - val_loss: 1023344.4375\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 618104.1875 - val_loss: 867358.3125\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 696269.5625 - val_loss: 1168377.2500\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 728079.0000 - val_loss: 1076912.7500\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 693062.3750 - val_loss: 853685.5000\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 555433.4375 - val_loss: 834766.1875\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 610373.7500 - val_loss: 1054407.0000\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 628541.3750 - val_loss: 1166002.8750\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 716261.4375 - val_loss: 753484.5000\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 578172.4375 - val_loss: 868817.1875\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 559767.5625 - val_loss: 1006710.1875\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 679216.8750 - val_loss: 726481.5000\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 580446.6250 - val_loss: 676594.2500\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 614860.5000 - val_loss: 1008666.9375\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 648624.8125 - val_loss: 980935.6250\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 638641.5000 - val_loss: 1225348.3750\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 627640.5625 - val_loss: 902016.7500\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 568597.4375 - val_loss: 944393.2500\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 595346.9375 - val_loss: 824289.5000\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 573398.5000 - val_loss: 1072525.3750\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 758613.2500 - val_loss: 976136.6875\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 595353.6250 - val_loss: 887624.3750\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 589065.7500 - val_loss: 722901.5625\n",
      "'########################################################Model7\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 7ms/step - loss: 45502640.0000 - val_loss: 23252480.0000\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 19853890.0000 - val_loss: 13149221.0000\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 12224582.0000 - val_loss: 10065878.0000\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 8583582.0000 - val_loss: 7104814.5000\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 6588746.0000 - val_loss: 6782109.0000\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 5376757.5000 - val_loss: 5410887.0000\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 4707081.5000 - val_loss: 4878965.5000\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3906536.5000 - val_loss: 4653987.5000\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3319472.2500 - val_loss: 3221559.5000\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2761012.2500 - val_loss: 2663326.5000\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2608870.5000 - val_loss: 3768452.0000\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2398599.7500 - val_loss: 2460587.0000\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 2022993.8750 - val_loss: 2798741.7500\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1741881.0000 - val_loss: 1871821.6250\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1683033.1250 - val_loss: 1723160.6250\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1495827.7500 - val_loss: 1565067.0000\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1479472.5000 - val_loss: 1498841.7500\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1399250.3750 - val_loss: 1724630.8750\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1157945.0000 - val_loss: 1254865.6250\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1191225.6250 - val_loss: 1858273.7500\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1116755.3750 - val_loss: 1100880.8750\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1038586.0625 - val_loss: 1062233.3750\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 964560.5625 - val_loss: 1497222.2500\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 958865.6250 - val_loss: 1356543.0000\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 869276.0000 - val_loss: 1032112.5625\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 911425.4375 - val_loss: 1030030.5625\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 810374.3750 - val_loss: 1102146.7500\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 804380.0000 - val_loss: 1137242.2500\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 857547.2500 - val_loss: 951108.1875\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 755455.9375 - val_loss: 846100.4375\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 718547.6875 - val_loss: 1248975.7500\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 707992.6875 - val_loss: 1179423.5000\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 678757.4375 - val_loss: 1047603.4375\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 617422.5625 - val_loss: 1017674.1250\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 729396.8750 - val_loss: 827955.5000\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 678627.3750 - val_loss: 908980.1875\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 715497.6875 - val_loss: 1105778.3750\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 777757.5625 - val_loss: 1051772.3750\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 731765.5625 - val_loss: 1240645.1250\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 684895.7500 - val_loss: 922888.3125\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 633615.6875 - val_loss: 991221.7500\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 668998.2500 - val_loss: 985907.0625\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 589155.8750 - val_loss: 642365.9375\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 643393.1875 - val_loss: 1330151.5000\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 635631.7500 - val_loss: 941525.3125\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 625083.5000 - val_loss: 961177.5000\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 655509.8750 - val_loss: 853220.1875\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 697588.3125 - val_loss: 1001792.1250\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 658878.0625 - val_loss: 960616.5000\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 668673.8125 - val_loss: 963291.2500\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 559978.2500 - val_loss: 1491235.8750\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 643549.3750 - val_loss: 798590.7500\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 585825.3125 - val_loss: 1107225.3750\n",
      "'########################################################Model8\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 9ms/step - loss: 43434812.0000 - val_loss: 18406782.0000\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 15346919.0000 - val_loss: 12224509.0000\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 10189466.0000 - val_loss: 7250259.0000\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 6799214.5000 - val_loss: 7400141.0000\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 6098725.5000 - val_loss: 6103736.0000\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 4946593.0000 - val_loss: 5758564.0000\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3814132.5000 - val_loss: 3919315.0000\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 3407939.7500 - val_loss: 4485830.5000\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 3019839.7500 - val_loss: 3166358.2500\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2745441.0000 - val_loss: 2612176.5000\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2319523.0000 - val_loss: 2460304.0000\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2117951.0000 - val_loss: 2789612.2500\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 2017039.5000 - val_loss: 2191724.5000\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1532169.6250 - val_loss: 1653587.7500\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1442961.3750 - val_loss: 2191715.0000\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1431119.5000 - val_loss: 1847858.0000\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1349719.6250 - val_loss: 1996284.8750\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 1248957.5000 - val_loss: 1679976.8750\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1088837.7500 - val_loss: 1214503.8750\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 957912.0625 - val_loss: 1427172.6250\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 1070770.7500 - val_loss: 1112245.2500\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 950015.3125 - val_loss: 1189266.2500\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 948364.2500 - val_loss: 1335535.8750\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 891884.3750 - val_loss: 1367916.6250\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 831348.9375 - val_loss: 1076218.8750\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 860516.9375 - val_loss: 963400.6250\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 817960.3750 - val_loss: 1227232.2500\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 847527.3125 - val_loss: 819482.2500\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 739233.8125 - val_loss: 1056564.2500\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 698028.6250 - val_loss: 966210.8750\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 613820.5625 - val_loss: 682576.9375\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 697601.7500 - val_loss: 814676.8750\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 699925.0625 - val_loss: 862849.5000\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 679341.3125 - val_loss: 818305.7500\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 702700.5625 - val_loss: 1019418.9375\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 678782.0000 - val_loss: 964011.8125\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 751302.1875 - val_loss: 1128547.5000\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 671158.8125 - val_loss: 1168465.7500\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 742736.6250 - val_loss: 922055.6875\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 636665.5625 - val_loss: 771604.3750\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 726431.8125 - val_loss: 1048851.5000\n",
      "'########################################################Model9\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 9ms/step - loss: 151.5191 - val_loss: 149.2705\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 143.1186 - val_loss: 145.0862\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 141.9080 - val_loss: 137.0480\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 137.8305 - val_loss: 137.7097\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 134.1796 - val_loss: 134.8715\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 134.7099 - val_loss: 134.9584\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 132.9926 - val_loss: 136.3022\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 132.4669 - val_loss: 134.1416\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 131.9680 - val_loss: 133.3079\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 131.7624 - val_loss: 135.7218\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 131.0980 - val_loss: 133.3810\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 131.2428 - val_loss: 132.9382\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 130.8346 - val_loss: 133.4827\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 130.0517 - val_loss: 132.4087\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 129.2466 - val_loss: 131.4898\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 127.8719 - val_loss: 132.2246\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 128.1088 - val_loss: 132.0287\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 126.8113 - val_loss: 130.8169\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 127.9660 - val_loss: 132.3204\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 127.3201 - val_loss: 134.0528\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 128.0948 - val_loss: 131.7133\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 127.4617 - val_loss: 132.0887\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 126.3976 - val_loss: 131.7373\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 125.7813 - val_loss: 130.7219\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 125.5295 - val_loss: 130.5459\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 125.9143 - val_loss: 132.3455\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 126.6728 - val_loss: 131.9146\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 126.2484 - val_loss: 131.1136\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 125.4040 - val_loss: 131.6819\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 125.0207 - val_loss: 131.1155\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 126.2790 - val_loss: 130.9235\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 127.8310 - val_loss: 131.4075\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 126.7979 - val_loss: 132.3718\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 125.5851 - val_loss: 131.3763\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 125.1213 - val_loss: 130.7178\n",
      "'########################################################Model0\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 3s 7ms/step - loss: 152.8398 - val_loss: 138.9931\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 136.4694 - val_loss: 140.9480\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 138.4724 - val_loss: 135.1726\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 132.9913 - val_loss: 133.7494\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 130.4731 - val_loss: 132.8362\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 131.6047 - val_loss: 135.5137\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 130.9106 - val_loss: 135.3230\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 131.4778 - val_loss: 135.7495\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 129.9107 - val_loss: 132.5512\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 128.6248 - val_loss: 131.7774\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 129.9832 - val_loss: 133.0056\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 130.7588 - val_loss: 131.9275\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 128.5103 - val_loss: 131.2706\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 127.7953 - val_loss: 131.0235\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 127.7706 - val_loss: 134.4668\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 128.3304 - val_loss: 131.0381\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 127.1608 - val_loss: 130.7406\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 127.4233 - val_loss: 130.8004\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 126.7815 - val_loss: 130.5400\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 126.3382 - val_loss: 130.0724\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 126.4029 - val_loss: 134.1927\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 127.2509 - val_loss: 132.0747\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 126.3998 - val_loss: 132.1917\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 128.3447 - val_loss: 132.1550\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 125.8644 - val_loss: 132.8128\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 125.6314 - val_loss: 131.5417\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 125.8232 - val_loss: 131.4811\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 125.2427 - val_loss: 131.1302\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 124.9932 - val_loss: 133.4746\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 125.9241 - val_loss: 131.6213\n",
      "'########################################################Model1\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 9ms/step - loss: 143.3395 - val_loss: 137.4870\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 136.8862 - val_loss: 139.3763\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 136.4371 - val_loss: 135.4810\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 133.2269 - val_loss: 134.2409\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 132.6863 - val_loss: 133.4515\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 132.2458 - val_loss: 133.2648\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 131.0236 - val_loss: 132.7823\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 129.9231 - val_loss: 132.7412\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 130.2712 - val_loss: 133.6688\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 130.9678 - val_loss: 132.7395\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 129.1602 - val_loss: 132.4514\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 128.5934 - val_loss: 132.0889\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 126.4433 - val_loss: 130.5612\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 125.8946 - val_loss: 130.2458\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 125.1123 - val_loss: 131.3401\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 125.3421 - val_loss: 130.1815\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 124.6522 - val_loss: 130.5621\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 124.3784 - val_loss: 129.8998\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 125.1775 - val_loss: 129.3641\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 123.1767 - val_loss: 128.1407\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 122.6597 - val_loss: 130.3214\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 123.6081 - val_loss: 130.4077\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 123.0510 - val_loss: 128.7269\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.5138 - val_loss: 129.6578\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 121.9996 - val_loss: 128.8176\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.6312 - val_loss: 128.4732\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.6624 - val_loss: 130.9054\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.0943 - val_loss: 128.4806\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.0998 - val_loss: 128.9570\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.1851 - val_loss: 130.6533\n",
      "'########################################################Model2\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 7ms/step - loss: 154.7460 - val_loss: 153.0639\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 154.5096 - val_loss: 156.1602\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 149.7419 - val_loss: 148.3495\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 148.6717 - val_loss: 148.1938\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 148.0962 - val_loss: 148.6374\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 149.7266 - val_loss: 148.5367\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 148.6133 - val_loss: 149.5267\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 148.0814 - val_loss: 148.3089\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 148.0283 - val_loss: 148.4117\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 147.7287 - val_loss: 148.2781\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 147.5883 - val_loss: 149.1114\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 147.4624 - val_loss: 148.3331\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 145.5879 - val_loss: 140.3939\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 136.9448 - val_loss: 139.0850\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 137.0552 - val_loss: 139.5198\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 136.6971 - val_loss: 139.0194\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 134.4035 - val_loss: 137.7088\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 132.6760 - val_loss: 135.6609\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 132.3636 - val_loss: 136.2999\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 131.3719 - val_loss: 135.8797\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 133.1690 - val_loss: 137.7015\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 132.1087 - val_loss: 135.1361\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 130.0282 - val_loss: 137.1471\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 131.2023 - val_loss: 136.1601\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 130.3110 - val_loss: 136.0372\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 128.6422 - val_loss: 135.1402\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 129.0214 - val_loss: 135.0409\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 127.4225 - val_loss: 131.8468\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 125.0645 - val_loss: 131.9177\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 124.9294 - val_loss: 130.6893\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 123.9942 - val_loss: 131.8866\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 123.3604 - val_loss: 130.5932\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 123.0629 - val_loss: 130.7968\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.2212 - val_loss: 130.0093\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 121.9535 - val_loss: 129.7309\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.2916 - val_loss: 129.9139\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 121.6394 - val_loss: 131.9304\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.7452 - val_loss: 132.7194\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 121.9969 - val_loss: 129.7368\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 120.8064 - val_loss: 128.6751\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 120.9163 - val_loss: 130.2418\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 120.9564 - val_loss: 128.8102\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 120.9284 - val_loss: 128.7424\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 120.5368 - val_loss: 129.3844\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 120.7084 - val_loss: 129.4466\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 120.1815 - val_loss: 128.5632\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 119.2756 - val_loss: 128.2649\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 119.4147 - val_loss: 130.5205\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 119.2475 - val_loss: 129.8580\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 118.6245 - val_loss: 129.0832\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 118.5002 - val_loss: 128.8012\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 118.7580 - val_loss: 129.4037\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 118.5314 - val_loss: 131.3269\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 118.9107 - val_loss: 130.8195\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 117.8851 - val_loss: 129.3324\n",
      "Epoch 56/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 117.6836 - val_loss: 129.4515\n",
      "Epoch 57/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 117.6725 - val_loss: 128.9415\n",
      "'########################################################Model3\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 9ms/step - loss: 151.4257 - val_loss: 147.8097\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 140.7483 - val_loss: 143.2041\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 136.2037 - val_loss: 137.5529\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 133.9106 - val_loss: 133.3453\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 135.0315 - val_loss: 136.7734\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 134.2735 - val_loss: 138.8799\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 135.5298 - val_loss: 137.1289\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 132.6924 - val_loss: 137.4306\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 131.0966 - val_loss: 132.4622\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 130.1125 - val_loss: 134.4835\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 129.9702 - val_loss: 133.5389\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 128.9150 - val_loss: 132.8342\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 129.0271 - val_loss: 131.1516\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 127.7752 - val_loss: 130.8425\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 127.3125 - val_loss: 131.0475\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 127.5487 - val_loss: 132.7136\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 127.0611 - val_loss: 132.1027\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 126.9033 - val_loss: 132.9488\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 127.0185 - val_loss: 134.4187\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 126.3973 - val_loss: 131.2633\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 127.9390 - val_loss: 132.1087\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 126.9434 - val_loss: 131.6479\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 126.6508 - val_loss: 133.2615\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 127.1426 - val_loss: 131.1487\n",
      "'########################################################Model4\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 9ms/step - loss: 153.3253 - val_loss: 145.2731\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 142.0569 - val_loss: 138.6589\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 138.2419 - val_loss: 138.4211\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 138.1019 - val_loss: 141.3287\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 137.9407 - val_loss: 139.2592\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 137.0798 - val_loss: 138.3247\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 137.2158 - val_loss: 137.6365\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 136.4214 - val_loss: 138.3172\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 136.4136 - val_loss: 140.1663\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 136.3866 - val_loss: 136.9864\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 135.4211 - val_loss: 137.4236\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 133.7875 - val_loss: 136.5829\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 133.1522 - val_loss: 133.5405\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 129.4781 - val_loss: 134.4759\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 127.2582 - val_loss: 132.0114\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 127.3172 - val_loss: 131.0597\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 125.5044 - val_loss: 130.2175\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 127.7810 - val_loss: 131.9345\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 127.1932 - val_loss: 132.4705\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 125.2614 - val_loss: 130.6243\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 124.8051 - val_loss: 130.3036\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 124.2308 - val_loss: 131.9093\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 124.1443 - val_loss: 131.6582\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 123.4787 - val_loss: 128.7258\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 123.2418 - val_loss: 129.3812\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 123.3700 - val_loss: 129.1427\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.6113 - val_loss: 128.8422\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.1318 - val_loss: 128.0763\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.4604 - val_loss: 129.0593\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 121.4348 - val_loss: 128.9715\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 121.4542 - val_loss: 128.4518\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 121.7135 - val_loss: 128.6210\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 121.3565 - val_loss: 128.0856\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.1680 - val_loss: 128.1634\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 120.5344 - val_loss: 129.0666\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 120.6194 - val_loss: 128.2650\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 120.3055 - val_loss: 128.5808\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 121.3569 - val_loss: 129.8144\n",
      "'########################################################Model5\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 7ms/step - loss: 143.7721 - val_loss: 144.2797\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 139.5316 - val_loss: 139.3750\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 134.7856 - val_loss: 134.5316\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 134.8534 - val_loss: 137.5047\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 135.4581 - val_loss: 137.1675\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 134.1893 - val_loss: 135.5774\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 134.8290 - val_loss: 133.9788\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 132.4073 - val_loss: 134.6699\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 134.2311 - val_loss: 134.8602\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 132.2911 - val_loss: 134.6260\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 132.2763 - val_loss: 133.4161\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 129.2690 - val_loss: 132.0350\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 129.1069 - val_loss: 132.0659\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 128.1907 - val_loss: 133.4018\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 128.7561 - val_loss: 132.4888\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 129.5924 - val_loss: 130.9396\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 128.7447 - val_loss: 130.8102\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 125.5582 - val_loss: 128.9013\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 124.3635 - val_loss: 131.1262\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 124.8470 - val_loss: 129.5312\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 124.0435 - val_loss: 130.6853\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 124.9804 - val_loss: 130.0248\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 124.5843 - val_loss: 129.4119\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 123.4387 - val_loss: 131.1112\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 123.8757 - val_loss: 129.2422\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 123.2082 - val_loss: 129.1945\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 123.5320 - val_loss: 130.1867\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 123.7209 - val_loss: 131.8439\n",
      "'########################################################Model6\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 9ms/step - loss: 147.6514 - val_loss: 146.9007\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 149.0482 - val_loss: 148.1695\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 149.0355 - val_loss: 147.9946\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 148.5219 - val_loss: 149.4995\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 148.7416 - val_loss: 148.4462\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 148.1109 - val_loss: 148.4922\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 148.2794 - val_loss: 147.6885\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 147.7388 - val_loss: 148.7179\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 147.4533 - val_loss: 148.3568\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 147.2643 - val_loss: 149.6764\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 147.4796 - val_loss: 147.9222\n",
      "'########################################################Model7\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 10ms/step - loss: 160.4513 - val_loss: 161.1342\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 155.9854 - val_loss: 155.1040\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 151.4691 - val_loss: 154.1707\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 145.3381 - val_loss: 139.4101\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 135.5890 - val_loss: 133.1510\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 134.5544 - val_loss: 138.1096\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 130.4901 - val_loss: 133.6767\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 129.8291 - val_loss: 133.7783\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 131.2793 - val_loss: 134.1713\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 128.9047 - val_loss: 131.4802\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 127.2676 - val_loss: 132.7159\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 127.0733 - val_loss: 131.8140\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 126.2119 - val_loss: 133.4326\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 128.0203 - val_loss: 130.4935\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 126.2013 - val_loss: 129.2782\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 124.7617 - val_loss: 130.5137\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 126.3137 - val_loss: 129.9992\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 124.8174 - val_loss: 128.1451\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 125.3019 - val_loss: 129.9860\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 124.7339 - val_loss: 129.7019\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 123.9544 - val_loss: 130.3922\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 124.3575 - val_loss: 130.0292\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 123.7897 - val_loss: 128.4252\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 123.1049 - val_loss: 127.1909\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 123.0922 - val_loss: 129.3598\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 122.6722 - val_loss: 127.9978\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 122.2539 - val_loss: 128.8574\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 123.2147 - val_loss: 130.4302\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 121.8819 - val_loss: 128.4218\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 122.2251 - val_loss: 129.8751\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 121.3614 - val_loss: 128.7215\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 121.8870 - val_loss: 128.7797\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 121.3213 - val_loss: 128.5264\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 121.4851 - val_loss: 131.1414\n",
      "'########################################################Model8\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 9ms/step - loss: 145.1946 - val_loss: 147.5672\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 143.5122 - val_loss: 139.5168\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 138.3935 - val_loss: 141.9624\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 139.5076 - val_loss: 139.4416\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 135.7135 - val_loss: 138.5583\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 136.2986 - val_loss: 138.0722\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 131.4799 - val_loss: 134.2506\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 131.1698 - val_loss: 135.4656\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 131.3350 - val_loss: 135.6518\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 131.2637 - val_loss: 134.1540\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 130.0612 - val_loss: 134.6464\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 131.4960 - val_loss: 133.7957\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 131.5082 - val_loss: 136.7569\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 129.4741 - val_loss: 131.5079\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 129.5799 - val_loss: 132.2490\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 127.9967 - val_loss: 131.3945\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 126.4099 - val_loss: 130.0658\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 4ms/step - loss: 125.7083 - val_loss: 130.2692\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 124.6847 - val_loss: 129.1396\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 124.4455 - val_loss: 129.7858\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 124.5577 - val_loss: 130.7085\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 124.1860 - val_loss: 129.7354\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 124.4523 - val_loss: 129.8631\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 123.8308 - val_loss: 130.0388\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 124.1990 - val_loss: 129.3437\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 123.3445 - val_loss: 130.2824\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 124.4514 - val_loss: 130.0132\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.9781 - val_loss: 129.1975\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 5ms/step - loss: 122.6930 - val_loss: 129.9324\n",
      "'########################################################Model9\n"
     ]
    }
   ],
   "source": [
    "model_num = 10\n",
    "\n",
    "mase_models_G = train_bagging_models_G(model_num, MASE(y_train,24),100,10,8,0.001)\n",
    "mape_models_G = train_bagging_models_G(model_num,'mape',100,10,8,0.001)\n",
    "smape_models_G = train_bagging_models_G(model_num, SMAPE(),100,10,8,0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b8e382f-5a29-464f-abe0-eeee880e371b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 1s 2ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.21251681681363305, 0.23380730046269357)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred1,_=smape_models_G\n",
    "pred2,_=mase_models_G\n",
    "pred3,_=mape_models_G\n",
    "\n",
    "smape_predictions_G = bagging_predict2(pred1, test_X)\n",
    "mase_predictions_G = bagging_predict2(pred2, test_X)\n",
    "mape_predictions_G = bagging_predict2(pred3, test_X)\n",
    "concat_G = np.concatenate([smape_predictions_G, mase_predictions_G,mape_predictions_G],axis=0)\n",
    "fin_pred_G = np.median(concat_G,axis=0)\n",
    "#pd.DataFrame(fin_pred).to_csv(\"freezing_I.csv\")\n",
    "mean_squared_error(test_y.flatten(),fin_pred_G.flatten()),mean_absolute_error(test_y.flatten(),fin_pred_G.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5fd6c48-f160-474c-b435-f7bbadb6f527",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.DataFrame(fin_pred_G.reshape(-1,24)).to_csv(\"../result3_new/NBEATs/pred_mid_G.csv\")\n",
    "for i in range(10):\n",
    "    pd.DataFrame(concat_G[i].reshape(-1,24)).to_csv(f\"../result3_new/NBEATs/pred_G{i}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
