{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f0036d6-fe11-4032-9ebd-2bf63597776b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-30 15:23:59.857697: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-30 15:23:59.930089: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-08-30 15:23:59.930107: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-08-30 15:24:00.294723: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-08-30 15:24:00.294779: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-08-30 15:24:00.294785: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nbeats_keras.model import NBeatsNet as NBeatsKeras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "#from nbeats_pytorch.model import NBeatsNet as NBeatsPytorch\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "import time\n",
    "from keras.models import load_model\n",
    "#from target_data_electronic70_7 import target_X, target_y ,test_X, test_y\n",
    "#from m4databasis21_7 import base_domain,zt_in,zt_out,M4Meta,inputsize,train_12,train_12_y\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error,mean_absolute_percentage_error\n",
    "plt.rcParams['font.family'] ='Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] =False\n",
    "from tensorflow.keras.losses import Loss\n",
    "import tensorflow as tf\n",
    "#from m4databasis35_7_70_7 import train_35,train_35_y,train_70,train_70_y\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, LayerNormalization, MultiHeadAttention, Dropout, Add, Concatenate,Flatten,Reshape\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c11e4f2-f795-4d8d-8c76-7cd76c0187d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "target_X= pd.read_csv(\"../data/solor_train_input_3.csv\").iloc[:,(1+24*0):].values\n",
    "target_y =pd.read_csv(\"../data/solor_train_output_3.csv\").iloc[:,1:].values\n",
    "test_X= pd.read_csv(\"../data/solor_val_input_3.csv\").iloc[:,(1+24*0):].values\n",
    "test_y =pd.read_csv(\"../data/solor_val_output_3.csv\").iloc[:,1:].values\n",
    "#backcast_length = X_train.shape[1]\n",
    "#forecast_length = y_train.shape[1]\n",
    "target_X.shape,test_X.shape\n",
    "X_train= target_X\n",
    "y_train=target_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cff7750c-7635-4132-984a-0f92f50db72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "# loss SMAPE\n",
    "class SMAPE(Loss):\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_pred = tf.reshape(y_pred, tf.shape(y_true))  # 예측 값의 차원을 맞춤\n",
    "       # y_pred=tf.clip_by_value(y_pred, 1e-10, tf.reduce_max(y_pred))\n",
    "       # y_true = tf.clip_by_value(y_true, 1e-10, tf.reduce_max(y_true))\n",
    "        \n",
    "        numerator = 100 * tf.abs(y_true- y_pred )\n",
    "        denominator =  (tf.abs(y_true ) + tf.abs(y_pred))/2\n",
    "        smape =  numerator /  denominator #tf.clip_by_value(denominator, 1e-10, tf.reduce_max(denominator))\n",
    "        return tf.reduce_mean(smape)\n",
    "\n",
    "#################################################################################\n",
    "# loss MASE\n",
    "class MASE(Loss):\n",
    "    def __init__(self, training_data, period, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.scale = self.calculate_scale(training_data, period)\n",
    "    def seasonal_diff(data, period):\n",
    "        return data[period:] - data[:-period]\n",
    "\n",
    "    def calculate_scale(self, training_data, period):\n",
    "        # 주기 차분 계산\n",
    "        diff = seasonal_diff(training_data, period)\n",
    "        scale = np.mean(np.abs(diff))\n",
    "        return scale\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        y_pred = tf.reshape(y_pred, tf.shape(y_true))  # 차원 맞추기\n",
    "        error = tf.abs(y_true - y_pred)\n",
    "        return tf.reduce_mean(error / self.scale)\n",
    "\n",
    "def seasonal_diff(data, period):\n",
    "    return data[period:] - data[:-period]\n",
    "\n",
    "#################################################################################\n",
    "#################################################################################\n",
    "# 하이퍼파라미터 인자 설정\n",
    "def hyperparameter():\n",
    "    # 1 backcast\n",
    "    # 2 forecast\n",
    "    # 3 unit\n",
    "    # 4 nhead\n",
    "    # 5 nlayers\n",
    "    # dropout\n",
    "    return X_train.shape[1],y_train.shape[1],64,2,2,0.1\n",
    "\n",
    "#################################################################################\n",
    "# nbeats + I모델 부트스트랩 샘플링 배깅\n",
    "\n",
    "def train_bagging_models(num_models, loss_fn , epochs_, patience_,batch_size_,lr):\n",
    "    models = {}\n",
    "    backcast,forecast,in_dim,out_dim,unit = hyperparameter()\n",
    "    historys = []\n",
    "    for n in range(num_models):\n",
    "        K.clear_session()\n",
    "        model = bulid_model(backcast,forecast,in_dim,out_dim,unit)\n",
    "       # model.set_weights(pretrained_weights)  # 전이 학습 가중치 적용\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "        model.compile(optimizer=optimizer , loss=loss_fn)\n",
    "        \n",
    "        # 부트스트랩 샘플링\n",
    "        #select = np.random.choice(len(X_train), size=len(X_train), replace=True)\n",
    "        #X_bootstrap = X_train[select]\n",
    "        #y_bootstrap = y_train[select]\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience = patience_, verbose = 0, restore_best_weights=True)\n",
    "        history = model.fit(X_train, y_train, batch_size = batch_size_,\n",
    "                  epochs=epochs_, verbose=1, \n",
    "                  callbacks=[early_stop],\n",
    "                 validation_split = 0.2)\n",
    "        models[f'model_{n+1}'] = model\n",
    "        historys.append(history)\n",
    "        #models.append(model)\n",
    "        print(f\"'########################################################Model{n}\")\n",
    "    return models,historys\n",
    "#################################################################################\n",
    "# nbeats + I모델 부트스트랩 샘플링 배깅\n",
    "\n",
    "def train_bagging_models_G(num_models, loss_fn , epochs_, patience_,batch_size_,lr):\n",
    "    models = {}\n",
    "    backcast,forecast,in_dim,out_dim,unit = hyperparameter()\n",
    "    historys = []\n",
    "    for n in range(num_models):\n",
    "        K.clear_session()\n",
    "        model = bulid_model_G(backcast,forecast,in_dim,out_dim,unit)\n",
    "       # model.set_weights(pretrained_weights)  # 전이 학습 가중치 적용\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "        model.compile(optimizer=optimizer , loss=loss_fn)\n",
    "        \n",
    "        # 부트스트랩 샘플링\n",
    "        select = np.random.choice(len(X_train), size=len(X_train), replace=True)\n",
    "        X_bootstrap = X_train[select]\n",
    "        y_bootstrap = y_train[select]\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience = patience_, verbose = 0, restore_best_weights=True)\n",
    "        history = model.fit(X_bootstrap, y_bootstrap, batch_size = batch_size_,\n",
    "                  epochs=epochs_, verbose=1, \n",
    "                  callbacks=[early_stop],\n",
    "                 validation_split = 0.2)\n",
    "        models[f'model_{n+1}'] = model\n",
    "        historys.append(history)\n",
    "        #models.append(model)\n",
    "        print(f\"'########################################################Model{n}\")\n",
    "    return models,historys\n",
    "\n",
    "#################################################################################\n",
    "# SMAPE 용\n",
    "def train_bagging_models_smape(num_models, loss_fn , epochs_, patience_,batch_size_,lr):\n",
    "    models = {}\n",
    "    backcast,forecast,in_dim,out_dim,unit = hyperparameter()\n",
    "    historys = []\n",
    "    for n in range(num_models):\n",
    "        K.clear_session()\n",
    "        model = bulid_model(backcast,forecast,in_dim,out_dim,unit)\n",
    "       # model.set_weights(pretrained_weights)  # 전이 학습 가중치 적용\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "        model.compile(optimizer=optimizer , loss=loss_fn)\n",
    "        \n",
    "        # 부트스트랩 샘플링\n",
    "        select = np.random.choice(len(X_train), size=len(X_train), replace=True)\n",
    "        X_bootstrap = X_train[select]\n",
    "        y_bootstrap = y_train[select]\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience = patience_, verbose = 0, restore_best_weights=True)\n",
    "        history = model.fit(X_bootstrap, y_bootstrap, batch_size = batch_size_,\n",
    "                  epochs=epochs_, verbose=1, \n",
    "                  callbacks=[early_stop],\n",
    "                 validation_split = 0.2)\n",
    "        models[f'model_{n+1}'] = model\n",
    "        historys.append(history)\n",
    "        #models.append(model)\n",
    "        print(f\"'########################################################Model{n}\")\n",
    "    return models,historys\n",
    "\n",
    "##########################################################################################\n",
    "# 트랜스퍼 레이어\n",
    "class PositionalEncoding(layers.Layer):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = layers.Dropout(rate=dropout)\n",
    "\n",
    "        position = np.arange(max_len)[:, np.newaxis]\n",
    "        div_term = np.exp(np.arange(0, d_model, 2) * (-np.log(10000.0) / d_model))\n",
    "        pe = np.zeros((max_len, d_model))\n",
    "        pe[:, 0::2] = np.sin(position * div_term)\n",
    "        pe[:, 1::2] = np.cos(position * div_term)\n",
    "        pe = pe[np.newaxis, ...]\n",
    "\n",
    "        self.pe = tf.constant(pe, dtype=tf.float32)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = x + self.pe[:, :tf.shape(x)[1], :]\n",
    "        return self.dropout(x)\n",
    "##########################################################################################\n",
    "# 트랜스퍼 레이어\n",
    "def create_model(fn,d_model, nlayers, nhead, dropout, iw, ow,lr):\n",
    "    \n",
    "    \n",
    "    x = layers.Dense(d_model // 2, activation='relu')(pretrained_output_reshaped)\n",
    "    x = layers.Dense(d_model, activation='relu')(x)\n",
    "    \n",
    "    pos_encoding = PositionalEncoding(d_model, dropout)\n",
    "    x = pos_encoding(x)\n",
    "    \n",
    "    for _ in range(nlayers):\n",
    "        attn_output = layers.MultiHeadAttention(num_heads=nhead, key_dim=d_model, dropout=dropout)(x, x)\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x + attn_output)\n",
    "        ffn_output = layers.Dense(d_model, activation='relu')(x)\n",
    "        ffn_output = layers.Dense(d_model)(ffn_output)\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x + ffn_output)\n",
    "    \n",
    "    x = layers.Dense(d_model // 2, activation='relu')(x)\n",
    "    x = layers.Dense(1)(x)\n",
    "    x = tf.squeeze(x, axis=-1)\n",
    "    \n",
    "    outputs = layers.Dense((iw + ow) // 2, activation='relu')(x)\n",
    "    outputs = layers.Dense(ow)(outputs)\n",
    "    \n",
    "    optimizer = Adam(learning_rate=lr)\n",
    "    target_model = Model(inputs=inputs, outputs=outputs)\n",
    "    target_model.compile(optimizer=optimizer, loss=fn)\n",
    "    \n",
    "    return target_model\n",
    "\n",
    "#################################################################################\n",
    "# 트랜스포머 모델 생성 함수\n",
    "def bulid_model(iw, ow, d_model, nhead, nlayers, dropout=0.5):\n",
    "    inputs = tf.keras.Input(shape=(iw, 1))\n",
    "    x = layers.Dense(d_model // 2, activation='relu')(inputs)\n",
    "    x = layers.Dense(d_model, activation='relu')(x)\n",
    "\n",
    "    pos_encoding = PositionalEncoding(d_model, dropout)\n",
    "    x = pos_encoding(x)\n",
    "\n",
    "    for _ in range(nlayers):\n",
    "        attn_output = layers.MultiHeadAttention(num_heads=nhead, key_dim=d_model, dropout=dropout)(x, x)\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x + attn_output)\n",
    "        ffn_output = layers.Dense(d_model, activation='relu')(x)\n",
    "        ffn_output = layers.Dense(d_model)(ffn_output)\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x + ffn_output)\n",
    "\n",
    "    x = layers.Dense(d_model // 2, activation='relu')(x)\n",
    "    x = layers.Dense(1)(x)\n",
    "    x = tf.squeeze(x, axis=-1)\n",
    "\n",
    "    outputs = layers.Dense((iw + ow) // 2, activation='relu')(x)\n",
    "    outputs = layers.Dense(ow)(outputs)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "#################################################################################\n",
    "# 부트스트랩 샘플링\n",
    "# 배깅\n",
    "\n",
    "def train_bagging_models(num_models, loss_fn , epochs_, patience_,batch_size_,lr=0.001):\n",
    "    models = {}\n",
    "    iw, ow, d_model, nhead, nlayers, dropout = hyperparameter()\n",
    "    historys = []\n",
    "    for n in range(num_models):\n",
    "        K.clear_session()\n",
    "        model = bulid_model(iw, ow, d_model, nhead, nlayers, dropout=0.5)\n",
    "       # model.set_weights(pretrained_weights)  # 전이 학습 가중치 적용\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "        model.compile(optimizer=optimizer , loss=loss_fn)\n",
    "        \n",
    "        # 부트스트랩 샘플링\n",
    "        #select = np.random.choice(len(X_train), size=len(X_train), replace=True)\n",
    "        #X_bootstrap = X_train[select]\n",
    "        #y_bootstrap = y_train[select]\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience = patience_, verbose = 1, restore_best_weights=True)\n",
    "        history = model.fit(X_train, y_train, batch_size = batch_size_,\n",
    "                  epochs=epochs_, verbose=1, \n",
    "                  callbacks=[early_stop],\n",
    "                 validation_split = 0.2)\n",
    "        models[f'model_{n+1}'] = model\n",
    "        historys.append(history)\n",
    "        #models.append(model)\n",
    "        print(f\"'########################################################Model{n}\")\n",
    "    return models,historys\n",
    "#################################################################################\n",
    "# 예측\n",
    "\n",
    "def bagging_predict(models, X):\n",
    "    predictions = np.array([model.predict(X) for model in models.values()])\n",
    "    return np.median(predictions, axis=0)\n",
    "\n",
    "def bagging_predict2(models, X):\n",
    "    predictions = np.array([model.predict(X) for model in models.values()])\n",
    "    return predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93870f9b-5e3c-42bf-ae32-acfc580104ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-30 15:24:29.163797: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-08-30 15:24:29.163844: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ymlee2-desktop): /proc/driver/nvidia/version does not exist\n",
      "2024-08-30 15:24:29.164370: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 15ms/step - loss: 1.3491 - val_loss: 0.7075\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.9213 - val_loss: 0.6998\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.9179 - val_loss: 0.6777\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.8863 - val_loss: 0.8098\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.8367 - val_loss: 0.6405\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.8349 - val_loss: 0.7920\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.8522 - val_loss: 0.7630\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.8358 - val_loss: 0.6946\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.8442 - val_loss: 0.6535\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.8377 - val_loss: 0.8254\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.8299 - val_loss: 0.7201\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.8063 - val_loss: 0.6974\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.8178 - val_loss: 0.7429\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.8114 - val_loss: 0.6468\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 0.8114Restoring model weights from the end of the best epoch: 5.\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.8114 - val_loss: 0.6495\n",
      "Epoch 15: early stopping\n",
      "'########################################################Model0\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 14ms/step - loss: 1.2081 - val_loss: 0.7938\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.9250 - val_loss: 0.7244\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.9133 - val_loss: 0.7936\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.9076 - val_loss: 0.6860\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.9139 - val_loss: 0.7018\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.8758 - val_loss: 0.6475\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.8433 - val_loss: 0.6510\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.8415 - val_loss: 0.7224\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.8345 - val_loss: 0.6983\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.8366 - val_loss: 0.6564\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.8166 - val_loss: 0.6340\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.8248 - val_loss: 0.6484\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.8037 - val_loss: 0.7101\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.7932 - val_loss: 0.6435\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.8004 - val_loss: 0.7650\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.8201 - val_loss: 0.6419\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.8177 - val_loss: 0.6830\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.7984 - val_loss: 0.6591\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.8091 - val_loss: 0.6482\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.7973 - val_loss: 0.7197\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.7995 - val_loss: 0.6260\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.8040 - val_loss: 0.6783\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.8054 - val_loss: 0.6835\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.8071 - val_loss: 0.6370\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.8220 - val_loss: 0.6424\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7944 - val_loss: 0.6474\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7815 - val_loss: 0.6214\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.7826 - val_loss: 0.7624\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.8080 - val_loss: 0.6470\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.7730 - val_loss: 0.6541\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.7863 - val_loss: 0.6119\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.7802 - val_loss: 0.6356\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.7948 - val_loss: 0.6625\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.7744 - val_loss: 0.6635\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.7858 - val_loss: 0.6076\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.7740 - val_loss: 0.6245\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.7771 - val_loss: 0.6342\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.7837 - val_loss: 0.6249\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.7696 - val_loss: 0.6130\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.7815 - val_loss: 0.6322\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.7731 - val_loss: 0.6260\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.7727 - val_loss: 0.7090\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.7678 - val_loss: 0.6179\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.7630 - val_loss: 0.6149\n",
      "Epoch 45/100\n",
      "69/73 [===========================>..] - ETA: 0s - loss: 0.7707Restoring model weights from the end of the best epoch: 35.\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.7674 - val_loss: 0.6522\n",
      "Epoch 45: early stopping\n",
      "'########################################################Model1\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 14ms/step - loss: 1.4881 - val_loss: 0.8446\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.9333 - val_loss: 0.7289\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.9059 - val_loss: 0.6840\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.9089 - val_loss: 0.7378\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.9264 - val_loss: 0.7217\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.9221 - val_loss: 0.7078\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.8843 - val_loss: 0.6603\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.8371 - val_loss: 0.7007\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.8440 - val_loss: 0.6864\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.8542 - val_loss: 0.6506\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.8304 - val_loss: 0.6627\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.8246 - val_loss: 0.6240\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.8225 - val_loss: 0.6345\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.8320 - val_loss: 0.6398\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.8069 - val_loss: 0.6312\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.8322 - val_loss: 0.6824\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.8080 - val_loss: 0.6371\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8163 - val_loss: 0.6554\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.8204 - val_loss: 0.7083\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8049 - val_loss: 0.6489\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.8162 - val_loss: 0.7260\n",
      "Epoch 22/100\n",
      "72/73 [============================>.] - ETA: 0s - loss: 0.8253Restoring model weights from the end of the best epoch: 12.\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.8231 - val_loss: 0.6881\n",
      "Epoch 22: early stopping\n",
      "'########################################################Model2\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 14ms/step - loss: 1.3368 - val_loss: 0.8857\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.9301 - val_loss: 0.6838\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.9087 - val_loss: 0.9462\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.9034 - val_loss: 0.7517\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8980 - val_loss: 0.6933\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8903 - val_loss: 0.6822\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.8426 - val_loss: 0.6560\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.8429 - val_loss: 0.6515\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.8253 - val_loss: 0.6744\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.8210 - val_loss: 0.6595\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.8064 - val_loss: 0.6732\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.8148 - val_loss: 0.6250\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7995 - val_loss: 0.6470\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7962 - val_loss: 0.6217\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.8018 - val_loss: 0.6726\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.8014 - val_loss: 0.6666\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.8001 - val_loss: 0.6407\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7978 - val_loss: 0.7618\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8019 - val_loss: 0.6725\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7742 - val_loss: 0.6643\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.7803 - val_loss: 0.6520\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7744 - val_loss: 0.6379\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7830 - val_loss: 0.6834\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 0.7914Restoring model weights from the end of the best epoch: 14.\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7914 - val_loss: 0.6223\n",
      "Epoch 24: early stopping\n",
      "'########################################################Model3\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 15ms/step - loss: 1.4168 - val_loss: 0.7237\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.9398 - val_loss: 0.6855\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.9262 - val_loss: 0.7131\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.9038 - val_loss: 0.6940\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.9041 - val_loss: 0.7113\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8801 - val_loss: 0.7463\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.8757 - val_loss: 0.6617\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.8377 - val_loss: 0.7016\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.8328 - val_loss: 0.7089\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.8101 - val_loss: 0.6687\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.8138 - val_loss: 0.6419\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8025 - val_loss: 0.6414\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8136 - val_loss: 0.6368\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.8229 - val_loss: 0.6731\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.8118 - val_loss: 0.7703\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.8398 - val_loss: 0.6648\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7970 - val_loss: 0.7173\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.8314 - val_loss: 0.6444\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7957 - val_loss: 0.6450\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7940 - val_loss: 0.6377\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.8197 - val_loss: 0.6339\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7834 - val_loss: 0.7039\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.8153 - val_loss: 0.6471\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7967 - val_loss: 0.6192\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7885 - val_loss: 0.6599\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7949 - val_loss: 0.6489\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.7962 - val_loss: 0.7466\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7842 - val_loss: 0.6300\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7685 - val_loss: 0.6308\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7831 - val_loss: 0.6121\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7886 - val_loss: 0.6506\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7945 - val_loss: 0.6176\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7858 - val_loss: 0.6131\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.7775 - val_loss: 0.6179\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7952 - val_loss: 0.6455\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7823 - val_loss: 0.6269\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7773 - val_loss: 0.6474\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.7874 - val_loss: 0.6364\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7806 - val_loss: 0.6350\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 0.7738Restoring model weights from the end of the best epoch: 30.\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7738 - val_loss: 0.6245\n",
      "Epoch 40: early stopping\n",
      "'########################################################Model4\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 3s 16ms/step - loss: 1.4401 - val_loss: 0.7670\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.9331 - val_loss: 0.7288\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.9105 - val_loss: 0.7013\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.8962 - val_loss: 0.7365\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.9029 - val_loss: 0.6894\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.9077 - val_loss: 0.6942\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.8720 - val_loss: 0.6631\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.8429 - val_loss: 0.6744\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8307 - val_loss: 0.6733\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.8334 - val_loss: 0.6308\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.8263 - val_loss: 0.6828\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7803 - val_loss: 0.6676\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.8303 - val_loss: 0.6367\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7934 - val_loss: 0.6483\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.8300 - val_loss: 0.6641\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8175 - val_loss: 0.6278\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7936 - val_loss: 0.6650\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.8135 - val_loss: 0.6609\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7980 - val_loss: 0.6461\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.8053 - val_loss: 0.6418\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7889 - val_loss: 0.6211\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7845 - val_loss: 0.6627\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7872 - val_loss: 0.6216\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7899 - val_loss: 0.6185\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7717 - val_loss: 0.7279\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7908 - val_loss: 0.6635\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7704 - val_loss: 0.6468\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7758 - val_loss: 0.6046\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7774 - val_loss: 0.6397\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7847 - val_loss: 0.6390\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.7841 - val_loss: 0.6206\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7754 - val_loss: 0.6090\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7880 - val_loss: 0.6064\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7658 - val_loss: 0.6155\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.7825 - val_loss: 0.6226\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7667 - val_loss: 0.6330\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7778 - val_loss: 0.6625\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7665 - val_loss: 0.6029\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7629 - val_loss: 0.6631\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7678 - val_loss: 0.6156\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7555 - val_loss: 0.6347\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7882 - val_loss: 0.6315\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7621 - val_loss: 0.6146\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.7746 - val_loss: 0.5857\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7608 - val_loss: 0.6050\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7647 - val_loss: 0.6019\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7628 - val_loss: 0.6030\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.7531 - val_loss: 0.6012\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7573 - val_loss: 0.6232\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7703 - val_loss: 0.6140\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.7742 - val_loss: 0.6724\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7766 - val_loss: 0.6268\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7502 - val_loss: 0.6147\n",
      "Epoch 54/100\n",
      "72/73 [============================>.] - ETA: 0s - loss: 0.7609Restoring model weights from the end of the best epoch: 44.\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7616 - val_loss: 0.6318\n",
      "Epoch 54: early stopping\n",
      "'########################################################Model5\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 15ms/step - loss: 1.5428 - val_loss: 0.7122\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.9423 - val_loss: 0.7106\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.9221 - val_loss: 0.7418\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.9168 - val_loss: 0.7076\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.9185 - val_loss: 0.7404\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.9144 - val_loss: 0.6903\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.8889 - val_loss: 0.6807\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.8503 - val_loss: 0.6460\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.8441 - val_loss: 0.6519\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.8367 - val_loss: 0.6725\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.8450 - val_loss: 0.6419\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8050 - val_loss: 0.6705\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.8165 - val_loss: 0.6467\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.8117 - val_loss: 0.6931\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.8124 - val_loss: 0.6552\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.8333 - val_loss: 0.6986\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.8065 - val_loss: 0.6331\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7953 - val_loss: 0.6389\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8126 - val_loss: 0.6409\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.7944 - val_loss: 0.8139\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.8331 - val_loss: 0.6267\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.8025 - val_loss: 0.7217\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.8211 - val_loss: 0.6608\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.8094 - val_loss: 0.6371\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7968 - val_loss: 0.6532\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7937 - val_loss: 0.6224\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.7781 - val_loss: 0.6526\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7934 - val_loss: 0.6383\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.8120 - val_loss: 0.6694\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7961 - val_loss: 0.6224\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7909 - val_loss: 0.6398\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7926 - val_loss: 0.6907\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.7942 - val_loss: 0.6630\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7856 - val_loss: 0.6256\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7736 - val_loss: 0.6487\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7872 - val_loss: 0.6214\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.7731 - val_loss: 0.6180\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7724 - val_loss: 0.6167\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7824 - val_loss: 0.6305\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.7826 - val_loss: 0.6405\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7842 - val_loss: 0.6338\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7654 - val_loss: 0.6174\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7596 - val_loss: 0.6418\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7871 - val_loss: 0.6083\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7720 - val_loss: 0.6341\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7596 - val_loss: 0.6300\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.7784 - val_loss: 0.6090\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7770 - val_loss: 0.6423\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7733 - val_loss: 0.6215\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7746 - val_loss: 0.6241\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7814 - val_loss: 0.6670\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7662 - val_loss: 0.6061\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7619 - val_loss: 0.6125\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7703 - val_loss: 0.7006\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7643 - val_loss: 0.6330\n",
      "Epoch 56/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7749 - val_loss: 0.6344\n",
      "Epoch 57/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7586 - val_loss: 0.6141\n",
      "Epoch 58/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7562 - val_loss: 0.6457\n",
      "Epoch 59/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7667 - val_loss: 0.6096\n",
      "Epoch 60/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.7557 - val_loss: 0.6335\n",
      "Epoch 61/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7677 - val_loss: 0.6138\n",
      "Epoch 62/100\n",
      "71/73 [============================>.] - ETA: 0s - loss: 0.7483Restoring model weights from the end of the best epoch: 52.\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7500 - val_loss: 0.6289\n",
      "Epoch 62: early stopping\n",
      "'########################################################Model6\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 13ms/step - loss: 1.4408 - val_loss: 0.7250\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.9324 - val_loss: 0.6850\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.9099 - val_loss: 0.8452\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.9122 - val_loss: 0.8008\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.8964 - val_loss: 0.6932\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.9174 - val_loss: 0.7042\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.8724 - val_loss: 0.7108\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.8437 - val_loss: 0.7848\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.8439 - val_loss: 0.6607\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.8297 - val_loss: 0.6691\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.8130 - val_loss: 0.6680\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.8261 - val_loss: 0.6377\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8014 - val_loss: 0.6328\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8081 - val_loss: 0.6627\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8293 - val_loss: 0.6583\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.8504 - val_loss: 0.6320\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.8166 - val_loss: 0.7398\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.8223 - val_loss: 0.6716\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7905 - val_loss: 0.7217\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7998 - val_loss: 0.7147\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.8235 - val_loss: 0.6416\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.8001 - val_loss: 0.6426\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7986 - val_loss: 0.6389\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7948 - val_loss: 0.6513\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8007 - val_loss: 0.6227\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7873 - val_loss: 0.6165\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7809 - val_loss: 0.8229\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.7931 - val_loss: 0.6250\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.7855 - val_loss: 0.6265\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7847 - val_loss: 0.6339\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7900 - val_loss: 0.6519\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7825 - val_loss: 0.6286\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7887 - val_loss: 0.6231\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7871 - val_loss: 0.6020\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7823 - val_loss: 0.6211\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7848 - val_loss: 0.6459\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7755 - val_loss: 0.6245\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7849 - val_loss: 0.6352\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7836 - val_loss: 0.6005\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7757 - val_loss: 0.6115\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.7685 - val_loss: 0.5984\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.7696 - val_loss: 0.6107\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7978 - val_loss: 0.6037\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7697 - val_loss: 0.6082\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7767 - val_loss: 0.6019\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7742 - val_loss: 0.6044\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7623 - val_loss: 0.5930\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7810 - val_loss: 0.6363\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7614 - val_loss: 0.6202\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7822 - val_loss: 0.6072\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7579 - val_loss: 0.6020\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7568 - val_loss: 0.5973\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.7691 - val_loss: 0.6115\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.7546 - val_loss: 0.6097\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7601 - val_loss: 0.6003\n",
      "Epoch 56/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7573 - val_loss: 0.5956\n",
      "Epoch 57/100\n",
      "72/73 [============================>.] - ETA: 0s - loss: 0.7731Restoring model weights from the end of the best epoch: 47.\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7718 - val_loss: 0.6142\n",
      "Epoch 57: early stopping\n",
      "'########################################################Model7\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 15ms/step - loss: 1.6392 - val_loss: 0.7719\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.9335 - val_loss: 0.7000\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.9238 - val_loss: 0.7362\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8988 - val_loss: 0.7402\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8621 - val_loss: 0.6968\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.8525 - val_loss: 0.7192\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.8479 - val_loss: 0.6873\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.8606 - val_loss: 0.6528\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.8269 - val_loss: 0.6796\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.8212 - val_loss: 0.6485\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.8095 - val_loss: 0.6437\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.8153 - val_loss: 0.6428\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.8256 - val_loss: 0.6667\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.8028 - val_loss: 0.6354\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8040 - val_loss: 0.6235\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8023 - val_loss: 0.6411\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7964 - val_loss: 0.6693\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7954 - val_loss: 0.6639\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7981 - val_loss: 0.6484\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7823 - val_loss: 0.6564\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7905 - val_loss: 0.6498\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7772 - val_loss: 0.8387\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7906 - val_loss: 0.6187\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7966 - val_loss: 0.6913\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.8111 - val_loss: 0.6450\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.7971 - val_loss: 0.6291\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7845 - val_loss: 0.6391\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7910 - val_loss: 0.6458\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7783 - val_loss: 0.6204\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8109 - val_loss: 0.6011\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7604 - val_loss: 0.6465\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.7726 - val_loss: 0.6219\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.7847 - val_loss: 0.6181\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7830 - val_loss: 0.6156\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7694 - val_loss: 0.6247\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7927 - val_loss: 0.6347\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7715 - val_loss: 0.6896\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7794 - val_loss: 0.6279\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7716 - val_loss: 0.6044\n",
      "Epoch 40/100\n",
      "69/73 [===========================>..] - ETA: 0s - loss: 0.7757Restoring model weights from the end of the best epoch: 30.\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.7710 - val_loss: 0.6192\n",
      "Epoch 40: early stopping\n",
      "'########################################################Model8\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 12ms/step - loss: 1.5242 - val_loss: 0.7343\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.9322 - val_loss: 0.7729\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.9234 - val_loss: 0.7305\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.8974 - val_loss: 0.7328\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.8813 - val_loss: 0.6889\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.8715 - val_loss: 0.6519\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.8465 - val_loss: 0.6599\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.8351 - val_loss: 0.6738\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.8270 - val_loss: 0.6585\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.8350 - val_loss: 0.6388\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.8083 - val_loss: 0.6841\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.8101 - val_loss: 0.6382\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8133 - val_loss: 0.6870\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8362 - val_loss: 0.6570\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7927 - val_loss: 0.6579\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8100 - val_loss: 0.6462\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.7927 - val_loss: 0.6398\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.7889 - val_loss: 0.6631\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7960 - val_loss: 0.6345\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7784 - val_loss: 0.6355\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7777 - val_loss: 0.6488\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7773 - val_loss: 0.6307\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7877 - val_loss: 0.6337\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7837 - val_loss: 0.6323\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 0.7884 - val_loss: 0.6391\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7772 - val_loss: 0.6208\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7787 - val_loss: 0.6851\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7860 - val_loss: 0.6215\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7718 - val_loss: 0.6289\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7658 - val_loss: 0.6312\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7794 - val_loss: 0.7053\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7788 - val_loss: 0.6109\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7672 - val_loss: 0.6877\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7644 - val_loss: 0.6370\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7955 - val_loss: 0.6306\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7662 - val_loss: 0.6142\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7550 - val_loss: 0.6281\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7685 - val_loss: 0.6142\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7680 - val_loss: 0.6280\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7706 - val_loss: 0.6133\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7745 - val_loss: 0.6101\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7886 - val_loss: 0.7143\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7735 - val_loss: 0.6197\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7785 - val_loss: 0.6191\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7660 - val_loss: 0.6192\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7586 - val_loss: 0.5983\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7874 - val_loss: 0.6291\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7634 - val_loss: 0.6104\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7647 - val_loss: 0.5990\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7568 - val_loss: 0.6016\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7564 - val_loss: 0.6859\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7562 - val_loss: 0.6063\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 0.7726 - val_loss: 0.6535\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7534 - val_loss: 0.6132\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7522 - val_loss: 0.7093\n",
      "Epoch 56/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 0.7605Restoring model weights from the end of the best epoch: 46.\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 0.7605 - val_loss: 0.6235\n",
      "Epoch 56: early stopping\n",
      "'########################################################Model9\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 12ms/step - loss: 23464016.0000 - val_loss: 263619.3438\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 130463.2812 - val_loss: 163210.6406\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 91075.4219 - val_loss: 145355.1250\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 80957.0547 - val_loss: 149092.9531\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 84830.0234 - val_loss: 169241.7188\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 75577.0312 - val_loss: 164882.4062\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 81507.2734 - val_loss: 179702.3438\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 70312.0938 - val_loss: 182809.2188\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 70305.7109 - val_loss: 165534.3906\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 71351.3203 - val_loss: 203541.2500\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 68335.7812 - val_loss: 180984.9062\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 72390.9688 - val_loss: 193211.7344\n",
      "Epoch 13/100\n",
      "71/73 [============================>.] - ETA: 0s - loss: 68517.0781Restoring model weights from the end of the best epoch: 3.\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 67942.2188 - val_loss: 192636.7969\n",
      "Epoch 13: early stopping\n",
      "'########################################################Model0\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 16ms/step - loss: 36445460.0000 - val_loss: 986872.1875\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 334352.8125 - val_loss: 141789.7031\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 102552.3672 - val_loss: 130716.2891\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 81825.7344 - val_loss: 159564.9219\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 63452.0469 - val_loss: 164711.1250\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 69273.0938 - val_loss: 187141.1094\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 72356.3047 - val_loss: 166113.6250\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 63855.4609 - val_loss: 202154.6562\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 64938.3672 - val_loss: 202038.6719\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 204728.6875 - val_loss: 174616.6406\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 62419.4766 - val_loss: 183523.6406\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 64588.5664 - val_loss: 188524.7031\n",
      "Epoch 13/100\n",
      "72/73 [============================>.] - ETA: 0s - loss: 61520.8125Restoring model weights from the end of the best epoch: 3.\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 61487.1445 - val_loss: 188982.2969\n",
      "Epoch 13: early stopping\n",
      "'########################################################Model1\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 16ms/step - loss: 42040140.0000 - val_loss: 1102150.7500\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 815114.8125 - val_loss: 155008.4219\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 950513.1250 - val_loss: 1047846.1875\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 163551.7188 - val_loss: 144973.9375\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 77580.7891 - val_loss: 160649.7031\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 69668.1719 - val_loss: 170095.2031\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 71224.9766 - val_loss: 217078.0000\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 62941.4219 - val_loss: 169811.8438\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 58245.1328 - val_loss: 194491.8438\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 55878.0820 - val_loss: 178301.2500\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 58813.8125 - val_loss: 190354.8750\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 65598.2578 - val_loss: 178203.8281\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 63997.0898 - val_loss: 213854.4062\n",
      "Epoch 14/100\n",
      "68/73 [==========================>...] - ETA: 0s - loss: 63403.5938Restoring model weights from the end of the best epoch: 4.\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 63012.7031 - val_loss: 184424.0469\n",
      "Epoch 14: early stopping\n",
      "'########################################################Model2\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 16ms/step - loss: 52352392.0000 - val_loss: 1356817.1250\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 1395615.8750 - val_loss: 182207.7031\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 109610.5781 - val_loss: 112087.0000\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 69450.0781 - val_loss: 156338.3906\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 73779.9609 - val_loss: 145864.9688\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 390578.4375 - val_loss: 304877.2500\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 93543.9297 - val_loss: 175668.7812\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 47531.8711 - val_loss: 160446.3906\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 52279.3008 - val_loss: 181339.7031\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 52749.3203 - val_loss: 179941.5156\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 50027.0000 - val_loss: 177539.5938\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 49319.5391 - val_loss: 182957.6562\n",
      "Epoch 13/100\n",
      "72/73 [============================>.] - ETA: 0s - loss: 51311.1914Restoring model weights from the end of the best epoch: 3.\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 51146.1914 - val_loss: 184326.8750\n",
      "Epoch 13: early stopping\n",
      "'########################################################Model3\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 12ms/step - loss: 34379316.0000 - val_loss: 1588666.0000\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 956283.1250 - val_loss: 193435.9375\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 384576.2812 - val_loss: 205449.4688\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 98555.0000 - val_loss: 130798.3984\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 85542.0234 - val_loss: 154849.0781\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 70669.5078 - val_loss: 183930.0625\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 65329.1914 - val_loss: 152801.5781\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 73679.8125 - val_loss: 224759.0781\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 66505.8672 - val_loss: 187521.4062\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 68171.2891 - val_loss: 191707.7031\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 59786.4844 - val_loss: 179920.7969\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 62724.6680 - val_loss: 184589.8438\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 56653.0547 - val_loss: 195038.8750\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 65321.9570Restoring model weights from the end of the best epoch: 4.\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 65321.9570 - val_loss: 227729.8281\n",
      "Epoch 14: early stopping\n",
      "'########################################################Model4\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 3s 16ms/step - loss: 24876550.0000 - val_loss: 419781.6250\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 242468.2500 - val_loss: 130858.7891\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 108662.0312 - val_loss: 138466.4375\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 78832.1094 - val_loss: 130847.6250\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 72874.9453 - val_loss: 133121.2031\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 63951.8555 - val_loss: 152716.3438\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 65028.5508 - val_loss: 163932.8281\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 230706.3594 - val_loss: 170568.5312\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 61584.1250 - val_loss: 195273.0000\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 58268.2070 - val_loss: 166052.3906\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 53274.6758 - val_loss: 166270.7656\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 50489.1328 - val_loss: 172870.5312\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 53197.1875 - val_loss: 253154.5156\n",
      "Epoch 14/100\n",
      "71/73 [============================>.] - ETA: 0s - loss: 59636.7812Restoring model weights from the end of the best epoch: 4.\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 59778.4336 - val_loss: 231977.3594\n",
      "Epoch 14: early stopping\n",
      "'########################################################Model5\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 16ms/step - loss: 32063424.0000 - val_loss: 1496264.0000\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 776601.8125 - val_loss: 144189.2031\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 82674.7969 - val_loss: 121950.6875\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 73538.9688 - val_loss: 128996.7344\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 65563.7109 - val_loss: 165681.7969\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 61894.5391 - val_loss: 133604.4375\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 726382.3750 - val_loss: 352463.2500\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 126583.4609 - val_loss: 180627.4688\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 65852.2422 - val_loss: 179296.0469\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 65966.0312 - val_loss: 192497.2344\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 62984.3789 - val_loss: 184942.4062\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 62404.3320 - val_loss: 168785.2969\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 61755.1016Restoring model weights from the end of the best epoch: 3.\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 61755.1016 - val_loss: 207661.1250\n",
      "Epoch 13: early stopping\n",
      "'########################################################Model6\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 15ms/step - loss: 37738444.0000 - val_loss: 769833.1250\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 322453.2812 - val_loss: 167124.2969\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 97011.0312 - val_loss: 143693.8594\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 76299.8516 - val_loss: 151015.1250\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 96366.9141 - val_loss: 156067.5938\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 70452.6797 - val_loss: 161650.7188\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 61521.6680 - val_loss: 163826.5938\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 67183.3125 - val_loss: 194629.6719\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 199219.5781 - val_loss: 213532.4062\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 70140.2812 - val_loss: 187627.1250\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 65174.2539 - val_loss: 188126.4531\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 59629.8125 - val_loss: 212716.9062\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 63204.8828Restoring model weights from the end of the best epoch: 3.\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 63204.8828 - val_loss: 182979.3438\n",
      "Epoch 13: early stopping\n",
      "'########################################################Model7\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 16ms/step - loss: 36007516.0000 - val_loss: 640979.3750\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 346447.9688 - val_loss: 127447.6562\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 104025.3203 - val_loss: 158006.4688\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 75562.6172 - val_loss: 146244.1875\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 73764.8047 - val_loss: 143866.5469\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 62874.7734 - val_loss: 150787.0938\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 65218.1992 - val_loss: 198948.0000\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 59119.8008 - val_loss: 164949.8594\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 57279.5352 - val_loss: 172863.5625\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 52585.6797 - val_loss: 192843.5156\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 56326.1016 - val_loss: 185193.5469\n",
      "Epoch 12/100\n",
      "71/73 [============================>.] - ETA: 0s - loss: 58770.6406Restoring model weights from the end of the best epoch: 2.\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 58635.2344 - val_loss: 180376.1406\n",
      "Epoch 12: early stopping\n",
      "'########################################################Model8\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 16ms/step - loss: 43490392.0000 - val_loss: 960534.3125\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 774731.4375 - val_loss: 246365.0000\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 294478.3125 - val_loss: 135507.0000\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 87746.1953 - val_loss: 131626.4062\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 75344.3047 - val_loss: 183099.1250\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 82338.6562 - val_loss: 154053.5781\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 462048.7188 - val_loss: 192234.2188\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 72884.6328 - val_loss: 194402.4062\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 60829.6484 - val_loss: 181106.1719\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 58708.5664 - val_loss: 175320.6562\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 55737.8438 - val_loss: 163505.6562\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 62284.6406 - val_loss: 177483.3281\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 60899.9570 - val_loss: 211030.9688\n",
      "Epoch 14/100\n",
      "72/73 [============================>.] - ETA: 0s - loss: 61989.5195Restoring model weights from the end of the best epoch: 4.\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 62182.6758 - val_loss: 210567.7812\n",
      "Epoch 14: early stopping\n",
      "'########################################################Model9\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 16ms/step - loss: 149.9945 - val_loss: 143.8443\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 137.8356 - val_loss: 138.7484\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 136.9966 - val_loss: 142.0914\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 136.4867 - val_loss: 143.4279\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 136.8035 - val_loss: 140.0061\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 136.5473 - val_loss: 145.0437\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 136.7511 - val_loss: 142.2327\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 136.1409 - val_loss: 139.9125\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 135.2848 - val_loss: 140.1830\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 134.8578 - val_loss: 138.0577\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 136.0574 - val_loss: 142.0395\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 135.2280 - val_loss: 138.9491\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 134.4051 - val_loss: 140.1484\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 135.1079 - val_loss: 139.7035\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 134.4988 - val_loss: 137.9749\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 133.6917 - val_loss: 138.0468\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 134.2554 - val_loss: 145.3791\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 134.8300 - val_loss: 139.5332\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 134.1513 - val_loss: 139.7745\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 133.1983 - val_loss: 137.7418\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 133.7437 - val_loss: 138.7306\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 133.2939 - val_loss: 138.1276\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 134.0333 - val_loss: 138.4497\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 135.0101 - val_loss: 138.9226\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 134.0052 - val_loss: 140.9577\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 133.6725 - val_loss: 140.5487\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 133.3366 - val_loss: 138.3443\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 133.1668 - val_loss: 151.8406\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 133.6413 - val_loss: 139.3704\n",
      "Epoch 30/100\n",
      "72/73 [============================>.] - ETA: 0s - loss: 132.9479Restoring model weights from the end of the best epoch: 20.\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 132.9834 - val_loss: 138.8789\n",
      "Epoch 30: early stopping\n",
      "'########################################################Model0\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 3s 16ms/step - loss: 147.7691 - val_loss: 144.6743\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 138.3371 - val_loss: 139.3540\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 137.5866 - val_loss: 144.3235\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 139.6346 - val_loss: 145.7065\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 139.8568 - val_loss: 140.8281\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 139.8569 - val_loss: 141.1895\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 139.7470 - val_loss: 145.1561\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 138.5023 - val_loss: 140.8920\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 139.0247 - val_loss: 141.1286\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 138.2408 - val_loss: 142.1251\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 139.5564 - val_loss: 142.9156\n",
      "Epoch 12/100\n",
      "71/73 [============================>.] - ETA: 0s - loss: 137.6303Restoring model weights from the end of the best epoch: 2.\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 137.6101 - val_loss: 140.3932\n",
      "Epoch 12: early stopping\n",
      "'########################################################Model1\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 16ms/step - loss: 144.8182 - val_loss: 139.3349\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 135.9240 - val_loss: 137.2610\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 135.1883 - val_loss: 139.5393\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 136.5621 - val_loss: 139.1446\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 135.4736 - val_loss: 137.4729\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 133.9285 - val_loss: 136.2732\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 133.5542 - val_loss: 138.9153\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 133.3240 - val_loss: 135.7662\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 132.5503 - val_loss: 135.6873\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 132.4607 - val_loss: 134.8826\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 133.3992 - val_loss: 139.6158\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 133.9797 - val_loss: 139.3316\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 135.5838 - val_loss: 139.3197\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 135.1742 - val_loss: 136.7435\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 134.7764 - val_loss: 136.6167\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 134.6446 - val_loss: 137.5655\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 133.0220 - val_loss: 135.2418\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 133.4921 - val_loss: 137.7375\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 135.5987 - val_loss: 137.7689\n",
      "Epoch 20/100\n",
      "71/73 [============================>.] - ETA: 0s - loss: 135.3473Restoring model weights from the end of the best epoch: 10.\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 135.2241 - val_loss: 136.6538\n",
      "Epoch 20: early stopping\n",
      "'########################################################Model2\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 16ms/step - loss: 146.4440 - val_loss: 137.5240\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 137.5255 - val_loss: 138.2328\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 136.3492 - val_loss: 135.7487\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 135.1284 - val_loss: 135.8497\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 134.7299 - val_loss: 134.9351\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 134.9182 - val_loss: 138.5725\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 135.2333 - val_loss: 136.6512\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 134.9994 - val_loss: 136.9807\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 134.5481 - val_loss: 135.2983\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 133.9564 - val_loss: 134.3042\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 134.0838 - val_loss: 134.3714\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 133.9954 - val_loss: 134.5091\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 133.9004 - val_loss: 135.3705\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 133.6795 - val_loss: 134.0102\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 133.9752 - val_loss: 133.4620\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 133.7180 - val_loss: 134.0636\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 133.9901 - val_loss: 133.4344\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 133.5773 - val_loss: 134.2558\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 133.7846 - val_loss: 133.8203\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 133.5602 - val_loss: 133.9589\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 133.8994 - val_loss: 136.5495\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 134.0753 - val_loss: 132.9993\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 133.2240 - val_loss: 133.9091\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 134.0774 - val_loss: 135.5407\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 133.8364 - val_loss: 133.0585\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 134.3820 - val_loss: 134.0841\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 133.1814 - val_loss: 137.0584\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 133.3217 - val_loss: 134.5847\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 133.0274 - val_loss: 134.1740\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 133.3617 - val_loss: 134.5252\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 133.4144 - val_loss: 132.9712\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 132.9712 - val_loss: 138.2800\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 134.0386 - val_loss: 133.8233\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 133.0743 - val_loss: 133.5302\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 133.0737 - val_loss: 133.5870\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 132.7548 - val_loss: 134.2271\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 132.8020 - val_loss: 133.2415\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 133.2933 - val_loss: 134.6947\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 132.8544 - val_loss: 133.4335\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 132.7868 - val_loss: 136.1077\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 133.6634 - val_loss: 132.7427\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 132.1569 - val_loss: 137.0231\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 133.0668 - val_loss: 133.2042\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 132.4770 - val_loss: 133.6596\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 133.5814 - val_loss: 133.4311\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 132.8003 - val_loss: 132.3482\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 132.9276 - val_loss: 132.6622\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 132.7594 - val_loss: 133.6722\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 132.8450 - val_loss: 134.7587\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 132.9418 - val_loss: 132.4771\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 133.1927 - val_loss: 135.5453\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 133.4970 - val_loss: 133.9294\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 132.5699 - val_loss: 133.5164\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 132.4743 - val_loss: 132.6458\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 132.3819 - val_loss: 134.9711\n",
      "Epoch 56/100\n",
      "71/73 [============================>.] - ETA: 0s - loss: 132.4701Restoring model weights from the end of the best epoch: 46.\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 132.5094 - val_loss: 133.5663\n",
      "Epoch 56: early stopping\n",
      "'########################################################Model3\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 16ms/step - loss: 149.8137 - val_loss: 149.0562\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 144.7795 - val_loss: 147.3987\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 142.9892 - val_loss: 145.9603\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 142.6207 - val_loss: 145.8953\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 143.4073 - val_loss: 145.5549\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 142.5606 - val_loss: 146.9637\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 142.4540 - val_loss: 152.8190\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 142.9527 - val_loss: 149.1118\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 142.6364 - val_loss: 145.6172\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 143.4628 - val_loss: 150.6180\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 144.8421 - val_loss: 147.5359\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 143.8749 - val_loss: 145.4459\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 144.7925 - val_loss: 148.5052\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 144.3466 - val_loss: 147.6874\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 143.6350 - val_loss: 146.3335\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 143.5708 - val_loss: 145.6743\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 143.9747 - val_loss: 146.9746\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 143.9675 - val_loss: 147.3360\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 143.4985 - val_loss: 145.2856\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 141.0649 - val_loss: 143.1795\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 140.8628 - val_loss: 144.0735\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 140.3407 - val_loss: 143.8416\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 140.3838 - val_loss: 144.6096\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 139.8487 - val_loss: 143.7285\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 140.9008 - val_loss: 143.7996\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 139.8732 - val_loss: 144.1721\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 139.8727 - val_loss: 143.9386\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 139.8037 - val_loss: 144.9684\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 139.3879 - val_loss: 144.2245\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 139.6887Restoring model weights from the end of the best epoch: 20.\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 139.6887 - val_loss: 143.8655\n",
      "Epoch 30: early stopping\n",
      "'########################################################Model4\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 16ms/step - loss: 151.6301 - val_loss: 150.4545\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 140.1657 - val_loss: 144.2003\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 139.6098 - val_loss: 143.5656\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 138.1551 - val_loss: 142.1916\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 138.5578 - val_loss: 145.4215\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 140.1271 - val_loss: 141.0078\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 139.2335 - val_loss: 140.7008\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 138.0038 - val_loss: 140.2573\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 139.2372 - val_loss: 140.6295\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 138.7543 - val_loss: 139.7552\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 137.8137 - val_loss: 139.7369\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 137.8042 - val_loss: 139.6858\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 137.3164 - val_loss: 139.8370\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 137.4905 - val_loss: 139.0476\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 138.2788 - val_loss: 139.8071\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 136.5914 - val_loss: 139.7055\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 137.4624 - val_loss: 138.9855\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 136.7812 - val_loss: 138.8292\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 136.6577 - val_loss: 139.1065\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 136.7758 - val_loss: 139.2731\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 137.1534 - val_loss: 139.0414\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 137.5490 - val_loss: 138.6799\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 136.8367 - val_loss: 139.1650\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 137.3791 - val_loss: 139.7392\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 136.6792 - val_loss: 141.1282\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 137.1767 - val_loss: 139.3868\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 137.4201 - val_loss: 139.2138\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 136.6784 - val_loss: 138.2265\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 135.9973 - val_loss: 138.9928\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 136.6162 - val_loss: 139.5964\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 138.1419 - val_loss: 138.5497\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 136.0689 - val_loss: 139.2331\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 136.8209 - val_loss: 140.0688\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 136.2927 - val_loss: 138.2469\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 135.9428 - val_loss: 143.6088\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 136.3309 - val_loss: 138.2974\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 136.2527 - val_loss: 139.5319\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 136.0581 - val_loss: 137.7634\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 136.4204 - val_loss: 138.4975\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 136.0571 - val_loss: 138.0110\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 136.4017 - val_loss: 138.1537\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 135.7670 - val_loss: 138.7177\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 136.6208 - val_loss: 138.0987\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 136.2015 - val_loss: 141.2095\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 136.8506 - val_loss: 138.7286\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 135.9752 - val_loss: 138.6076\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 135.6555 - val_loss: 138.6337\n",
      "Epoch 48/100\n",
      "72/73 [============================>.] - ETA: 0s - loss: 135.7824Restoring model weights from the end of the best epoch: 38.\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 135.7977 - val_loss: 138.9364\n",
      "Epoch 48: early stopping\n",
      "'########################################################Model5\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 16ms/step - loss: 155.9444 - val_loss: 145.7200\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 140.2997 - val_loss: 142.2669\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 136.3771 - val_loss: 138.0383\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 130.8031 - val_loss: 136.2300\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 129.9322 - val_loss: 133.8108\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 130.3301 - val_loss: 136.4853\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 130.0369 - val_loss: 135.3284\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 129.0867 - val_loss: 132.6277\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 128.7232 - val_loss: 132.0429\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 129.0010 - val_loss: 134.0611\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 128.1279 - val_loss: 132.0277\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 128.4940 - val_loss: 130.6283\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 128.4790 - val_loss: 132.6917\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 128.3746 - val_loss: 132.2708\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 129.1861 - val_loss: 134.4331\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 127.8001 - val_loss: 133.1725\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 127.0462 - val_loss: 133.3122\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 125.5872 - val_loss: 131.1695\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 126.9468 - val_loss: 131.7672\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 126.4080 - val_loss: 130.0212\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 127.5273 - val_loss: 131.3833\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 126.1595 - val_loss: 131.1317\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 126.1566 - val_loss: 132.0364\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 127.1686 - val_loss: 138.1174\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 126.6510 - val_loss: 130.2558\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 127.1827 - val_loss: 133.7148\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 126.0605 - val_loss: 130.0074\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 125.1819 - val_loss: 130.1496\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 125.7032 - val_loss: 134.5771\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 125.9434 - val_loss: 128.9610\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 124.9973 - val_loss: 129.9291\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 124.4969 - val_loss: 131.8110\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 124.8123 - val_loss: 131.9088\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 124.4175 - val_loss: 133.2521\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 124.6465 - val_loss: 134.8415\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 124.7577 - val_loss: 129.5179\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 125.9240 - val_loss: 129.7096\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 125.9235 - val_loss: 133.0509\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 124.7536 - val_loss: 131.3580\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 124.2476Restoring model weights from the end of the best epoch: 30.\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 124.2476 - val_loss: 129.7786\n",
      "Epoch 40: early stopping\n",
      "'########################################################Model6\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 12ms/step - loss: 162.5483 - val_loss: 158.0178\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 139.6849 - val_loss: 138.5537\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 133.5454 - val_loss: 137.5349\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 133.7341 - val_loss: 137.0212\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 133.9746 - val_loss: 135.5859\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 133.6144 - val_loss: 135.9615\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 133.4713 - val_loss: 135.9451\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 133.6854 - val_loss: 134.9961\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 132.0047 - val_loss: 136.5287\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 131.6016 - val_loss: 134.8259\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 131.1767 - val_loss: 132.7137\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 131.1581 - val_loss: 133.2301\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 130.8107 - val_loss: 132.5862\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 131.3469 - val_loss: 137.3355\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 127.7896 - val_loss: 130.9072\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 128.3018 - val_loss: 130.0940\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 128.3514 - val_loss: 130.9410\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 127.6257 - val_loss: 132.5554\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 128.1389 - val_loss: 129.5970\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 127.4666 - val_loss: 130.3324\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 127.3936 - val_loss: 130.2612\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 126.8908 - val_loss: 132.2500\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 127.6073 - val_loss: 131.7221\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 126.7620 - val_loss: 132.5068\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 126.7351 - val_loss: 131.1579\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 127.3252 - val_loss: 130.1300\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 127.3261 - val_loss: 130.7939\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 126.5552 - val_loss: 129.7998\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 126.9610Restoring model weights from the end of the best epoch: 19.\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 126.9610 - val_loss: 130.3033\n",
      "Epoch 29: early stopping\n",
      "'########################################################Model7\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 3s 16ms/step - loss: 157.2074 - val_loss: 153.8966\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 150.6900 - val_loss: 153.0072\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 12ms/step - loss: 143.8141 - val_loss: 144.0867\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 142.5316 - val_loss: 149.4115\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 144.7368 - val_loss: 146.3165\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 142.7136 - val_loss: 141.2579\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 138.6742 - val_loss: 140.5111\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 134.4976 - val_loss: 137.9498\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 134.0341 - val_loss: 137.2946\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 135.1197 - val_loss: 139.6880\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 134.3195 - val_loss: 137.5964\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 13ms/step - loss: 133.9771 - val_loss: 136.8077\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 134.1664 - val_loss: 138.0120\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 133.9442 - val_loss: 136.6666\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 133.7553 - val_loss: 137.4062\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 133.8081 - val_loss: 137.1308\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 133.0924 - val_loss: 137.4529\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 134.0719 - val_loss: 137.6896\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 134.1414 - val_loss: 138.9447\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 133.6512 - val_loss: 138.0898\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 133.5643 - val_loss: 136.4638\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 134.1854 - val_loss: 138.9908\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 133.7274 - val_loss: 138.9401\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 133.4547 - val_loss: 137.1378\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 133.1485 - val_loss: 135.8873\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 133.5250 - val_loss: 136.4099\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 133.5701 - val_loss: 136.8700\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 132.8808 - val_loss: 137.0620\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 133.7500 - val_loss: 137.5296\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 133.0748 - val_loss: 136.8505\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 133.3838 - val_loss: 136.0421\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 133.4639 - val_loss: 136.7082\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 133.3609 - val_loss: 138.2886\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 132.9544 - val_loss: 136.0985\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 132.7577Restoring model weights from the end of the best epoch: 25.\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 132.7577 - val_loss: 136.1662\n",
      "Epoch 35: early stopping\n",
      "'########################################################Model8\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 14ms/step - loss: 150.9318 - val_loss: 153.0675\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 137.9103 - val_loss: 139.6346\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 135.8885 - val_loss: 139.7474\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 136.0639 - val_loss: 148.8512\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 136.5806 - val_loss: 141.0795\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 135.8044 - val_loss: 138.3153\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 135.8536 - val_loss: 140.1280\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 135.8512 - val_loss: 139.6846\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 136.1160 - val_loss: 139.8027\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 137.7444 - val_loss: 141.2372\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 137.7432 - val_loss: 140.1125\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 137.5435 - val_loss: 141.2676\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 140.0346 - val_loss: 141.2952\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 139.7227 - val_loss: 141.2661\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 139.8868 - val_loss: 144.1780\n",
      "Epoch 16/100\n",
      "72/73 [============================>.] - ETA: 0s - loss: 140.9055Restoring model weights from the end of the best epoch: 6.\n",
      "73/73 [==============================] - 1s 11ms/step - loss: 140.8743 - val_loss: 140.7116\n",
      "Epoch 16: early stopping\n",
      "'########################################################Model9\n"
     ]
    }
   ],
   "source": [
    "model_num = 10\n",
    "\n",
    "\n",
    "mase_models = train_bagging_models(model_num, MASE(y_train,24),100,10,8)\n",
    "mape_models = train_bagging_models(model_num,'mape',100,10,8)\n",
    "smape_models = train_bagging_models(model_num, SMAPE(),100,10,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "468ad253-6a73-4a53-9d07-ad17ec4c1836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 11ms/step\n",
      "12/12 [==============================] - 0s 11ms/step\n",
      "12/12 [==============================] - 0s 11ms/step\n",
      "12/12 [==============================] - 0s 12ms/step\n",
      "12/12 [==============================] - 0s 11ms/step\n",
      "12/12 [==============================] - 0s 11ms/step\n",
      "12/12 [==============================] - 0s 12ms/step\n",
      "12/12 [==============================] - 0s 11ms/step\n",
      "12/12 [==============================] - 0s 11ms/step\n",
      "12/12 [==============================] - 0s 11ms/step\n",
      "12/12 [==============================] - 0s 12ms/step\n",
      "12/12 [==============================] - 0s 12ms/step\n",
      "12/12 [==============================] - 0s 11ms/step\n",
      "12/12 [==============================] - 0s 11ms/step\n",
      "12/12 [==============================] - 0s 11ms/step\n",
      "12/12 [==============================] - 0s 10ms/step\n",
      "12/12 [==============================] - 0s 10ms/step\n",
      "12/12 [==============================] - 0s 11ms/step\n",
      "12/12 [==============================] - 0s 10ms/step\n",
      "12/12 [==============================] - 0s 10ms/step\n",
      "12/12 [==============================] - 0s 10ms/step\n",
      "12/12 [==============================] - 0s 11ms/step\n",
      "12/12 [==============================] - 0s 10ms/step\n",
      "12/12 [==============================] - 0s 11ms/step\n",
      "12/12 [==============================] - 0s 11ms/step\n",
      "12/12 [==============================] - 0s 11ms/step\n",
      "12/12 [==============================] - 0s 11ms/step\n",
      "12/12 [==============================] - 0s 11ms/step\n",
      "12/12 [==============================] - 0s 11ms/step\n",
      "12/12 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.22155343142144104, 0.25426281812969287)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred1,_=smape_models\n",
    "pred2,_=mase_models\n",
    "pred3,_=mape_models\n",
    "\n",
    "smape_predictions = bagging_predict2(pred1, test_X)\n",
    "mase_predictions = bagging_predict2(pred2, test_X)\n",
    "mape_predictions = bagging_predict2(pred3, test_X)\n",
    "concat = np.concatenate([smape_predictions, mase_predictions,mape_predictions],axis=0)\n",
    "fin_pred = np.median(concat,axis=0)\n",
    "#pd.DataFrame(fin_pred).to_csv(\"freezing_I.csv\")\n",
    "mean_squared_error(test_y.flatten(),fin_pred.flatten()),mean_absolute_error(test_y.flatten(),fin_pred.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b0204ee-8daf-431a-b391-0926f4570676",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(fin_pred).to_csv(\"../result7_new/transformer/pred_mid.csv\")\n",
    "for i in range(10):\n",
    "    pd.DataFrame(concat[i]).to_csv(f\"../result7_new/transformer/pred{i}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
