{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84526bc5-cd1a-4fac-a796-57902266c3bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "636876fb-747b-4480-8ea0-8ff0618bd573",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-30 15:38:39.069868: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-30 15:38:39.146385: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-08-30 15:38:39.146404: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-08-30 15:38:39.501769: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-08-30 15:38:39.501818: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-08-30 15:38:39.501824: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nbeats_keras.model import NBeatsNet as NBeatsKeras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "#from nbeats_pytorch.model import NBeatsNet as NBeatsPytorch\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "import time\n",
    "from keras.models import load_model\n",
    "#from target_data_electronic70_7 import target_X, target_y ,test_X, test_y\n",
    "#from m4databasis21_7 import base_domain,zt_in,zt_out,M4Meta,inputsize,train_12,train_12_y\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error,mean_absolute_percentage_error\n",
    "plt.rcParams['font.family'] ='Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] =False\n",
    "from tensorflow.keras.losses import Loss\n",
    "import tensorflow as tf\n",
    "#from m4databasis35_7_70_7 import train_35,train_35_y,train_70,train_70_y\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, LayerNormalization, MultiHeadAttention, Dropout, Add, Concatenate,Flatten,Reshape\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, TimeDistributed, Lambda\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3850e1af-7ef4-47f2-b130-6732c47014c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((725, 72), (725, 24))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_X= pd.read_csv(\"../data/solor_train_input_3.csv\").iloc[:,(1+24*0):].values\n",
    "target_y =pd.read_csv(\"../data/solor_train_output_3.csv\").iloc[:,1:].values\n",
    "test_X= pd.read_csv(\"../data/solor_val_input_3.csv\").iloc[:,(1+24*0):].values\n",
    "test_y =pd.read_csv(\"../data/solor_val_output_3.csv\").iloc[:,1:].values\n",
    "\n",
    "X_train = target_X\n",
    "y_train = target_y\n",
    "X_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3aff672-3e0d-4a08-9d95-0a0eacbdbb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "# loss SMAPE\n",
    "class SMAPE(Loss):\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_pred = tf.reshape(y_pred, tf.shape(y_true))  # 예측 값의 차원을 맞춤\n",
    "       # y_pred=tf.clip_by_value(y_pred, 1e-10, tf.reduce_max(y_pred))\n",
    "       # y_true = tf.clip_by_value(y_true, 1e-10, tf.reduce_max(y_true))\n",
    "        \n",
    "        numerator = 100 * tf.abs(y_true- y_pred )\n",
    "        denominator =  (tf.abs(y_true ) + tf.abs(y_pred))/2\n",
    "        smape =  numerator /  denominator #tf.clip_by_value(denominator, 1e-10, tf.reduce_max(denominator))\n",
    "        return tf.reduce_mean(smape)\n",
    "\n",
    "#################################################################################\n",
    "# loss MASE\n",
    "class MASE(Loss):\n",
    "    def __init__(self, training_data, period, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.scale = self.calculate_scale(training_data, period)\n",
    "    def seasonal_diff(data, period):\n",
    "        return data[period:] - data[:-period]\n",
    "\n",
    "    def calculate_scale(self, training_data, period):\n",
    "        # 주기 차분 계산\n",
    "        diff = seasonal_diff(training_data, period)\n",
    "        scale = np.mean(np.abs(diff))\n",
    "        return scale\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        y_pred = tf.reshape(y_pred, tf.shape(y_true))  # 차원 맞추기\n",
    "        error = tf.abs(y_true - y_pred)\n",
    "        return tf.reduce_mean(error / self.scale)\n",
    "\n",
    "def seasonal_diff(data, period):\n",
    "    return data[period:] - data[:-period]\n",
    "#################################################################################\n",
    "# 하이퍼파라미터 인자 설정\n",
    "def hyperparameter():\n",
    "    # 1 backcast\n",
    "    # 2 forecast\n",
    "    # 3 inputdim\n",
    "    # 4 outputdim\n",
    "    # 5 unit\n",
    "    # 6 bacth size\n",
    "    return X_train.shape[1],1,y_train.shape[1],y_train.shape[1]\n",
    "\n",
    "#################################################################################\n",
    "# nbeats 모델 생성 함수\n",
    "def build_model(input_timesteps,features,output_timesteps,unit):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(unit, return_sequences=True, input_shape=(input_timesteps, features)))\n",
    "    #model.add(LSTM(unit, return_sequences=True))\n",
    "    # Use Lambda layer to select the last 'output_timesteps' outputs\n",
    "    model.add(Lambda(lambda x: x[:, -output_timesteps:, :]))\n",
    "    model.add(TimeDistributed(Dense(1)))\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model.compile(loss='mse', optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "#################################################################################\n",
    "# 부트스트랩 샘플링\n",
    "# 배깅\n",
    "\n",
    "def train_bagging_models(num_models, loss_fn , epochs_, patience_,batch_size_,lr):\n",
    "    models = {}\n",
    "    input_timesteps,features,output_timesteps,unit = hyperparameter()\n",
    "    historys = []\n",
    "    for n in range(num_models):\n",
    "        K.clear_session()\n",
    "        model = build_model(input_timesteps,features,output_timesteps,unit)\n",
    "       # model.set_weights(pretrained_weights)  # 전이 학습 가중치 적용\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "        model.compile(optimizer=optimizer , loss=loss_fn)\n",
    "        \n",
    "        # 부트스트랩 샘플링\n",
    "        #select = np.random.choice(len(X_train), size=len(X_train), replace=True)\n",
    "        #X_bootstrap = X_train[select]\n",
    "        #y_bootstrap = y_train[select]\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience = patience_, verbose = 1, restore_best_weights=True)\n",
    "        history = model.fit(X_train, y_train, batch_size = batch_size_,\n",
    "                  epochs=epochs_, verbose=1, \n",
    "                  callbacks=[early_stop],\n",
    "                 validation_split = 0.2)\n",
    "        models[f'model_{n+1}'] = model\n",
    "        historys.append(history)\n",
    "        #models.append(model)\n",
    "        print(f\"'########################################################Model{n}\")\n",
    "    return models,historys\n",
    "\n",
    "#################################################################################\n",
    "# SMAPE 용\n",
    "def train_bagging_models_smape(num_models, loss_fn , epochs_, patience_,batch_size_):\n",
    "    models = {}\n",
    "    backcast,forecast,in_dim,out_dim,unit = hyperparameter()\n",
    "    historys = []\n",
    "    for n in range(num_models):\n",
    "        K.clear_session()\n",
    "        model = bulid_model(backcast,forecast,in_dim,out_dim,unit)\n",
    "       # model.set_weights(pretrained_weights)  # 전이 학습 가중치 적용\n",
    "        optimizer = Adam(learning_rate=0.001)\n",
    "        model.compile(optimizer=optimizer , loss=loss_fn)\n",
    "        \n",
    "        # 부트스트랩 샘플링\n",
    "        #select = np.random.choice(len(X_train), size=len(X_train), replace=True)\n",
    "        #_bootstrap = X_train[select]\n",
    "        #y_bootstrap = y_train[select]\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience = patience_, verbose = 1, restore_best_weights=True)\n",
    "        history = model.fit(X_train, y_train, batch_size = batch_size_,\n",
    "                  epochs=epochs_, verbose=1, \n",
    "                  callbacks=[early_stop],\n",
    "                 validation_split = 0.2)\n",
    "        models[f'model_{n+1}'] = model\n",
    "        historys.append(history)\n",
    "        #models.append(model)\n",
    "        print(f\"'########################################################Model{n}\")\n",
    "    return models,historys\n",
    "\n",
    "\n",
    "\n",
    "#################################################################################\n",
    "\n",
    "def bagging_predict(models, X):\n",
    "    predictions = np.array([model.predict(X) for model in models.values()])\n",
    "    return np.median(predictions, axis=0)\n",
    "\n",
    "def bagging_predict2(models, X):\n",
    "    predictions = np.array([model.predict(X) for model in models.values()])\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fce9eb03-7500-4d76-af24-72f76cc67df4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-30 15:39:00.501138: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-08-30 15:39:00.501169: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ymlee2-desktop): /proc/driver/nvidia/version does not exist\n",
      "2024-08-30 15:39:00.501634: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 2s 13ms/step - loss: 1.4894 - val_loss: 0.9372\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.9532 - val_loss: 0.7339\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.8275 - val_loss: 0.6726\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8045 - val_loss: 0.6404\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8026 - val_loss: 0.6533\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7932 - val_loss: 0.6505\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7885 - val_loss: 0.6354\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7819 - val_loss: 0.6198\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7770 - val_loss: 0.6101\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7747 - val_loss: 0.6087\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7739 - val_loss: 0.6237\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7695 - val_loss: 0.6073\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7718 - val_loss: 0.6100\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7671 - val_loss: 0.6010\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7659 - val_loss: 0.6001\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7615 - val_loss: 0.6129\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7608 - val_loss: 0.5943\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7575 - val_loss: 0.6118\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7581 - val_loss: 0.5920\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7609 - val_loss: 0.6020\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7559 - val_loss: 0.6019\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7600 - val_loss: 0.5946\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7518 - val_loss: 0.5865\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7503 - val_loss: 0.5927\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7502 - val_loss: 0.5833\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7502 - val_loss: 0.5883\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7527 - val_loss: 0.5817\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7470 - val_loss: 0.5925\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7460 - val_loss: 0.5968\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7469 - val_loss: 0.5788\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7437 - val_loss: 0.6173\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7461 - val_loss: 0.5885\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7426 - val_loss: 0.5783\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7423 - val_loss: 0.6017\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7434 - val_loss: 0.5864\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7406 - val_loss: 0.5781\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7427 - val_loss: 0.5895\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7380 - val_loss: 0.5807\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7368 - val_loss: 0.5865\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7433 - val_loss: 0.5873\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7419 - val_loss: 0.5833\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7420 - val_loss: 0.5815\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7379 - val_loss: 0.5800\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7408 - val_loss: 0.6100\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7435 - val_loss: 0.5800\n",
      "Epoch 46/100\n",
      "68/73 [==========================>...] - ETA: 0s - loss: 0.7454Restoring model weights from the end of the best epoch: 36.\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7390 - val_loss: 0.5845\n",
      "Epoch 46: early stopping\n",
      "'########################################################Model0\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 12ms/step - loss: 1.4315 - val_loss: 1.0006\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 1.0072 - val_loss: 0.7488\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8496 - val_loss: 0.6673\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8167 - val_loss: 0.6517\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8164 - val_loss: 0.6500\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8065 - val_loss: 0.6689\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8039 - val_loss: 0.6388\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8032 - val_loss: 0.6331\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8009 - val_loss: 0.6330\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8001 - val_loss: 0.6319\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7928 - val_loss: 0.6273\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7960 - val_loss: 0.6441\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7946 - val_loss: 0.6287\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7947 - val_loss: 0.6345\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7906 - val_loss: 0.6256\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7891 - val_loss: 0.6192\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7921 - val_loss: 0.6210\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7890 - val_loss: 0.6288\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7882 - val_loss: 0.6670\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7881 - val_loss: 0.6262\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7856 - val_loss: 0.6240\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7820 - val_loss: 0.6195\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7801 - val_loss: 0.6343\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7787 - val_loss: 0.6111\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7773 - val_loss: 0.6066\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7710 - val_loss: 0.6202\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7734 - val_loss: 0.6060\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7712 - val_loss: 0.5988\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7677 - val_loss: 0.6059\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7621 - val_loss: 0.6103\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7629 - val_loss: 0.6186\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7624 - val_loss: 0.6389\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7627 - val_loss: 0.6088\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7568 - val_loss: 0.5980\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7541 - val_loss: 0.5945\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7557 - val_loss: 0.6055\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7531 - val_loss: 0.6113\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7537 - val_loss: 0.5910\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7540 - val_loss: 0.5888\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7482 - val_loss: 0.5949\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7484 - val_loss: 0.5806\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7475 - val_loss: 0.5932\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7461 - val_loss: 0.5840\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7451 - val_loss: 0.5790\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7434 - val_loss: 0.5908\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7464 - val_loss: 0.5872\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7415 - val_loss: 0.5892\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7439 - val_loss: 0.5921\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7416 - val_loss: 0.5833\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7406 - val_loss: 0.5778\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7423 - val_loss: 0.5771\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7423 - val_loss: 0.5792\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7394 - val_loss: 0.5876\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7388 - val_loss: 0.5828\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7377 - val_loss: 0.5751\n",
      "Epoch 56/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7363 - val_loss: 0.5818\n",
      "Epoch 57/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7371 - val_loss: 0.5832\n",
      "Epoch 58/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7386 - val_loss: 0.5793\n",
      "Epoch 59/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7418 - val_loss: 0.5833\n",
      "Epoch 60/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7390 - val_loss: 0.5745\n",
      "Epoch 61/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7387 - val_loss: 0.5788\n",
      "Epoch 62/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7340 - val_loss: 0.5724\n",
      "Epoch 63/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7328 - val_loss: 0.5787\n",
      "Epoch 64/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7308 - val_loss: 0.5765\n",
      "Epoch 65/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7309 - val_loss: 0.5726\n",
      "Epoch 66/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7309 - val_loss: 0.5738\n",
      "Epoch 67/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7310 - val_loss: 0.5784\n",
      "Epoch 68/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7318 - val_loss: 0.5861\n",
      "Epoch 69/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7288 - val_loss: 0.5727\n",
      "Epoch 70/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7271 - val_loss: 0.5753\n",
      "Epoch 71/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7316 - val_loss: 0.5796\n",
      "Epoch 72/100\n",
      "68/73 [==========================>...] - ETA: 0s - loss: 0.7282Restoring model weights from the end of the best epoch: 62.\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7298 - val_loss: 0.5802\n",
      "Epoch 72: early stopping\n",
      "'########################################################Model1\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 12ms/step - loss: 1.3991 - val_loss: 0.9699\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.9645 - val_loss: 0.7279\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8362 - val_loss: 0.6915\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.8135 - val_loss: 0.6883\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7997 - val_loss: 0.6321\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7900 - val_loss: 0.6284\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7824 - val_loss: 0.6249\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7775 - val_loss: 0.6168\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7784 - val_loss: 0.6272\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.7730 - val_loss: 0.6104\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7743 - val_loss: 0.6025\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7683 - val_loss: 0.6062\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7595 - val_loss: 0.6009\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7574 - val_loss: 0.6315\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7575 - val_loss: 0.6019\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7559 - val_loss: 0.5935\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7504 - val_loss: 0.6118\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7494 - val_loss: 0.5950\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7476 - val_loss: 0.5872\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7502 - val_loss: 0.5923\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7440 - val_loss: 0.6234\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7442 - val_loss: 0.5905\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7477 - val_loss: 0.5967\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7425 - val_loss: 0.6075\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7477 - val_loss: 0.5838\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7446 - val_loss: 0.6045\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7422 - val_loss: 0.5903\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7439 - val_loss: 0.5811\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7441 - val_loss: 0.6083\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7414 - val_loss: 0.5745\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7374 - val_loss: 0.5922\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7340 - val_loss: 0.5871\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7406 - val_loss: 0.5790\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7338 - val_loss: 0.5800\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7455 - val_loss: 0.5904\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7421 - val_loss: 0.5850\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7338 - val_loss: 0.5715\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7377 - val_loss: 0.5807\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7346 - val_loss: 0.5722\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7350 - val_loss: 0.5717\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7316 - val_loss: 0.5792\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7373 - val_loss: 0.5853\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7321 - val_loss: 0.5726\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7298 - val_loss: 0.5808\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7375 - val_loss: 0.5761\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7372 - val_loss: 0.5826\n",
      "Epoch 47/100\n",
      "72/73 [============================>.] - ETA: 0s - loss: 0.7336Restoring model weights from the end of the best epoch: 37.\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7340 - val_loss: 0.5821\n",
      "Epoch 47: early stopping\n",
      "'########################################################Model2\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 14ms/step - loss: 1.2628 - val_loss: 0.9077\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.9168 - val_loss: 0.6990\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8365 - val_loss: 0.6633\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8123 - val_loss: 0.6521\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7985 - val_loss: 0.6372\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7891 - val_loss: 0.6441\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7813 - val_loss: 0.6265\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7752 - val_loss: 0.6168\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7742 - val_loss: 0.6244\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7700 - val_loss: 0.6277\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7691 - val_loss: 0.6045\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7636 - val_loss: 0.5939\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7607 - val_loss: 0.6000\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7558 - val_loss: 0.5927\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7559 - val_loss: 0.6419\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7563 - val_loss: 0.5893\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7504 - val_loss: 0.6084\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7534 - val_loss: 0.6256\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7502 - val_loss: 0.5977\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7534 - val_loss: 0.5919\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7484 - val_loss: 0.5827\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7473 - val_loss: 0.6025\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7457 - val_loss: 0.5820\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7380 - val_loss: 0.5831\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7417 - val_loss: 0.5834\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7459 - val_loss: 0.5918\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7461 - val_loss: 0.6035\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7400 - val_loss: 0.6008\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7444 - val_loss: 0.5832\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7442 - val_loss: 0.5931\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7355 - val_loss: 0.5924\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7393 - val_loss: 0.6019\n",
      "Epoch 33/100\n",
      "68/73 [==========================>...] - ETA: 0s - loss: 0.7367Restoring model weights from the end of the best epoch: 23.\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7352 - val_loss: 0.5886\n",
      "Epoch 33: early stopping\n",
      "'########################################################Model3\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 12ms/step - loss: 1.2181 - val_loss: 0.8604\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.9007 - val_loss: 0.6866\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8330 - val_loss: 0.6833\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8173 - val_loss: 0.6565\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8080 - val_loss: 0.6465\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8017 - val_loss: 0.6407\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8019 - val_loss: 0.6389\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7961 - val_loss: 0.6367\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7955 - val_loss: 0.6373\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7940 - val_loss: 0.6293\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7905 - val_loss: 0.6263\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7891 - val_loss: 0.6215\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7858 - val_loss: 0.6189\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7798 - val_loss: 0.6182\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7786 - val_loss: 0.6148\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7719 - val_loss: 0.6202\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7672 - val_loss: 0.6189\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7637 - val_loss: 0.6328\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7657 - val_loss: 0.5935\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7598 - val_loss: 0.6019\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7531 - val_loss: 0.5889\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7512 - val_loss: 0.6093\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7521 - val_loss: 0.5986\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7548 - val_loss: 0.5907\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7492 - val_loss: 0.5926\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 1s 8ms/step - loss: 0.7473 - val_loss: 0.5980\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7449 - val_loss: 0.5850\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7472 - val_loss: 0.5865\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7480 - val_loss: 0.5969\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7454 - val_loss: 0.6035\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7451 - val_loss: 0.5886\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7479 - val_loss: 0.6001\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7400 - val_loss: 0.5859\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7400 - val_loss: 0.5888\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7435 - val_loss: 0.5800\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7371 - val_loss: 0.5779\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7398 - val_loss: 0.5782\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7367 - val_loss: 0.5843\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7399 - val_loss: 0.5992\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7405 - val_loss: 0.5736\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7372 - val_loss: 0.5779\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7401 - val_loss: 0.5866\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7392 - val_loss: 0.5855\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7356 - val_loss: 0.5832\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7345 - val_loss: 0.5760\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7392 - val_loss: 0.5834\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7347 - val_loss: 0.5801\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7341 - val_loss: 0.5786\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7344 - val_loss: 0.5742\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7337 - val_loss: 0.5707\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7308 - val_loss: 0.5744\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7283 - val_loss: 0.5781\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7319 - val_loss: 0.5825\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7312 - val_loss: 0.5832\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7326 - val_loss: 0.5705\n",
      "Epoch 56/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7324 - val_loss: 0.5693\n",
      "Epoch 57/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7275 - val_loss: 0.5685\n",
      "Epoch 58/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7311 - val_loss: 0.5766\n",
      "Epoch 59/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7329 - val_loss: 0.5888\n",
      "Epoch 60/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7269 - val_loss: 0.6155\n",
      "Epoch 61/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7327 - val_loss: 0.5681\n",
      "Epoch 62/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7311 - val_loss: 0.5735\n",
      "Epoch 63/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7277 - val_loss: 0.5820\n",
      "Epoch 64/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7313 - val_loss: 0.5686\n",
      "Epoch 65/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7284 - val_loss: 0.5909\n",
      "Epoch 66/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7342 - val_loss: 0.5734\n",
      "Epoch 67/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7275 - val_loss: 0.5761\n",
      "Epoch 68/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7288 - val_loss: 0.5886\n",
      "Epoch 69/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7276 - val_loss: 0.5705\n",
      "Epoch 70/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7265 - val_loss: 0.5791\n",
      "Epoch 71/100\n",
      "70/73 [===========================>..] - ETA: 0s - loss: 0.7244Restoring model weights from the end of the best epoch: 61.\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7277 - val_loss: 0.5697\n",
      "Epoch 71: early stopping\n",
      "'########################################################Model4\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 12ms/step - loss: 1.5519 - val_loss: 1.0461\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 1.0277 - val_loss: 0.7420\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.8431 - val_loss: 0.6531\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8185 - val_loss: 0.6482\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8106 - val_loss: 0.6440\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8056 - val_loss: 0.6432\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8004 - val_loss: 0.6535\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8023 - val_loss: 0.6525\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7984 - val_loss: 0.6344\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7963 - val_loss: 0.6329\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7932 - val_loss: 0.6320\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7959 - val_loss: 0.6287\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7926 - val_loss: 0.6312\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7924 - val_loss: 0.6280\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7888 - val_loss: 0.6184\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7907 - val_loss: 0.6212\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7851 - val_loss: 0.6255\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7859 - val_loss: 0.6149\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7821 - val_loss: 0.6172\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7855 - val_loss: 0.6224\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7823 - val_loss: 0.6287\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7864 - val_loss: 0.6138\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7794 - val_loss: 0.6143\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7747 - val_loss: 0.6229\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7737 - val_loss: 0.6330\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7681 - val_loss: 0.6039\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7636 - val_loss: 0.5945\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7639 - val_loss: 0.6129\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7699 - val_loss: 0.5972\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7569 - val_loss: 0.5969\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7571 - val_loss: 0.5985\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7512 - val_loss: 0.6129\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7561 - val_loss: 0.6050\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7543 - val_loss: 0.6026\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7528 - val_loss: 0.6021\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7476 - val_loss: 0.5887\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7491 - val_loss: 0.5947\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7466 - val_loss: 0.5920\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7460 - val_loss: 0.5963\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7460 - val_loss: 0.5910\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7426 - val_loss: 0.5940\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7473 - val_loss: 0.5910\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7483 - val_loss: 0.6023\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7524 - val_loss: 0.5870\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7374 - val_loss: 0.5778\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7405 - val_loss: 0.5901\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7388 - val_loss: 0.5938\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7423 - val_loss: 0.5907\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7464 - val_loss: 0.5761\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7380 - val_loss: 0.5793\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7387 - val_loss: 0.5789\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7377 - val_loss: 0.5831\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7349 - val_loss: 0.5848\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7342 - val_loss: 0.5735\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7350 - val_loss: 0.5798\n",
      "Epoch 56/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7395 - val_loss: 0.5795\n",
      "Epoch 57/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7313 - val_loss: 0.5802\n",
      "Epoch 58/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7328 - val_loss: 0.5835\n",
      "Epoch 59/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7323 - val_loss: 0.5898\n",
      "Epoch 60/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7292 - val_loss: 0.6159\n",
      "Epoch 61/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7283 - val_loss: 0.5737\n",
      "Epoch 62/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7318 - val_loss: 0.5704\n",
      "Epoch 63/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7315 - val_loss: 0.5725\n",
      "Epoch 64/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7350 - val_loss: 0.5727\n",
      "Epoch 65/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7360 - val_loss: 0.5850\n",
      "Epoch 66/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7378 - val_loss: 0.5709\n",
      "Epoch 67/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7266 - val_loss: 0.5853\n",
      "Epoch 68/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7289 - val_loss: 0.5767\n",
      "Epoch 69/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7270 - val_loss: 0.5757\n",
      "Epoch 70/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7270 - val_loss: 0.5722\n",
      "Epoch 71/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7319 - val_loss: 0.5747\n",
      "Epoch 72/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7272 - val_loss: 0.5671\n",
      "Epoch 73/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7256 - val_loss: 0.5808\n",
      "Epoch 74/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7241 - val_loss: 0.5713\n",
      "Epoch 75/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7263 - val_loss: 0.5889\n",
      "Epoch 76/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7268 - val_loss: 0.5661\n",
      "Epoch 77/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7227 - val_loss: 0.5644\n",
      "Epoch 78/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7250 - val_loss: 0.5752\n",
      "Epoch 79/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7268 - val_loss: 0.5709\n",
      "Epoch 80/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7241 - val_loss: 0.5730\n",
      "Epoch 81/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7256 - val_loss: 0.5711\n",
      "Epoch 82/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7240 - val_loss: 0.5691\n",
      "Epoch 83/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7277 - val_loss: 0.5775\n",
      "Epoch 84/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7255 - val_loss: 0.5844\n",
      "Epoch 85/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7273 - val_loss: 0.5767\n",
      "Epoch 86/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7238 - val_loss: 0.5809\n",
      "Epoch 87/100\n",
      "71/73 [============================>.] - ETA: 0s - loss: 0.7254Restoring model weights from the end of the best epoch: 77.\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7254 - val_loss: 0.5739\n",
      "Epoch 87: early stopping\n",
      "'########################################################Model5\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 12ms/step - loss: 1.3166 - val_loss: 0.9100\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.9329 - val_loss: 0.6911\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8246 - val_loss: 0.6750\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8096 - val_loss: 0.6435\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8035 - val_loss: 0.6368\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7982 - val_loss: 0.6577\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7877 - val_loss: 0.6539\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7845 - val_loss: 0.6218\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7739 - val_loss: 0.6141\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7757 - val_loss: 0.6144\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7684 - val_loss: 0.6059\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7740 - val_loss: 0.6139\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7675 - val_loss: 0.6018\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7620 - val_loss: 0.6041\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7662 - val_loss: 0.5956\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7593 - val_loss: 0.5953\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7579 - val_loss: 0.5914\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7629 - val_loss: 0.5928\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7511 - val_loss: 0.5978\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7561 - val_loss: 0.6169\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7526 - val_loss: 0.5900\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7487 - val_loss: 0.6238\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7493 - val_loss: 0.6098\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7534 - val_loss: 0.5929\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7464 - val_loss: 0.5986\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7456 - val_loss: 0.5913\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7447 - val_loss: 0.5961\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7525 - val_loss: 0.5937\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7504 - val_loss: 0.5967\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7474 - val_loss: 0.6235\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7464 - val_loss: 0.5879\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7508 - val_loss: 0.5810\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7403 - val_loss: 0.5902\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7389 - val_loss: 0.5872\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7389 - val_loss: 0.5884\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7404 - val_loss: 0.5934\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7417 - val_loss: 0.5841\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7371 - val_loss: 0.5777\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7361 - val_loss: 0.5778\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7348 - val_loss: 0.5989\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7375 - val_loss: 0.5896\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7356 - val_loss: 0.5788\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7346 - val_loss: 0.5785\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7387 - val_loss: 0.5898\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7383 - val_loss: 0.5839\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7359 - val_loss: 0.5869\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7338 - val_loss: 0.5779\n",
      "Epoch 48/100\n",
      "72/73 [============================>.] - ETA: 0s - loss: 0.7308Restoring model weights from the end of the best epoch: 38.\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7340 - val_loss: 0.5888\n",
      "Epoch 48: early stopping\n",
      "'########################################################Model6\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 13ms/step - loss: 1.3804 - val_loss: 0.9696\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 1.0023 - val_loss: 0.7220\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8384 - val_loss: 0.6680\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8084 - val_loss: 0.6469\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7997 - val_loss: 0.6368\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7896 - val_loss: 0.6202\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7828 - val_loss: 0.6235\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7769 - val_loss: 0.6136\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7721 - val_loss: 0.6221\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7697 - val_loss: 0.6291\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7666 - val_loss: 0.6142\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7615 - val_loss: 0.6003\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7629 - val_loss: 0.5974\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7611 - val_loss: 0.5970\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7566 - val_loss: 0.5948\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7527 - val_loss: 0.5923\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7509 - val_loss: 0.6080\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7541 - val_loss: 0.5858\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7548 - val_loss: 0.5936\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7527 - val_loss: 0.5866\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7506 - val_loss: 0.5917\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7491 - val_loss: 0.5900\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7465 - val_loss: 0.5892\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7449 - val_loss: 0.5819\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7425 - val_loss: 0.5777\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7401 - val_loss: 0.5978\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7437 - val_loss: 0.5866\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7462 - val_loss: 0.5833\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7417 - val_loss: 0.5823\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7458 - val_loss: 0.5841\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7441 - val_loss: 0.5978\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7391 - val_loss: 0.5824\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7418 - val_loss: 0.5807\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7366 - val_loss: 0.5897\n",
      "Epoch 35/100\n",
      "67/73 [==========================>...] - ETA: 0s - loss: 0.7482Restoring model weights from the end of the best epoch: 25.\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7379 - val_loss: 0.5780\n",
      "Epoch 35: early stopping\n",
      "'########################################################Model7\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 12ms/step - loss: 1.5724 - val_loss: 1.0516\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 1.0595 - val_loss: 0.7700\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8686 - val_loss: 0.6726\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8218 - val_loss: 0.6490\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8123 - val_loss: 0.6425\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8066 - val_loss: 0.6607\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.8061 - val_loss: 0.6404\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8022 - val_loss: 0.6449\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7973 - val_loss: 0.6313\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7970 - val_loss: 0.6274\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7959 - val_loss: 0.6329\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7922 - val_loss: 0.6223\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7930 - val_loss: 0.6255\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7880 - val_loss: 0.6193\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7866 - val_loss: 0.6241\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7861 - val_loss: 0.6229\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7885 - val_loss: 0.6176\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7806 - val_loss: 0.6252\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7743 - val_loss: 0.6076\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7689 - val_loss: 0.6050\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7720 - val_loss: 0.6003\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7725 - val_loss: 0.6111\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7651 - val_loss: 0.6194\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7588 - val_loss: 0.6148\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7627 - val_loss: 0.6109\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7575 - val_loss: 0.6414\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7563 - val_loss: 0.6033\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7553 - val_loss: 0.5905\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7551 - val_loss: 0.6039\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7502 - val_loss: 0.6076\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7564 - val_loss: 0.6079\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7475 - val_loss: 0.6055\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7495 - val_loss: 0.5966\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7494 - val_loss: 0.5912\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7461 - val_loss: 0.5856\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7458 - val_loss: 0.5880\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7483 - val_loss: 0.5951\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7457 - val_loss: 0.6329\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7501 - val_loss: 0.5905\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7403 - val_loss: 0.5927\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7439 - val_loss: 0.6015\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7432 - val_loss: 0.5941\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7359 - val_loss: 0.5771\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7465 - val_loss: 0.5821\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7395 - val_loss: 0.5923\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7400 - val_loss: 0.5800\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7357 - val_loss: 0.5883\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7343 - val_loss: 0.5852\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7384 - val_loss: 0.5895\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7384 - val_loss: 0.5836\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7332 - val_loss: 0.5914\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7337 - val_loss: 0.5829\n",
      "Epoch 53/100\n",
      "72/73 [============================>.] - ETA: 0s - loss: 0.7280Restoring model weights from the end of the best epoch: 43.\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7276 - val_loss: 0.5786\n",
      "Epoch 53: early stopping\n",
      "'########################################################Model8\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 12ms/step - loss: 1.6255 - val_loss: 1.0684\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 1.0226 - val_loss: 0.7587\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8667 - val_loss: 0.6869\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8310 - val_loss: 0.6599\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8157 - val_loss: 0.6497\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8080 - val_loss: 0.6495\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.8059 - val_loss: 0.6393\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7966 - val_loss: 0.6324\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7907 - val_loss: 0.6331\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7884 - val_loss: 0.6313\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7823 - val_loss: 0.6389\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7769 - val_loss: 0.6331\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7715 - val_loss: 0.6113\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7673 - val_loss: 0.6028\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7658 - val_loss: 0.5999\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7637 - val_loss: 0.6352\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7668 - val_loss: 0.6054\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7567 - val_loss: 0.6067\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7579 - val_loss: 0.5936\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7539 - val_loss: 0.5981\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7520 - val_loss: 0.6224\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7534 - val_loss: 0.6018\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7513 - val_loss: 0.5913\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7484 - val_loss: 0.6124\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7503 - val_loss: 0.5912\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7444 - val_loss: 0.6058\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7451 - val_loss: 0.5820\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7473 - val_loss: 0.5958\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7441 - val_loss: 0.5935\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7435 - val_loss: 0.5916\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7431 - val_loss: 0.5856\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7426 - val_loss: 0.6048\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 0.7465 - val_loss: 0.6070\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7398 - val_loss: 0.5869\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7416 - val_loss: 0.5795\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7417 - val_loss: 0.5995\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7371 - val_loss: 0.5972\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7401 - val_loss: 0.5796\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7353 - val_loss: 0.5947\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7459 - val_loss: 0.5964\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7422 - val_loss: 0.5813\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7314 - val_loss: 0.5859\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7364 - val_loss: 0.5887\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7439 - val_loss: 0.5899\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7361 - val_loss: 0.5770\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7321 - val_loss: 0.5979\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7352 - val_loss: 0.5982\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7358 - val_loss: 0.5864\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7350 - val_loss: 0.5991\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7300 - val_loss: 0.5828\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7329 - val_loss: 0.5918\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7352 - val_loss: 0.5774\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7282 - val_loss: 0.6011\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7302 - val_loss: 0.5793\n",
      "Epoch 55/100\n",
      "71/73 [============================>.] - ETA: 0s - loss: 0.7366Restoring model weights from the end of the best epoch: 45.\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 0.7375 - val_loss: 0.5786\n",
      "Epoch 55: early stopping\n",
      "'########################################################Model9\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 12ms/step - loss: 1315562.3750 - val_loss: 563939.1250\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 532711.3750 - val_loss: 533461.8750\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 472828.6250 - val_loss: 609443.5625\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 740793.1875 - val_loss: 879759.4375\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 723729.4375 - val_loss: 359324.3750\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 492703.7188 - val_loss: 588018.4375\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 430609.5625 - val_loss: 422771.4062\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 384801.4375 - val_loss: 260467.8906\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 746528.8750 - val_loss: 560092.6250\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 619476.3125 - val_loss: 490818.3125\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 332479.0938 - val_loss: 177147.1094\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 385416.5938 - val_loss: 214346.8594\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 427872.7812 - val_loss: 205751.1562\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 405661.0000 - val_loss: 411459.8438\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 407834.2188 - val_loss: 668766.8125\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 304930.0000 - val_loss: 207310.4688\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 357872.3125 - val_loss: 286653.1250\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 397858.6250 - val_loss: 350890.0312\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 438459.3750 - val_loss: 654976.8750\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 283047.6875 - val_loss: 707461.5000\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 407184.7812Restoring model weights from the end of the best epoch: 11.\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 407184.7812 - val_loss: 583039.5000\n",
      "Epoch 21: early stopping\n",
      "'########################################################Model0\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 13ms/step - loss: 3471159.0000 - val_loss: 288564.5938\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 414957.4375 - val_loss: 322085.5000\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 656643.8750 - val_loss: 1037983.0000\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 714752.2500 - val_loss: 562633.8125\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 455698.5938 - val_loss: 348593.0625\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 303171.5625 - val_loss: 452899.8750\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 453740.7500 - val_loss: 962082.3125\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 425866.6875 - val_loss: 302111.3125\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 393791.4375 - val_loss: 537204.5000\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 290478.2812 - val_loss: 303342.5625\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 577270.3125 - val_loss: 267475.3438\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 296703.6562 - val_loss: 444676.9062\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 299859.5625 - val_loss: 507478.7188\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 423602.5625 - val_loss: 338195.1250\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 376543.9375 - val_loss: 560419.8750\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 352357.7500 - val_loss: 105740.2734\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 333268.9062 - val_loss: 195833.7188\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 353641.5312 - val_loss: 92789.1719\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 408278.7500 - val_loss: 749761.6250\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 351440.8125 - val_loss: 270707.9688\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 379490.7500 - val_loss: 94391.6562\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 400549.4688 - val_loss: 395992.7500\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 362864.6562 - val_loss: 214174.3281\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 479936.5000 - val_loss: 543248.7500\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 343860.6875 - val_loss: 249558.9219\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 244918.6719 - val_loss: 806008.2500\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 328665.3438 - val_loss: 492927.7812\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 211110.1719Restoring model weights from the end of the best epoch: 18.\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 211110.1719 - val_loss: 172775.2656\n",
      "Epoch 28: early stopping\n",
      "'########################################################Model1\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 12ms/step - loss: 2651646.0000 - val_loss: 1258665.3750\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 498364.4062 - val_loss: 428245.5000\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 294344.7500 - val_loss: 255821.0000\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 330005.5938 - val_loss: 360879.2812\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 488700.6250 - val_loss: 1208776.0000\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 518376.3438 - val_loss: 304939.2500\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 372808.1250 - val_loss: 99405.8750\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 314098.1875 - val_loss: 592136.2500\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 338036.4062 - val_loss: 535830.7500\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 285501.8750 - val_loss: 232434.4219\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 323071.1250 - val_loss: 383301.5312\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 395763.7188 - val_loss: 911841.9375\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 288872.4375 - val_loss: 92055.9062\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 351389.4375 - val_loss: 439552.6250\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 236178.4844 - val_loss: 290390.7188\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 226186.2969 - val_loss: 224094.7344\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 242053.8750 - val_loss: 232954.5625\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 264953.5938 - val_loss: 851214.0000\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 310140.6562 - val_loss: 308325.8125\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 195213.7500 - val_loss: 250249.1875\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 191814.7656 - val_loss: 110230.6406\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 266559.6562 - val_loss: 76359.9688\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 262641.9375 - val_loss: 640613.6250\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 266675.9062 - val_loss: 174928.8906\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 252589.9531 - val_loss: 470124.2500\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 286473.8750 - val_loss: 155265.2031\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 228589.4375 - val_loss: 62383.3594\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 212271.7031 - val_loss: 79209.3672\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 205514.6562 - val_loss: 77553.0625\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 159874.7656 - val_loss: 136118.7969\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 262546.5938 - val_loss: 356210.2188\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 213386.2656 - val_loss: 167860.2344\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 206610.4531 - val_loss: 326655.4062\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 333335.1250 - val_loss: 92730.1016\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 194390.4375 - val_loss: 188127.6562\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 215578.4531 - val_loss: 120335.0078\n",
      "Epoch 37/100\n",
      "71/73 [============================>.] - ETA: 0s - loss: 269992.6875Restoring model weights from the end of the best epoch: 27.\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 268840.7500 - val_loss: 383913.0000\n",
      "Epoch 37: early stopping\n",
      "'########################################################Model2\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 12ms/step - loss: 2420273.0000 - val_loss: 464555.6562\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 425769.1875 - val_loss: 208793.2812\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 452893.5000 - val_loss: 1400387.6250\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 593917.8125 - val_loss: 291228.6562\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 435790.0625 - val_loss: 263034.5938\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 317215.5312 - val_loss: 720022.7500\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 554784.3750 - val_loss: 566028.9375\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 327479.9688 - val_loss: 216760.5312\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 385416.0000 - val_loss: 218721.8750\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 408344.0312 - val_loss: 363578.2188\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 381334.4375 - val_loss: 374235.6562\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 378769.8125 - val_loss: 76024.2656\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 196416.5469 - val_loss: 79865.4375\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 527136.1875 - val_loss: 1167405.2500\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 386829.2812 - val_loss: 97830.8047\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 312367.1875 - val_loss: 602871.5000\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 341227.6562 - val_loss: 785824.5625\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 280850.9688 - val_loss: 145781.7812\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 258696.5000 - val_loss: 201807.4062\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 361814.9375 - val_loss: 289872.8125\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 358548.8438 - val_loss: 183004.1719\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 323015.7812Restoring model weights from the end of the best epoch: 12.\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 323015.7812 - val_loss: 511182.2812\n",
      "Epoch 22: early stopping\n",
      "'########################################################Model3\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 12ms/step - loss: 1766892.8750 - val_loss: 521560.1250\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 839341.4375 - val_loss: 225889.0781\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 663019.0000 - val_loss: 545950.8125\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 428909.9688 - val_loss: 151987.4688\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 369002.4375 - val_loss: 510235.1562\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 590450.0625 - val_loss: 638786.5625\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 430894.2500 - val_loss: 143561.2969\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 607542.5000 - val_loss: 434949.0000\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 269955.2500 - val_loss: 337684.5000\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 306607.0625 - val_loss: 473310.6875\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 406066.9375 - val_loss: 498676.9688\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 295554.9062 - val_loss: 498782.6250\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 240384.9375 - val_loss: 71191.0781\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 338014.0312 - val_loss: 559943.3125\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 349843.8750 - val_loss: 750758.3125\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 522464.3750 - val_loss: 488978.8750\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 301371.4375 - val_loss: 138480.7188\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 466905.3125 - val_loss: 826675.5000\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 275392.9375 - val_loss: 70611.0781\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 389407.1250 - val_loss: 261745.7969\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 370753.0000 - val_loss: 490892.5312\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 231387.2500 - val_loss: 72653.3516\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 270132.5625 - val_loss: 114043.3203\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 177940.6250 - val_loss: 291431.2188\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 293483.0312 - val_loss: 242872.7188\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 329158.2812 - val_loss: 197300.0938\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 340472.0312 - val_loss: 183018.7188\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 228016.4062 - val_loss: 319293.2812\n",
      "Epoch 29/100\n",
      "71/73 [============================>.] - ETA: 0s - loss: 218300.7188Restoring model weights from the end of the best epoch: 19.\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 227194.4062 - val_loss: 518922.0000\n",
      "Epoch 29: early stopping\n",
      "'########################################################Model4\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 13ms/step - loss: 2775538.0000 - val_loss: 906282.6875\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 476690.3125 - val_loss: 543647.0625\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 461488.8125 - val_loss: 281970.3438\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 578939.1875 - val_loss: 196955.5938\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 560260.5000 - val_loss: 473612.1250\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 433736.3750 - val_loss: 248662.8906\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 457323.6562 - val_loss: 317389.5312\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 406994.2812 - val_loss: 133681.0625\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 531358.6250 - val_loss: 193383.3750\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 321060.4062 - val_loss: 259304.8594\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 358274.5000 - val_loss: 141378.1719\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 328006.2812 - val_loss: 182731.0000\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 389985.1875 - val_loss: 167154.8281\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 418352.2500 - val_loss: 110259.8281\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 321847.1875 - val_loss: 253760.8281\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 472641.0000 - val_loss: 117533.7969\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 344922.6250 - val_loss: 88857.2734\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 220932.3281 - val_loss: 149546.8281\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 193301.6250 - val_loss: 161342.7031\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 381458.6562 - val_loss: 410592.5938\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 424522.7812 - val_loss: 412389.8750\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 206335.7031 - val_loss: 124024.2344\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 241240.9688 - val_loss: 296100.5000\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 266267.9688 - val_loss: 207340.1094\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 197978.2344 - val_loss: 79785.3750\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 147812.9531 - val_loss: 133399.8281\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 212333.7031 - val_loss: 42881.3984\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 302515.5000 - val_loss: 393976.7188\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 198884.6406 - val_loss: 200748.7812\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 259773.0469 - val_loss: 90126.0469\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 137883.6094 - val_loss: 286487.9375\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 217916.5156 - val_loss: 147082.7969\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 234272.3281 - val_loss: 147073.1875\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 426046.3750 - val_loss: 222144.5469\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 228676.8438 - val_loss: 305153.0000\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 225044.3750 - val_loss: 188944.6406\n",
      "Epoch 37/100\n",
      "68/73 [==========================>...] - ETA: 0s - loss: 212914.1719Restoring model weights from the end of the best epoch: 27.\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 213524.2812 - val_loss: 194847.8281\n",
      "Epoch 37: early stopping\n",
      "'########################################################Model5\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 13ms/step - loss: 3110117.7500 - val_loss: 422016.3438\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 500667.3125 - val_loss: 228377.1562\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 362928.4062 - val_loss: 180943.9844\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 559965.1250 - val_loss: 679089.7500\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 346319.3125 - val_loss: 302998.7188\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 522767.6250 - val_loss: 402121.3125\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 279778.6250 - val_loss: 236640.3281\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 375692.1250 - val_loss: 319142.1562\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 797264.2500 - val_loss: 714656.3750\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 389912.3750 - val_loss: 196213.1719\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 357232.8438 - val_loss: 781600.0000\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 428475.3438 - val_loss: 179576.0156\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 286687.3750 - val_loss: 386126.6562\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 351022.7812 - val_loss: 175391.2969\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 307498.5938 - val_loss: 195349.6406\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 433334.3750 - val_loss: 282914.2500\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 412880.3750 - val_loss: 77453.0938\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 388427.9688 - val_loss: 677678.8125\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 236131.6406 - val_loss: 268507.1875\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 350411.0625 - val_loss: 1118533.6250\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 399121.9062 - val_loss: 210876.0625\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 233456.6094 - val_loss: 270287.0000\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 273681.0312 - val_loss: 397274.2500\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 329038.1875 - val_loss: 86081.1719\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 309843.5312 - val_loss: 513875.3125\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 255180.7969 - val_loss: 368539.4062\n",
      "Epoch 27/100\n",
      "72/73 [============================>.] - ETA: 0s - loss: 312388.4375Restoring model weights from the end of the best epoch: 17.\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 310952.4375 - val_loss: 85730.3828\n",
      "Epoch 27: early stopping\n",
      "'########################################################Model6\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 12ms/step - loss: 7234562.5000 - val_loss: 772361.3125\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 478801.1562 - val_loss: 352411.1875\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 477234.2500 - val_loss: 293721.6562\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 594858.5625 - val_loss: 856820.1250\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 531899.0625 - val_loss: 235990.3750\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 409852.4375 - val_loss: 320456.9062\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 248996.6406 - val_loss: 137273.9375\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 403511.4688 - val_loss: 366242.7188\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 261694.9531 - val_loss: 243056.0625\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 452699.8125 - val_loss: 384588.3125\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 340061.2812 - val_loss: 242515.6719\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 225279.5938 - val_loss: 172434.2812\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 362863.6562 - val_loss: 256940.1719\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 274126.2812 - val_loss: 263524.2812\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 312828.1250 - val_loss: 560829.4375\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 379930.3750 - val_loss: 350190.9375\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 373141.3750Restoring model weights from the end of the best epoch: 7.\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 373141.3750 - val_loss: 441826.5625\n",
      "Epoch 17: early stopping\n",
      "'########################################################Model7\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 13ms/step - loss: 1411144.7500 - val_loss: 964342.3125\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 609449.6250 - val_loss: 489112.0000\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 397708.6250 - val_loss: 491625.7500\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 480566.0000 - val_loss: 237790.9531\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 534802.1250 - val_loss: 189253.2344\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 472719.4062 - val_loss: 312904.0000\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 307245.5625 - val_loss: 232447.8125\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 314132.3438 - val_loss: 862606.7500\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 382689.0625 - val_loss: 341542.0938\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 337281.1562 - val_loss: 161651.5312\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 278309.7188 - val_loss: 510099.6562\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 446946.3750 - val_loss: 485217.2188\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 286656.6250 - val_loss: 239415.0625\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 410535.6875 - val_loss: 748105.1250\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 288549.0625 - val_loss: 135567.1562\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 184608.2031 - val_loss: 224285.8125\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 262593.0312 - val_loss: 378047.4688\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 303952.3438 - val_loss: 209872.5000\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 197912.7031 - val_loss: 408988.0000\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 265142.2500 - val_loss: 269651.0000\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 397383.2812 - val_loss: 232680.3594\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 348880.8125 - val_loss: 314565.2812\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 337662.7188 - val_loss: 866143.5625\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 303847.3125 - val_loss: 196169.0000\n",
      "Epoch 25/100\n",
      "71/73 [============================>.] - ETA: 0s - loss: 223406.5312Restoring model weights from the end of the best epoch: 15.\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 222212.2188 - val_loss: 240742.5156\n",
      "Epoch 25: early stopping\n",
      "'########################################################Model8\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 13ms/step - loss: 2881877.5000 - val_loss: 588261.8750\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 658655.6250 - val_loss: 970488.5000\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 582100.0625 - val_loss: 286217.1875\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 568174.1875 - val_loss: 578120.1250\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 317966.9062 - val_loss: 443039.5938\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 619335.5625 - val_loss: 344176.5625\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 351149.1875 - val_loss: 678762.8125\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 529952.1875 - val_loss: 161049.8125\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 480253.3438 - val_loss: 106861.1328\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 373084.4062 - val_loss: 694938.2500\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 384116.7500 - val_loss: 150867.3594\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 455320.5000 - val_loss: 505470.1250\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 672728.7500 - val_loss: 409047.6250\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 386889.7500 - val_loss: 297659.5625\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 319074.5000 - val_loss: 111685.8438\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 389147.9375 - val_loss: 217129.1250\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 300942.5625 - val_loss: 107482.0781\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 318455.6250 - val_loss: 536884.5000\n",
      "Epoch 19/100\n",
      "71/73 [============================>.] - ETA: 0s - loss: 199694.6562Restoring model weights from the end of the best epoch: 9.\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 198307.3281 - val_loss: 120249.9688\n",
      "Epoch 19: early stopping\n",
      "'########################################################Model9\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 13ms/step - loss: 140.4027 - val_loss: 140.6500\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 134.6906 - val_loss: 137.9308\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 129.9994 - val_loss: 133.5031\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 127.4405 - val_loss: 133.2983\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 126.4783 - val_loss: 131.9083\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 126.7160 - val_loss: 131.0488\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 125.6249 - val_loss: 130.7328\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 125.2780 - val_loss: 131.4571\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 124.5595 - val_loss: 130.2328\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 125.1438 - val_loss: 129.9724\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 124.3621 - val_loss: 129.1915\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 124.5934 - val_loss: 129.4243\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 123.8618 - val_loss: 129.2518\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 123.5698 - val_loss: 129.9333\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 124.0057 - val_loss: 130.2103\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 123.2766 - val_loss: 128.6346\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 123.3517 - val_loss: 128.9062\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.8983 - val_loss: 129.5148\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.8530 - val_loss: 128.0681\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.8728 - val_loss: 128.9693\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.9932 - val_loss: 127.8091\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.4314 - val_loss: 127.5673\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.5097 - val_loss: 129.3509\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.6178 - val_loss: 127.7993\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.7450 - val_loss: 128.6985\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 123.2172 - val_loss: 128.7208\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.6422 - val_loss: 129.1372\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.7817 - val_loss: 129.2609\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.4499 - val_loss: 128.4999\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 122.0857 - val_loss: 129.0529\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.7049 - val_loss: 126.7852\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 123.3102 - val_loss: 128.7614\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.3711 - val_loss: 128.4244\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.7000 - val_loss: 127.8924\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 121.6621 - val_loss: 127.9965\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 121.8006 - val_loss: 127.3399\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.9299 - val_loss: 127.3106\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.3881 - val_loss: 126.7137\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.2579 - val_loss: 127.6918\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.3474 - val_loss: 128.0599\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.0099 - val_loss: 125.8312\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.6950 - val_loss: 128.1803\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.0026 - val_loss: 128.3053\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.7020 - val_loss: 126.3619\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.9632 - val_loss: 126.4121\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.7923 - val_loss: 125.5408\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.0996 - val_loss: 127.2948\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.6687 - val_loss: 127.5227\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.8317 - val_loss: 127.0676\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.7763 - val_loss: 126.8863\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.1680 - val_loss: 125.8705\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.8443 - val_loss: 126.1118\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.7000 - val_loss: 129.7888\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.9213 - val_loss: 125.5602\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.8052 - val_loss: 126.6845\n",
      "Epoch 56/100\n",
      "68/73 [==========================>...] - ETA: 0s - loss: 121.2912Restoring model weights from the end of the best epoch: 46.\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.0572 - val_loss: 125.6777\n",
      "Epoch 56: early stopping\n",
      "'########################################################Model0\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 13ms/step - loss: 146.5275 - val_loss: 141.4308\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 136.3184 - val_loss: 140.0362\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 134.2064 - val_loss: 137.6845\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 129.3945 - val_loss: 135.1163\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 126.9213 - val_loss: 132.4778\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 125.4299 - val_loss: 130.5706\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 124.5419 - val_loss: 130.1951\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 124.1637 - val_loss: 129.8721\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 124.1296 - val_loss: 130.9952\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 123.4630 - val_loss: 128.9181\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 123.6217 - val_loss: 131.2032\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 123.9420 - val_loss: 129.4276\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 123.0188 - val_loss: 128.9169\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 123.0670 - val_loss: 128.6222\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.6576 - val_loss: 127.6835\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.6611 - val_loss: 127.8934\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.1801 - val_loss: 127.8108\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.9293 - val_loss: 129.5299\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.3368 - val_loss: 128.3570\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.4668 - val_loss: 128.2991\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.9209 - val_loss: 127.9427\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.9300 - val_loss: 127.9750\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.5326 - val_loss: 127.7598\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.0327 - val_loss: 126.8488\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 121.5571 - val_loss: 127.3281\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.9246 - val_loss: 128.0784\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.1420 - val_loss: 129.5160\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 123.0625 - val_loss: 127.7697\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.4863 - val_loss: 127.2492\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.0935 - val_loss: 128.4485\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.2632 - val_loss: 127.1782\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.5008 - val_loss: 126.8047\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.5859 - val_loss: 127.8737\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.4217 - val_loss: 128.0440\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.3059 - val_loss: 127.1938\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.3883 - val_loss: 127.0317\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.3680 - val_loss: 126.6997\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.1641 - val_loss: 126.4028\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.2617 - val_loss: 127.2186\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.0086 - val_loss: 127.2206\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.1407 - val_loss: 128.4568\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.1469 - val_loss: 126.2177\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.4700 - val_loss: 128.1694\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.0295 - val_loss: 126.7966\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.8908 - val_loss: 126.9468\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.9924 - val_loss: 127.1400\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.8354 - val_loss: 125.9302\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.3253 - val_loss: 127.1683\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.3833 - val_loss: 125.8654\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.7281 - val_loss: 125.4216\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.6200 - val_loss: 125.6544\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.5704 - val_loss: 128.0938\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.2178 - val_loss: 127.2590\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.1556 - val_loss: 125.9986\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.7202 - val_loss: 125.9161\n",
      "Epoch 56/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.7169 - val_loss: 126.4609\n",
      "Epoch 57/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 120.8657 - val_loss: 126.3427\n",
      "Epoch 58/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.5106 - val_loss: 127.2988\n",
      "Epoch 59/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 120.7531 - val_loss: 126.2071\n",
      "Epoch 60/100\n",
      "69/73 [===========================>..] - ETA: 0s - loss: 120.8079Restoring model weights from the end of the best epoch: 50.\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 120.5711 - val_loss: 126.8247\n",
      "Epoch 60: early stopping\n",
      "'########################################################Model1\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 13ms/step - loss: 194.7827 - val_loss: 154.4930\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 138.2734 - val_loss: 140.7992\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 134.9720 - val_loss: 138.4532\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 130.2783 - val_loss: 133.7950\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 127.5496 - val_loss: 133.4514\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 126.5873 - val_loss: 131.3633\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 125.8893 - val_loss: 131.1446\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 125.3700 - val_loss: 130.3843\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 125.2567 - val_loss: 130.9966\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 124.8546 - val_loss: 130.9039\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 124.5216 - val_loss: 129.8101\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 124.3100 - val_loss: 128.9656\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 123.9059 - val_loss: 131.0199\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 124.2036 - val_loss: 129.1628\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 124.1333 - val_loss: 129.5001\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 123.5543 - val_loss: 128.4437\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 123.6543 - val_loss: 128.3790\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 123.9644 - val_loss: 128.8739\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 123.4910 - val_loss: 131.0530\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 123.9843 - val_loss: 128.3201\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 123.0379 - val_loss: 128.1631\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 124.1260 - val_loss: 130.8806\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 123.7935 - val_loss: 130.4425\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 123.2025 - val_loss: 129.0766\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 123.3612 - val_loss: 130.3157\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 123.1793 - val_loss: 128.4095\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 123.3622 - val_loss: 128.7280\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 123.2233 - val_loss: 128.3743\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.8749 - val_loss: 128.6763\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.9931 - val_loss: 129.5920\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 123.0840 - val_loss: 127.9322\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.6011 - val_loss: 128.2581\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.4865 - val_loss: 128.1897\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.2171 - val_loss: 128.5660\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 122.3735 - val_loss: 127.1893\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.9770 - val_loss: 126.9947\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.1835 - val_loss: 128.3616\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 121.9392 - val_loss: 127.8045\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.7721 - val_loss: 126.9505\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.6605 - val_loss: 129.4368\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 121.7707 - val_loss: 127.1083\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.4829 - val_loss: 127.9561\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 121.6273 - val_loss: 128.4115\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 121.7238 - val_loss: 126.7326\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 121.4774 - val_loss: 126.6839\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.5125 - val_loss: 127.2302\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.8391 - val_loss: 126.7699\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.0291 - val_loss: 126.4902\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.2168 - val_loss: 128.0237\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.3316 - val_loss: 126.8924\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 121.2452 - val_loss: 126.4267\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.0285 - val_loss: 126.6137\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.3221 - val_loss: 128.9885\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.4014 - val_loss: 126.9078\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.8281 - val_loss: 126.8265\n",
      "Epoch 56/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.8548 - val_loss: 126.7226\n",
      "Epoch 57/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.5428 - val_loss: 126.2541\n",
      "Epoch 58/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 121.1628 - val_loss: 128.6680\n",
      "Epoch 59/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.0083 - val_loss: 126.3820\n",
      "Epoch 60/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.6744 - val_loss: 126.7425\n",
      "Epoch 61/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.9507 - val_loss: 127.1017\n",
      "Epoch 62/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.0242 - val_loss: 126.3191\n",
      "Epoch 63/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.7798 - val_loss: 126.0711\n",
      "Epoch 64/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.0267 - val_loss: 127.6590\n",
      "Epoch 65/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.9638 - val_loss: 126.5935\n",
      "Epoch 66/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.3765 - val_loss: 129.5809\n",
      "Epoch 67/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.2476 - val_loss: 127.4859\n",
      "Epoch 68/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.7543 - val_loss: 126.3053\n",
      "Epoch 69/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.4751 - val_loss: 126.3225\n",
      "Epoch 70/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 120.2122 - val_loss: 126.1731\n",
      "Epoch 71/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.3677 - val_loss: 127.5406\n",
      "Epoch 72/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.3990 - val_loss: 126.5205\n",
      "Epoch 73/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.2604 - val_loss: 126.0168\n",
      "Epoch 74/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.2540 - val_loss: 125.4114\n",
      "Epoch 75/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.1606 - val_loss: 125.4704\n",
      "Epoch 76/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.0983 - val_loss: 126.9685\n",
      "Epoch 77/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.1889 - val_loss: 125.8420\n",
      "Epoch 78/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.0666 - val_loss: 125.8960\n",
      "Epoch 79/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.0983 - val_loss: 127.8277\n",
      "Epoch 80/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.2746 - val_loss: 126.0017\n",
      "Epoch 81/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.2961 - val_loss: 125.2039\n",
      "Epoch 82/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 119.7940 - val_loss: 126.8376\n",
      "Epoch 83/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 119.8772 - val_loss: 125.3896\n",
      "Epoch 84/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.0912 - val_loss: 125.7919\n",
      "Epoch 85/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 119.8713 - val_loss: 126.0188\n",
      "Epoch 86/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.3136 - val_loss: 126.6055\n",
      "Epoch 87/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 119.9314 - val_loss: 126.8799\n",
      "Epoch 88/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.1444 - val_loss: 126.0060\n",
      "Epoch 89/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 119.7444 - val_loss: 126.1827\n",
      "Epoch 90/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 119.6162 - val_loss: 125.2967\n",
      "Epoch 91/100\n",
      "72/73 [============================>.] - ETA: 0s - loss: 120.3696Restoring model weights from the end of the best epoch: 81.\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.4263 - val_loss: 126.6741\n",
      "Epoch 91: early stopping\n",
      "'########################################################Model2\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 13ms/step - loss: 145.5091 - val_loss: 141.0211\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 135.8442 - val_loss: 139.5095\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 133.1651 - val_loss: 136.0696\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 127.8633 - val_loss: 131.8338\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 126.6546 - val_loss: 130.4718\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 125.8959 - val_loss: 132.0780\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 125.0119 - val_loss: 128.9897\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 124.9823 - val_loss: 129.5783\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 123.7779 - val_loss: 128.6259\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 123.4407 - val_loss: 128.0557\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 124.1043 - val_loss: 129.4985\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 123.7168 - val_loss: 127.7861\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 123.8669 - val_loss: 127.6642\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 123.2342 - val_loss: 128.9993\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 123.5616 - val_loss: 128.6112\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 123.2280 - val_loss: 128.4157\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 122.9096 - val_loss: 128.5228\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 123.0110 - val_loss: 128.6328\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.6248 - val_loss: 128.4786\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.7541 - val_loss: 127.8203\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.8129 - val_loss: 127.6666\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.6587 - val_loss: 128.2712\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.4657 - val_loss: 127.4146\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 121.9569 - val_loss: 129.3617\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.3175 - val_loss: 129.0668\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 122.5679 - val_loss: 128.2102\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 122.1766 - val_loss: 128.6792\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.4588 - val_loss: 127.6425\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 121.6816 - val_loss: 126.8582\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.7284 - val_loss: 126.8520\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.3907 - val_loss: 126.9997\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 122.0077 - val_loss: 127.4627\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.4350 - val_loss: 127.8540\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.7650 - val_loss: 126.5554\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.2595 - val_loss: 126.3421\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.2524 - val_loss: 126.6965\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.3481 - val_loss: 126.8804\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.2896 - val_loss: 127.0975\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.1261 - val_loss: 126.0447\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.2359 - val_loss: 127.4745\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.0900 - val_loss: 126.9895\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.2291 - val_loss: 126.7595\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.3133 - val_loss: 128.1874\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.3966 - val_loss: 127.3506\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.2286 - val_loss: 126.5172\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.8935 - val_loss: 126.2333\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.7872 - val_loss: 126.1432\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.2434 - val_loss: 125.9909\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.7063 - val_loss: 127.1895\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.7451 - val_loss: 125.7281\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.1450 - val_loss: 125.9556\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.6652 - val_loss: 126.1397\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 121.1134 - val_loss: 126.5278\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.8034 - val_loss: 127.9919\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.0618 - val_loss: 125.6063\n",
      "Epoch 56/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.4352 - val_loss: 125.6308\n",
      "Epoch 57/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 120.5221 - val_loss: 125.4895\n",
      "Epoch 58/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.2924 - val_loss: 127.3357\n",
      "Epoch 59/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.7929 - val_loss: 125.3358\n",
      "Epoch 60/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.3559 - val_loss: 126.4460\n",
      "Epoch 61/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.6237 - val_loss: 126.5672\n",
      "Epoch 62/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.6942 - val_loss: 125.7715\n",
      "Epoch 63/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 120.2755 - val_loss: 126.9710\n",
      "Epoch 64/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.2611 - val_loss: 125.6759\n",
      "Epoch 65/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.1207 - val_loss: 125.8972\n",
      "Epoch 66/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.3936 - val_loss: 125.5714\n",
      "Epoch 67/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 120.1889 - val_loss: 125.6972\n",
      "Epoch 68/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 120.8002 - val_loss: 126.5815\n",
      "Epoch 69/100\n",
      "72/73 [============================>.] - ETA: 0s - loss: 120.3021Restoring model weights from the end of the best epoch: 59.\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 120.3356 - val_loss: 126.1435\n",
      "Epoch 69: early stopping\n",
      "'########################################################Model3\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 13ms/step - loss: 142.3289 - val_loss: 141.4452\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 134.1825 - val_loss: 136.6358\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 129.1193 - val_loss: 132.6847\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 126.3348 - val_loss: 131.4537\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 126.2155 - val_loss: 134.1020\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 126.2560 - val_loss: 131.3237\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 124.6731 - val_loss: 130.6077\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 124.6488 - val_loss: 129.0454\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 124.0523 - val_loss: 129.5225\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 124.0660 - val_loss: 130.1675\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 123.5070 - val_loss: 128.5251\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 123.4899 - val_loss: 128.4133\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 123.3918 - val_loss: 129.2793\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 123.8607 - val_loss: 128.2640\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 124.0907 - val_loss: 127.9870\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 123.1131 - val_loss: 127.8243\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.8648 - val_loss: 128.3519\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 122.6719 - val_loss: 128.6560\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.5269 - val_loss: 128.8683\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 123.0013 - val_loss: 127.6674\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.5081 - val_loss: 130.8775\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 123.5850 - val_loss: 128.8648\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.3732 - val_loss: 127.1939\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.7034 - val_loss: 131.2057\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 122.8303 - val_loss: 127.8209\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.4415 - val_loss: 127.5242\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.4053 - val_loss: 129.8990\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.1763 - val_loss: 127.1933\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.1894 - val_loss: 127.3438\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.8565 - val_loss: 127.4073\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 121.3650 - val_loss: 126.8566\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.2480 - val_loss: 126.9259\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.4156 - val_loss: 126.3117\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.7324 - val_loss: 127.1367\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.6371 - val_loss: 128.4028\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.6440 - val_loss: 127.0918\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.2940 - val_loss: 126.2055\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.1255 - val_loss: 126.6981\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.6677 - val_loss: 127.5697\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.1783 - val_loss: 128.3212\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.5847 - val_loss: 126.7331\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.4392 - val_loss: 127.7520\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.1049 - val_loss: 126.9349\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.7847 - val_loss: 126.0651\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 120.9795 - val_loss: 128.0520\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.2423 - val_loss: 126.0969\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.7780 - val_loss: 127.4619\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.0944 - val_loss: 127.4762\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.1373 - val_loss: 126.4986\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 120.8693 - val_loss: 126.6320\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.8572 - val_loss: 125.9471\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.8946 - val_loss: 126.8098\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.7003 - val_loss: 126.5446\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.9206 - val_loss: 126.0898\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.4136 - val_loss: 127.5693\n",
      "Epoch 56/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.7075 - val_loss: 126.7180\n",
      "Epoch 57/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.4909 - val_loss: 125.8963\n",
      "Epoch 58/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.1388 - val_loss: 128.7661\n",
      "Epoch 59/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.8760 - val_loss: 126.4730\n",
      "Epoch 60/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.4479 - val_loss: 125.6863\n",
      "Epoch 61/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 120.3747 - val_loss: 125.9543\n",
      "Epoch 62/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 120.5514 - val_loss: 126.7095\n",
      "Epoch 63/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.5462 - val_loss: 126.6650\n",
      "Epoch 64/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 120.4172 - val_loss: 126.5032\n",
      "Epoch 65/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 120.7722 - val_loss: 127.2234\n",
      "Epoch 66/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.8716 - val_loss: 126.0584\n",
      "Epoch 67/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.2603 - val_loss: 126.3840\n",
      "Epoch 68/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.6244 - val_loss: 127.0038\n",
      "Epoch 69/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.8707 - val_loss: 126.2689\n",
      "Epoch 70/100\n",
      "70/73 [===========================>..] - ETA: 0s - loss: 120.6323Restoring model weights from the end of the best epoch: 60.\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 120.8596 - val_loss: 128.5153\n",
      "Epoch 70: early stopping\n",
      "'########################################################Model4\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 13ms/step - loss: 145.6646 - val_loss: 141.2127\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 135.9234 - val_loss: 139.8455\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 133.6555 - val_loss: 137.0017\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 128.2862 - val_loss: 133.2199\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 126.3103 - val_loss: 131.0195\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 125.4717 - val_loss: 129.6701\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 124.5526 - val_loss: 129.6879\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 124.6517 - val_loss: 129.9599\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 123.9709 - val_loss: 128.6540\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 123.8431 - val_loss: 130.4886\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 123.6762 - val_loss: 129.2582\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 123.8342 - val_loss: 129.1640\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 123.4470 - val_loss: 130.6778\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 124.0513 - val_loss: 128.2355\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.8567 - val_loss: 128.7715\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.5581 - val_loss: 127.6699\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.3436 - val_loss: 128.8619\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.6752 - val_loss: 127.5089\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.0659 - val_loss: 129.0573\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 122.1223 - val_loss: 126.8135\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 122.0265 - val_loss: 127.3440\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.7509 - val_loss: 127.6227\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.2773 - val_loss: 127.1621\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.9837 - val_loss: 128.0197\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.2612 - val_loss: 128.6803\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.7263 - val_loss: 127.5472\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.6596 - val_loss: 127.1590\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.5666 - val_loss: 126.8856\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.6061 - val_loss: 127.6197\n",
      "Epoch 30/100\n",
      "71/73 [============================>.] - ETA: 0s - loss: 121.6848Restoring model weights from the end of the best epoch: 20.\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.6833 - val_loss: 127.3428\n",
      "Epoch 30: early stopping\n",
      "'########################################################Model5\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 13ms/step - loss: 146.1440 - val_loss: 140.8618\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 135.4171 - val_loss: 139.5958\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 133.7408 - val_loss: 137.8540\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 131.0843 - val_loss: 134.3790\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 127.4142 - val_loss: 134.2586\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 126.4715 - val_loss: 131.6561\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 125.7138 - val_loss: 131.1138\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 126.6322 - val_loss: 131.4612\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 124.6223 - val_loss: 129.6022\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 123.9780 - val_loss: 128.8568\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 123.8204 - val_loss: 128.8963\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 125.1259 - val_loss: 131.3708\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 123.7995 - val_loss: 129.8556\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 125.0144 - val_loss: 131.3319\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 123.9539 - val_loss: 128.2537\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 123.4313 - val_loss: 129.3705\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 123.7945 - val_loss: 128.2823\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.8625 - val_loss: 128.9121\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 123.4394 - val_loss: 128.2074\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 123.2174 - val_loss: 127.3347\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.6681 - val_loss: 128.1642\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 122.7315 - val_loss: 127.1879\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 122.4143 - val_loss: 129.2962\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 122.4713 - val_loss: 127.5112\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.1941 - val_loss: 127.4464\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.1354 - val_loss: 127.3079\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.0621 - val_loss: 128.3080\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.0204 - val_loss: 126.7620\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 122.2079 - val_loss: 126.9855\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.9217 - val_loss: 128.7767\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.7226 - val_loss: 128.3238\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.7918 - val_loss: 127.0672\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 122.1190 - val_loss: 127.9311\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.6539 - val_loss: 128.1367\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 122.5088 - val_loss: 127.6439\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.1052 - val_loss: 127.2280\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.8676 - val_loss: 126.6771\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.4877 - val_loss: 129.0258\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.2724 - val_loss: 129.0946\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.5938 - val_loss: 127.2353\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 121.2961 - val_loss: 126.5194\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.7601 - val_loss: 126.8055\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 122.7007 - val_loss: 127.4143\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 121.4718 - val_loss: 126.6914\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.2215 - val_loss: 127.8840\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 121.2848 - val_loss: 127.7249\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.7742 - val_loss: 126.3762\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 121.3248 - val_loss: 126.4973\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.7026 - val_loss: 127.1094\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.3756 - val_loss: 126.9179\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.6030 - val_loss: 126.8079\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.2143 - val_loss: 126.3481\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.2898 - val_loss: 127.8921\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.8691 - val_loss: 126.6291\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.1730 - val_loss: 127.2881\n",
      "Epoch 56/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.4317 - val_loss: 126.2780\n",
      "Epoch 57/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.4381 - val_loss: 126.4277\n",
      "Epoch 58/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.5469 - val_loss: 127.8271\n",
      "Epoch 59/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.2091 - val_loss: 125.7349\n",
      "Epoch 60/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.9951 - val_loss: 126.4734\n",
      "Epoch 61/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.0910 - val_loss: 126.4154\n",
      "Epoch 62/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.3182 - val_loss: 127.1631\n",
      "Epoch 63/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.3646 - val_loss: 126.0781\n",
      "Epoch 64/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 121.2844 - val_loss: 126.2782\n",
      "Epoch 65/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.9395 - val_loss: 126.2941\n",
      "Epoch 66/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 121.1293 - val_loss: 127.0544\n",
      "Epoch 67/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.2468 - val_loss: 126.8331\n",
      "Epoch 68/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.0078 - val_loss: 126.7124\n",
      "Epoch 69/100\n",
      "72/73 [============================>.] - ETA: 0s - loss: 121.1554Restoring model weights from the end of the best epoch: 59.\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.0397 - val_loss: 127.1810\n",
      "Epoch 69: early stopping\n",
      "'########################################################Model6\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 13ms/step - loss: 142.9810 - val_loss: 141.1588\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 135.7027 - val_loss: 139.7502\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 133.0185 - val_loss: 136.3336\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 128.0305 - val_loss: 133.5707\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 126.7907 - val_loss: 130.4294\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 125.7964 - val_loss: 131.8725\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 125.2299 - val_loss: 129.6115\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 123.9728 - val_loss: 129.5947\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 123.3943 - val_loss: 129.5410\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 123.8750 - val_loss: 128.2688\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.9073 - val_loss: 128.1029\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 123.9164 - val_loss: 130.5402\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 123.3962 - val_loss: 127.8384\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.6869 - val_loss: 128.3976\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.4419 - val_loss: 127.5405\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.5793 - val_loss: 128.1869\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.5191 - val_loss: 129.8688\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.8398 - val_loss: 127.8643\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.0537 - val_loss: 127.7540\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 121.9234 - val_loss: 127.8725\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 123.0891 - val_loss: 128.1392\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 121.9479 - val_loss: 127.8617\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 122.0787 - val_loss: 127.0697\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 121.7771 - val_loss: 126.7663\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.5923 - val_loss: 127.0027\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.3836 - val_loss: 126.9692\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 121.7282 - val_loss: 126.7605\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.6044 - val_loss: 126.6555\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 121.1420 - val_loss: 126.6123\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.4929 - val_loss: 127.8657\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.3937 - val_loss: 127.1919\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 121.3448 - val_loss: 128.3658\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.7041 - val_loss: 126.2925\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.1628 - val_loss: 127.0903\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.1397 - val_loss: 127.3196\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.2607 - val_loss: 126.8348\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.5638 - val_loss: 127.5714\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.9611 - val_loss: 126.6988\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.8965 - val_loss: 127.0877\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.8535 - val_loss: 127.0413\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.7944 - val_loss: 126.2281\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.9545 - val_loss: 126.4438\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 120.4677 - val_loss: 126.2846\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 121.0302 - val_loss: 126.2923\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.7004 - val_loss: 126.8075\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.9647 - val_loss: 126.0257\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.9354 - val_loss: 127.6031\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.6921 - val_loss: 126.7253\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 120.3885 - val_loss: 125.8527\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 120.6200 - val_loss: 127.0210\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.7798 - val_loss: 127.7730\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.4589 - val_loss: 125.4849\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.3761 - val_loss: 126.2536\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.3028 - val_loss: 126.5716\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 120.3741 - val_loss: 125.6280\n",
      "Epoch 56/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.3216 - val_loss: 126.2329\n",
      "Epoch 57/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.2844 - val_loss: 125.7118\n",
      "Epoch 58/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 120.7576 - val_loss: 127.3140\n",
      "Epoch 59/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 120.6810 - val_loss: 125.6896\n",
      "Epoch 60/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 120.3438 - val_loss: 126.0664\n",
      "Epoch 61/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 120.1973 - val_loss: 126.1121\n",
      "Epoch 62/100\n",
      "69/73 [===========================>..] - ETA: 0s - loss: 120.1328Restoring model weights from the end of the best epoch: 52.\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 120.2069 - val_loss: 125.9701\n",
      "Epoch 62: early stopping\n",
      "'########################################################Model7\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 13ms/step - loss: 142.6207 - val_loss: 141.1495\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 135.5272 - val_loss: 138.8288\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 130.5482 - val_loss: 133.9151\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 128.0443 - val_loss: 133.3083\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 126.6469 - val_loss: 131.5387\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 125.9792 - val_loss: 131.1410\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 125.3785 - val_loss: 130.4824\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 124.8475 - val_loss: 130.1549\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 125.6105 - val_loss: 129.0255\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 124.9267 - val_loss: 129.6690\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 124.0965 - val_loss: 132.0694\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 124.4551 - val_loss: 131.0590\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 124.2150 - val_loss: 129.5122\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 124.6180 - val_loss: 130.0558\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 124.3467 - val_loss: 130.1874\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 123.4256 - val_loss: 129.5552\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 123.5430 - val_loss: 128.3206\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 123.3720 - val_loss: 128.4004\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 123.1493 - val_loss: 128.0401\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 123.4182 - val_loss: 128.8059\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.6205 - val_loss: 127.7176\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.6341 - val_loss: 129.0425\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 123.4037 - val_loss: 129.7052\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 122.5556 - val_loss: 127.4098\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.6356 - val_loss: 127.9770\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 122.2234 - val_loss: 128.4271\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 122.2347 - val_loss: 127.9880\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 122.1720 - val_loss: 128.2349\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.7054 - val_loss: 127.6507\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 121.9693 - val_loss: 127.5582\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 121.5911 - val_loss: 127.7163\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.1728 - val_loss: 129.9724\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 122.1689 - val_loss: 129.4923\n",
      "Epoch 34/100\n",
      "68/73 [==========================>...] - ETA: 0s - loss: 122.1080Restoring model weights from the end of the best epoch: 24.\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 121.9546 - val_loss: 127.6767\n",
      "Epoch 34: early stopping\n",
      "'########################################################Model8\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 13ms/step - loss: 200.0000 - val_loss: 200.0000\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 200.0000 - val_loss: 200.0000\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 200.0000 - val_loss: 200.0000\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 200.0000 - val_loss: 200.0000\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 200.0000 - val_loss: 200.0000\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 200.0000 - val_loss: 200.0000\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 200.0000 - val_loss: 200.0000\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 200.0000 - val_loss: 200.0000\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 200.0000 - val_loss: 200.0000\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 1s 9ms/step - loss: 200.0000 - val_loss: 200.0000\n",
      "Epoch 11/100\n",
      "69/73 [===========================>..] - ETA: 0s - loss: 200.0000Restoring model weights from the end of the best epoch: 1.\n",
      "73/73 [==============================] - 1s 10ms/step - loss: 200.0000 - val_loss: 200.0000\n",
      "Epoch 11: early stopping\n",
      "'########################################################Model9\n"
     ]
    }
   ],
   "source": [
    "model_num = 10\n",
    "\n",
    "\n",
    "mase_models = train_bagging_models(model_num, MASE(y_train,24),100,10,8,0.001)\n",
    "mape_models = train_bagging_models(model_num,'mape',100,10,8,0.001)\n",
    "smape_models = train_bagging_models(model_num, SMAPE(),100,10,8,0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b35de203-07f8-48f9-8ede-0a0bcba1ea27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 1s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 2ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "12/12 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.23909080303451422, 0.24162191940344738)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred1,_=smape_models\n",
    "pred2,_=mase_models\n",
    "pred3,_=mape_models\n",
    "\n",
    "smape_predictions = bagging_predict2(pred1, test_X)\n",
    "mase_predictions = bagging_predict2(pred2, test_X)\n",
    "mape_predictions = bagging_predict2(pred3, test_X)\n",
    "concat = np.concatenate([smape_predictions, mase_predictions,mape_predictions],axis=0)\n",
    "fin_pred = np.median(concat,axis=0)\n",
    "#pd.DataFrame(fin_pred).to_csv(\"freezing_I.csv\")\n",
    "mean_squared_error(test_y.flatten(),fin_pred.flatten()),mean_absolute_error(test_y.flatten(),fin_pred.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c80efe85-f798-42c9-b7c2-9756f51cf6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(fin_pred.reshape(-1,24)).to_csv(\"../result5/LSTM/pred_mid.csv\")\n",
    "for i in range(10):\n",
    "    pd.DataFrame(concat[i].reshape(-1,24)).to_csv(f\"../result5/LSTM/pred{i}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
