{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84526bc5-cd1a-4fac-a796-57902266c3bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "636876fb-747b-4480-8ea0-8ff0618bd573",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-22 13:20:43.995152: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-22 13:20:44.071002: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-08-22 13:20:44.071021: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-08-22 13:20:44.431520: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-08-22 13:20:44.431574: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-08-22 13:20:44.431580: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nbeats_keras.model import NBeatsNet as NBeatsKeras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "#from nbeats_pytorch.model import NBeatsNet as NBeatsPytorch\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "import time\n",
    "from keras.models import load_model\n",
    "#from target_data_electronic70_7 import target_X, target_y ,test_X, test_y\n",
    "#from m4databasis21_7 import base_domain,zt_in,zt_out,M4Meta,inputsize,train_12,train_12_y\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error,mean_absolute_percentage_error\n",
    "plt.rcParams['font.family'] ='Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] =False\n",
    "from tensorflow.keras.losses import Loss\n",
    "import tensorflow as tf\n",
    "#from m4databasis35_7_70_7 import train_35,train_35_y,train_70,train_70_y\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, LayerNormalization, MultiHeadAttention, Dropout, Add, Concatenate,Flatten,Reshape\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, TimeDistributed, Lambda\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3850e1af-7ef4-47f2-b130-6732c47014c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((721, 168), (721, 24))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_X= pd.read_csv(\"../data/solor_train_input_7.csv\").iloc[:,(1+24*0):].values\n",
    "target_y =pd.read_csv(\"../data/solor_train_output_7.csv\").iloc[:,1:].values\n",
    "test_X= pd.read_csv(\"../data/solor_val_input_7.csv\").iloc[:,(1+24*0):].values\n",
    "test_y =pd.read_csv(\"../data/solor_val_output_7.csv\").iloc[:,1:].values\n",
    "\n",
    "X_train = target_X\n",
    "y_train = target_y\n",
    "X_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3aff672-3e0d-4a08-9d95-0a0eacbdbb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "# loss SMAPE\n",
    "class SMAPE(Loss):\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_pred = tf.reshape(y_pred, tf.shape(y_true))  # 예측 값의 차원을 맞춤\n",
    "       # y_pred=tf.clip_by_value(y_pred, 1e-10, tf.reduce_max(y_pred))\n",
    "       # y_true = tf.clip_by_value(y_true, 1e-10, tf.reduce_max(y_true))\n",
    "        \n",
    "        numerator = 100 * tf.abs(y_true- y_pred )\n",
    "        denominator =  (tf.abs(y_true ) + tf.abs(y_pred))/2\n",
    "        smape =  numerator /  denominator #tf.clip_by_value(denominator, 1e-10, tf.reduce_max(denominator))\n",
    "        return tf.reduce_mean(smape)\n",
    "\n",
    "#################################################################################\n",
    "# loss MASE\n",
    "class MASE(Loss):\n",
    "    def __init__(self, training_data, period, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.scale = self.calculate_scale(training_data, period)\n",
    "    def seasonal_diff(data, period):\n",
    "        return data[period:] - data[:-period]\n",
    "\n",
    "    def calculate_scale(self, training_data, period):\n",
    "        # 주기 차분 계산\n",
    "        diff = seasonal_diff(training_data, period)\n",
    "        scale = np.mean(np.abs(diff))\n",
    "        return scale\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        y_pred = tf.reshape(y_pred, tf.shape(y_true))  # 차원 맞추기\n",
    "        error = tf.abs(y_true - y_pred)\n",
    "        return tf.reduce_mean(error / self.scale)\n",
    "\n",
    "def seasonal_diff(data, period):\n",
    "    return data[period:] - data[:-period]\n",
    "#################################################################################\n",
    "# 하이퍼파라미터 인자 설정\n",
    "def hyperparameter():\n",
    "    # 1 backcast\n",
    "    # 2 forecast\n",
    "    # 3 inputdim\n",
    "    # 4 outputdim\n",
    "    # 5 unit\n",
    "    # 6 bacth size\n",
    "    return X_train.shape[1],1,y_train.shape[1],y_train.shape[1]\n",
    "\n",
    "#################################################################################\n",
    "# nbeats 모델 생성 함수\n",
    "def build_model(input_timesteps,features,output_timesteps,unit):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(unit, return_sequences=True, input_shape=(input_timesteps, features)))\n",
    "    #model.add(LSTM(unit, return_sequences=True))\n",
    "    # Use Lambda layer to select the last 'output_timesteps' outputs\n",
    "    model.add(Lambda(lambda x: x[:, -output_timesteps:, :]))\n",
    "    model.add(TimeDistributed(Dense(1)))\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model.compile(loss='mse', optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "#################################################################################\n",
    "# 부트스트랩 샘플링\n",
    "# 배깅\n",
    "\n",
    "def train_bagging_models(num_models, loss_fn , epochs_, patience_,batch_size_,lr):\n",
    "    models = {}\n",
    "    input_timesteps,features,output_timesteps,unit = hyperparameter()\n",
    "    historys = []\n",
    "    for n in range(num_models):\n",
    "        K.clear_session()\n",
    "        model = build_model(input_timesteps,features,output_timesteps,unit)\n",
    "       # model.set_weights(pretrained_weights)  # 전이 학습 가중치 적용\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "        model.compile(optimizer=optimizer , loss=loss_fn)\n",
    "        \n",
    "        # 부트스트랩 샘플링\n",
    "        #select = np.random.choice(len(X_train), size=len(X_train), replace=True)\n",
    "        #X_bootstrap = X_train[select]\n",
    "        #y_bootstrap = y_train[select]\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience = patience_, verbose = 1, restore_best_weights=True)\n",
    "        history = model.fit(X_train, y_train, batch_size = batch_size_,\n",
    "                  epochs=epochs_, verbose=1, \n",
    "                  callbacks=[early_stop],\n",
    "                 validation_split = 0.2)\n",
    "        models[f'model_{n+1}'] = model\n",
    "        historys.append(history)\n",
    "        #models.append(model)\n",
    "        print(f\"'########################################################Model{n}\")\n",
    "    return models,historys\n",
    "\n",
    "#################################################################################\n",
    "# SMAPE 용\n",
    "def train_bagging_models_smape(num_models, loss_fn , epochs_, patience_,batch_size_):\n",
    "    models = {}\n",
    "    backcast,forecast,in_dim,out_dim,unit = hyperparameter()\n",
    "    historys = []\n",
    "    for n in range(num_models):\n",
    "        K.clear_session()\n",
    "        model = bulid_model(backcast,forecast,in_dim,out_dim,unit)\n",
    "       # model.set_weights(pretrained_weights)  # 전이 학습 가중치 적용\n",
    "        optimizer = Adam(learning_rate=0.001)\n",
    "        model.compile(optimizer=optimizer , loss=loss_fn)\n",
    "        \n",
    "        # 부트스트랩 샘플링\n",
    "        #select = np.random.choice(len(X_train), size=len(X_train), replace=True)\n",
    "        #_bootstrap = X_train[select]\n",
    "        #y_bootstrap = y_train[select]\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience = patience_, verbose = 1, restore_best_weights=True)\n",
    "        history = model.fit(X_train, y_train, batch_size = batch_size_,\n",
    "                  epochs=epochs_, verbose=1, \n",
    "                  callbacks=[early_stop],\n",
    "                 validation_split = 0.2)\n",
    "        models[f'model_{n+1}'] = model\n",
    "        historys.append(history)\n",
    "        #models.append(model)\n",
    "        print(f\"'########################################################Model{n}\")\n",
    "    return models,historys\n",
    "\n",
    "\n",
    "\n",
    "#################################################################################\n",
    "\n",
    "def bagging_predict(models, X):\n",
    "    predictions = np.array([model.predict(X) for model in models.values()])\n",
    "    return np.median(predictions, axis=0)\n",
    "\n",
    "def bagging_predict2(models, X):\n",
    "    predictions = np.array([model.predict(X) for model in models.values()])\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fce9eb03-7500-4d76-af24-72f76cc67df4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-22 13:21:31.950509: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-08-22 13:21:31.950553: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ymlee2-desktop): /proc/driver/nvidia/version does not exist\n",
      "2024-08-22 13:21:31.951142: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "72/72 [==============================] - 2s 16ms/step - loss: 1.5916 - val_loss: 1.0696\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 1.0592 - val_loss: 0.7495\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.8505 - val_loss: 0.6526\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.8161 - val_loss: 0.6472\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.8058 - val_loss: 0.6303\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7939 - val_loss: 0.6405\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7849 - val_loss: 0.6150\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7749 - val_loss: 0.6286\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7739 - val_loss: 0.6302\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7711 - val_loss: 0.5935\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7652 - val_loss: 0.6099\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7632 - val_loss: 0.5965\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7630 - val_loss: 0.5962\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7608 - val_loss: 0.6064\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7534 - val_loss: 0.5974\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7507 - val_loss: 0.5787\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7528 - val_loss: 0.5856\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7531 - val_loss: 0.5809\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7516 - val_loss: 0.6004\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7514 - val_loss: 0.5864\n",
      "Epoch 21/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7438 - val_loss: 0.5821\n",
      "Epoch 22/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7419 - val_loss: 0.5813\n",
      "Epoch 23/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7525 - val_loss: 0.5919\n",
      "Epoch 24/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7422 - val_loss: 0.5783\n",
      "Epoch 25/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7385 - val_loss: 0.5860\n",
      "Epoch 26/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7423 - val_loss: 0.5718\n",
      "Epoch 27/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7384 - val_loss: 0.5748\n",
      "Epoch 28/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7411 - val_loss: 0.5861\n",
      "Epoch 29/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7379 - val_loss: 0.5822\n",
      "Epoch 30/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7412 - val_loss: 0.5743\n",
      "Epoch 31/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7418 - val_loss: 0.5820\n",
      "Epoch 32/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7363 - val_loss: 0.5849\n",
      "Epoch 33/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7357 - val_loss: 0.5868\n",
      "Epoch 34/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7434 - val_loss: 0.6078\n",
      "Epoch 35/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7408 - val_loss: 0.5747\n",
      "Epoch 36/100\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.7334Restoring model weights from the end of the best epoch: 26.\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.7344 - val_loss: 0.5845\n",
      "Epoch 36: early stopping\n",
      "'########################################################Model0\n",
      "Epoch 1/100\n",
      "72/72 [==============================] - 2s 16ms/step - loss: 1.6193 - val_loss: 1.0368\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 1.0375 - val_loss: 0.7702\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.8686 - val_loss: 0.6827\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.8393 - val_loss: 0.6598\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.8256 - val_loss: 0.6523\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.8199 - val_loss: 0.6537\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.8135 - val_loss: 0.6499\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.8104 - val_loss: 0.6524\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.8082 - val_loss: 0.6368\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.8055 - val_loss: 0.6434\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7999 - val_loss: 0.6305\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7948 - val_loss: 0.6389\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7889 - val_loss: 0.6243\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7849 - val_loss: 0.6143\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7830 - val_loss: 0.6292\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7792 - val_loss: 0.6199\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7720 - val_loss: 0.6105\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7691 - val_loss: 0.6100\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7669 - val_loss: 0.6062\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7686 - val_loss: 0.6087\n",
      "Epoch 21/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7614 - val_loss: 0.5977\n",
      "Epoch 22/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.7628 - val_loss: 0.5942\n",
      "Epoch 23/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7573 - val_loss: 0.5946\n",
      "Epoch 24/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7590 - val_loss: 0.5927\n",
      "Epoch 25/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7548 - val_loss: 0.5906\n",
      "Epoch 26/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7507 - val_loss: 0.5954\n",
      "Epoch 27/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7517 - val_loss: 0.6081\n",
      "Epoch 28/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.7520 - val_loss: 0.5790\n",
      "Epoch 29/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7465 - val_loss: 0.5803\n",
      "Epoch 30/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7416 - val_loss: 0.5794\n",
      "Epoch 31/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7492 - val_loss: 0.5981\n",
      "Epoch 32/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7503 - val_loss: 0.5859\n",
      "Epoch 33/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7434 - val_loss: 0.5783\n",
      "Epoch 34/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7425 - val_loss: 0.5737\n",
      "Epoch 35/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7489 - val_loss: 0.5839\n",
      "Epoch 36/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7428 - val_loss: 0.5865\n",
      "Epoch 37/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7434 - val_loss: 0.6118\n",
      "Epoch 38/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7413 - val_loss: 0.5752\n",
      "Epoch 39/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7395 - val_loss: 0.5963\n",
      "Epoch 40/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7451 - val_loss: 0.5837\n",
      "Epoch 41/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7414 - val_loss: 0.5846\n",
      "Epoch 42/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7398 - val_loss: 0.5755\n",
      "Epoch 43/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7414 - val_loss: 0.5951\n",
      "Epoch 44/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.7373 - val_loss: 0.5710\n",
      "Epoch 45/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7420 - val_loss: 0.5788\n",
      "Epoch 46/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.7346 - val_loss: 0.5710\n",
      "Epoch 47/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7356 - val_loss: 0.5767\n",
      "Epoch 48/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.7389 - val_loss: 0.5814\n",
      "Epoch 49/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7359 - val_loss: 0.6026\n",
      "Epoch 50/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.7378 - val_loss: 0.5860\n",
      "Epoch 51/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.7411 - val_loss: 0.5779\n",
      "Epoch 52/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7355 - val_loss: 0.5746\n",
      "Epoch 53/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7326 - val_loss: 0.5929\n",
      "Epoch 54/100\n",
      "69/72 [===========================>..] - ETA: 0s - loss: 0.7365Restoring model weights from the end of the best epoch: 44.\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7401 - val_loss: 0.5871\n",
      "Epoch 54: early stopping\n",
      "'########################################################Model1\n",
      "Epoch 1/100\n",
      "72/72 [==============================] - 2s 16ms/step - loss: 1.3029 - val_loss: 0.9113\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.9169 - val_loss: 0.7144\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.8197 - val_loss: 0.6481\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7968 - val_loss: 0.6494\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7918 - val_loss: 0.6223\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7798 - val_loss: 0.6156\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7739 - val_loss: 0.5991\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7714 - val_loss: 0.6072\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7660 - val_loss: 0.5983\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7625 - val_loss: 0.6099\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7661 - val_loss: 0.5934\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7584 - val_loss: 0.5951\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7524 - val_loss: 0.5878\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7516 - val_loss: 0.6121\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7485 - val_loss: 0.5947\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7526 - val_loss: 0.5976\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7485 - val_loss: 0.5952\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7444 - val_loss: 0.6019\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7435 - val_loss: 0.5969\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7397 - val_loss: 0.5869\n",
      "Epoch 21/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7397 - val_loss: 0.6070\n",
      "Epoch 22/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7398 - val_loss: 0.5908\n",
      "Epoch 23/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7518 - val_loss: 0.6066\n",
      "Epoch 24/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7424 - val_loss: 0.5832\n",
      "Epoch 25/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7339 - val_loss: 0.5776\n",
      "Epoch 26/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7411 - val_loss: 0.5765\n",
      "Epoch 27/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7339 - val_loss: 0.5942\n",
      "Epoch 28/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7373 - val_loss: 0.5811\n",
      "Epoch 29/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7398 - val_loss: 0.6036\n",
      "Epoch 30/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7392 - val_loss: 0.5746\n",
      "Epoch 31/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7363 - val_loss: 0.5776\n",
      "Epoch 32/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7339 - val_loss: 0.5893\n",
      "Epoch 33/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7299 - val_loss: 0.5867\n",
      "Epoch 34/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7301 - val_loss: 0.5902\n",
      "Epoch 35/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7353 - val_loss: 0.5826\n",
      "Epoch 36/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7304 - val_loss: 0.6107\n",
      "Epoch 37/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7386 - val_loss: 0.5943\n",
      "Epoch 38/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7334 - val_loss: 0.5760\n",
      "Epoch 39/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7346 - val_loss: 0.5772\n",
      "Epoch 40/100\n",
      "69/72 [===========================>..] - ETA: 0s - loss: 0.7213Restoring model weights from the end of the best epoch: 30.\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7270 - val_loss: 0.5784\n",
      "Epoch 40: early stopping\n",
      "'########################################################Model2\n",
      "Epoch 1/100\n",
      "72/72 [==============================] - 2s 16ms/step - loss: 1.4248 - val_loss: 0.9855\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.9793 - val_loss: 0.6994\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.8281 - val_loss: 0.6612\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7973 - val_loss: 0.6422\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7931 - val_loss: 0.6171\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7815 - val_loss: 0.6247\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7768 - val_loss: 0.6061\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7747 - val_loss: 0.6121\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7778 - val_loss: 0.6129\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7689 - val_loss: 0.6402\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7713 - val_loss: 0.6319\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7647 - val_loss: 0.6041\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7637 - val_loss: 0.6058\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7617 - val_loss: 0.6090\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7603 - val_loss: 0.5959\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7575 - val_loss: 0.6041\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7541 - val_loss: 0.5925\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7540 - val_loss: 0.6000\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7535 - val_loss: 0.6657\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.7602 - val_loss: 0.6044\n",
      "Epoch 21/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7563 - val_loss: 0.5989\n",
      "Epoch 22/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7518 - val_loss: 0.5827\n",
      "Epoch 23/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7469 - val_loss: 0.5874\n",
      "Epoch 24/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7533 - val_loss: 0.5967\n",
      "Epoch 25/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7448 - val_loss: 0.5831\n",
      "Epoch 26/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7449 - val_loss: 0.5916\n",
      "Epoch 27/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7439 - val_loss: 0.5907\n",
      "Epoch 28/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7440 - val_loss: 0.5808\n",
      "Epoch 29/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7442 - val_loss: 0.5987\n",
      "Epoch 30/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7465 - val_loss: 0.5968\n",
      "Epoch 31/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7436 - val_loss: 0.5845\n",
      "Epoch 32/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7405 - val_loss: 0.5879\n",
      "Epoch 33/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7415 - val_loss: 0.6156\n",
      "Epoch 34/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.7497 - val_loss: 0.5926\n",
      "Epoch 35/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.7403 - val_loss: 0.6030\n",
      "Epoch 36/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7370 - val_loss: 0.5795\n",
      "Epoch 37/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7329 - val_loss: 0.5874\n",
      "Epoch 38/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7319 - val_loss: 0.5765\n",
      "Epoch 39/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7396 - val_loss: 0.5729\n",
      "Epoch 40/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7363 - val_loss: 0.5748\n",
      "Epoch 41/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7372 - val_loss: 0.5824\n",
      "Epoch 42/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7343 - val_loss: 0.5799\n",
      "Epoch 43/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7379 - val_loss: 0.5821\n",
      "Epoch 44/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7330 - val_loss: 0.6005\n",
      "Epoch 45/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7346 - val_loss: 0.5930\n",
      "Epoch 46/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7368 - val_loss: 0.5860\n",
      "Epoch 47/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7324 - val_loss: 0.5745\n",
      "Epoch 48/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7361 - val_loss: 0.5713\n",
      "Epoch 49/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7317 - val_loss: 0.5899\n",
      "Epoch 50/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7340 - val_loss: 0.5794\n",
      "Epoch 51/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7312 - val_loss: 0.5765\n",
      "Epoch 52/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7312 - val_loss: 0.5803\n",
      "Epoch 53/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7286 - val_loss: 0.5765\n",
      "Epoch 54/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7306 - val_loss: 0.5810\n",
      "Epoch 55/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7341 - val_loss: 0.6470\n",
      "Epoch 56/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7381 - val_loss: 0.5731\n",
      "Epoch 57/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7278 - val_loss: 0.5774\n",
      "Epoch 58/100\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.7294Restoring model weights from the end of the best epoch: 48.\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7294 - val_loss: 0.5838\n",
      "Epoch 58: early stopping\n",
      "'########################################################Model3\n",
      "Epoch 1/100\n",
      "72/72 [==============================] - 2s 16ms/step - loss: 1.3070 - val_loss: 0.9069\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.9434 - val_loss: 0.7063\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.8421 - val_loss: 0.6609\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.8174 - val_loss: 0.6517\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.8065 - val_loss: 0.6391\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.8062 - val_loss: 0.6421\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7969 - val_loss: 0.6633\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7958 - val_loss: 0.6354\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7869 - val_loss: 0.6226\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.7793 - val_loss: 0.6234\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7741 - val_loss: 0.6104\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.7732 - val_loss: 0.6112\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7663 - val_loss: 0.6161\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7650 - val_loss: 0.6217\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7592 - val_loss: 0.6152\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7584 - val_loss: 0.6134\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7581 - val_loss: 0.5981\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7552 - val_loss: 0.6001\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7569 - val_loss: 0.5955\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.7541 - val_loss: 0.5939\n",
      "Epoch 21/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7483 - val_loss: 0.5898\n",
      "Epoch 22/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7476 - val_loss: 0.5992\n",
      "Epoch 23/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7512 - val_loss: 0.5956\n",
      "Epoch 24/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7481 - val_loss: 0.5836\n",
      "Epoch 25/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7456 - val_loss: 0.5927\n",
      "Epoch 26/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7492 - val_loss: 0.5929\n",
      "Epoch 27/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7433 - val_loss: 0.5962\n",
      "Epoch 28/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7485 - val_loss: 0.5883\n",
      "Epoch 29/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7420 - val_loss: 0.5791\n",
      "Epoch 30/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7411 - val_loss: 0.5839\n",
      "Epoch 31/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7424 - val_loss: 0.5996\n",
      "Epoch 32/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7450 - val_loss: 0.5916\n",
      "Epoch 33/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7430 - val_loss: 0.6188\n",
      "Epoch 34/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7426 - val_loss: 0.5743\n",
      "Epoch 35/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7411 - val_loss: 0.5870\n",
      "Epoch 36/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7429 - val_loss: 0.5968\n",
      "Epoch 37/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7411 - val_loss: 0.5799\n",
      "Epoch 38/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7335 - val_loss: 0.5971\n",
      "Epoch 39/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7374 - val_loss: 0.5957\n",
      "Epoch 40/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7430 - val_loss: 0.5754\n",
      "Epoch 41/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7340 - val_loss: 0.5940\n",
      "Epoch 42/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7427 - val_loss: 0.5791\n",
      "Epoch 43/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7374 - val_loss: 0.5756\n",
      "Epoch 44/100\n",
      "69/72 [===========================>..] - ETA: 0s - loss: 0.7391Restoring model weights from the end of the best epoch: 34.\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7370 - val_loss: 0.5773\n",
      "Epoch 44: early stopping\n",
      "'########################################################Model4\n",
      "Epoch 1/100\n",
      "72/72 [==============================] - 2s 16ms/step - loss: 1.3280 - val_loss: 0.9068\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.9201 - val_loss: 0.6771\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.8249 - val_loss: 0.6548\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.8165 - val_loss: 0.6457\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.8051 - val_loss: 0.6313\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.8005 - val_loss: 0.6342\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7978 - val_loss: 0.6306\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.8025 - val_loss: 0.6517\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7984 - val_loss: 0.6426\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7939 - val_loss: 0.6346\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7972 - val_loss: 0.6221\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7945 - val_loss: 0.6204\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7942 - val_loss: 0.6222\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7869 - val_loss: 0.6356\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7898 - val_loss: 0.6202\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7908 - val_loss: 0.6224\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7864 - val_loss: 0.6191\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7831 - val_loss: 0.6224\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7819 - val_loss: 0.6131\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7847 - val_loss: 0.6428\n",
      "Epoch 21/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7804 - val_loss: 0.6157\n",
      "Epoch 22/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7777 - val_loss: 0.6148\n",
      "Epoch 23/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7780 - val_loss: 0.6153\n",
      "Epoch 24/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7745 - val_loss: 0.6241\n",
      "Epoch 25/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7713 - val_loss: 0.6096\n",
      "Epoch 26/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7681 - val_loss: 0.6025\n",
      "Epoch 27/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7660 - val_loss: 0.6007\n",
      "Epoch 28/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7671 - val_loss: 0.6095\n",
      "Epoch 29/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7619 - val_loss: 0.6079\n",
      "Epoch 30/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7604 - val_loss: 0.6009\n",
      "Epoch 31/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7621 - val_loss: 0.6039\n",
      "Epoch 32/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7577 - val_loss: 0.5944\n",
      "Epoch 33/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7595 - val_loss: 0.5998\n",
      "Epoch 34/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7606 - val_loss: 0.6074\n",
      "Epoch 35/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7575 - val_loss: 0.5916\n",
      "Epoch 36/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7558 - val_loss: 0.6005\n",
      "Epoch 37/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7524 - val_loss: 0.5995\n",
      "Epoch 38/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.7524 - val_loss: 0.5937\n",
      "Epoch 39/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7537 - val_loss: 0.5815\n",
      "Epoch 40/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7490 - val_loss: 0.5838\n",
      "Epoch 41/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7502 - val_loss: 0.5954\n",
      "Epoch 42/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.7521 - val_loss: 0.5935\n",
      "Epoch 43/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7488 - val_loss: 0.5824\n",
      "Epoch 44/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7487 - val_loss: 0.5916\n",
      "Epoch 45/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7454 - val_loss: 0.5785\n",
      "Epoch 46/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7458 - val_loss: 0.6039\n",
      "Epoch 47/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7408 - val_loss: 0.5867\n",
      "Epoch 48/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7401 - val_loss: 0.5821\n",
      "Epoch 49/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7413 - val_loss: 0.5914\n",
      "Epoch 50/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7402 - val_loss: 0.5915\n",
      "Epoch 51/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7426 - val_loss: 0.5852\n",
      "Epoch 52/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7391 - val_loss: 0.5788\n",
      "Epoch 53/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7414 - val_loss: 0.5842\n",
      "Epoch 54/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7407 - val_loss: 0.5794\n",
      "Epoch 55/100\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.7360Restoring model weights from the end of the best epoch: 45.\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.7360 - val_loss: 0.5797\n",
      "Epoch 55: early stopping\n",
      "'########################################################Model5\n",
      "Epoch 1/100\n",
      "72/72 [==============================] - 2s 16ms/step - loss: 1.5387 - val_loss: 1.0242\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 1.0212 - val_loss: 0.7715\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.8787 - val_loss: 0.6949\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.8426 - val_loss: 0.6845\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.8254 - val_loss: 0.6647\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.8157 - val_loss: 0.6702\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.8129 - val_loss: 0.6515\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.8079 - val_loss: 0.6404\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.8054 - val_loss: 0.6527\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.8066 - val_loss: 0.6374\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7960 - val_loss: 0.6457\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7930 - val_loss: 0.6298\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7840 - val_loss: 0.6295\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7790 - val_loss: 0.6226\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.7728 - val_loss: 0.6139\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7696 - val_loss: 0.6099\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7636 - val_loss: 0.5936\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7583 - val_loss: 0.6101\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.7665 - val_loss: 0.5958\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7623 - val_loss: 0.6116\n",
      "Epoch 21/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7620 - val_loss: 0.5878\n",
      "Epoch 22/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7543 - val_loss: 0.6247\n",
      "Epoch 23/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7503 - val_loss: 0.5946\n",
      "Epoch 24/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.7497 - val_loss: 0.5815\n",
      "Epoch 25/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7463 - val_loss: 0.5866\n",
      "Epoch 26/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7454 - val_loss: 0.5837\n",
      "Epoch 27/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7449 - val_loss: 0.5850\n",
      "Epoch 28/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7489 - val_loss: 0.5877\n",
      "Epoch 29/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7476 - val_loss: 0.5857\n",
      "Epoch 30/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7462 - val_loss: 0.5877\n",
      "Epoch 31/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7452 - val_loss: 0.6144\n",
      "Epoch 32/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7419 - val_loss: 0.5749\n",
      "Epoch 33/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7438 - val_loss: 0.5850\n",
      "Epoch 34/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7439 - val_loss: 0.5948\n",
      "Epoch 35/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7441 - val_loss: 0.5792\n",
      "Epoch 36/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7430 - val_loss: 0.5773\n",
      "Epoch 37/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7439 - val_loss: 0.5906\n",
      "Epoch 38/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7434 - val_loss: 0.5847\n",
      "Epoch 39/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7405 - val_loss: 0.5819\n",
      "Epoch 40/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7410 - val_loss: 0.5754\n",
      "Epoch 41/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7371 - val_loss: 0.5865\n",
      "Epoch 42/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7410 - val_loss: 0.5723\n",
      "Epoch 43/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7394 - val_loss: 0.5856\n",
      "Epoch 44/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7392 - val_loss: 0.5875\n",
      "Epoch 45/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7438 - val_loss: 0.5788\n",
      "Epoch 46/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7388 - val_loss: 0.5812\n",
      "Epoch 47/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7360 - val_loss: 0.5746\n",
      "Epoch 48/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7393 - val_loss: 0.5721\n",
      "Epoch 49/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7436 - val_loss: 0.5880\n",
      "Epoch 50/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7386 - val_loss: 0.5716\n",
      "Epoch 51/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7367 - val_loss: 0.5789\n",
      "Epoch 52/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7408 - val_loss: 0.5920\n",
      "Epoch 53/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7396 - val_loss: 0.5830\n",
      "Epoch 54/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7394 - val_loss: 0.5749\n",
      "Epoch 55/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7325 - val_loss: 0.5924\n",
      "Epoch 56/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7379 - val_loss: 0.5708\n",
      "Epoch 57/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7338 - val_loss: 0.5778\n",
      "Epoch 58/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7345 - val_loss: 0.5728\n",
      "Epoch 59/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7329 - val_loss: 0.5718\n",
      "Epoch 60/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7310 - val_loss: 0.6163\n",
      "Epoch 61/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7375 - val_loss: 0.5815\n",
      "Epoch 62/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7347 - val_loss: 0.5897\n",
      "Epoch 63/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.7361 - val_loss: 0.5755\n",
      "Epoch 64/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.7343 - val_loss: 0.5871\n",
      "Epoch 65/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.7346 - val_loss: 0.5815\n",
      "Epoch 66/100\n",
      "69/72 [===========================>..] - ETA: 0s - loss: 0.7431Restoring model weights from the end of the best epoch: 56.\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.7380 - val_loss: 0.5818\n",
      "Epoch 66: early stopping\n",
      "'########################################################Model6\n",
      "Epoch 1/100\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 1.6054 - val_loss: 1.1219\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 1.0702 - val_loss: 0.7769\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.8282 - val_loss: 0.6625\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.7979 - val_loss: 0.6289\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7889 - val_loss: 0.6214\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.7888 - val_loss: 0.6394\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7802 - val_loss: 0.6151\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.7704 - val_loss: 0.6171\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7650 - val_loss: 0.6681\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7660 - val_loss: 0.5928\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7606 - val_loss: 0.6213\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.7577 - val_loss: 0.5862\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.7528 - val_loss: 0.5866\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7539 - val_loss: 0.5951\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.7528 - val_loss: 0.5860\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.7506 - val_loss: 0.5920\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7508 - val_loss: 0.5823\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7533 - val_loss: 0.5946\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.7517 - val_loss: 0.5865\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7465 - val_loss: 0.5851\n",
      "Epoch 21/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.7458 - val_loss: 0.5972\n",
      "Epoch 22/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.7473 - val_loss: 0.5852\n",
      "Epoch 23/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.7449 - val_loss: 0.5837\n",
      "Epoch 24/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.7431 - val_loss: 0.5935\n",
      "Epoch 25/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7440 - val_loss: 0.5838\n",
      "Epoch 26/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.7452 - val_loss: 0.5904\n",
      "Epoch 27/100\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.7558Restoring model weights from the end of the best epoch: 17.\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.7502 - val_loss: 0.5831\n",
      "Epoch 27: early stopping\n",
      "'########################################################Model7\n",
      "Epoch 1/100\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 1.4604 - val_loss: 1.0316\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 1.0306 - val_loss: 0.7096\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.8367 - val_loss: 0.7078\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.8093 - val_loss: 0.6385\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.8017 - val_loss: 0.6161\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.7859 - val_loss: 0.6513\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7793 - val_loss: 0.6102\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.7825 - val_loss: 0.6112\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7721 - val_loss: 0.6407\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7678 - val_loss: 0.6046\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7665 - val_loss: 0.6113\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7612 - val_loss: 0.5972\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7642 - val_loss: 0.5869\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.7569 - val_loss: 0.6189\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.7538 - val_loss: 0.5985\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.7579 - val_loss: 0.5860\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.7526 - val_loss: 0.6307\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7551 - val_loss: 0.5855\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.7513 - val_loss: 0.5857\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7637 - val_loss: 0.5957\n",
      "Epoch 21/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.7593 - val_loss: 0.5838\n",
      "Epoch 22/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.7478 - val_loss: 0.5890\n",
      "Epoch 23/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.7497 - val_loss: 0.5906\n",
      "Epoch 24/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7492 - val_loss: 0.5989\n",
      "Epoch 25/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.7449 - val_loss: 0.5800\n",
      "Epoch 26/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.7436 - val_loss: 0.5779\n",
      "Epoch 27/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7463 - val_loss: 0.5866\n",
      "Epoch 28/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.7446 - val_loss: 0.5883\n",
      "Epoch 29/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7390 - val_loss: 0.5783\n",
      "Epoch 30/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7380 - val_loss: 0.5936\n",
      "Epoch 31/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7373 - val_loss: 0.5867\n",
      "Epoch 32/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7461 - val_loss: 0.6120\n",
      "Epoch 33/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7438 - val_loss: 0.5805\n",
      "Epoch 34/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.7382 - val_loss: 0.5719\n",
      "Epoch 35/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7368 - val_loss: 0.5839\n",
      "Epoch 36/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7354 - val_loss: 0.5865\n",
      "Epoch 37/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7358 - val_loss: 0.5864\n",
      "Epoch 38/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7396 - val_loss: 0.6005\n",
      "Epoch 39/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7403 - val_loss: 0.5874\n",
      "Epoch 40/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7383 - val_loss: 0.6143\n",
      "Epoch 41/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7379 - val_loss: 0.5874\n",
      "Epoch 42/100\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.7373 - val_loss: 0.5701\n",
      "Epoch 43/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.7358 - val_loss: 0.6045\n",
      "Epoch 44/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.7378 - val_loss: 0.5848\n",
      "Epoch 45/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.7383 - val_loss: 0.5792\n",
      "Epoch 46/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7303 - val_loss: 0.5782\n",
      "Epoch 47/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7334 - val_loss: 0.6165\n",
      "Epoch 48/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7343 - val_loss: 0.6011\n",
      "Epoch 49/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.7262 - val_loss: 0.5781\n",
      "Epoch 50/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7325 - val_loss: 0.5707\n",
      "Epoch 51/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7287 - val_loss: 0.5773\n",
      "Epoch 52/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.7332 - val_loss: 0.5694\n",
      "Epoch 53/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7314 - val_loss: 0.5868\n",
      "Epoch 54/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7310 - val_loss: 0.5905\n",
      "Epoch 55/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.7355 - val_loss: 0.5854\n",
      "Epoch 56/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7307 - val_loss: 0.5721\n",
      "Epoch 57/100\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.7365 - val_loss: 0.5869\n",
      "Epoch 58/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7300 - val_loss: 0.5674\n",
      "Epoch 59/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7289 - val_loss: 0.5693\n",
      "Epoch 60/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7288 - val_loss: 0.5663\n",
      "Epoch 61/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7329 - val_loss: 0.5681\n",
      "Epoch 62/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7339 - val_loss: 0.5753\n",
      "Epoch 63/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.7283 - val_loss: 0.6030\n",
      "Epoch 64/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7283 - val_loss: 0.5805\n",
      "Epoch 65/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7305 - val_loss: 0.5685\n",
      "Epoch 66/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7305 - val_loss: 0.5730\n",
      "Epoch 67/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.7289 - val_loss: 0.5750\n",
      "Epoch 68/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7291 - val_loss: 0.5730\n",
      "Epoch 69/100\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.7272 - val_loss: 0.5843\n",
      "Epoch 70/100\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.7267Restoring model weights from the end of the best epoch: 60.\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7288 - val_loss: 0.5894\n",
      "Epoch 70: early stopping\n",
      "'########################################################Model8\n",
      "Epoch 1/100\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 1.4789 - val_loss: 1.0196\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.9933 - val_loss: 0.6948\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.8254 - val_loss: 0.6637\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.7942 - val_loss: 0.6256\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7882 - val_loss: 0.6295\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7818 - val_loss: 0.6047\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7739 - val_loss: 0.6331\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7778 - val_loss: 0.6133\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7666 - val_loss: 0.6309\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.7699 - val_loss: 0.5958\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.7625 - val_loss: 0.6010\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7537 - val_loss: 0.5911\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.7530 - val_loss: 0.5868\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7552 - val_loss: 0.5962\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7533 - val_loss: 0.5876\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.7508 - val_loss: 0.6046\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7488 - val_loss: 0.5843\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7504 - val_loss: 0.6126\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7551 - val_loss: 0.5929\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.7533 - val_loss: 0.5884\n",
      "Epoch 21/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7444 - val_loss: 0.5958\n",
      "Epoch 22/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7527 - val_loss: 0.6042\n",
      "Epoch 23/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.7532 - val_loss: 0.5838\n",
      "Epoch 24/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.7449 - val_loss: 0.5812\n",
      "Epoch 25/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7405 - val_loss: 0.5907\n",
      "Epoch 26/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.7389 - val_loss: 0.5823\n",
      "Epoch 27/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7318 - val_loss: 0.6201\n",
      "Epoch 28/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7466 - val_loss: 0.6011\n",
      "Epoch 29/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.7381 - val_loss: 0.5811\n",
      "Epoch 30/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.7384 - val_loss: 0.5866\n",
      "Epoch 31/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7382 - val_loss: 0.5837\n",
      "Epoch 32/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.7342 - val_loss: 0.5748\n",
      "Epoch 33/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.7398 - val_loss: 0.6113\n",
      "Epoch 34/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.7333 - val_loss: 0.5815\n",
      "Epoch 35/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7341 - val_loss: 0.5701\n",
      "Epoch 36/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7325 - val_loss: 0.5933\n",
      "Epoch 37/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.7382 - val_loss: 0.5792\n",
      "Epoch 38/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.7339 - val_loss: 0.5733\n",
      "Epoch 39/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7336 - val_loss: 0.5730\n",
      "Epoch 40/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.7323 - val_loss: 0.5724\n",
      "Epoch 41/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7346 - val_loss: 0.5763\n",
      "Epoch 42/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.7368 - val_loss: 0.5843\n",
      "Epoch 43/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7286 - val_loss: 0.5711\n",
      "Epoch 44/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.7372 - val_loss: 0.5736\n",
      "Epoch 45/100\n",
      "69/72 [===========================>..] - ETA: 0s - loss: 0.7259Restoring model weights from the end of the best epoch: 35.\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.7298 - val_loss: 0.5770\n",
      "Epoch 45: early stopping\n",
      "'########################################################Model9\n",
      "Epoch 1/100\n",
      "72/72 [==============================] - 2s 17ms/step - loss: 1859336.8750 - val_loss: 456880.1250\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 449049.2188 - val_loss: 641815.4375\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 335630.3750 - val_loss: 352376.0312\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 415278.5000 - val_loss: 211016.6250\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 466951.0625 - val_loss: 168647.0312\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 393839.4062 - val_loss: 610150.9375\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 280237.6562 - val_loss: 337665.0312\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 254628.6094 - val_loss: 230785.3594\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 198201.3594 - val_loss: 425728.9062\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 365632.4688 - val_loss: 374173.7812\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 344093.8750 - val_loss: 821182.8125\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 256006.8594 - val_loss: 216051.3906\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 226783.7344 - val_loss: 314593.2812\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 281208.1250 - val_loss: 390192.0938\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - ETA: 0s - loss: 339789.6250Restoring model weights from the end of the best epoch: 5.\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 339789.6250 - val_loss: 745912.6875\n",
      "Epoch 15: early stopping\n",
      "'########################################################Model0\n",
      "Epoch 1/100\n",
      "72/72 [==============================] - 3s 25ms/step - loss: 2416101.2500 - val_loss: 476746.7500\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 285985.8438 - val_loss: 554737.7500\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 450197.4375 - val_loss: 530479.6875\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 297627.4688 - val_loss: 194836.4219\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 283677.6250 - val_loss: 455641.9688\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 314255.2500 - val_loss: 302851.0000\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 244509.6719 - val_loss: 174972.7656\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 335724.1250 - val_loss: 165088.9844\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 303284.8125 - val_loss: 137415.4531\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 269134.2500 - val_loss: 329402.7812\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 250190.8125 - val_loss: 166826.5156\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 404327.5625 - val_loss: 170401.6719\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 237469.8594 - val_loss: 598076.3125\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 283000.8438 - val_loss: 142150.7344\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 174191.3750 - val_loss: 245201.9531\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 206534.7969 - val_loss: 488569.7188\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 226732.7500 - val_loss: 438238.7812\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 342420.0625 - val_loss: 182574.8438\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - ETA: 0s - loss: 281886.3750Restoring model weights from the end of the best epoch: 9.\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 281886.3750 - val_loss: 582645.0000\n",
      "Epoch 19: early stopping\n",
      "'########################################################Model1\n",
      "Epoch 1/100\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 2532538.2500 - val_loss: 331933.5625\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 440254.1875 - val_loss: 314613.0625\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 402193.1562 - val_loss: 1049279.0000\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 402206.1562 - val_loss: 201020.9844\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 406231.0000 - val_loss: 236363.6094\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 385254.9688 - val_loss: 179341.3281\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 499401.0625 - val_loss: 162883.7500\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 268864.3125 - val_loss: 244895.3125\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 297143.9375 - val_loss: 610074.1250\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 297147.1562 - val_loss: 172042.9375\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 248637.3906 - val_loss: 221060.6406\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 199615.4375 - val_loss: 225556.0625\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 310089.0312 - val_loss: 682324.8125\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 442842.1250 - val_loss: 95999.9609\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 371966.0938 - val_loss: 533906.0000\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 342750.0938 - val_loss: 384569.1562\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 302489.1250 - val_loss: 829062.9375\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 459249.1562 - val_loss: 447042.5000\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 419270.3438 - val_loss: 397914.2500\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 378949.5312 - val_loss: 788749.3750\n",
      "Epoch 21/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 200962.7188 - val_loss: 199485.7188\n",
      "Epoch 22/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 210792.7500 - val_loss: 238058.8438\n",
      "Epoch 23/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 251807.1875 - val_loss: 619445.9375\n",
      "Epoch 24/100\n",
      "70/72 [============================>.] - ETA: 0s - loss: 244546.8281Restoring model weights from the end of the best epoch: 14.\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 242854.2188 - val_loss: 206349.7969\n",
      "Epoch 24: early stopping\n",
      "'########################################################Model2\n",
      "Epoch 1/100\n",
      "72/72 [==============================] - 2s 16ms/step - loss: 1961271.1250 - val_loss: 911032.8750\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 650839.7500 - val_loss: 1053544.2500\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 922299.0000 - val_loss: 931551.3125\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 670349.5625 - val_loss: 1006690.7500\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 585409.3750 - val_loss: 925275.5000\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 738862.6250 - val_loss: 717790.6875\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 406266.3438 - val_loss: 354958.2500\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 368411.3125 - val_loss: 411893.0625\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 407890.2188 - val_loss: 424065.7500\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 326708.1562 - val_loss: 1288243.6250\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 717119.0000 - val_loss: 675222.7500\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 637204.3750 - val_loss: 884573.6250\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 547941.5625 - val_loss: 372610.2500\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 411968.3750 - val_loss: 841175.7500\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 376037.8438 - val_loss: 1053547.7500\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 416486.5938 - val_loss: 210507.6875\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 279358.9062 - val_loss: 521525.2812\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 386832.8125 - val_loss: 430313.0000\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 375899.1875 - val_loss: 226806.2344\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 378754.5312 - val_loss: 218680.2656\n",
      "Epoch 21/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 421494.2188 - val_loss: 280062.9688\n",
      "Epoch 22/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 345502.5938 - val_loss: 425338.6250\n",
      "Epoch 23/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 404763.9375 - val_loss: 114018.7812\n",
      "Epoch 24/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 466101.0000 - val_loss: 280246.2812\n",
      "Epoch 25/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 456200.0312 - val_loss: 594964.5625\n",
      "Epoch 26/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 272744.4062 - val_loss: 193555.2812\n",
      "Epoch 27/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 436690.4062 - val_loss: 472655.1250\n",
      "Epoch 28/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 415266.4375 - val_loss: 337310.7188\n",
      "Epoch 29/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 401325.6875 - val_loss: 650214.6250\n",
      "Epoch 30/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 281431.7500 - val_loss: 160360.0312\n",
      "Epoch 31/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 295673.5000 - val_loss: 170546.3438\n",
      "Epoch 32/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 214646.5000 - val_loss: 131875.4375\n",
      "Epoch 33/100\n",
      "71/72 [============================>.] - ETA: 0s - loss: 403749.7500Restoring model weights from the end of the best epoch: 23.\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 400813.9688 - val_loss: 364416.4375\n",
      "Epoch 33: early stopping\n",
      "'########################################################Model3\n",
      "Epoch 1/100\n",
      "72/72 [==============================] - 2s 16ms/step - loss: 3169344.7500 - val_loss: 188888.2188\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 382336.4062 - val_loss: 590257.3125\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 390980.6875 - val_loss: 542573.8750\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 343073.9375 - val_loss: 82399.2344\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 168246.0938 - val_loss: 285169.1875\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 197686.7656 - val_loss: 140254.8281\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 152221.0312 - val_loss: 50437.2344\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 308035.2500 - val_loss: 174649.7969\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 353268.4688 - val_loss: 287219.5625\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 228653.3906 - val_loss: 262964.5000\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 210162.3594 - val_loss: 150225.5938\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 128654.0312 - val_loss: 122304.2500\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 239546.2500 - val_loss: 184024.6250\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 172625.1250 - val_loss: 263354.5000\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 196733.4375 - val_loss: 382388.5625\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 144167.2500 - val_loss: 133856.3594\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 171152.2812 - val_loss: 36962.4219\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 226261.3750 - val_loss: 215322.2812\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 333739.8750 - val_loss: 248001.1094\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 220478.3750 - val_loss: 209615.2344\n",
      "Epoch 21/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 129036.4297 - val_loss: 98602.1641\n",
      "Epoch 22/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 249366.8906 - val_loss: 84591.1562\n",
      "Epoch 23/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 163708.2812 - val_loss: 69563.4844\n",
      "Epoch 24/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 190451.7031 - val_loss: 48433.1953\n",
      "Epoch 25/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 117047.6953 - val_loss: 88067.3906\n",
      "Epoch 26/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 114958.2422 - val_loss: 277125.6250\n",
      "Epoch 27/100\n",
      "68/72 [===========================>..] - ETA: 0s - loss: 114956.9062Restoring model weights from the end of the best epoch: 17.\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 119026.2500 - val_loss: 50876.5391\n",
      "Epoch 27: early stopping\n",
      "'########################################################Model4\n",
      "Epoch 1/100\n",
      "72/72 [==============================] - 2s 17ms/step - loss: 2207595.7500 - val_loss: 530823.0625\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 437506.7500 - val_loss: 937285.9375\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 468465.3438 - val_loss: 592257.1250\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 375976.8750 - val_loss: 326397.8438\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 317590.0938 - val_loss: 175265.3281\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 319538.8125 - val_loss: 202182.0781\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 347131.8438 - val_loss: 202573.5781\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 370646.1250 - val_loss: 670911.5000\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 432872.3125 - val_loss: 229671.7344\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 325881.5625 - val_loss: 336903.4062\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 221374.7031 - val_loss: 173411.2656\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 278146.9688 - val_loss: 117970.9219\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 233739.1719 - val_loss: 112063.7188\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 482695.5625 - val_loss: 669761.5625\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 317221.6875 - val_loss: 234865.8750\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 225029.0781 - val_loss: 695573.1875\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 227311.9375 - val_loss: 201822.2969\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 277576.2500 - val_loss: 276812.3438\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 199675.9531 - val_loss: 155621.7031\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 155673.3125 - val_loss: 155686.7344\n",
      "Epoch 21/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 174799.6250 - val_loss: 104786.7344\n",
      "Epoch 22/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 283183.6562 - val_loss: 914267.2500\n",
      "Epoch 23/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 299325.3125 - val_loss: 190666.0625\n",
      "Epoch 24/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 181418.3281 - val_loss: 212874.4531\n",
      "Epoch 25/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 180104.7500 - val_loss: 626432.2500\n",
      "Epoch 26/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 279358.5938 - val_loss: 209564.2188\n",
      "Epoch 27/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 190099.4531 - val_loss: 121760.0938\n",
      "Epoch 28/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 192596.7500 - val_loss: 97064.8750\n",
      "Epoch 29/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 149545.1094 - val_loss: 119316.7734\n",
      "Epoch 30/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 256648.3906 - val_loss: 228789.3594\n",
      "Epoch 31/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 202512.2344 - val_loss: 200947.2188\n",
      "Epoch 32/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 186899.0469 - val_loss: 143776.6094\n",
      "Epoch 33/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 253238.3906 - val_loss: 228649.8281\n",
      "Epoch 34/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 133572.5156 - val_loss: 299463.6875\n",
      "Epoch 35/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 248740.1406 - val_loss: 296805.7500\n",
      "Epoch 36/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 170909.5781 - val_loss: 100402.2969\n",
      "Epoch 37/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 182637.4062 - val_loss: 196939.5000\n",
      "Epoch 38/100\n",
      "72/72 [==============================] - ETA: 0s - loss: 172788.2969Restoring model weights from the end of the best epoch: 28.\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 172788.2969 - val_loss: 356356.0938\n",
      "Epoch 38: early stopping\n",
      "'########################################################Model5\n",
      "Epoch 1/100\n",
      "72/72 [==============================] - 2s 16ms/step - loss: 2851496.2500 - val_loss: 1032623.8750\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 721863.0000 - val_loss: 725878.6875\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 624710.8125 - val_loss: 897514.1250\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 601412.6250 - val_loss: 361368.0312\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 664213.1250 - val_loss: 608493.3750\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 885068.5000 - val_loss: 301360.0000\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 446631.1250 - val_loss: 238532.6094\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 509959.0000 - val_loss: 463539.5312\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 363711.2500 - val_loss: 317921.3750\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 490511.6562 - val_loss: 230552.3125\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 323042.7188 - val_loss: 235879.2344\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 406118.4375 - val_loss: 349952.4688\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 522266.2812 - val_loss: 184532.1562\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 516092.5000 - val_loss: 743582.0625\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 329230.3750 - val_loss: 215862.1406\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 455621.3125 - val_loss: 311147.4062\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 494452.1562 - val_loss: 645030.7500\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 403585.5000 - val_loss: 411953.0000\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 246575.6094 - val_loss: 249144.8750\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 343980.6250 - val_loss: 102563.8984\n",
      "Epoch 21/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 288354.1875 - val_loss: 597685.9375\n",
      "Epoch 22/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 380294.2500 - val_loss: 161928.2656\n",
      "Epoch 23/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 448732.8438 - val_loss: 784810.1250\n",
      "Epoch 24/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 335007.3750 - val_loss: 138134.0625\n",
      "Epoch 25/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 294806.0625 - val_loss: 444958.2188\n",
      "Epoch 26/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 428634.0938 - val_loss: 356431.8750\n",
      "Epoch 27/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 429050.1875 - val_loss: 449368.9375\n",
      "Epoch 28/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 241919.5000 - val_loss: 214562.0000\n",
      "Epoch 29/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 350872.3750 - val_loss: 398633.0000\n",
      "Epoch 30/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 248316.7812 - val_loss: 89962.9062\n",
      "Epoch 31/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 253565.5625 - val_loss: 126243.0859\n",
      "Epoch 32/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 201409.7188 - val_loss: 523057.5938\n",
      "Epoch 33/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 327881.6250 - val_loss: 489717.9688\n",
      "Epoch 34/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 226169.9688 - val_loss: 138847.7188\n",
      "Epoch 35/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 335915.4062 - val_loss: 148440.3438\n",
      "Epoch 36/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 201162.0938 - val_loss: 415474.2500\n",
      "Epoch 37/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 260181.5625 - val_loss: 461795.8438\n",
      "Epoch 38/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 197888.1406 - val_loss: 337843.7500\n",
      "Epoch 39/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 221160.6250 - val_loss: 142429.0938\n",
      "Epoch 40/100\n",
      "71/72 [============================>.] - ETA: 0s - loss: 274961.5312Restoring model weights from the end of the best epoch: 30.\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 274393.5312 - val_loss: 285229.7500\n",
      "Epoch 40: early stopping\n",
      "'########################################################Model6\n",
      "Epoch 1/100\n",
      "72/72 [==============================] - 2s 16ms/step - loss: 1501144.3750 - val_loss: 1730175.5000\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 585244.2500 - val_loss: 682678.4375\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 516784.8438 - val_loss: 472512.0625\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 749440.1250 - val_loss: 1048147.6250\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 952387.2500 - val_loss: 380926.9375\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 531215.0625 - val_loss: 894582.3125\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 429131.1562 - val_loss: 687499.5000\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 753036.6250 - val_loss: 479625.7188\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 335347.1875 - val_loss: 760736.4375\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 611461.7500 - val_loss: 428439.9688\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 347964.4375 - val_loss: 220264.7656\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 352643.5625 - val_loss: 320660.4375\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 573372.8750 - val_loss: 744873.3750\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 451686.6875 - val_loss: 276063.9062\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 363921.5938 - val_loss: 205265.7188\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 435107.5938 - val_loss: 429875.5312\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 373499.9062 - val_loss: 219729.6406\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 291942.5312 - val_loss: 181913.3594\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 389280.1875 - val_loss: 578248.2500\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 329319.9688 - val_loss: 439549.9062\n",
      "Epoch 21/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 440243.8125 - val_loss: 448128.0000\n",
      "Epoch 22/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 356959.8750 - val_loss: 233429.6875\n",
      "Epoch 23/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 401307.9688 - val_loss: 802759.3125\n",
      "Epoch 24/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 300396.2188 - val_loss: 347263.6250\n",
      "Epoch 25/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 248596.8906 - val_loss: 136658.5000\n",
      "Epoch 26/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 437867.1250 - val_loss: 315590.5938\n",
      "Epoch 27/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 470225.3438 - val_loss: 357051.9688\n",
      "Epoch 28/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 199353.0156 - val_loss: 312431.7188\n",
      "Epoch 29/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 287587.1562 - val_loss: 216836.5312\n",
      "Epoch 30/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 182663.5000 - val_loss: 174382.3281\n",
      "Epoch 31/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 359136.1562 - val_loss: 173690.6719\n",
      "Epoch 32/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 260495.8125 - val_loss: 331354.2812\n",
      "Epoch 33/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 204070.7500 - val_loss: 185526.2031\n",
      "Epoch 34/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 283482.4062 - val_loss: 315531.2812\n",
      "Epoch 35/100\n",
      "72/72 [==============================] - ETA: 0s - loss: 252115.8281Restoring model weights from the end of the best epoch: 25.\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 252115.8281 - val_loss: 206355.1094\n",
      "Epoch 35: early stopping\n",
      "'########################################################Model7\n",
      "Epoch 1/100\n",
      "72/72 [==============================] - 2s 17ms/step - loss: 1116947.8750 - val_loss: 916561.2500\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 574486.7500 - val_loss: 879989.9375\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 461616.3438 - val_loss: 1097467.0000\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 505222.7812 - val_loss: 752165.5000\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 291602.2188 - val_loss: 700368.5000\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 493503.2812 - val_loss: 122728.3984\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 324879.8750 - val_loss: 130236.4531\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 362005.5938 - val_loss: 378787.0938\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 313660.2812 - val_loss: 370622.1250\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 302360.9688 - val_loss: 263483.6562\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 354467.4375 - val_loss: 233646.3750\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 321035.6250 - val_loss: 159364.3750\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 429439.1562 - val_loss: 310515.5625\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 215564.3125 - val_loss: 242347.3906\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 588297.0625 - val_loss: 597006.2500\n",
      "Epoch 16/100\n",
      "71/72 [============================>.] - ETA: 0s - loss: 326700.8750Restoring model weights from the end of the best epoch: 6.\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 323286.5938 - val_loss: 232830.2656\n",
      "Epoch 16: early stopping\n",
      "'########################################################Model8\n",
      "Epoch 1/100\n",
      "72/72 [==============================] - 2s 16ms/step - loss: 1205520.5000 - val_loss: 1101043.2500\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 344110.7812 - val_loss: 299132.7188\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 608390.4375 - val_loss: 452163.8750\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 294240.3125 - val_loss: 806681.0000\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 647221.0000 - val_loss: 448836.1875\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 412883.4375 - val_loss: 360440.2500\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 327290.6562 - val_loss: 455096.5000\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 324613.3750 - val_loss: 411417.5312\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 271360.1562 - val_loss: 271221.7500\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 311288.3438 - val_loss: 298819.8125\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 255475.9219 - val_loss: 149357.2812\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 411866.7500 - val_loss: 259372.8594\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 557237.3750 - val_loss: 208046.8125\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 325337.6562 - val_loss: 285117.7812\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 345038.4688 - val_loss: 869932.6250\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 215084.2344 - val_loss: 212072.4219\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 207511.2969 - val_loss: 521209.5000\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 377374.8438 - val_loss: 403917.6250\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 318234.0312 - val_loss: 344255.2188\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 250711.4219 - val_loss: 176746.9375\n",
      "Epoch 21/100\n",
      "71/72 [============================>.] - ETA: 0s - loss: 224880.3125Restoring model weights from the end of the best epoch: 11.\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 224782.8125 - val_loss: 482722.3125\n",
      "Epoch 21: early stopping\n",
      "'########################################################Model9\n",
      "Epoch 1/100\n",
      "72/72 [==============================] - 2s 17ms/step - loss: 149.5487 - val_loss: 141.8409\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 136.6975 - val_loss: 140.4903\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 134.6336 - val_loss: 138.4062\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 131.2212 - val_loss: 135.5505\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 127.9260 - val_loss: 132.4076\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 127.2818 - val_loss: 135.4467\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 125.9679 - val_loss: 130.9053\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 125.1146 - val_loss: 131.5497\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 125.0675 - val_loss: 129.3212\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 124.5740 - val_loss: 129.7627\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 123.4811 - val_loss: 129.2648\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 123.8184 - val_loss: 131.2263\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 123.4209 - val_loss: 128.6691\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 122.9632 - val_loss: 129.2439\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.5522 - val_loss: 128.0799\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 122.2734 - val_loss: 127.8098\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.1139 - val_loss: 129.8932\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.4891 - val_loss: 127.5307\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.9728 - val_loss: 126.9964\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.3758 - val_loss: 128.6546\n",
      "Epoch 21/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.8356 - val_loss: 127.3272\n",
      "Epoch 22/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.9117 - val_loss: 127.7607\n",
      "Epoch 23/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 121.6167 - val_loss: 127.3954\n",
      "Epoch 24/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 121.6482 - val_loss: 127.4719\n",
      "Epoch 25/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.0636 - val_loss: 128.2232\n",
      "Epoch 26/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.7633 - val_loss: 128.6175\n",
      "Epoch 27/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.7864 - val_loss: 128.5681\n",
      "Epoch 28/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 121.5072 - val_loss: 126.7366\n",
      "Epoch 29/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.6070 - val_loss: 127.9397\n",
      "Epoch 30/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.0903 - val_loss: 126.9818\n",
      "Epoch 31/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.3690 - val_loss: 127.0155\n",
      "Epoch 32/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.3854 - val_loss: 126.2758\n",
      "Epoch 33/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.3617 - val_loss: 127.3583\n",
      "Epoch 34/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.0488 - val_loss: 126.1103\n",
      "Epoch 35/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.9216 - val_loss: 127.1332\n",
      "Epoch 36/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.1442 - val_loss: 127.8249\n",
      "Epoch 37/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 121.0626 - val_loss: 128.2547\n",
      "Epoch 38/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 120.7940 - val_loss: 125.8571\n",
      "Epoch 39/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.9977 - val_loss: 127.3456\n",
      "Epoch 40/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.2554 - val_loss: 129.0729\n",
      "Epoch 41/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.3647 - val_loss: 126.5950\n",
      "Epoch 42/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.7345 - val_loss: 126.9366\n",
      "Epoch 43/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 120.8126 - val_loss: 128.6477\n",
      "Epoch 44/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 120.7306 - val_loss: 127.1664\n",
      "Epoch 45/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 120.9483 - val_loss: 126.0629\n",
      "Epoch 46/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 120.7797 - val_loss: 125.6041\n",
      "Epoch 47/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.5564 - val_loss: 127.4047\n",
      "Epoch 48/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.6303 - val_loss: 126.4350\n",
      "Epoch 49/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.5775 - val_loss: 126.5945\n",
      "Epoch 50/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.9789 - val_loss: 126.5068\n",
      "Epoch 51/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.4076 - val_loss: 126.0582\n",
      "Epoch 52/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 120.3928 - val_loss: 127.0478\n",
      "Epoch 53/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.3970 - val_loss: 126.8612\n",
      "Epoch 54/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.4599 - val_loss: 126.3478\n",
      "Epoch 55/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.2711 - val_loss: 125.9672\n",
      "Epoch 56/100\n",
      "68/72 [===========================>..] - ETA: 0s - loss: 120.5119Restoring model weights from the end of the best epoch: 46.\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.3498 - val_loss: 126.2615\n",
      "Epoch 56: early stopping\n",
      "'########################################################Model0\n",
      "Epoch 1/100\n",
      "72/72 [==============================] - 2s 17ms/step - loss: 140.7970 - val_loss: 140.1626\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 133.9831 - val_loss: 137.3570\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 128.8668 - val_loss: 132.7587\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 126.0070 - val_loss: 130.4908\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 125.2748 - val_loss: 129.8591\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 125.0961 - val_loss: 131.3020\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 124.8492 - val_loss: 129.3381\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 123.9001 - val_loss: 129.1976\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 124.5019 - val_loss: 129.1505\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 124.0793 - val_loss: 129.0914\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 124.1032 - val_loss: 130.1497\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 123.6350 - val_loss: 129.3728\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 123.7478 - val_loss: 128.2641\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 123.5517 - val_loss: 127.9889\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 123.3509 - val_loss: 128.2651\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 123.1800 - val_loss: 129.6956\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 122.7631 - val_loss: 127.5639\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 122.7667 - val_loss: 129.8035\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 123.5194 - val_loss: 129.6326\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 122.8649 - val_loss: 128.7009\n",
      "Epoch 21/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 123.1544 - val_loss: 128.4263\n",
      "Epoch 22/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.3228 - val_loss: 128.1431\n",
      "Epoch 23/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 123.1042 - val_loss: 128.8343\n",
      "Epoch 24/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.8435 - val_loss: 127.9105\n",
      "Epoch 25/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.9107 - val_loss: 127.4115\n",
      "Epoch 26/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 122.0146 - val_loss: 126.7376\n",
      "Epoch 27/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 121.8214 - val_loss: 128.0003\n",
      "Epoch 28/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.6233 - val_loss: 127.9455\n",
      "Epoch 29/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 122.2150 - val_loss: 127.2061\n",
      "Epoch 30/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.0023 - val_loss: 127.6986\n",
      "Epoch 31/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.6532 - val_loss: 127.1850\n",
      "Epoch 32/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.8315 - val_loss: 127.2538\n",
      "Epoch 33/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.1875 - val_loss: 126.9026\n",
      "Epoch 34/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 121.5938 - val_loss: 127.8975\n",
      "Epoch 35/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.2708 - val_loss: 126.9236\n",
      "Epoch 36/100\n",
      "70/72 [============================>.] - ETA: 0s - loss: 120.8869Restoring model weights from the end of the best epoch: 26.\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 121.2447 - val_loss: 127.5753\n",
      "Epoch 36: early stopping\n",
      "'########################################################Model1\n",
      "Epoch 1/100\n",
      "72/72 [==============================] - 2s 17ms/step - loss: 136.8788 - val_loss: 138.9274\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 131.0239 - val_loss: 134.0270\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 127.3981 - val_loss: 131.2677\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 125.8692 - val_loss: 133.1454\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 125.9625 - val_loss: 132.2202\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 125.0948 - val_loss: 131.1336\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 124.5348 - val_loss: 129.5150\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 124.5508 - val_loss: 131.4503\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 124.3473 - val_loss: 130.8963\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 124.0533 - val_loss: 128.9467\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 123.7486 - val_loss: 130.6069\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 123.6352 - val_loss: 130.2496\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 123.1686 - val_loss: 128.2278\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 123.3100 - val_loss: 129.0231\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.4139 - val_loss: 128.2023\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 123.0100 - val_loss: 129.3797\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.9887 - val_loss: 128.6086\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.6304 - val_loss: 128.8792\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.1030 - val_loss: 127.9953\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 122.6933 - val_loss: 127.6764\n",
      "Epoch 21/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.6047 - val_loss: 129.3285\n",
      "Epoch 22/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.4097 - val_loss: 127.5777\n",
      "Epoch 23/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.3493 - val_loss: 129.6445\n",
      "Epoch 24/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 122.2295 - val_loss: 126.9411\n",
      "Epoch 25/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 121.7476 - val_loss: 127.1732\n",
      "Epoch 26/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.6873 - val_loss: 126.6540\n",
      "Epoch 27/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.6099 - val_loss: 127.2678\n",
      "Epoch 28/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.6926 - val_loss: 127.4964\n",
      "Epoch 29/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.7444 - val_loss: 127.7612\n",
      "Epoch 30/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.3501 - val_loss: 127.9378\n",
      "Epoch 31/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.2348 - val_loss: 127.2723\n",
      "Epoch 32/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.5801 - val_loss: 127.3888\n",
      "Epoch 33/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.6128 - val_loss: 127.6220\n",
      "Epoch 34/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.0145 - val_loss: 126.0304\n",
      "Epoch 35/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.2141 - val_loss: 127.6570\n",
      "Epoch 36/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 121.1779 - val_loss: 126.9850\n",
      "Epoch 37/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.1449 - val_loss: 127.7085\n",
      "Epoch 38/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.2770 - val_loss: 126.9406\n",
      "Epoch 39/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.4398 - val_loss: 126.0710\n",
      "Epoch 40/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 120.8177 - val_loss: 128.2327\n",
      "Epoch 41/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.6985 - val_loss: 126.0403\n",
      "Epoch 42/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.0495 - val_loss: 127.0442\n",
      "Epoch 43/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.0060 - val_loss: 126.2778\n",
      "Epoch 44/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.7408 - val_loss: 125.6589\n",
      "Epoch 45/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.4487 - val_loss: 126.4092\n",
      "Epoch 46/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.4362 - val_loss: 127.3850\n",
      "Epoch 47/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.5942 - val_loss: 126.1036\n",
      "Epoch 48/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.4094 - val_loss: 125.7696\n",
      "Epoch 49/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.4060 - val_loss: 125.8527\n",
      "Epoch 50/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.2046 - val_loss: 125.4333\n",
      "Epoch 51/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.9098 - val_loss: 127.3700\n",
      "Epoch 52/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.6516 - val_loss: 126.9271\n",
      "Epoch 53/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.1596 - val_loss: 126.2363\n",
      "Epoch 54/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.4250 - val_loss: 125.8297\n",
      "Epoch 55/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 119.9690 - val_loss: 125.4228\n",
      "Epoch 56/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 120.0449 - val_loss: 128.1171\n",
      "Epoch 57/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.1818 - val_loss: 125.8836\n",
      "Epoch 58/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 119.7031 - val_loss: 125.1743\n",
      "Epoch 59/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 119.8719 - val_loss: 127.1652\n",
      "Epoch 60/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.6167 - val_loss: 125.0336\n",
      "Epoch 61/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.0010 - val_loss: 125.6440\n",
      "Epoch 62/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 119.8487 - val_loss: 125.0259\n",
      "Epoch 63/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 119.6287 - val_loss: 125.6261\n",
      "Epoch 64/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 119.7630 - val_loss: 125.6330\n",
      "Epoch 65/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 119.7638 - val_loss: 125.9437\n",
      "Epoch 66/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 120.5781 - val_loss: 126.0462\n",
      "Epoch 67/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 119.8172 - val_loss: 124.8610\n",
      "Epoch 68/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 119.8009 - val_loss: 125.1076\n",
      "Epoch 69/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 119.5607 - val_loss: 124.6914\n",
      "Epoch 70/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.0110 - val_loss: 127.0835\n",
      "Epoch 71/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 119.8389 - val_loss: 124.4812\n",
      "Epoch 72/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 119.8642 - val_loss: 125.0586\n",
      "Epoch 73/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 119.4710 - val_loss: 124.9680\n",
      "Epoch 74/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 119.9122 - val_loss: 125.5832\n",
      "Epoch 75/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 119.6135 - val_loss: 125.6433\n",
      "Epoch 76/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 119.7668 - val_loss: 125.3186\n",
      "Epoch 77/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 120.0191 - val_loss: 125.4470\n",
      "Epoch 78/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 119.6355 - val_loss: 125.3702\n",
      "Epoch 79/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 119.4595 - val_loss: 124.7590\n",
      "Epoch 80/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 119.7395 - val_loss: 125.7414\n",
      "Epoch 81/100\n",
      "72/72 [==============================] - ETA: 0s - loss: 120.0995Restoring model weights from the end of the best epoch: 71.\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.0995 - val_loss: 126.4075\n",
      "Epoch 81: early stopping\n",
      "'########################################################Model2\n",
      "Epoch 1/100\n",
      "72/72 [==============================] - 2s 16ms/step - loss: 143.8311 - val_loss: 140.7055\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 135.3130 - val_loss: 139.1867\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 132.5137 - val_loss: 135.2254\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 127.9586 - val_loss: 133.6016\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 126.1561 - val_loss: 131.0176\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 125.7307 - val_loss: 131.4312\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 125.2945 - val_loss: 129.9399\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 124.3396 - val_loss: 129.9495\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 123.6088 - val_loss: 128.9785\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 123.2267 - val_loss: 129.0983\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 123.6359 - val_loss: 129.8611\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 123.5666 - val_loss: 130.8631\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 122.7939 - val_loss: 127.9019\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 122.5791 - val_loss: 128.4693\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.5288 - val_loss: 128.8414\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.4401 - val_loss: 127.9953\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.2418 - val_loss: 128.3817\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 122.6285 - val_loss: 127.3778\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 122.4813 - val_loss: 127.6980\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 122.3038 - val_loss: 129.4323\n",
      "Epoch 21/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 122.1666 - val_loss: 128.1918\n",
      "Epoch 22/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.4090 - val_loss: 128.6639\n",
      "Epoch 23/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.6934 - val_loss: 127.8201\n",
      "Epoch 24/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.5540 - val_loss: 126.9623\n",
      "Epoch 25/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 121.4350 - val_loss: 127.4894\n",
      "Epoch 26/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.0331 - val_loss: 130.1417\n",
      "Epoch 27/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 121.6766 - val_loss: 128.0562\n",
      "Epoch 28/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 121.4352 - val_loss: 126.4606\n",
      "Epoch 29/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.7608 - val_loss: 127.5608\n",
      "Epoch 30/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.3013 - val_loss: 126.9975\n",
      "Epoch 31/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.5570 - val_loss: 127.0424\n",
      "Epoch 32/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.4033 - val_loss: 127.3758\n",
      "Epoch 33/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.1102 - val_loss: 126.5519\n",
      "Epoch 34/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.3346 - val_loss: 126.7702\n",
      "Epoch 35/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.3964 - val_loss: 127.2833\n",
      "Epoch 36/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.1146 - val_loss: 127.6012\n",
      "Epoch 37/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.1977 - val_loss: 128.0265\n",
      "Epoch 38/100\n",
      "71/72 [============================>.] - ETA: 0s - loss: 121.1712Restoring model weights from the end of the best epoch: 28.\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.1971 - val_loss: 128.2091\n",
      "Epoch 38: early stopping\n",
      "'########################################################Model3\n",
      "Epoch 1/100\n",
      "72/72 [==============================] - 2s 17ms/step - loss: 149.2375 - val_loss: 142.0201\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 136.8034 - val_loss: 140.7050\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 134.6919 - val_loss: 137.8529\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 129.3590 - val_loss: 132.7762\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 126.9894 - val_loss: 132.5118\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 125.8712 - val_loss: 131.5640\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 126.0890 - val_loss: 132.1378\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 124.9998 - val_loss: 130.8017\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 124.1784 - val_loss: 129.8969\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 124.2731 - val_loss: 130.2866\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 123.2893 - val_loss: 128.7216\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 123.5029 - val_loss: 132.6989\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 124.6455 - val_loss: 127.9139\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 123.7394 - val_loss: 127.8673\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.6384 - val_loss: 128.9154\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.0719 - val_loss: 127.2489\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.3449 - val_loss: 128.3945\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 122.0799 - val_loss: 128.9391\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.9846 - val_loss: 127.0954\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.5262 - val_loss: 130.7720\n",
      "Epoch 21/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.6264 - val_loss: 129.7211\n",
      "Epoch 22/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.9413 - val_loss: 127.2155\n",
      "Epoch 23/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.6014 - val_loss: 128.1428\n",
      "Epoch 24/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 123.4152 - val_loss: 127.4594\n",
      "Epoch 25/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.8340 - val_loss: 128.1427\n",
      "Epoch 26/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.3869 - val_loss: 127.0619\n",
      "Epoch 27/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 121.5328 - val_loss: 128.9235\n",
      "Epoch 28/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 122.0191 - val_loss: 128.5816\n",
      "Epoch 29/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.2393 - val_loss: 127.0118\n",
      "Epoch 30/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.2595 - val_loss: 128.2125\n",
      "Epoch 31/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.1833 - val_loss: 127.4787\n",
      "Epoch 32/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.2370 - val_loss: 126.3451\n",
      "Epoch 33/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.1328 - val_loss: 126.3396\n",
      "Epoch 34/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.8193 - val_loss: 128.0050\n",
      "Epoch 35/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.0561 - val_loss: 128.2946\n",
      "Epoch 36/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.1000 - val_loss: 126.4712\n",
      "Epoch 37/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.3704 - val_loss: 127.8342\n",
      "Epoch 38/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 121.3248 - val_loss: 126.5295\n",
      "Epoch 39/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.1339 - val_loss: 125.8288\n",
      "Epoch 40/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 120.9315 - val_loss: 129.0278\n",
      "Epoch 41/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.1946 - val_loss: 125.7913\n",
      "Epoch 42/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 120.9901 - val_loss: 125.4759\n",
      "Epoch 43/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.8403 - val_loss: 125.5111\n",
      "Epoch 44/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 120.5108 - val_loss: 126.1614\n",
      "Epoch 45/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 120.5641 - val_loss: 125.3912\n",
      "Epoch 46/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 121.0279 - val_loss: 127.3245\n",
      "Epoch 47/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.4315 - val_loss: 125.5393\n",
      "Epoch 48/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.0443 - val_loss: 127.6343\n",
      "Epoch 49/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.6675 - val_loss: 125.6895\n",
      "Epoch 50/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.3757 - val_loss: 125.7522\n",
      "Epoch 51/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 120.4200 - val_loss: 127.7983\n",
      "Epoch 52/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.9748 - val_loss: 126.3596\n",
      "Epoch 53/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.4156 - val_loss: 126.8161\n",
      "Epoch 54/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 120.5644 - val_loss: 127.3807\n",
      "Epoch 55/100\n",
      "71/72 [============================>.] - ETA: 0s - loss: 120.6308Restoring model weights from the end of the best epoch: 45.\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.5529 - val_loss: 125.9515\n",
      "Epoch 55: early stopping\n",
      "'########################################################Model4\n",
      "Epoch 1/100\n",
      "72/72 [==============================] - 2s 17ms/step - loss: 149.2604 - val_loss: 141.5996\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 136.1186 - val_loss: 140.0226\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 132.3740 - val_loss: 134.7640\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 128.1771 - val_loss: 132.7046\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 127.1026 - val_loss: 133.4899\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 126.4088 - val_loss: 132.7702\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 126.2045 - val_loss: 130.7321\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 124.6553 - val_loss: 130.0859\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 124.4868 - val_loss: 130.5242\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 124.0789 - val_loss: 129.0934\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 123.7983 - val_loss: 129.7543\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 123.5963 - val_loss: 128.5569\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 123.5324 - val_loss: 129.2128\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.8238 - val_loss: 128.0047\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.8028 - val_loss: 127.7434\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 123.0126 - val_loss: 128.5294\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.5343 - val_loss: 128.0129\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.1922 - val_loss: 127.9056\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 122.1442 - val_loss: 127.7970\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.1609 - val_loss: 127.6411\n",
      "Epoch 21/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.7963 - val_loss: 127.1143\n",
      "Epoch 22/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.6043 - val_loss: 128.6039\n",
      "Epoch 23/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 122.2032 - val_loss: 127.0227\n",
      "Epoch 24/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 122.0272 - val_loss: 128.2344\n",
      "Epoch 25/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.7407 - val_loss: 128.2692\n",
      "Epoch 26/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 121.4415 - val_loss: 126.6801\n",
      "Epoch 27/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.5284 - val_loss: 127.7905\n",
      "Epoch 28/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.6712 - val_loss: 127.7165\n",
      "Epoch 29/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.8754 - val_loss: 127.0584\n",
      "Epoch 30/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 121.4729 - val_loss: 129.0614\n",
      "Epoch 31/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.9920 - val_loss: 128.0787\n",
      "Epoch 32/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.1283 - val_loss: 127.2700\n",
      "Epoch 33/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 120.9648 - val_loss: 126.0385\n",
      "Epoch 34/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.8978 - val_loss: 126.7720\n",
      "Epoch 35/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.0058 - val_loss: 126.6982\n",
      "Epoch 36/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.2963 - val_loss: 126.5747\n",
      "Epoch 37/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.1528 - val_loss: 126.7530\n",
      "Epoch 38/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.8854 - val_loss: 126.1980\n",
      "Epoch 39/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.8770 - val_loss: 126.0007\n",
      "Epoch 40/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.8405 - val_loss: 127.8653\n",
      "Epoch 41/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 121.0032 - val_loss: 126.4876\n",
      "Epoch 42/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.2871 - val_loss: 126.3546\n",
      "Epoch 43/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.4553 - val_loss: 125.3119\n",
      "Epoch 44/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.6724 - val_loss: 127.9918\n",
      "Epoch 45/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 120.5772 - val_loss: 129.1059\n",
      "Epoch 46/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.6976 - val_loss: 126.0963\n",
      "Epoch 47/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.2905 - val_loss: 126.6737\n",
      "Epoch 48/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.9662 - val_loss: 125.6161\n",
      "Epoch 49/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.2272 - val_loss: 126.3747\n",
      "Epoch 50/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.2188 - val_loss: 125.8989\n",
      "Epoch 51/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.2169 - val_loss: 125.7942\n",
      "Epoch 52/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.3931 - val_loss: 127.2873\n",
      "Epoch 53/100\n",
      "71/72 [============================>.] - ETA: 0s - loss: 120.7036Restoring model weights from the end of the best epoch: 43.\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.4739 - val_loss: 125.5425\n",
      "Epoch 53: early stopping\n",
      "'########################################################Model5\n",
      "Epoch 1/100\n",
      "72/72 [==============================] - 2s 17ms/step - loss: 144.9348 - val_loss: 140.9711\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 135.6586 - val_loss: 139.5122\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 132.5919 - val_loss: 134.9649\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 127.8646 - val_loss: 132.5747\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 126.2998 - val_loss: 131.2968\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 126.1259 - val_loss: 130.4014\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 124.7433 - val_loss: 129.2831\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 124.1008 - val_loss: 129.4676\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 124.3813 - val_loss: 129.1184\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 123.7608 - val_loss: 130.3851\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 124.1387 - val_loss: 130.9538\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 123.6823 - val_loss: 128.1814\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 122.8645 - val_loss: 130.3135\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 123.7075 - val_loss: 130.3701\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.9730 - val_loss: 129.0486\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.5382 - val_loss: 127.9770\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.2155 - val_loss: 129.2651\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.8303 - val_loss: 128.6049\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 123.0452 - val_loss: 128.7308\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.0741 - val_loss: 127.6867\n",
      "Epoch 21/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.9685 - val_loss: 127.9477\n",
      "Epoch 22/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 123.1629 - val_loss: 128.0802\n",
      "Epoch 23/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.0210 - val_loss: 130.0310\n",
      "Epoch 24/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.0225 - val_loss: 127.1055\n",
      "Epoch 25/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.4108 - val_loss: 130.6023\n",
      "Epoch 26/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.4159 - val_loss: 127.1711\n",
      "Epoch 27/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 122.0785 - val_loss: 127.2856\n",
      "Epoch 28/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.0331 - val_loss: 128.5261\n",
      "Epoch 29/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.2130 - val_loss: 127.2437\n",
      "Epoch 30/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.7723 - val_loss: 127.6968\n",
      "Epoch 31/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.9838 - val_loss: 129.4572\n",
      "Epoch 32/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.3934 - val_loss: 127.3347\n",
      "Epoch 33/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 121.5893 - val_loss: 127.4546\n",
      "Epoch 34/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.4319 - val_loss: 126.5664\n",
      "Epoch 35/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.3053 - val_loss: 128.1959\n",
      "Epoch 36/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 121.4544 - val_loss: 127.8155\n",
      "Epoch 37/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.9004 - val_loss: 127.5505\n",
      "Epoch 38/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.0359 - val_loss: 126.8223\n",
      "Epoch 39/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.8770 - val_loss: 126.2391\n",
      "Epoch 40/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.8844 - val_loss: 128.1222\n",
      "Epoch 41/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.2450 - val_loss: 126.5939\n",
      "Epoch 42/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 120.6820 - val_loss: 129.1995\n",
      "Epoch 43/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.6225 - val_loss: 126.1349\n",
      "Epoch 44/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.5468 - val_loss: 127.0462\n",
      "Epoch 45/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 120.9843 - val_loss: 126.5718\n",
      "Epoch 46/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.7547 - val_loss: 125.9746\n",
      "Epoch 47/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.4874 - val_loss: 126.9325\n",
      "Epoch 48/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.3791 - val_loss: 126.6976\n",
      "Epoch 49/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 120.7205 - val_loss: 125.8638\n",
      "Epoch 50/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.2646 - val_loss: 125.8179\n",
      "Epoch 51/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 120.2687 - val_loss: 125.8442\n",
      "Epoch 52/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 120.4310 - val_loss: 126.5407\n",
      "Epoch 53/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 120.5520 - val_loss: 126.8857\n",
      "Epoch 54/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.7261 - val_loss: 126.2758\n",
      "Epoch 55/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 120.7748 - val_loss: 126.1718\n",
      "Epoch 56/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.0415 - val_loss: 125.3321\n",
      "Epoch 57/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.5337 - val_loss: 127.0004\n",
      "Epoch 58/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.6148 - val_loss: 128.0104\n",
      "Epoch 59/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.5210 - val_loss: 126.9551\n",
      "Epoch 60/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 120.8810 - val_loss: 127.9979\n",
      "Epoch 61/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.5980 - val_loss: 126.7315\n",
      "Epoch 62/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.2464 - val_loss: 127.3319\n",
      "Epoch 63/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 120.2439 - val_loss: 126.7821\n",
      "Epoch 64/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.5126 - val_loss: 125.9857\n",
      "Epoch 65/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 119.8816 - val_loss: 125.9298\n",
      "Epoch 66/100\n",
      "71/72 [============================>.] - ETA: 0s - loss: 120.9091Restoring model weights from the end of the best epoch: 56.\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.8586 - val_loss: 125.5636\n",
      "Epoch 66: early stopping\n",
      "'########################################################Model6\n",
      "Epoch 1/100\n",
      "72/72 [==============================] - 2s 17ms/step - loss: 157.0936 - val_loss: 142.2971\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 136.5811 - val_loss: 139.9164\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 132.9003 - val_loss: 135.7339\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 128.3832 - val_loss: 135.5437\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 127.1893 - val_loss: 135.0914\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 126.4772 - val_loss: 131.8995\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 125.6143 - val_loss: 130.3004\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 127.0164 - val_loss: 133.0802\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 125.3474 - val_loss: 130.6861\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 124.7570 - val_loss: 130.1985\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 126.1423 - val_loss: 130.7346\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 124.4070 - val_loss: 128.8409\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 124.0987 - val_loss: 129.8100\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 123.7838 - val_loss: 129.5867\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 123.4566 - val_loss: 129.3341\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 124.0798 - val_loss: 132.6413\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 125.0204 - val_loss: 130.9055\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 123.4153 - val_loss: 128.2381\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 123.4852 - val_loss: 129.3662\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 123.1121 - val_loss: 129.4973\n",
      "Epoch 21/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 123.1805 - val_loss: 128.3925\n",
      "Epoch 22/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 123.1030 - val_loss: 129.4783\n",
      "Epoch 23/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 123.0236 - val_loss: 129.3519\n",
      "Epoch 24/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.7344 - val_loss: 128.6770\n",
      "Epoch 25/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 122.3629 - val_loss: 128.4967\n",
      "Epoch 26/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 123.2734 - val_loss: 128.4315\n",
      "Epoch 27/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.2481 - val_loss: 128.0599\n",
      "Epoch 28/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.7946 - val_loss: 127.9811\n",
      "Epoch 29/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.2880 - val_loss: 127.4913\n",
      "Epoch 30/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.9893 - val_loss: 129.5027\n",
      "Epoch 31/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.5819 - val_loss: 127.8765\n",
      "Epoch 32/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 123.1118 - val_loss: 129.9075\n",
      "Epoch 33/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.4309 - val_loss: 127.7159\n",
      "Epoch 34/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.2497 - val_loss: 128.5533\n",
      "Epoch 35/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.5469 - val_loss: 129.8703\n",
      "Epoch 36/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.3383 - val_loss: 129.8690\n",
      "Epoch 37/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.5558 - val_loss: 127.0792\n",
      "Epoch 38/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.7027 - val_loss: 127.3487\n",
      "Epoch 39/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.8675 - val_loss: 127.4842\n",
      "Epoch 40/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.0105 - val_loss: 128.4153\n",
      "Epoch 41/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.5533 - val_loss: 126.9707\n",
      "Epoch 42/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.4843 - val_loss: 127.8216\n",
      "Epoch 43/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.9846 - val_loss: 127.0722\n",
      "Epoch 44/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.6845 - val_loss: 127.9242\n",
      "Epoch 45/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.4317 - val_loss: 126.9150\n",
      "Epoch 46/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.0084 - val_loss: 126.6819\n",
      "Epoch 47/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.3820 - val_loss: 126.8957\n",
      "Epoch 48/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.0733 - val_loss: 127.3575\n",
      "Epoch 49/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.8852 - val_loss: 126.5778\n",
      "Epoch 50/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.8435 - val_loss: 127.0689\n",
      "Epoch 51/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 121.1826 - val_loss: 126.9765\n",
      "Epoch 52/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.0435 - val_loss: 129.3360\n",
      "Epoch 53/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.4659 - val_loss: 126.0373\n",
      "Epoch 54/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.6685 - val_loss: 127.5702\n",
      "Epoch 55/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.3762 - val_loss: 126.2557\n",
      "Epoch 56/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.0347 - val_loss: 125.9706\n",
      "Epoch 57/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.3430 - val_loss: 127.6447\n",
      "Epoch 58/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.0655 - val_loss: 126.1719\n",
      "Epoch 59/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.4529 - val_loss: 126.0243\n",
      "Epoch 60/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.8917 - val_loss: 126.1531\n",
      "Epoch 61/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.0094 - val_loss: 126.5436\n",
      "Epoch 62/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.0508 - val_loss: 126.4181\n",
      "Epoch 63/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.1166 - val_loss: 125.9285\n",
      "Epoch 64/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.8808 - val_loss: 126.6810\n",
      "Epoch 65/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.4999 - val_loss: 126.0955\n",
      "Epoch 66/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.7328 - val_loss: 126.0123\n",
      "Epoch 67/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.1987 - val_loss: 127.8984\n",
      "Epoch 68/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.7932 - val_loss: 126.1487\n",
      "Epoch 69/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.6684 - val_loss: 126.3108\n",
      "Epoch 70/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.0232 - val_loss: 126.3275\n",
      "Epoch 71/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.8897 - val_loss: 127.8441\n",
      "Epoch 72/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.5512 - val_loss: 126.8806\n",
      "Epoch 73/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.4315 - val_loss: 125.1236\n",
      "Epoch 74/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 120.3471 - val_loss: 127.3911\n",
      "Epoch 75/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.9158 - val_loss: 126.6794\n",
      "Epoch 76/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.9435 - val_loss: 126.0280\n",
      "Epoch 77/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.9703 - val_loss: 126.6855\n",
      "Epoch 78/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.7476 - val_loss: 126.1037\n",
      "Epoch 79/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.7154 - val_loss: 127.6045\n",
      "Epoch 80/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.0207 - val_loss: 128.8660\n",
      "Epoch 81/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.5642 - val_loss: 126.7510\n",
      "Epoch 82/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.3533 - val_loss: 125.9032\n",
      "Epoch 83/100\n",
      "68/72 [===========================>..] - ETA: 0s - loss: 120.5831Restoring model weights from the end of the best epoch: 73.\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.5810 - val_loss: 126.1530\n",
      "Epoch 83: early stopping\n",
      "'########################################################Model7\n",
      "Epoch 1/100\n",
      "72/72 [==============================] - 2s 17ms/step - loss: 148.0188 - val_loss: 141.2249\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 135.7577 - val_loss: 139.8327\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 133.5869 - val_loss: 137.4216\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 129.5527 - val_loss: 132.2104\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 127.8029 - val_loss: 131.8573\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 126.3560 - val_loss: 131.4686\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 125.2515 - val_loss: 130.7320\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 125.1270 - val_loss: 130.4160\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 124.8761 - val_loss: 129.7644\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 124.7901 - val_loss: 131.8192\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 124.2794 - val_loss: 130.0456\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 123.7606 - val_loss: 129.2095\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 123.5932 - val_loss: 128.9626\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 123.5840 - val_loss: 128.3777\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 123.3644 - val_loss: 131.1022\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 123.5455 - val_loss: 129.4713\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.9181 - val_loss: 129.2120\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 122.8354 - val_loss: 127.7806\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.3860 - val_loss: 128.0006\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.3198 - val_loss: 129.9799\n",
      "Epoch 21/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.7065 - val_loss: 127.9552\n",
      "Epoch 22/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.2123 - val_loss: 128.2208\n",
      "Epoch 23/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.0395 - val_loss: 127.6427\n",
      "Epoch 24/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.9682 - val_loss: 127.7013\n",
      "Epoch 25/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 121.9657 - val_loss: 128.1474\n",
      "Epoch 26/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.7335 - val_loss: 127.6772\n",
      "Epoch 27/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.9093 - val_loss: 127.2190\n",
      "Epoch 28/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 122.3662 - val_loss: 127.3803\n",
      "Epoch 29/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.5941 - val_loss: 127.5138\n",
      "Epoch 30/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.7838 - val_loss: 127.3054\n",
      "Epoch 31/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.9386 - val_loss: 127.2736\n",
      "Epoch 32/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.2792 - val_loss: 126.9737\n",
      "Epoch 33/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 121.4609 - val_loss: 127.0642\n",
      "Epoch 34/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.2735 - val_loss: 126.4527\n",
      "Epoch 35/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.5230 - val_loss: 126.4953\n",
      "Epoch 36/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.6948 - val_loss: 126.8248\n",
      "Epoch 37/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.9268 - val_loss: 128.7121\n",
      "Epoch 38/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 121.8336 - val_loss: 127.4886\n",
      "Epoch 39/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.1375 - val_loss: 126.3266\n",
      "Epoch 40/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.5917 - val_loss: 128.1228\n",
      "Epoch 41/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.6251 - val_loss: 126.4191\n",
      "Epoch 42/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.8043 - val_loss: 126.0762\n",
      "Epoch 43/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.0444 - val_loss: 126.6646\n",
      "Epoch 44/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.2460 - val_loss: 127.6865\n",
      "Epoch 45/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.9625 - val_loss: 126.4644\n",
      "Epoch 46/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 121.1360 - val_loss: 127.0134\n",
      "Epoch 47/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.6133 - val_loss: 126.5797\n",
      "Epoch 48/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.7446 - val_loss: 127.0173\n",
      "Epoch 49/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.3757 - val_loss: 126.6213\n",
      "Epoch 50/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.9860 - val_loss: 126.1822\n",
      "Epoch 51/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 121.0009 - val_loss: 129.0744\n",
      "Epoch 52/100\n",
      "70/72 [============================>.] - ETA: 0s - loss: 121.2644Restoring model weights from the end of the best epoch: 42.\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.2551 - val_loss: 126.4858\n",
      "Epoch 52: early stopping\n",
      "'########################################################Model8\n",
      "Epoch 1/100\n",
      "72/72 [==============================] - 2s 17ms/step - loss: 143.9757 - val_loss: 140.5459\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 134.2751 - val_loss: 137.3760\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 129.6432 - val_loss: 132.4355\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 127.5902 - val_loss: 132.3681\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 126.1574 - val_loss: 130.4583\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 125.0983 - val_loss: 129.9955\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 125.2952 - val_loss: 129.6415\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 123.7805 - val_loss: 129.3114\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 123.2952 - val_loss: 129.1518\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 123.9053 - val_loss: 130.7262\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 123.3674 - val_loss: 128.4417\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.9886 - val_loss: 127.7139\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.5186 - val_loss: 127.8330\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.5643 - val_loss: 128.6883\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.4247 - val_loss: 128.7327\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 123.1425 - val_loss: 128.2836\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.7865 - val_loss: 128.2434\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.8560 - val_loss: 127.0194\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.2594 - val_loss: 127.7989\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 122.3683 - val_loss: 127.5000\n",
      "Epoch 21/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 121.7163 - val_loss: 129.0981\n",
      "Epoch 22/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 121.6691 - val_loss: 127.1629\n",
      "Epoch 23/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.8553 - val_loss: 127.2341\n",
      "Epoch 24/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 121.4428 - val_loss: 128.3823\n",
      "Epoch 25/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 122.4310 - val_loss: 126.3310\n",
      "Epoch 26/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.4285 - val_loss: 126.7716\n",
      "Epoch 27/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.5270 - val_loss: 126.4978\n",
      "Epoch 28/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 121.1173 - val_loss: 126.4749\n",
      "Epoch 29/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 120.9728 - val_loss: 128.2691\n",
      "Epoch 30/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 121.0353 - val_loss: 127.0371\n",
      "Epoch 31/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 121.7953 - val_loss: 127.2085\n",
      "Epoch 32/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 121.1992 - val_loss: 127.5643\n",
      "Epoch 33/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 121.0039 - val_loss: 126.9911\n",
      "Epoch 34/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 121.3816 - val_loss: 126.7120\n",
      "Epoch 35/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 121.5502 - val_loss: 126.3160\n",
      "Epoch 36/100\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 121.3834 - val_loss: 127.6238\n",
      "Epoch 37/100\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 120.8363 - val_loss: 126.7612\n",
      "Epoch 38/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 120.4642 - val_loss: 125.7683\n",
      "Epoch 39/100\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 120.6630 - val_loss: 125.8845\n",
      "Epoch 40/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 120.8015 - val_loss: 128.9387\n",
      "Epoch 41/100\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 121.1987 - val_loss: 126.2916\n",
      "Epoch 42/100\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 120.6872 - val_loss: 126.1641\n",
      "Epoch 43/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 120.2150 - val_loss: 125.8150\n",
      "Epoch 44/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 120.3128 - val_loss: 126.8891\n",
      "Epoch 45/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 120.6274 - val_loss: 126.9354\n",
      "Epoch 46/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 120.3382 - val_loss: 126.7786\n",
      "Epoch 47/100\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 120.4413 - val_loss: 125.8676\n",
      "Epoch 48/100\n",
      "70/72 [============================>.] - ETA: 0s - loss: 119.9455Restoring model weights from the end of the best epoch: 38.\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 120.1987 - val_loss: 126.5167\n",
      "Epoch 48: early stopping\n",
      "'########################################################Model9\n"
     ]
    }
   ],
   "source": [
    "model_num = 10\n",
    "\n",
    "\n",
    "mase_models = train_bagging_models(model_num, MASE(y_train,24),100,10,8,0.001)\n",
    "mape_models = train_bagging_models(model_num,'mape',100,10,8,0.001)\n",
    "smape_models = train_bagging_models(model_num, SMAPE(),100,10,8,0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b35de203-07f8-48f9-8ede-0a0bcba1ea27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 5ms/step\n",
      "12/12 [==============================] - 0s 8ms/step\n",
      "12/12 [==============================] - 0s 5ms/step\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "12/12 [==============================] - 0s 8ms/step\n",
      "12/12 [==============================] - 0s 8ms/step\n",
      "12/12 [==============================] - 0s 8ms/step\n",
      "12/12 [==============================] - 0s 6ms/step\n",
      "12/12 [==============================] - 0s 8ms/step\n",
      "12/12 [==============================] - 0s 8ms/step\n",
      "12/12 [==============================] - 0s 8ms/step\n",
      "12/12 [==============================] - 1s 7ms/step\n",
      "12/12 [==============================] - 0s 8ms/step\n",
      "12/12 [==============================] - 0s 8ms/step\n",
      "12/12 [==============================] - 0s 6ms/step\n",
      "12/12 [==============================] - 0s 5ms/step\n",
      "12/12 [==============================] - 0s 5ms/step\n",
      "12/12 [==============================] - 0s 5ms/step\n",
      "12/12 [==============================] - 0s 5ms/step\n",
      "12/12 [==============================] - 0s 5ms/step\n",
      "12/12 [==============================] - 0s 8ms/step\n",
      "12/12 [==============================] - 0s 5ms/step\n",
      "12/12 [==============================] - 0s 8ms/step\n",
      "12/12 [==============================] - 0s 8ms/step\n",
      "12/12 [==============================] - 0s 7ms/step\n",
      "12/12 [==============================] - 0s 8ms/step\n",
      "12/12 [==============================] - 0s 8ms/step\n",
      "12/12 [==============================] - 0s 8ms/step\n",
      "12/12 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.23775922444365957, 0.2417236099818133)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred1,_=smape_models\n",
    "pred2,_=mase_models\n",
    "pred3,_=mape_models\n",
    "\n",
    "smape_predictions = bagging_predict2(pred1, test_X)\n",
    "mase_predictions = bagging_predict2(pred2, test_X)\n",
    "mape_predictions = bagging_predict2(pred3, test_X)\n",
    "concat = np.concatenate([smape_predictions, mase_predictions,mape_predictions],axis=0)\n",
    "fin_pred = np.median(concat,axis=0)\n",
    "#pd.DataFrame(fin_pred).to_csv(\"freezing_I.csv\")\n",
    "mean_squared_error(test_y.flatten(),fin_pred.flatten()),mean_absolute_error(test_y.flatten(),fin_pred.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c80efe85-f798-42c9-b7c2-9756f51cf6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(fin_pred.reshape(-1,24)).to_csv(\"../result7_new/LSTM/pred_mid.csv\")\n",
    "for i in range(10):\n",
    "    pd.DataFrame(concat[i].reshape(-1,24)).to_csv(f\"../result7_new/LSTM/pred{i}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
