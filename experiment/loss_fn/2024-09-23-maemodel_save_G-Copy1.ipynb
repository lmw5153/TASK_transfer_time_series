{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ebab801-077c-43dc-9f56-b335c1d5fcae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-21 00:54:56.777467: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-21 00:54:56.855044: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-09-21 00:54:56.855063: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-09-21 00:54:57.271403: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-09-21 00:54:57.271462: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-09-21 00:54:57.271468: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nbeats_keras.model import NBeatsNet as NBeatsKeras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "#from nbeats_pytorch.model import NBeatsNet as NBeatsPytorch\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "import time\n",
    "from keras.models import load_model\n",
    "#from target_data_electronic70_7 import target_X, target_y ,test_X, test_y\n",
    "#from m4databasis21_7 import base_domain,zt_in,zt_out,M4Meta,inputsize,train_12,train_12_y\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error,mean_absolute_percentage_error\n",
    "from tensorflow.keras.losses import Loss\n",
    "import tensorflow as tf\n",
    "#from m4databasis35_7_70_7 import train_35,train_35_y,train_70,train_70_y\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, LayerNormalization, MultiHeadAttention, Dropout, Add, Concatenate,Flatten,Reshape\n",
    "#import pandas as pd\n",
    "#####################################################################################\n",
    "X_train = pd.read_csv(\"../data/M4_train.csv\").iloc[:,(1):].values \n",
    "y_train = pd.read_csv(\"../data/M4_test.csv\").iloc[:,1:].values\n",
    "X_train.shape[1], y_train.shape[1]\n",
    "target_X= pd.read_csv(\"../data/ele_train_input_7.csv\").iloc[:,1:].values.astype(np.float32)/10000\n",
    "target_y =pd.read_csv(\"../data/ele_train_output_7.csv\").iloc[:,1:].values.astype(np.float32)/10000\n",
    "test_X= pd.read_csv(\"../data/ele_val_input_7.csv\").iloc[:,1:].values.astype(np.float32)/10000\n",
    "test_y =pd.read_csv(\"../data/ele_val_output_7.csv\").iloc[:,1:].values.astype(np.float32)/10000\n",
    "\n",
    "target_X.shape,test_X.shape\n",
    "\n",
    "\n",
    "#################################################################################\n",
    "# loss SMAPE\n",
    "class SMAPE(Loss):\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_pred = tf.reshape(y_pred, tf.shape(y_true))  # 예측 값의 차원을 맞춤\n",
    "       # y_pred=tf.clip_by_value(y_pred, 1e-10, tf.reduce_max(y_pred))\n",
    "       # y_true = tf.clip_by_value(y_true, 1e-10, tf.reduce_max(y_true))\n",
    "        \n",
    "        numerator = 100 * tf.abs(y_true- y_pred )\n",
    "        denominator =  (tf.abs(y_true ) + tf.abs(y_pred))/2\n",
    "        smape =  numerator /  denominator #tf.clip_by_value(denominator, 1e-10, tf.reduce_max(denominator))\n",
    "        return tf.reduce_mean(smape)\n",
    "\n",
    "#################################################################################\n",
    "# loss MASE\n",
    "class MASE(Loss):\n",
    "    def __init__(self, training_data, period, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.scale = self.calculate_scale(training_data, period)\n",
    "    def seasonal_diff(data, period):\n",
    "        return data[period:] - data[:-period]\n",
    "\n",
    "    def calculate_scale(self, training_data, period):\n",
    "        # 주기 차분 계산\n",
    "        diff = seasonal_diff(training_data, period)\n",
    "        scale = np.mean(np.abs(diff))\n",
    "        return scale\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        y_pred = tf.reshape(y_pred, tf.shape(y_true))  # 차원 맞추기\n",
    "        error = tf.abs(y_true - y_pred)\n",
    "        return tf.reduce_mean(error / self.scale)\n",
    "\n",
    "def seasonal_diff(data, period):\n",
    "    return data[period:] - data[:-period]\n",
    "\n",
    "\n",
    "#################################################################################\n",
    "#################################################################################\n",
    "# 하이퍼파라미터 인자 설정\n",
    "def hyperparameter():\n",
    "    # 1 backcast\n",
    "    # 2 forecast\n",
    "    # 3 inputdim\n",
    "    # 4 outputdim\n",
    "    # 5 unit\n",
    "    # 6 bacth size\n",
    "    return X_train.shape[1], y_train.shape[1],1,1,128\n",
    "\n",
    "#################################################################################\n",
    "# nbeats + I모델 생성 함수\n",
    "def bulid_model(backcast_,forecast_,input_dim,output_dim,unit):\n",
    "    model= NBeatsKeras(backcast_length=backcast_, \n",
    "                       forecast_length=forecast_,\n",
    "                       input_dim=input_dim,\n",
    "                       output_dim=output_dim,\n",
    "                       stack_types=(NBeatsKeras.TREND_BLOCK,\n",
    "                                    NBeatsKeras.TREND_BLOCK,\n",
    "                                    NBeatsKeras.TREND_BLOCK,\n",
    "                                    NBeatsKeras.SEASONALITY_BLOCK,\n",
    "                                    NBeatsKeras.SEASONALITY_BLOCK,\n",
    "                                    NBeatsKeras.SEASONALITY_BLOCK)\n",
    "                   ,nb_blocks_per_stack=1, thetas_dim=(1,2,2,4,4,4),\n",
    "                   share_weights_in_stack=True, hidden_layer_units=unit)\n",
    "    return model \n",
    "#################################################################################\n",
    "# nbeats + G모델 생성 함수    \n",
    "def bulid_model_G(backcast_,forecast_,input_dim,output_dim,unit):\n",
    "    model= NBeatsKeras(backcast_length=backcast_, \n",
    "                       forecast_length=forecast_,\n",
    "                       input_dim=input_dim,\n",
    "                       output_dim=output_dim,\n",
    "                       stack_types=(NBeatsKeras.GENERIC_BLOCK,NBeatsKeras.GENERIC_BLOCK)\n",
    "                   ,nb_blocks_per_stack=5, thetas_dim=(4,4),\n",
    "                   share_weights_in_stack=False, hidden_layer_units=unit)\n",
    "    return model \n",
    "#################################################################################\n",
    "# nbeats + I모델 부트스트랩 샘플링 배깅\n",
    "import os\n",
    "\n",
    "def train_bagging_models(num_models, loss_fn, epochs_, patience_, batch_size_, lr, save_path='./models/'):\n",
    "    models = {}\n",
    "    backcast, forecast, in_dim, out_dim, unit = hyperparameter()\n",
    "    historys = []\n",
    "    \n",
    "    # 모델을 저장할 경로를 설정 (필요한 경우 저장 경로를 만듦)\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    \n",
    "    for n in range(num_models):\n",
    "        K.clear_session()\n",
    "        model = bulid_model(backcast, forecast, in_dim, out_dim, unit)\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "        model.compile(optimizer=optimizer, loss=loss_fn)\n",
    "        \n",
    "        # 부트스트랩 샘플링\n",
    "        select = np.random.choice(len(X_train), size=len(X_train), replace=True)\n",
    "        X_bootstrap = X_train[select]\n",
    "        y_bootstrap = y_train[select]\n",
    "        \n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience=patience_, verbose=0, restore_best_weights=True)\n",
    "        history = model.fit(X_bootstrap, y_bootstrap, batch_size=batch_size_,\n",
    "                            epochs=epochs_, verbose=0, \n",
    "                            callbacks=[early_stop],\n",
    "                            validation_split=0.2)\n",
    "        \n",
    "        # 모델 저장 경로 지정 및 모델 저장\n",
    "        model_save_path = os.path.join(save_path, f'{loss_fn}_model_{n+1}.h5')\n",
    "        model.save(model_save_path)\n",
    "        print(f'Model {n+1} saved at {model_save_path}')\n",
    "        \n",
    "        models[f'model_{n+1}'] = model\n",
    "        historys.append(history)\n",
    "        print(f'######################################################## Model {n+1}')\n",
    "    \n",
    "    return models, historys\n",
    "#################################################################################\n",
    "# nbeats + I모델 부트스트랩 샘플링 배깅\n",
    "\n",
    "import os\n",
    "\n",
    "def train_bagging_models_G(name,num_models, loss_fn, epochs_, patience_, batch_size_, lr, save_path='mape_models_G/'):\n",
    "    models = {}\n",
    "    backcast, forecast, in_dim, out_dim, unit = hyperparameter()\n",
    "    historys = []\n",
    "    \n",
    "    # 모델을 저장할 경로를 설정 (필요한 경우 저장 경로를 만듦)\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    \n",
    "    for n in range(num_models):\n",
    "        K.clear_session()\n",
    "        model = bulid_model_G(backcast, forecast, in_dim, out_dim, unit)\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "        model.compile(optimizer=optimizer, loss=loss_fn)\n",
    "        \n",
    "        # 부트스트랩 샘플링\n",
    "        select = np.random.choice(len(X_train), size=len(X_train), replace=True)\n",
    "        X_bootstrap = X_train[select]\n",
    "        y_bootstrap = y_train[select]\n",
    "        \n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience=patience_, restore_best_weights=True)\n",
    "        history = model.fit(X_bootstrap, y_bootstrap, batch_size=batch_size_,\n",
    "                            epochs=epochs_, verbose=0, \n",
    "                            callbacks=[early_stop],\n",
    "                            validation_split=0.2)\n",
    "        \n",
    "        # 모델 저장 경로 지정 및 모델 저장\n",
    "        model_save_path = os.path.join(save_path, f'{name}_model_G_{n+1}.h5')\n",
    "        model.save(model_save_path)\n",
    "        print(f'Model {n+1} saved at {model_save_path}')\n",
    "        \n",
    "        models[f'model_{n+1}'] = model\n",
    "        historys.append(history)\n",
    "        print(f'######################################################## Model {n+1}')\n",
    "    \n",
    "    return models, historys\n",
    "\n",
    "#################################################################################\n",
    "##########################################################################################\n",
    "# 트랜스퍼 레이어\n",
    "class PositionalEncoding(layers.Layer):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = layers.Dropout(rate=dropout)\n",
    "\n",
    "        position = np.arange(max_len)[:, np.newaxis]\n",
    "        div_term = np.exp(np.arange(0, d_model, 2) * (-np.log(10000.0) / d_model))\n",
    "        pe = np.zeros((max_len, d_model))\n",
    "        pe[:, 0::2] = np.sin(position * div_term)\n",
    "        pe[:, 1::2] = np.cos(position * div_term)\n",
    "        pe = pe[np.newaxis, ...]\n",
    "\n",
    "        self.pe = tf.constant(pe, dtype=tf.float32)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = x + self.pe[:, :tf.shape(x)[1], :]\n",
    "        return self.dropout(x)\n",
    "##########################################################################################\n",
    "# 트랜스퍼 레이어\n",
    "def create_model(fn,d_model, nlayers, nhead, dropout, iw, ow,lr,pretrained_output_reshaped,inputs):\n",
    "    \n",
    "    \n",
    "    x = layers.Dense(d_model // 2, activation='relu')(pretrained_output_reshaped)\n",
    "    x = layers.Dense(d_model, activation='relu')(x)\n",
    "    \n",
    "    pos_encoding = PositionalEncoding(d_model, dropout)\n",
    "    x = pos_encoding(x)\n",
    "    \n",
    "    for _ in range(nlayers):\n",
    "        attn_output = layers.MultiHeadAttention(num_heads=nhead, key_dim=d_model, dropout=dropout)(x, x)\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x + attn_output)\n",
    "        ffn_output = layers.Dense(d_model, activation='relu')(x)\n",
    "        ffn_output = layers.Dense(d_model)(ffn_output)\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x + ffn_output)\n",
    "    \n",
    "    x = layers.Dense(d_model // 2, activation='relu')(x)\n",
    "    x = layers.Dense(1)(x)\n",
    "    x = tf.squeeze(x, axis=-1)\n",
    "    \n",
    "    outputs = layers.Dense((iw + ow) // 2, activation='relu')(x)\n",
    "    outputs = layers.Dense(ow)(outputs)\n",
    "    \n",
    "    optimizer = Adam(learning_rate=lr)\n",
    "    target_model = Model(inputs=inputs, outputs=outputs)\n",
    "    target_model.compile(optimizer=optimizer, loss=fn)\n",
    "    \n",
    "    return target_model\n",
    "########################################################################################################################\n",
    "from keras.models import load_model\n",
    "\n",
    "def transfer_(model_num, model_paths, trainable, lossf, epochs_, batch_size_, pt, lr_):\n",
    "    history_mapes_G = []\n",
    "    model_pred = []\n",
    "    model_path = model_paths\n",
    "    for i in range(1, model_num + 1):\n",
    "        K.clear_session()\n",
    "        \n",
    "        # 저장된 모델 경로에서 모델 불러오기\n",
    "        #model_path = model_paths[i - 1]  # 각 모델의 경로를 리스트로 받아 처리\n",
    "        #model_paths = model_path #+ f'_model_G_{i}.h5'\n",
    "        \n",
    "        #mase_loss_ = MASE(training_data=target_y, period=y_train.shape[1]) \n",
    "        model1 = load_model(model_path+ f'_model_G_{i}.h5')  # 저장된 모델 불러오기\n",
    "        print(f\"{model_path}_model_G_{i}.h5\")\n",
    "        \n",
    "        # 모든 레이어를 학습 불가능하게 설정 (필요한 경우)\n",
    "        for layer in model1.layers[:-1]:  # 마지막 레이어를 제외하고 학습 가능 여부 설정\n",
    "            layer.trainable = trainable\n",
    "        \n",
    "        pretrained_layers = model1.layers[:-1]\n",
    "        \n",
    "        # 전이 학습을 위한 새로운 입력과 모델 구성\n",
    "        pretrained_model = Model(inputs=model1.input, outputs=pretrained_layers[-1].output)\n",
    "        inputs = Input(shape=(X_train.shape[1], 1))\n",
    "        pretrained_output = pretrained_model(inputs)\n",
    "        pretrained_output_reshaped = layers.Reshape((y_train.shape[1], -1))(pretrained_output)\n",
    "        \n",
    "        # 새로운 모델 생성 및 전이 학습\n",
    "        model_instance = create_model(\n",
    "            lossf, d_model=64, nlayers=1, nhead=1, dropout=0.1, iw=X_train.shape[1], \n",
    "            ow=y_train.shape[1], lr=lr_, pretrained_output_reshaped=pretrained_output_reshaped, inputs=inputs\n",
    "        )\n",
    "        \n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience=pt, verbose=0, restore_best_weights=True)\n",
    "    \n",
    "        history = model_instance.fit(\n",
    "            target_X, target_y, batch_size=batch_size_, epochs=epochs_, verbose=0,\n",
    "            callbacks=[early_stop], validation_split=0.2\n",
    "        )\n",
    "        \n",
    "        pred = model_instance.predict(test_X)\n",
    "        pred = pred.reshape(-1, y_train.shape[1])\n",
    "        model_pred.append(pred)\n",
    "        history_mapes_G.append(history)\n",
    "        \n",
    "        print(f\"######################################################## fitted {i}\")\n",
    "    \n",
    "    return model_pred\n",
    "#################################################################################\n",
    "# 예측\n",
    "\n",
    "def bagging_predict(models, X):\n",
    "    predictions = np.array([model.predict(X) for model in models.values()])\n",
    "    return np.median(predictions, axis=0)\n",
    "\n",
    "def bagging_predict2(models, X):\n",
    "    predictions = np.array([model.predict(X) for model in models.values()])\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fbe6ff-9174-4d97-95eb-9b72a19869b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a27e2cd6-1f6f-4c32-94ef-a199729c9e9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-21 00:54:58.452751: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-09-21 00:54:58.452794: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ymlee2-desktop): /proc/driver/nvidia/version does not exist\n",
      "2024-09-21 00:54:58.453324: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 saved at mae_models_G/mae_model_G_1.h5\n",
      "######################################################## Model 1\n",
      "Model 2 saved at mae_models_G/mae_model_G_2.h5\n",
      "######################################################## Model 2\n",
      "Model 3 saved at mae_models_G/mae_model_G_3.h5\n",
      "######################################################## Model 3\n",
      "Model 4 saved at mae_models_G/mae_model_G_4.h5\n",
      "######################################################## Model 4\n",
      "Model 5 saved at mae_models_G/mae_model_G_5.h5\n",
      "######################################################## Model 5\n",
      "Model 6 saved at mae_models_G/mae_model_G_6.h5\n",
      "######################################################## Model 6\n",
      "Model 7 saved at mae_models_G/mae_model_G_7.h5\n",
      "######################################################## Model 7\n",
      "Model 8 saved at mae_models_G/mae_model_G_8.h5\n",
      "######################################################## Model 8\n",
      "Model 9 saved at mae_models_G/mae_model_G_9.h5\n",
      "######################################################## Model 9\n",
      "Model 10 saved at mae_models_G/mae_model_G_10.h5\n",
      "######################################################## Model 10\n",
      "Model 11 saved at mae_models_G/mae_model_G_11.h5\n",
      "######################################################## Model 11\n",
      "Model 12 saved at mae_models_G/mae_model_G_12.h5\n",
      "######################################################## Model 12\n",
      "Model 13 saved at mae_models_G/mae_model_G_13.h5\n",
      "######################################################## Model 13\n",
      "Model 14 saved at mae_models_G/mae_model_G_14.h5\n",
      "######################################################## Model 14\n",
      "Model 15 saved at mae_models_G/mae_model_G_15.h5\n",
      "######################################################## Model 15\n",
      "Model 16 saved at mae_models_G/mae_model_G_16.h5\n",
      "######################################################## Model 16\n",
      "Model 17 saved at mae_models_G/mae_model_G_17.h5\n",
      "######################################################## Model 17\n",
      "Model 18 saved at mae_models_G/mae_model_G_18.h5\n",
      "######################################################## Model 18\n",
      "Model 19 saved at mae_models_G/mae_model_G_19.h5\n",
      "######################################################## Model 19\n",
      "Model 20 saved at mae_models_G/mae_model_G_20.h5\n",
      "######################################################## Model 20\n",
      "Model 21 saved at mae_models_G/mae_model_G_21.h5\n",
      "######################################################## Model 21\n",
      "Model 22 saved at mae_models_G/mae_model_G_22.h5\n",
      "######################################################## Model 22\n",
      "Model 23 saved at mae_models_G/mae_model_G_23.h5\n",
      "######################################################## Model 23\n",
      "Model 24 saved at mae_models_G/mae_model_G_24.h5\n",
      "######################################################## Model 24\n",
      "Model 25 saved at mae_models_G/mae_model_G_25.h5\n",
      "######################################################## Model 25\n",
      "Model 26 saved at mae_models_G/mae_model_G_26.h5\n",
      "######################################################## Model 26\n",
      "Model 27 saved at mae_models_G/mae_model_G_27.h5\n",
      "######################################################## Model 27\n",
      "Model 28 saved at mae_models_G/mae_model_G_28.h5\n",
      "######################################################## Model 28\n",
      "Model 29 saved at mae_models_G/mae_model_G_29.h5\n",
      "######################################################## Model 29\n",
      "Model 30 saved at mae_models_G/mae_model_G_30.h5\n",
      "######################################################## Model 30\n"
     ]
    }
   ],
   "source": [
    "#mape_models = train_bagging_models_G('mape',30,'mape',100,10,512,0.001)\n",
    "#smape_models = train_bagging_models_G('smape',1,SMAPE(),50,5,512,0.001)\n",
    "mae_models = train_bagging_models_G('mae',30,'mae',100,10,512,0.001,save_path='mae_models_G/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb556995-5d3b-4edb-921f-062ea5192e63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae_models_G/mae_model_G_1.h5\n",
      "12/12 [==============================] - 1s 5ms/step\n",
      "######################################################## fitted 1\n",
      "mae_models_G/mae_model_G_2.h5\n",
      "12/12 [==============================] - 1s 4ms/step\n",
      "######################################################## fitted 2\n",
      "mae_models_G/mae_model_G_3.h5\n",
      "12/12 [==============================] - 1s 4ms/step\n",
      "######################################################## fitted 3\n",
      "mae_models_G/mae_model_G_4.h5\n",
      "12/12 [==============================] - 1s 5ms/step\n",
      "######################################################## fitted 4\n",
      "mae_models_G/mae_model_G_5.h5\n",
      "12/12 [==============================] - 0s 4ms/step\n",
      "######################################################## fitted 5\n",
      "mae_models_G/mae_model_G_6.h5\n",
      "12/12 [==============================] - 1s 5ms/step\n",
      "######################################################## fitted 6\n",
      "mae_models_G/mae_model_G_7.h5\n",
      "12/12 [==============================] - 1s 5ms/step\n",
      "######################################################## fitted 7\n",
      "mae_models_G/mae_model_G_8.h5\n",
      "12/12 [==============================] - 1s 5ms/step\n",
      "######################################################## fitted 8\n",
      "mae_models_G/mae_model_G_9.h5\n",
      "12/12 [==============================] - 0s 4ms/step\n",
      "######################################################## fitted 9\n",
      "mae_models_G/mae_model_G_10.h5\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "######################################################## fitted 10\n",
      "mae_models_G/mae_model_G_11.h5\n",
      "12/12 [==============================] - 0s 4ms/step\n",
      "######################################################## fitted 11\n",
      "mae_models_G/mae_model_G_12.h5\n",
      "12/12 [==============================] - 0s 4ms/step\n",
      "######################################################## fitted 12\n",
      "mae_models_G/mae_model_G_13.h5\n",
      "12/12 [==============================] - 0s 4ms/step\n",
      "######################################################## fitted 13\n",
      "mae_models_G/mae_model_G_14.h5\n",
      "12/12 [==============================] - 0s 4ms/step\n",
      "######################################################## fitted 14\n",
      "mae_models_G/mae_model_G_15.h5\n",
      "12/12 [==============================] - 0s 4ms/step\n",
      "######################################################## fitted 15\n",
      "mae_models_G/mae_model_G_16.h5\n",
      "12/12 [==============================] - 0s 4ms/step\n",
      "######################################################## fitted 16\n",
      "mae_models_G/mae_model_G_17.h5\n",
      "12/12 [==============================] - 0s 4ms/step\n",
      "######################################################## fitted 17\n",
      "mae_models_G/mae_model_G_18.h5\n",
      "12/12 [==============================] - 0s 4ms/step\n",
      "######################################################## fitted 18\n",
      "mae_models_G/mae_model_G_19.h5\n",
      "12/12 [==============================] - 0s 4ms/step\n",
      "######################################################## fitted 19\n",
      "mae_models_G/mae_model_G_20.h5\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "######################################################## fitted 20\n",
      "mae_models_G/mae_model_G_21.h5\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "######################################################## fitted 21\n",
      "mae_models_G/mae_model_G_22.h5\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "######################################################## fitted 22\n",
      "mae_models_G/mae_model_G_23.h5\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "######################################################## fitted 23\n",
      "mae_models_G/mae_model_G_24.h5\n",
      "12/12 [==============================] - 0s 3ms/step\n",
      "######################################################## fitted 24\n",
      "mae_models_G/mae_model_G_25.h5\n",
      "12/12 [==============================] - 0s 4ms/step\n",
      "######################################################## fitted 25\n",
      "mae_models_G/mae_model_G_26.h5\n",
      "12/12 [==============================] - 0s 4ms/step\n",
      "######################################################## fitted 26\n",
      "mae_models_G/mae_model_G_27.h5\n",
      "12/12 [==============================] - 0s 4ms/step\n",
      "######################################################## fitted 27\n",
      "mae_models_G/mae_model_G_28.h5\n",
      "12/12 [==============================] - 0s 4ms/step\n",
      "######################################################## fitted 28\n",
      "mae_models_G/mae_model_G_29.h5\n",
      "12/12 [==============================] - 0s 4ms/step\n",
      "######################################################## fitted 29\n",
      "mae_models_G/mae_model_G_30.h5\n",
      "12/12 [==============================] - 0s 4ms/step\n",
      "######################################################## fitted 30\n"
     ]
    }
   ],
   "source": [
    "#mape_pred = transfer_(3,'models_G/mape',True, 'mape',5,8,30,0.00005)\n",
    "mae_pred = transfer_(30,'mae_models_G/mae',True, 'mae',300,8,30,0.0005)\n",
    "#smape_pred = transfer_(1,'models_G/smape',True, SMAPE(),3,8,30,0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eca183b8-2e10-4729-acea-3e36a61ac7c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.08472316, 0.18215819)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_G = np.concatenate([np.array(mae_pred)])\n",
    "\n",
    "fin_pred_G = np.median(concat_G,axis=0)\n",
    "\n",
    "mean_squared_error(test_y.flatten(),fin_pred_G.flatten()),mean_absolute_error(test_y.flatten(),fin_pred_G.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "73850a59-1820-4b58-9626-77d87cf54882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.08798879, 0.1868172)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_G = np.concatenate([np.array(mae_pred)[:10]])\n",
    "\n",
    "fin_pred_G = np.median(concat_G,axis=0)\n",
    "\n",
    "mean_squared_error(test_y.flatten(),fin_pred_G.flatten()),mean_absolute_error(test_y.flatten(),fin_pred_G.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "416066f6-d997-4ff2-b24d-6312b323785c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.085886024, 0.18399596)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_G = np.concatenate([np.array(mae_pred)[:20]])\n",
    "\n",
    "fin_pred_G = np.median(concat_G,axis=0)\n",
    "\n",
    "mean_squared_error(test_y.flatten(),fin_pred_G.flatten()),mean_absolute_error(test_y.flatten(),fin_pred_G.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74fa47fa-f2ab-4078-b673-8d7635e72fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mselist = [mean_squared_error(test_y.flatten(),concat_G[i].flatten()) for i in range(30)]\n",
    "mselist.index(np.min(mselist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e885812e-bc14-45a3-8055-5e82e7d4024d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_1(model_num, model_paths,N, trainable, lossf, epochs_, batch_size_, pt, lr_):\n",
    "    history_mapes_G = []\n",
    "    model_pred = []\n",
    "    model_path = model_paths\n",
    "    for i in range(1, model_num + 1):\n",
    "        K.clear_session()\n",
    "        \n",
    "        # 저장된 모델 경로에서 모델 불러오기\n",
    "        #model_path = model_paths[i - 1]  # 각 모델의 경로를 리스트로 받아 처리\n",
    "        #model_paths = model_path #+ f'_model_G_{i}.h5'\n",
    "        model1 = load_model(model_path+ f'_model_G_{N}.h5')  # 저장된 모델 불러오기\n",
    "        print(f\"{i}{model_path}_model_G_{N}.h5\")\n",
    "        \n",
    "        # 모든 레이어를 학습 불가능하게 설정 (필요한 경우)\n",
    "        for layer in model1.layers[:-1]:  # 마지막 레이어를 제외하고 학습 가능 여부 설정\n",
    "            layer.trainable = trainable\n",
    "        \n",
    "        pretrained_layers = model1.layers[:-1]\n",
    "        \n",
    "        # 전이 학습을 위한 새로운 입력과 모델 구성\n",
    "        pretrained_model = Model(inputs=model1.input, outputs=pretrained_layers[-1].output)\n",
    "        inputs = Input(shape=(X_train.shape[1], 1))\n",
    "        pretrained_output = pretrained_model(inputs)\n",
    "        pretrained_output_reshaped = layers.Reshape((y_train.shape[1], -1))(pretrained_output)\n",
    "        \n",
    "        # 새로운 모델 생성 및 전이 학습\n",
    "        model_instance = create_model(\n",
    "            lossf, d_model=64, nlayers=1, nhead=1, dropout=0.1, iw=X_train.shape[1], \n",
    "            ow=y_train.shape[1], lr=lr_, pretrained_output_reshaped=pretrained_output_reshaped, inputs=inputs\n",
    "        )\n",
    "        \n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience=pt, verbose=0, restore_best_weights=True)\n",
    "    \n",
    "        history = model_instance.fit(\n",
    "            target_X, target_y, batch_size=batch_size_, epochs=epochs_, verbose=0,\n",
    "            callbacks=[early_stop], validation_split=0.2\n",
    "        )\n",
    "        \n",
    "        pred = model_instance.predict(test_X)\n",
    "        pred = pred.reshape(-1, y_train.shape[1])\n",
    "        model_pred.append(pred)\n",
    "        history_mapes_G.append(history)\n",
    "        \n",
    "        print(f\"######################################################## fitted {i}\")\n",
    "    \n",
    "    return model_pred, history_mapes_G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f341fee9-d44c-475e-91ac-371cab07ca75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1mae_models_G/mae_model_G_6.h5\n",
      "12/12 [==============================] - 1s 7ms/step\n",
      "######################################################## fitted 1\n",
      "2mae_models_G/mae_model_G_6.h5\n",
      "12/12 [==============================] - 1s 6ms/step\n",
      "######################################################## fitted 2\n",
      "3mae_models_G/mae_model_G_6.h5\n",
      "12/12 [==============================] - 1s 7ms/step\n",
      "######################################################## fitted 3\n",
      "4mae_models_G/mae_model_G_6.h5\n",
      "12/12 [==============================] - 1s 7ms/step\n",
      "######################################################## fitted 4\n",
      "5mae_models_G/mae_model_G_6.h5\n",
      "12/12 [==============================] - 0s 4ms/step\n",
      "######################################################## fitted 5\n",
      "6mae_models_G/mae_model_G_6.h5\n",
      "12/12 [==============================] - 1s 7ms/step\n",
      "######################################################## fitted 6\n",
      "7mae_models_G/mae_model_G_6.h5\n",
      "12/12 [==============================] - 1s 7ms/step\n",
      "######################################################## fitted 7\n",
      "8mae_models_G/mae_model_G_6.h5\n",
      "12/12 [==============================] - 1s 7ms/step\n",
      "######################################################## fitted 8\n",
      "9mae_models_G/mae_model_G_6.h5\n",
      "12/12 [==============================] - 1s 6ms/step\n",
      "######################################################## fitted 9\n",
      "10mae_models_G/mae_model_G_6.h5\n",
      "12/12 [==============================] - 1s 6ms/step\n",
      "######################################################## fitted 10\n",
      "11mae_models_G/mae_model_G_6.h5\n",
      "12/12 [==============================] - 1s 7ms/step\n",
      "######################################################## fitted 11\n",
      "12mae_models_G/mae_model_G_6.h5\n",
      "12/12 [==============================] - 1s 8ms/step\n",
      "######################################################## fitted 12\n",
      "13mae_models_G/mae_model_G_6.h5\n",
      "12/12 [==============================] - 1s 7ms/step\n",
      "######################################################## fitted 13\n",
      "14mae_models_G/mae_model_G_6.h5\n",
      "12/12 [==============================] - 1s 8ms/step\n",
      "######################################################## fitted 14\n",
      "15mae_models_G/mae_model_G_6.h5\n",
      "12/12 [==============================] - 1s 8ms/step\n",
      "######################################################## fitted 15\n",
      "16mae_models_G/mae_model_G_6.h5\n",
      "12/12 [==============================] - 1s 7ms/step\n",
      "######################################################## fitted 16\n",
      "17mae_models_G/mae_model_G_6.h5\n",
      "12/12 [==============================] - 1s 8ms/step\n",
      "######################################################## fitted 17\n",
      "18mae_models_G/mae_model_G_6.h5\n",
      "12/12 [==============================] - 1s 8ms/step\n",
      "######################################################## fitted 18\n",
      "19mae_models_G/mae_model_G_6.h5\n",
      "12/12 [==============================] - 1s 7ms/step\n",
      "######################################################## fitted 19\n",
      "20mae_models_G/mae_model_G_6.h5\n",
      "12/12 [==============================] - 1s 8ms/step\n",
      "######################################################## fitted 20\n",
      "21mae_models_G/mae_model_G_6.h5\n",
      "12/12 [==============================] - 1s 9ms/step\n",
      "######################################################## fitted 21\n",
      "22mae_models_G/mae_model_G_6.h5\n",
      "12/12 [==============================] - 1s 10ms/step\n",
      "######################################################## fitted 22\n",
      "23mae_models_G/mae_model_G_6.h5\n",
      "12/12 [==============================] - 1s 9ms/step\n",
      "######################################################## fitted 23\n",
      "24mae_models_G/mae_model_G_6.h5\n",
      "12/12 [==============================] - 1s 6ms/step\n",
      "######################################################## fitted 24\n",
      "25mae_models_G/mae_model_G_6.h5\n",
      "12/12 [==============================] - 1s 6ms/step\n",
      "######################################################## fitted 25\n",
      "26mae_models_G/mae_model_G_6.h5\n",
      "12/12 [==============================] - 1s 7ms/step\n",
      "######################################################## fitted 26\n",
      "27mae_models_G/mae_model_G_6.h5\n",
      "12/12 [==============================] - 1s 9ms/step\n",
      "######################################################## fitted 27\n",
      "28mae_models_G/mae_model_G_6.h5\n",
      "12/12 [==============================] - 1s 7ms/step\n",
      "######################################################## fitted 28\n",
      "29mae_models_G/mae_model_G_6.h5\n",
      "12/12 [==============================] - 1s 9ms/step\n",
      "######################################################## fitted 29\n",
      "30mae_models_G/mae_model_G_6.h5\n",
      "12/12 [==============================] - 1s 7ms/step\n",
      "######################################################## fitted 30\n"
     ]
    }
   ],
   "source": [
    "mape_pred2 = transfer_1(30,'mae_models_G/mae',6,True, 'mae',300,8,30,0.0005)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ed86721e-5711-4c80-ace2-f22d7d5c0fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.08502979, 0.18325412)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_G2 = np.concatenate([np.array(mape_pred2[0]\n",
    "                                    )])\n",
    "\n",
    "fin_pred_G2 = np.median(concat_G2,axis=0)\n",
    "\n",
    "mean_squared_error(test_y.flatten(),fin_pred_G2.flatten()),mean_absolute_error(test_y.flatten(),fin_pred_G2.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a629916a-a565-4dea-a777-c534a181662a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mselist2 = [mean_squared_error(test_y.flatten(),concat_G2[i].flatten()) for i in range(30)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8d77b0f2-60ad-4bd9-8b10-d4853999fcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'MSE':mselist,\n",
    "             'min-MSE':mselist2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b5f7932c-c661-4055-a893-6f3042992672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>min-MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.097148</td>\n",
       "      <td>0.097655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.005075</td>\n",
       "      <td>0.004372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.087037</td>\n",
       "      <td>0.089642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.093808</td>\n",
       "      <td>0.094760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.096516</td>\n",
       "      <td>0.097572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.099189</td>\n",
       "      <td>0.100628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.111841</td>\n",
       "      <td>0.112168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             MSE    min-MSE\n",
       "count  30.000000  30.000000\n",
       "mean    0.097148   0.097655\n",
       "std     0.005075   0.004372\n",
       "min     0.087037   0.089642\n",
       "25%     0.093808   0.094760\n",
       "50%     0.096516   0.097572\n",
       "75%     0.099189   0.100628\n",
       "max     0.111841   0.112168"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6890dd6b-4be7-4863-89c1-b7486af27875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "86636b6f-0060-44f8-a70e-f8f0c351565d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(mselist,bins=30,alpha=0.7)\n",
    "plt.hist(mselist2,bins=30,alpha=0.7)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
