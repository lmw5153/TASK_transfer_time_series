{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e097566-30f2-4f57-b3a2-2ae3b7d02005",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 16:52:40.762216: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-23 16:52:40.864506: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-09-23 16:52:40.864533: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-09-23 16:52:41.323500: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-09-23 16:52:41.323557: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-09-23 16:52:41.323563: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nbeats_keras.model import NBeatsNet as NBeatsKeras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "#from nbeats_pytorch.model import NBeatsNet as NBeatsPytorch\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "import time\n",
    "from keras.models import load_model\n",
    "#from target_data_electronic70_7 import target_X, target_y ,test_X, test_y\n",
    "#from m4databasis21_7 import base_domain,zt_in,zt_out,M4Meta,inputsize,train_12,train_12_y\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error,mean_absolute_percentage_error,r2_score\n",
    "plt.rcParams['font.family'] ='Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] =False\n",
    "from tensorflow.keras.losses import Loss\n",
    "import tensorflow as tf\n",
    "#from m4databasis35_7_70_7 import train_35,train_35_y,train_70,train_70_y\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, LayerNormalization, MultiHeadAttention, Dropout, Add, Concatenate,Flatten,Reshape\n",
    "#import pandas as pd\n",
    "#from sklearn.metrics import r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31c74fd4-9d10-4b7d-9c83-4da3c7f1871f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((348, 168), (117, 168), (348, 24), (117, 24))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "target_X= pd.read_csv(\"low_X.csv\").iloc[:,(1+24*0):].values\n",
    "target_y =pd.read_csv(\"low_y.csv\").iloc[:,1:].values\n",
    "#test_X= pd.read_csv(\"../data/solor_val_input_7.csv\").iloc[:,(1+24*0):].values\n",
    "#test_y =pd.read_csv(\"../data/solor_val_output_7.csv\").iloc[:,1:].values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train,test_X,y_train,test_y=train_test_split(target_X,target_y,random_state=1, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#X_train=target_X\n",
    "#y_train=target_y\n",
    "\n",
    "backcast_length = X_train.shape[1]\n",
    "forecast_length = y_train.shape[1]\n",
    "\n",
    "X_train.shape,test_X.shape,y_train.shape,test_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475bd839-0f9e-49d3-96a8-f1fe23500d97",
   "metadata": {},
   "source": [
    "# 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "117869af-8623-4129-aa35-bcc7ee3da674",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "# loss SMAPE\n",
    "class SMAPE(Loss):\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_pred = tf.reshape(y_pred, tf.shape(y_true))  # 예측 값의 차원을 맞춤\n",
    "       # y_pred=tf.clip_by_value(y_pred, 1e-10, tf.reduce_max(y_pred))\n",
    "       # y_true = tf.clip_by_value(y_true, 1e-10, tf.reduce_max(y_true))\n",
    "        \n",
    "        numerator = 100 * tf.abs(y_true- y_pred )\n",
    "        denominator =  (tf.abs(y_true ) + tf.abs(y_pred))/2\n",
    "        smape =  numerator /  denominator #tf.clip_by_value(denominator, 1e-10, tf.reduce_max(denominator))\n",
    "        return tf.reduce_mean(smape)\n",
    "\n",
    "#################################################################################\n",
    "# loss MASE\n",
    "class MASE(Loss):\n",
    "    def __init__(self, training_data, period, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.scale = self.calculate_scale(training_data, period)\n",
    "    def seasonal_diff(data, period):\n",
    "        return data[period:] - data[:-period]\n",
    "\n",
    "    def calculate_scale(self, training_data, period):\n",
    "        # 주기 차분 계산\n",
    "        diff = seasonal_diff(training_data, period)\n",
    "        scale = np.mean(np.abs(diff))\n",
    "        return scale\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        y_pred = tf.reshape(y_pred, tf.shape(y_true))  # 차원 맞추기\n",
    "        error = tf.abs(y_true - y_pred)\n",
    "        return tf.reduce_mean(error / self.scale)\n",
    "\n",
    "def seasonal_diff(data, period):\n",
    "    return data[period:] - data[:-period]\n",
    "\n",
    "#################################################################################\n",
    "#################################################################################\n",
    "# 하이퍼파라미터 인자 설정\n",
    "def hyperparameter():\n",
    "    # 1 backcast\n",
    "    # 2 forecast\n",
    "    # 3 inputdim\n",
    "    # 4 outputdim\n",
    "    # 5 unit\n",
    "    # 6 bacth size\n",
    "    return X_train.shape[1],y_train.shape[1],1,1,128\n",
    "\n",
    "#################################################################################\n",
    "# nbeats + I모델 생성 함수\n",
    "def bulid_model(backcast_,forecast_,input_dim,output_dim,unit):\n",
    "    model= NBeatsKeras(backcast_length=backcast_, \n",
    "                       forecast_length=forecast_,\n",
    "                       input_dim=input_dim,\n",
    "                       output_dim=output_dim,\n",
    "                       stack_types=(NBeatsKeras.TREND_BLOCK,\n",
    "                                    NBeatsKeras.SEASONALITY_BLOCK)\n",
    "                   ,nb_blocks_per_stack=1, thetas_dim=(1,3),\n",
    "                   share_weights_in_stack=True, hidden_layer_units=unit)\n",
    "    return model \n",
    "#################################################################################\n",
    "# nbeats + G모델 생성 함수    \n",
    "def bulid_model_G(backcast_,forecast_,input_dim,output_dim,unit):\n",
    "    model= NBeatsKeras(backcast_length=backcast_, \n",
    "                       forecast_length=forecast_,\n",
    "                       input_dim=input_dim,\n",
    "                       output_dim=output_dim,\n",
    "                       stack_types=(NBeatsKeras.GENERIC_BLOCK,NBeatsKeras.GENERIC_BLOCK)\n",
    "                   ,nb_blocks_per_stack=5, thetas_dim=(4,4),\n",
    "                   share_weights_in_stack=False, hidden_layer_units=unit)\n",
    "    return model \n",
    "#################################################################################\n",
    "# nbeats + I모델 부트스트랩 샘플링 배깅\n",
    "\n",
    "def train_bagging_models(num_models, loss_fn , epochs_, patience_,batch_size_,lr):\n",
    "    models = {}\n",
    "    backcast,forecast,in_dim,out_dim,unit = hyperparameter()\n",
    "    historys = []\n",
    "    for n in range(num_models):\n",
    "        K.clear_session()\n",
    "        model = bulid_model(backcast,forecast,in_dim,out_dim,unit)\n",
    "       # model.set_weights(pretrained_weights)  # 전이 학습 가중치 적용\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "        model.compile(optimizer=optimizer , loss=loss_fn)\n",
    "        \n",
    "        # 부트스트랩 샘플링\n",
    "        #select = np.random.choice(len(X_train), size=len(X_train), replace=True)\n",
    "        #X_bootstrap = X_train[select]\n",
    "        #y_bootstrap = y_train[select]\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience = patience_, verbose = 0, restore_best_weights=True)\n",
    "        history = model.fit(X_train, y_train, batch_size = batch_size_,\n",
    "                  epochs=epochs_, verbose=0, \n",
    "                  callbacks=[early_stop],\n",
    "                 validation_split = 0.2)\n",
    "        models[f'model_{n+1}'] = model\n",
    "        historys.append(history)\n",
    "        #models.append(model)\n",
    "        print(f\"'########################################################Model{n}\")\n",
    "    return models,historys\n",
    "#################################################################################\n",
    "# nbeats + I모델 부트스트랩 샘플링 배깅\n",
    "\n",
    "def train_bagging_models_G(num_models, loss_fn , epochs_, patience_,batch_size_,lr):\n",
    "    models = {}\n",
    "    backcast,forecast,in_dim,out_dim,unit = hyperparameter()\n",
    "    historys = []\n",
    "    for n in range(num_models):\n",
    "        K.clear_session()\n",
    "        model = bulid_model_G(backcast,forecast,in_dim,out_dim,unit)\n",
    "       # model.set_weights(pretrained_weights)  # 전이 학습 가중치 적용\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "        model.compile(optimizer=optimizer , loss=loss_fn)\n",
    "        \n",
    "        # 부트스트랩 샘플링\n",
    "        #select = np.random.choice(len(X_train), size=len(X_train), replace=True)\n",
    "        #X_bootstrap = X_train[select]\n",
    "        #y_bootstrap = y_train[select]\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience = patience_, verbose = 0, restore_best_weights=True)\n",
    "        history = model.fit(X_train, y_train, batch_size = batch_size_,\n",
    "                  epochs=epochs_, verbose=0, \n",
    "                  callbacks=[early_stop],\n",
    "                 validation_split = 0.2)\n",
    "        models[f'model_{n+1}'] = model\n",
    "        historys.append(history)\n",
    "        #models.append(model)\n",
    "        print(f\"'########################################################Model{n}\")\n",
    "    return models,historys\n",
    "\n",
    "#################################################################################\n",
    "# SMAPE 용\n",
    "def train_bagging_models_smape(num_models, loss_fn , epochs_, patience_,batch_size_,lr):\n",
    "    models = {}\n",
    "    backcast,forecast,in_dim,out_dim,unit = hyperparameter()\n",
    "    historys = []\n",
    "    for n in range(num_models):\n",
    "        K.clear_session()\n",
    "        model = bulid_model(backcast,forecast,in_dim,out_dim,unit)\n",
    "       # model.set_weights(pretrained_weights)  # 전이 학습 가중치 적용\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "        model.compile(optimizer=optimizer , loss=loss_fn)\n",
    "        \n",
    "        # 부트스트랩 샘플링\n",
    "        #select = np.random.choice(len(X_train), size=len(X_train), replace=True)\n",
    "        #X_bootstrap = X_train[select]\n",
    "        #y_bootstrap = y_train[select]\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience = patience_, verbose = 0, restore_best_weights=True)\n",
    "        history = model.fit(X_bootstrap, y_bootstrap, batch_size = batch_size_,\n",
    "                  epochs=epochs_, verbose=1, \n",
    "                  callbacks=[early_stop],\n",
    "                 validation_split = 0.2)\n",
    "        models[f'model_{n+1}'] = model\n",
    "        historys.append(history)\n",
    "        #models.append(model)\n",
    "        print(f\"'########################################################Model{n}\")\n",
    "    return models,historys\n",
    "\n",
    "##########################################################################################\n",
    "# 트랜스퍼 레이어\n",
    "class PositionalEncoding(layers.Layer):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = layers.Dropout(rate=dropout)\n",
    "\n",
    "        position = np.arange(max_len)[:, np.newaxis]\n",
    "        div_term = np.exp(np.arange(0, d_model, 2) * (-np.log(10000.0) / d_model))\n",
    "        pe = np.zeros((max_len, d_model))\n",
    "        pe[:, 0::2] = np.sin(position * div_term)\n",
    "        pe[:, 1::2] = np.cos(position * div_term)\n",
    "        pe = pe[np.newaxis, ...]\n",
    "\n",
    "        self.pe = tf.constant(pe, dtype=tf.float32)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = x + self.pe[:, :tf.shape(x)[1], :]\n",
    "        return self.dropout(x)\n",
    "##########################################################################################\n",
    "# 트랜스퍼 레이어\n",
    "def create_model(fn,d_model, nlayers, nhead, dropout, iw, ow,lr):\n",
    "    \n",
    "    \n",
    "    x = layers.Dense(d_model // 2, activation='relu')(pretrained_output_reshaped)\n",
    "    x = layers.Dense(d_model, activation='relu')(x)\n",
    "    \n",
    "    pos_encoding = PositionalEncoding(d_model, dropout)\n",
    "    x = pos_encoding(x)\n",
    "    \n",
    "    for _ in range(nlayers):\n",
    "        attn_output = layers.MultiHeadAttention(num_heads=nhead, key_dim=d_model, dropout=dropout)(x, x)\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x + attn_output)\n",
    "        ffn_output = layers.Dense(d_model, activation='relu')(x)\n",
    "        ffn_output = layers.Dense(d_model)(ffn_output)\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x + ffn_output)\n",
    "    \n",
    "    x = layers.Dense(d_model // 2, activation='relu')(x)\n",
    "    x = layers.Dense(1)(x)\n",
    "    x = tf.squeeze(x, axis=-1)\n",
    "    \n",
    "    outputs = layers.Dense((iw + ow) // 2, activation='relu')(x)\n",
    "    outputs = layers.Dense(ow)(outputs)\n",
    "    \n",
    "    optimizer = Adam(learning_rate=lr)\n",
    "    target_model = Model(inputs=inputs, outputs=outputs)\n",
    "    target_model.compile(optimizer=optimizer, loss=fn)\n",
    "    \n",
    "    return target_model\n",
    "#################################################################################\n",
    "# 예측\n",
    "\n",
    "def bagging_predict(models, X):\n",
    "    predictions = np.array([model.predict(X) for model in models.values()])\n",
    "    return np.median(predictions, axis=0)\n",
    "\n",
    "def bagging_predict2(models, X):\n",
    "    predictions = np.array([model.predict(X) for model in models.values()])\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa4c593-18a3-4fa1-be2e-8894dc7d453f",
   "metadata": {},
   "source": [
    "# 모형적합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99f13c2f-9812-460b-9269-22aa352bfc7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-13 02:22:00.066572: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-09-13 02:22:00.066619: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ymlee2-desktop): /proc/driver/nvidia/version does not exist\n",
      "2024-09-13 02:22:00.067249: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "35/35 [==============================] - 2s 14ms/step - loss: 0.9775 - val_loss: 0.8192\n",
      "Epoch 2/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.7523 - val_loss: 0.7921\n",
      "Epoch 3/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.6713 - val_loss: 0.7753\n",
      "Epoch 4/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.6192 - val_loss: 0.7749\n",
      "Epoch 5/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.5722 - val_loss: 0.7773\n",
      "Epoch 6/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.5307 - val_loss: 0.7752\n",
      "Epoch 7/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4977 - val_loss: 0.7878\n",
      "Epoch 8/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4799 - val_loss: 0.7764\n",
      "Epoch 9/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4558 - val_loss: 0.7938\n",
      "Epoch 10/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4351 - val_loss: 0.7955\n",
      "Epoch 11/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4083 - val_loss: 0.7862\n",
      "Epoch 12/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3950 - val_loss: 0.7958\n",
      "Epoch 13/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3797 - val_loss: 0.7943\n",
      "Epoch 14/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3632 - val_loss: 0.7925\n",
      "Epoch 15/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3530 - val_loss: 0.8005\n",
      "Epoch 16/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3394 - val_loss: 0.7949\n",
      "Epoch 17/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3287 - val_loss: 0.7992\n",
      "Epoch 18/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3227 - val_loss: 0.8021\n",
      "Epoch 19/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3063 - val_loss: 0.7973\n",
      "Epoch 20/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2981 - val_loss: 0.7990\n",
      "Epoch 21/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2901 - val_loss: 0.7933\n",
      "Epoch 22/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2816 - val_loss: 0.7955\n",
      "Epoch 23/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2750 - val_loss: 0.7983\n",
      "Epoch 24/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2738 - val_loss: 0.8016\n",
      "Epoch 25/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2655 - val_loss: 0.7909\n",
      "Epoch 26/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2587 - val_loss: 0.7898\n",
      "Epoch 27/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2501 - val_loss: 0.7934\n",
      "Epoch 28/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2444 - val_loss: 0.7902\n",
      "Epoch 29/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2458 - val_loss: 0.7910\n",
      "Epoch 30/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2467 - val_loss: 0.7877\n",
      "Epoch 31/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2376 - val_loss: 0.7932\n",
      "Epoch 32/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2360 - val_loss: 0.7889\n",
      "Epoch 33/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2331 - val_loss: 0.7895\n",
      "Epoch 34/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2299 - val_loss: 0.7908\n",
      "'########################################################Model0\n",
      "Epoch 1/300\n",
      "35/35 [==============================] - 2s 15ms/step - loss: 1.0310 - val_loss: 0.8212\n",
      "Epoch 2/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.7508 - val_loss: 0.7812\n",
      "Epoch 3/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.6686 - val_loss: 0.7812\n",
      "Epoch 4/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.6102 - val_loss: 0.7763\n",
      "Epoch 5/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.5692 - val_loss: 0.7706\n",
      "Epoch 6/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.5312 - val_loss: 0.7840\n",
      "Epoch 7/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4993 - val_loss: 0.7947\n",
      "Epoch 8/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4764 - val_loss: 0.7893\n",
      "Epoch 9/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4489 - val_loss: 0.8000\n",
      "Epoch 10/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4270 - val_loss: 0.7891\n",
      "Epoch 11/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4045 - val_loss: 0.7883\n",
      "Epoch 12/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3925 - val_loss: 0.7976\n",
      "Epoch 13/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3791 - val_loss: 0.8013\n",
      "Epoch 14/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3680 - val_loss: 0.7891\n",
      "Epoch 15/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3515 - val_loss: 0.7981\n",
      "Epoch 16/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3369 - val_loss: 0.7912\n",
      "Epoch 17/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3272 - val_loss: 0.8034\n",
      "Epoch 18/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3102 - val_loss: 0.7957\n",
      "Epoch 19/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3090 - val_loss: 0.7970\n",
      "Epoch 20/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2951 - val_loss: 0.7942\n",
      "Epoch 21/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2938 - val_loss: 0.7944\n",
      "Epoch 22/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2806 - val_loss: 0.7901\n",
      "Epoch 23/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2735 - val_loss: 0.7868\n",
      "Epoch 24/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2670 - val_loss: 0.7917\n",
      "Epoch 25/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2636 - val_loss: 0.7920\n",
      "Epoch 26/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2614 - val_loss: 0.7955\n",
      "Epoch 27/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2558 - val_loss: 0.7836\n",
      "Epoch 28/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2448 - val_loss: 0.7915\n",
      "Epoch 29/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2421 - val_loss: 0.7893\n",
      "Epoch 30/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2368 - val_loss: 0.7824\n",
      "Epoch 31/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2352 - val_loss: 0.7895\n",
      "Epoch 32/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2333 - val_loss: 0.7850\n",
      "Epoch 33/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2283 - val_loss: 0.7843\n",
      "Epoch 34/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2274 - val_loss: 0.7843\n",
      "Epoch 35/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2233 - val_loss: 0.7845\n",
      "'########################################################Model1\n",
      "Epoch 1/300\n",
      "35/35 [==============================] - 2s 13ms/step - loss: 0.9889 - val_loss: 0.7976\n",
      "Epoch 2/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.7530 - val_loss: 0.7723\n",
      "Epoch 3/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.6716 - val_loss: 0.7525\n",
      "Epoch 4/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.6096 - val_loss: 0.7557\n",
      "Epoch 5/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.5662 - val_loss: 0.7584\n",
      "Epoch 6/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.5435 - val_loss: 0.7637\n",
      "Epoch 7/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.5027 - val_loss: 0.7634\n",
      "Epoch 8/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4706 - val_loss: 0.7790\n",
      "Epoch 9/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4514 - val_loss: 0.7702\n",
      "Epoch 10/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4264 - val_loss: 0.7724\n",
      "Epoch 11/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4125 - val_loss: 0.7761\n",
      "Epoch 12/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3980 - val_loss: 0.7770\n",
      "Epoch 13/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3809 - val_loss: 0.7791\n",
      "Epoch 14/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3628 - val_loss: 0.7797\n",
      "Epoch 15/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3459 - val_loss: 0.7872\n",
      "Epoch 16/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3335 - val_loss: 0.7762\n",
      "Epoch 17/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3268 - val_loss: 0.7771\n",
      "Epoch 18/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3124 - val_loss: 0.7755\n",
      "Epoch 19/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3093 - val_loss: 0.7672\n",
      "Epoch 20/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3003 - val_loss: 0.7706\n",
      "Epoch 21/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2896 - val_loss: 0.7816\n",
      "Epoch 22/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2824 - val_loss: 0.7696\n",
      "Epoch 23/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2738 - val_loss: 0.7756\n",
      "Epoch 24/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2670 - val_loss: 0.7731\n",
      "Epoch 25/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2588 - val_loss: 0.7757\n",
      "Epoch 26/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2573 - val_loss: 0.7825\n",
      "Epoch 27/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2555 - val_loss: 0.7744\n",
      "Epoch 28/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2481 - val_loss: 0.7751\n",
      "Epoch 29/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2508 - val_loss: 0.7786\n",
      "Epoch 30/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2397 - val_loss: 0.7712\n",
      "Epoch 31/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2380 - val_loss: 0.7695\n",
      "Epoch 32/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2342 - val_loss: 0.7692\n",
      "Epoch 33/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2326 - val_loss: 0.7724\n",
      "'########################################################Model2\n",
      "Epoch 1/300\n",
      "35/35 [==============================] - 1s 13ms/step - loss: 1.0854 - val_loss: 0.8325\n",
      "Epoch 2/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.7704 - val_loss: 0.7623\n",
      "Epoch 3/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.6828 - val_loss: 0.7631\n",
      "Epoch 4/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.6266 - val_loss: 0.7644\n",
      "Epoch 5/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.5861 - val_loss: 0.7673\n",
      "Epoch 6/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.5423 - val_loss: 0.7644\n",
      "Epoch 7/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.5159 - val_loss: 0.7644\n",
      "Epoch 8/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4846 - val_loss: 0.7761\n",
      "Epoch 9/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4642 - val_loss: 0.7759\n",
      "Epoch 10/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4424 - val_loss: 0.7716\n",
      "Epoch 11/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4245 - val_loss: 0.7819\n",
      "Epoch 12/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4070 - val_loss: 0.7770\n",
      "Epoch 13/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3923 - val_loss: 0.7780\n",
      "Epoch 14/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3711 - val_loss: 0.7822\n",
      "Epoch 15/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3596 - val_loss: 0.7801\n",
      "Epoch 16/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3489 - val_loss: 0.7821\n",
      "Epoch 17/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3304 - val_loss: 0.7858\n",
      "Epoch 18/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3343 - val_loss: 0.7824\n",
      "Epoch 19/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3153 - val_loss: 0.7841\n",
      "Epoch 20/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3088 - val_loss: 0.7865\n",
      "Epoch 21/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2998 - val_loss: 0.7908\n",
      "Epoch 22/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2908 - val_loss: 0.7871\n",
      "Epoch 23/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2873 - val_loss: 0.7866\n",
      "Epoch 24/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2825 - val_loss: 0.7894\n",
      "Epoch 25/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2756 - val_loss: 0.7894\n",
      "Epoch 26/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2662 - val_loss: 0.7824\n",
      "Epoch 27/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2597 - val_loss: 0.7869\n",
      "Epoch 28/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2570 - val_loss: 0.7920\n",
      "Epoch 29/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2490 - val_loss: 0.7838\n",
      "Epoch 30/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2503 - val_loss: 0.7883\n",
      "Epoch 31/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2459 - val_loss: 0.7844\n",
      "Epoch 32/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2398 - val_loss: 0.7829\n",
      "'########################################################Model3\n",
      "Epoch 1/300\n",
      "35/35 [==============================] - 2s 13ms/step - loss: 1.0464 - val_loss: 0.8040\n",
      "Epoch 2/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.7535 - val_loss: 0.7785\n",
      "Epoch 3/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.6666 - val_loss: 0.7751\n",
      "Epoch 4/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.6098 - val_loss: 0.7756\n",
      "Epoch 5/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.5700 - val_loss: 0.7751\n",
      "Epoch 6/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.5328 - val_loss: 0.7750\n",
      "Epoch 7/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4966 - val_loss: 0.7802\n",
      "Epoch 8/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4714 - val_loss: 0.7873\n",
      "Epoch 9/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4517 - val_loss: 0.7752\n",
      "Epoch 10/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4283 - val_loss: 0.7844\n",
      "Epoch 11/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4015 - val_loss: 0.7863\n",
      "Epoch 12/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3840 - val_loss: 0.7933\n",
      "Epoch 13/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3708 - val_loss: 0.7897\n",
      "Epoch 14/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3538 - val_loss: 0.7992\n",
      "Epoch 15/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3438 - val_loss: 0.7911\n",
      "Epoch 16/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3265 - val_loss: 0.7969\n",
      "Epoch 17/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3163 - val_loss: 0.7962\n",
      "Epoch 18/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3121 - val_loss: 0.7985\n",
      "Epoch 19/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3023 - val_loss: 0.7933\n",
      "Epoch 20/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2932 - val_loss: 0.7952\n",
      "Epoch 21/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2887 - val_loss: 0.7952\n",
      "Epoch 22/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2777 - val_loss: 0.7937\n",
      "Epoch 23/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2756 - val_loss: 0.7936\n",
      "Epoch 24/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2636 - val_loss: 0.7922\n",
      "Epoch 25/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2595 - val_loss: 0.7929\n",
      "Epoch 26/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2530 - val_loss: 0.7946\n",
      "Epoch 27/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2462 - val_loss: 0.7864\n",
      "Epoch 28/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2445 - val_loss: 0.7840\n",
      "Epoch 29/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2417 - val_loss: 0.7892\n",
      "Epoch 30/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2367 - val_loss: 0.7888\n",
      "Epoch 31/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2351 - val_loss: 0.7918\n",
      "Epoch 32/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2310 - val_loss: 0.7859\n",
      "Epoch 33/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2280 - val_loss: 0.7955\n",
      "Epoch 34/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2261 - val_loss: 0.7865\n",
      "Epoch 35/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2241 - val_loss: 0.7894\n",
      "Epoch 36/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2243 - val_loss: 0.7875\n",
      "'########################################################Model4\n",
      "Epoch 1/300\n",
      "35/35 [==============================] - 2s 14ms/step - loss: 1.0075 - val_loss: 0.8174\n",
      "Epoch 2/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.7505 - val_loss: 0.7787\n",
      "Epoch 3/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.6622 - val_loss: 0.7771\n",
      "Epoch 4/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.6027 - val_loss: 0.7775\n",
      "Epoch 5/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.5645 - val_loss: 0.7719\n",
      "Epoch 6/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.5151 - val_loss: 0.7798\n",
      "Epoch 7/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4898 - val_loss: 0.7771\n",
      "Epoch 8/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4666 - val_loss: 0.7742\n",
      "Epoch 9/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.4408 - val_loss: 0.7853\n",
      "Epoch 10/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4169 - val_loss: 0.7838\n",
      "Epoch 11/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4047 - val_loss: 0.7767\n",
      "Epoch 12/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3827 - val_loss: 0.7829\n",
      "Epoch 13/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3691 - val_loss: 0.7792\n",
      "Epoch 14/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3502 - val_loss: 0.7836\n",
      "Epoch 15/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3405 - val_loss: 0.7809\n",
      "Epoch 16/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3331 - val_loss: 0.7716\n",
      "Epoch 17/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3218 - val_loss: 0.7900\n",
      "Epoch 18/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3100 - val_loss: 0.7764\n",
      "Epoch 19/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2977 - val_loss: 0.7740\n",
      "Epoch 20/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2885 - val_loss: 0.7797\n",
      "Epoch 21/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2890 - val_loss: 0.7839\n",
      "Epoch 22/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2757 - val_loss: 0.7777\n",
      "Epoch 23/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2698 - val_loss: 0.7855\n",
      "Epoch 24/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2627 - val_loss: 0.7807\n",
      "Epoch 25/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2598 - val_loss: 0.7757\n",
      "Epoch 26/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2540 - val_loss: 0.7795\n",
      "Epoch 27/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2499 - val_loss: 0.7765\n",
      "Epoch 28/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2437 - val_loss: 0.7707\n",
      "Epoch 29/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2425 - val_loss: 0.7745\n",
      "Epoch 30/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2393 - val_loss: 0.7766\n",
      "Epoch 31/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2311 - val_loss: 0.7712\n",
      "Epoch 32/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2302 - val_loss: 0.7673\n",
      "Epoch 33/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2264 - val_loss: 0.7707\n",
      "Epoch 34/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2270 - val_loss: 0.7636\n",
      "Epoch 35/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2218 - val_loss: 0.7717\n",
      "Epoch 36/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2225 - val_loss: 0.7660\n",
      "Epoch 37/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2227 - val_loss: 0.7694\n",
      "Epoch 38/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2224 - val_loss: 0.7698\n",
      "Epoch 39/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2180 - val_loss: 0.7680\n",
      "Epoch 40/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2151 - val_loss: 0.7684\n",
      "Epoch 41/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2134 - val_loss: 0.7597\n",
      "Epoch 42/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2126 - val_loss: 0.7617\n",
      "Epoch 43/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2095 - val_loss: 0.7679\n",
      "Epoch 44/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2036 - val_loss: 0.7617\n",
      "Epoch 45/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2031 - val_loss: 0.7607\n",
      "Epoch 46/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2040 - val_loss: 0.7587\n",
      "Epoch 47/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2051 - val_loss: 0.7618\n",
      "Epoch 48/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2030 - val_loss: 0.7627\n",
      "Epoch 49/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2031 - val_loss: 0.7682\n",
      "Epoch 50/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2023 - val_loss: 0.7642\n",
      "Epoch 51/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2001 - val_loss: 0.7641\n",
      "Epoch 52/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2003 - val_loss: 0.7563\n",
      "Epoch 53/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2007 - val_loss: 0.7617\n",
      "Epoch 54/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1948 - val_loss: 0.7583\n",
      "Epoch 55/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1978 - val_loss: 0.7555\n",
      "Epoch 56/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1996 - val_loss: 0.7594\n",
      "Epoch 57/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1959 - val_loss: 0.7562\n",
      "Epoch 58/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1937 - val_loss: 0.7552\n",
      "Epoch 59/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1937 - val_loss: 0.7563\n",
      "Epoch 60/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1939 - val_loss: 0.7610\n",
      "Epoch 61/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1932 - val_loss: 0.7517\n",
      "Epoch 62/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1947 - val_loss: 0.7568\n",
      "Epoch 63/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1949 - val_loss: 0.7546\n",
      "Epoch 64/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1927 - val_loss: 0.7557\n",
      "Epoch 65/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1941 - val_loss: 0.7608\n",
      "Epoch 66/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1887 - val_loss: 0.7558\n",
      "Epoch 67/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1893 - val_loss: 0.7525\n",
      "Epoch 68/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1898 - val_loss: 0.7505\n",
      "Epoch 69/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1882 - val_loss: 0.7595\n",
      "Epoch 70/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1895 - val_loss: 0.7553\n",
      "Epoch 71/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1908 - val_loss: 0.7535\n",
      "Epoch 72/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1903 - val_loss: 0.7574\n",
      "Epoch 73/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1896 - val_loss: 0.7581\n",
      "Epoch 74/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1884 - val_loss: 0.7575\n",
      "Epoch 75/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1882 - val_loss: 0.7530\n",
      "Epoch 76/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1872 - val_loss: 0.7547\n",
      "Epoch 77/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1867 - val_loss: 0.7500\n",
      "Epoch 78/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1894 - val_loss: 0.7574\n",
      "Epoch 79/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1894 - val_loss: 0.7533\n",
      "Epoch 80/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1883 - val_loss: 0.7533\n",
      "Epoch 81/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1871 - val_loss: 0.7463\n",
      "Epoch 82/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1849 - val_loss: 0.7535\n",
      "Epoch 83/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1847 - val_loss: 0.7533\n",
      "Epoch 84/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1860 - val_loss: 0.7509\n",
      "Epoch 85/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1868 - val_loss: 0.7519\n",
      "Epoch 86/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1859 - val_loss: 0.7520\n",
      "Epoch 87/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1853 - val_loss: 0.7564\n",
      "Epoch 88/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1858 - val_loss: 0.7509\n",
      "Epoch 89/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1828 - val_loss: 0.7517\n",
      "Epoch 90/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1827 - val_loss: 0.7488\n",
      "Epoch 91/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1809 - val_loss: 0.7524\n",
      "Epoch 92/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1824 - val_loss: 0.7496\n",
      "Epoch 93/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1826 - val_loss: 0.7538\n",
      "Epoch 94/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1842 - val_loss: 0.7476\n",
      "Epoch 95/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1834 - val_loss: 0.7489\n",
      "Epoch 96/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1859 - val_loss: 0.7549\n",
      "Epoch 97/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1827 - val_loss: 0.7487\n",
      "Epoch 98/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1817 - val_loss: 0.7528\n",
      "Epoch 99/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1857 - val_loss: 0.7471\n",
      "Epoch 100/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1827 - val_loss: 0.7526\n",
      "Epoch 101/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1804 - val_loss: 0.7503\n",
      "Epoch 102/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1836 - val_loss: 0.7520\n",
      "Epoch 103/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1841 - val_loss: 0.7514\n",
      "Epoch 104/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1822 - val_loss: 0.7521\n",
      "Epoch 105/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1814 - val_loss: 0.7542\n",
      "Epoch 106/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1834 - val_loss: 0.7453\n",
      "Epoch 107/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1811 - val_loss: 0.7485\n",
      "Epoch 108/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1806 - val_loss: 0.7515\n",
      "Epoch 109/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1806 - val_loss: 0.7546\n",
      "Epoch 110/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1783 - val_loss: 0.7465\n",
      "Epoch 111/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1795 - val_loss: 0.7534\n",
      "Epoch 112/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1796 - val_loss: 0.7490\n",
      "Epoch 113/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1794 - val_loss: 0.7485\n",
      "Epoch 114/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1800 - val_loss: 0.7466\n",
      "Epoch 115/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1772 - val_loss: 0.7490\n",
      "Epoch 116/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1775 - val_loss: 0.7479\n",
      "Epoch 117/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1785 - val_loss: 0.7494\n",
      "Epoch 118/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1795 - val_loss: 0.7459\n",
      "Epoch 119/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1787 - val_loss: 0.7479\n",
      "Epoch 120/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1793 - val_loss: 0.7506\n",
      "Epoch 121/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1781 - val_loss: 0.7455\n",
      "Epoch 122/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1765 - val_loss: 0.7444\n",
      "Epoch 123/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1765 - val_loss: 0.7498\n",
      "Epoch 124/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1749 - val_loss: 0.7435\n",
      "Epoch 125/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1753 - val_loss: 0.7451\n",
      "Epoch 126/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1757 - val_loss: 0.7497\n",
      "Epoch 127/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1777 - val_loss: 0.7430\n",
      "Epoch 128/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1779 - val_loss: 0.7489\n",
      "Epoch 129/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1770 - val_loss: 0.7483\n",
      "Epoch 130/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1813 - val_loss: 0.7446\n",
      "Epoch 131/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1757 - val_loss: 0.7480\n",
      "Epoch 132/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1759 - val_loss: 0.7422\n",
      "Epoch 133/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1753 - val_loss: 0.7486\n",
      "Epoch 134/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1765 - val_loss: 0.7428\n",
      "Epoch 135/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1752 - val_loss: 0.7458\n",
      "Epoch 136/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1746 - val_loss: 0.7477\n",
      "Epoch 137/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1740 - val_loss: 0.7417\n",
      "Epoch 138/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1757 - val_loss: 0.7476\n",
      "Epoch 139/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1759 - val_loss: 0.7415\n",
      "Epoch 140/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1748 - val_loss: 0.7476\n",
      "Epoch 141/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1757 - val_loss: 0.7432\n",
      "Epoch 142/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1744 - val_loss: 0.7470\n",
      "Epoch 143/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1740 - val_loss: 0.7463\n",
      "Epoch 144/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1751 - val_loss: 0.7466\n",
      "Epoch 145/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1726 - val_loss: 0.7398\n",
      "Epoch 146/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1735 - val_loss: 0.7437\n",
      "Epoch 147/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1727 - val_loss: 0.7453\n",
      "Epoch 148/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1724 - val_loss: 0.7459\n",
      "Epoch 149/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1719 - val_loss: 0.7433\n",
      "Epoch 150/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1725 - val_loss: 0.7468\n",
      "Epoch 151/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1733 - val_loss: 0.7465\n",
      "Epoch 152/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1736 - val_loss: 0.7461\n",
      "Epoch 153/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1724 - val_loss: 0.7436\n",
      "Epoch 154/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1723 - val_loss: 0.7460\n",
      "Epoch 155/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1727 - val_loss: 0.7449\n",
      "Epoch 156/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1713 - val_loss: 0.7446\n",
      "Epoch 157/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1705 - val_loss: 0.7493\n",
      "Epoch 158/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1698 - val_loss: 0.7468\n",
      "Epoch 159/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1704 - val_loss: 0.7451\n",
      "Epoch 160/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1731 - val_loss: 0.7481\n",
      "Epoch 161/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1696 - val_loss: 0.7497\n",
      "Epoch 162/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1707 - val_loss: 0.7430\n",
      "Epoch 163/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1692 - val_loss: 0.7481\n",
      "Epoch 164/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1718 - val_loss: 0.7459\n",
      "Epoch 165/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1736 - val_loss: 0.7493\n",
      "Epoch 166/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1689 - val_loss: 0.7428\n",
      "Epoch 167/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1741 - val_loss: 0.7454\n",
      "Epoch 168/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1688 - val_loss: 0.7452\n",
      "Epoch 169/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1721 - val_loss: 0.7463\n",
      "Epoch 170/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1719 - val_loss: 0.7458\n",
      "Epoch 171/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1703 - val_loss: 0.7485\n",
      "Epoch 172/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1699 - val_loss: 0.7442\n",
      "Epoch 173/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1684 - val_loss: 0.7468\n",
      "Epoch 174/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1686 - val_loss: 0.7448\n",
      "Epoch 175/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1677 - val_loss: 0.7439\n",
      "'########################################################Model5\n",
      "Epoch 1/300\n",
      "35/35 [==============================] - 1s 12ms/step - loss: 1.1350 - val_loss: 0.8230\n",
      "Epoch 2/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.7561 - val_loss: 0.7670\n",
      "Epoch 3/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.6746 - val_loss: 0.7915\n",
      "Epoch 4/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.6190 - val_loss: 0.7793\n",
      "Epoch 5/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.5729 - val_loss: 0.7879\n",
      "Epoch 6/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.5367 - val_loss: 0.7853\n",
      "Epoch 7/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.5089 - val_loss: 0.7898\n",
      "Epoch 8/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4808 - val_loss: 0.7996\n",
      "Epoch 9/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4511 - val_loss: 0.7992\n",
      "Epoch 10/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4329 - val_loss: 0.8048\n",
      "Epoch 11/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4136 - val_loss: 0.7955\n",
      "Epoch 12/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3927 - val_loss: 0.8161\n",
      "Epoch 13/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3814 - val_loss: 0.8075\n",
      "Epoch 14/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3613 - val_loss: 0.8172\n",
      "Epoch 15/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3475 - val_loss: 0.8141\n",
      "Epoch 16/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3410 - val_loss: 0.8089\n",
      "Epoch 17/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3331 - val_loss: 0.8015\n",
      "Epoch 18/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3239 - val_loss: 0.8061\n",
      "Epoch 19/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3072 - val_loss: 0.8061\n",
      "Epoch 20/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2995 - val_loss: 0.8206\n",
      "Epoch 21/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2896 - val_loss: 0.8011\n",
      "Epoch 22/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2847 - val_loss: 0.8018\n",
      "Epoch 23/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2805 - val_loss: 0.8142\n",
      "Epoch 24/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2674 - val_loss: 0.8096\n",
      "Epoch 25/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2651 - val_loss: 0.8094\n",
      "Epoch 26/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2603 - val_loss: 0.7981\n",
      "Epoch 27/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2516 - val_loss: 0.8061\n",
      "Epoch 28/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2489 - val_loss: 0.7984\n",
      "Epoch 29/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2432 - val_loss: 0.8051\n",
      "Epoch 30/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2451 - val_loss: 0.7884\n",
      "Epoch 31/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2354 - val_loss: 0.8027\n",
      "Epoch 32/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2335 - val_loss: 0.7935\n",
      "'########################################################Model6\n",
      "Epoch 1/300\n",
      "35/35 [==============================] - 1s 13ms/step - loss: 1.0270 - val_loss: 0.7702\n",
      "Epoch 2/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.7375 - val_loss: 0.7526\n",
      "Epoch 3/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.6539 - val_loss: 0.7505\n",
      "Epoch 4/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.6024 - val_loss: 0.7530\n",
      "Epoch 5/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.5628 - val_loss: 0.7547\n",
      "Epoch 6/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.5274 - val_loss: 0.7631\n",
      "Epoch 7/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.5042 - val_loss: 0.7678\n",
      "Epoch 8/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4822 - val_loss: 0.7631\n",
      "Epoch 9/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4577 - val_loss: 0.7608\n",
      "Epoch 10/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4355 - val_loss: 0.7706\n",
      "Epoch 11/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4066 - val_loss: 0.7716\n",
      "Epoch 12/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3967 - val_loss: 0.7713\n",
      "Epoch 13/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3738 - val_loss: 0.7724\n",
      "Epoch 14/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3601 - val_loss: 0.7736\n",
      "Epoch 15/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3480 - val_loss: 0.7722\n",
      "Epoch 16/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3339 - val_loss: 0.7787\n",
      "Epoch 17/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3216 - val_loss: 0.7746\n",
      "Epoch 18/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3192 - val_loss: 0.7797\n",
      "Epoch 19/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3048 - val_loss: 0.7881\n",
      "Epoch 20/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2992 - val_loss: 0.7907\n",
      "Epoch 21/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2886 - val_loss: 0.7856\n",
      "Epoch 22/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2794 - val_loss: 0.7805\n",
      "Epoch 23/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2713 - val_loss: 0.7892\n",
      "Epoch 24/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2665 - val_loss: 0.7836\n",
      "Epoch 25/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2569 - val_loss: 0.7837\n",
      "Epoch 26/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2551 - val_loss: 0.7817\n",
      "Epoch 27/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2467 - val_loss: 0.7853\n",
      "Epoch 28/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2427 - val_loss: 0.7873\n",
      "Epoch 29/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2427 - val_loss: 0.7797\n",
      "Epoch 30/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2349 - val_loss: 0.7944\n",
      "Epoch 31/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2393 - val_loss: 0.7802\n",
      "Epoch 32/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2363 - val_loss: 0.7755\n",
      "Epoch 33/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2342 - val_loss: 0.7854\n",
      "'########################################################Model7\n",
      "Epoch 1/300\n",
      "35/35 [==============================] - 2s 14ms/step - loss: 0.9839 - val_loss: 0.8019\n",
      "Epoch 2/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.7383 - val_loss: 0.7801\n",
      "Epoch 3/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.6632 - val_loss: 0.7668\n",
      "Epoch 4/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.6070 - val_loss: 0.7654\n",
      "Epoch 5/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.5593 - val_loss: 0.7659\n",
      "Epoch 6/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.5254 - val_loss: 0.7688\n",
      "Epoch 7/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4929 - val_loss: 0.7757\n",
      "Epoch 8/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4665 - val_loss: 0.7700\n",
      "Epoch 9/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4418 - val_loss: 0.7774\n",
      "Epoch 10/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4241 - val_loss: 0.7749\n",
      "Epoch 11/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3958 - val_loss: 0.7797\n",
      "Epoch 12/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3821 - val_loss: 0.7751\n",
      "Epoch 13/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3661 - val_loss: 0.7816\n",
      "Epoch 14/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3474 - val_loss: 0.7737\n",
      "Epoch 15/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3355 - val_loss: 0.7815\n",
      "Epoch 16/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3332 - val_loss: 0.7738\n",
      "Epoch 17/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3191 - val_loss: 0.7772\n",
      "Epoch 18/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3054 - val_loss: 0.7805\n",
      "Epoch 19/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2939 - val_loss: 0.7768\n",
      "Epoch 20/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2876 - val_loss: 0.7705\n",
      "Epoch 21/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2786 - val_loss: 0.7782\n",
      "Epoch 22/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2723 - val_loss: 0.7756\n",
      "Epoch 23/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2655 - val_loss: 0.7735\n",
      "Epoch 24/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2626 - val_loss: 0.7778\n",
      "Epoch 25/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2531 - val_loss: 0.7680\n",
      "Epoch 26/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2509 - val_loss: 0.7734\n",
      "Epoch 27/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2418 - val_loss: 0.7662\n",
      "Epoch 28/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2422 - val_loss: 0.7636\n",
      "Epoch 29/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2391 - val_loss: 0.7700\n",
      "Epoch 30/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2322 - val_loss: 0.7622\n",
      "Epoch 31/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2318 - val_loss: 0.7640\n",
      "Epoch 32/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2290 - val_loss: 0.7668\n",
      "Epoch 33/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2279 - val_loss: 0.7621\n",
      "Epoch 34/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2256 - val_loss: 0.7626\n",
      "Epoch 35/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2191 - val_loss: 0.7682\n",
      "Epoch 36/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2192 - val_loss: 0.7659\n",
      "Epoch 37/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2159 - val_loss: 0.7619\n",
      "Epoch 38/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2162 - val_loss: 0.7637\n",
      "Epoch 39/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2128 - val_loss: 0.7628\n",
      "Epoch 40/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2116 - val_loss: 0.7571\n",
      "Epoch 41/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2126 - val_loss: 0.7621\n",
      "Epoch 42/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2098 - val_loss: 0.7629\n",
      "Epoch 43/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2074 - val_loss: 0.7619\n",
      "Epoch 44/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2071 - val_loss: 0.7603\n",
      "Epoch 45/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2039 - val_loss: 0.7618\n",
      "Epoch 46/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2025 - val_loss: 0.7528\n",
      "Epoch 47/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2010 - val_loss: 0.7605\n",
      "Epoch 48/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2012 - val_loss: 0.7513\n",
      "Epoch 49/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2044 - val_loss: 0.7628\n",
      "Epoch 50/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2044 - val_loss: 0.7614\n",
      "Epoch 51/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1996 - val_loss: 0.7606\n",
      "Epoch 52/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2033 - val_loss: 0.7604\n",
      "Epoch 53/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1992 - val_loss: 0.7588\n",
      "Epoch 54/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2009 - val_loss: 0.7555\n",
      "Epoch 55/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1973 - val_loss: 0.7581\n",
      "Epoch 56/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1966 - val_loss: 0.7583\n",
      "Epoch 57/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1960 - val_loss: 0.7613\n",
      "Epoch 58/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1935 - val_loss: 0.7522\n",
      "Epoch 59/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1968 - val_loss: 0.7500\n",
      "Epoch 60/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1943 - val_loss: 0.7572\n",
      "Epoch 61/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1916 - val_loss: 0.7527\n",
      "Epoch 62/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1894 - val_loss: 0.7541\n",
      "Epoch 63/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1919 - val_loss: 0.7495\n",
      "Epoch 64/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1905 - val_loss: 0.7508\n",
      "Epoch 65/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1934 - val_loss: 0.7552\n",
      "Epoch 66/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1924 - val_loss: 0.7542\n",
      "Epoch 67/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1902 - val_loss: 0.7480\n",
      "Epoch 68/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1895 - val_loss: 0.7492\n",
      "Epoch 69/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1894 - val_loss: 0.7506\n",
      "Epoch 70/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1884 - val_loss: 0.7495\n",
      "Epoch 71/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1886 - val_loss: 0.7509\n",
      "Epoch 72/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1862 - val_loss: 0.7465\n",
      "Epoch 73/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1901 - val_loss: 0.7486\n",
      "Epoch 74/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1907 - val_loss: 0.7463\n",
      "Epoch 75/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1881 - val_loss: 0.7492\n",
      "Epoch 76/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1857 - val_loss: 0.7448\n",
      "Epoch 77/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1863 - val_loss: 0.7439\n",
      "Epoch 78/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1870 - val_loss: 0.7488\n",
      "Epoch 79/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1870 - val_loss: 0.7474\n",
      "Epoch 80/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1861 - val_loss: 0.7465\n",
      "Epoch 81/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1860 - val_loss: 0.7476\n",
      "Epoch 82/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1843 - val_loss: 0.7450\n",
      "Epoch 83/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1858 - val_loss: 0.7441\n",
      "Epoch 84/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1842 - val_loss: 0.7469\n",
      "Epoch 85/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1829 - val_loss: 0.7473\n",
      "Epoch 86/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1836 - val_loss: 0.7470\n",
      "Epoch 87/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1852 - val_loss: 0.7404\n",
      "Epoch 88/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1849 - val_loss: 0.7437\n",
      "Epoch 89/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1852 - val_loss: 0.7447\n",
      "Epoch 90/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1842 - val_loss: 0.7414\n",
      "Epoch 91/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1813 - val_loss: 0.7444\n",
      "Epoch 92/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1835 - val_loss: 0.7437\n",
      "Epoch 93/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1833 - val_loss: 0.7454\n",
      "Epoch 94/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1840 - val_loss: 0.7459\n",
      "Epoch 95/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1810 - val_loss: 0.7408\n",
      "Epoch 96/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1821 - val_loss: 0.7382\n",
      "Epoch 97/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1813 - val_loss: 0.7468\n",
      "Epoch 98/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1823 - val_loss: 0.7406\n",
      "Epoch 99/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1800 - val_loss: 0.7446\n",
      "Epoch 100/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1808 - val_loss: 0.7432\n",
      "Epoch 101/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1817 - val_loss: 0.7432\n",
      "Epoch 102/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1791 - val_loss: 0.7413\n",
      "Epoch 103/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1807 - val_loss: 0.7404\n",
      "Epoch 104/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1801 - val_loss: 0.7385\n",
      "Epoch 105/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1795 - val_loss: 0.7418\n",
      "Epoch 106/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1784 - val_loss: 0.7410\n",
      "Epoch 107/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1776 - val_loss: 0.7405\n",
      "Epoch 108/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1805 - val_loss: 0.7417\n",
      "Epoch 109/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1794 - val_loss: 0.7340\n",
      "Epoch 110/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1805 - val_loss: 0.7374\n",
      "Epoch 111/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1806 - val_loss: 0.7385\n",
      "Epoch 112/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1771 - val_loss: 0.7396\n",
      "Epoch 113/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1798 - val_loss: 0.7388\n",
      "Epoch 114/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1785 - val_loss: 0.7392\n",
      "Epoch 115/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1810 - val_loss: 0.7399\n",
      "Epoch 116/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1800 - val_loss: 0.7340\n",
      "Epoch 117/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1795 - val_loss: 0.7392\n",
      "Epoch 118/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1766 - val_loss: 0.7369\n",
      "Epoch 119/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1776 - val_loss: 0.7399\n",
      "Epoch 120/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1782 - val_loss: 0.7353\n",
      "Epoch 121/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1765 - val_loss: 0.7351\n",
      "Epoch 122/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1762 - val_loss: 0.7370\n",
      "Epoch 123/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1761 - val_loss: 0.7374\n",
      "Epoch 124/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1803 - val_loss: 0.7365\n",
      "Epoch 125/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1766 - val_loss: 0.7349\n",
      "Epoch 126/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1776 - val_loss: 0.7371\n",
      "Epoch 127/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1763 - val_loss: 0.7375\n",
      "Epoch 128/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1754 - val_loss: 0.7359\n",
      "Epoch 129/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1774 - val_loss: 0.7381\n",
      "Epoch 130/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1755 - val_loss: 0.7372\n",
      "Epoch 131/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1779 - val_loss: 0.7342\n",
      "Epoch 132/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1744 - val_loss: 0.7332\n",
      "Epoch 133/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1755 - val_loss: 0.7396\n",
      "Epoch 134/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1775 - val_loss: 0.7328\n",
      "Epoch 135/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1747 - val_loss: 0.7317\n",
      "Epoch 136/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1734 - val_loss: 0.7370\n",
      "Epoch 137/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1737 - val_loss: 0.7368\n",
      "Epoch 138/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1750 - val_loss: 0.7307\n",
      "Epoch 139/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1759 - val_loss: 0.7343\n",
      "Epoch 140/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1749 - val_loss: 0.7349\n",
      "Epoch 141/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1754 - val_loss: 0.7359\n",
      "Epoch 142/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1749 - val_loss: 0.7318\n",
      "Epoch 143/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1759 - val_loss: 0.7345\n",
      "Epoch 144/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1712 - val_loss: 0.7346\n",
      "Epoch 145/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1725 - val_loss: 0.7301\n",
      "Epoch 146/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1737 - val_loss: 0.7362\n",
      "Epoch 147/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1725 - val_loss: 0.7346\n",
      "Epoch 148/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1734 - val_loss: 0.7301\n",
      "Epoch 149/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1706 - val_loss: 0.7316\n",
      "Epoch 150/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1734 - val_loss: 0.7316\n",
      "Epoch 151/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1739 - val_loss: 0.7262\n",
      "Epoch 152/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1732 - val_loss: 0.7298\n",
      "Epoch 153/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1735 - val_loss: 0.7325\n",
      "Epoch 154/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1717 - val_loss: 0.7315\n",
      "Epoch 155/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1717 - val_loss: 0.7271\n",
      "Epoch 156/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1734 - val_loss: 0.7331\n",
      "Epoch 157/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1725 - val_loss: 0.7322\n",
      "Epoch 158/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1739 - val_loss: 0.7273\n",
      "Epoch 159/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1715 - val_loss: 0.7330\n",
      "Epoch 160/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1721 - val_loss: 0.7321\n",
      "Epoch 161/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1693 - val_loss: 0.7317\n",
      "Epoch 162/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1693 - val_loss: 0.7398\n",
      "Epoch 163/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1727 - val_loss: 0.7349\n",
      "Epoch 164/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1718 - val_loss: 0.7382\n",
      "Epoch 165/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1721 - val_loss: 0.7312\n",
      "Epoch 166/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1719 - val_loss: 0.7354\n",
      "Epoch 167/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1692 - val_loss: 0.7374\n",
      "Epoch 168/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1681 - val_loss: 0.7316\n",
      "Epoch 169/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1682 - val_loss: 0.7347\n",
      "Epoch 170/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1704 - val_loss: 0.7364\n",
      "Epoch 171/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1699 - val_loss: 0.7305\n",
      "Epoch 172/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1706 - val_loss: 0.7342\n",
      "Epoch 173/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1705 - val_loss: 0.7350\n",
      "Epoch 174/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1699 - val_loss: 0.7294\n",
      "Epoch 175/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1699 - val_loss: 0.7336\n",
      "Epoch 176/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1685 - val_loss: 0.7338\n",
      "Epoch 177/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1675 - val_loss: 0.7311\n",
      "Epoch 178/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1672 - val_loss: 0.7340\n",
      "Epoch 179/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1671 - val_loss: 0.7313\n",
      "Epoch 180/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.1691 - val_loss: 0.7323\n",
      "Epoch 181/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.1680 - val_loss: 0.7349\n",
      "'########################################################Model8\n",
      "Epoch 1/300\n",
      "35/35 [==============================] - 1s 13ms/step - loss: 1.0385 - val_loss: 0.8223\n",
      "Epoch 2/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.7580 - val_loss: 0.7748\n",
      "Epoch 3/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.6737 - val_loss: 0.7749\n",
      "Epoch 4/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.6121 - val_loss: 0.7675\n",
      "Epoch 5/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.5719 - val_loss: 0.7745\n",
      "Epoch 6/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.5370 - val_loss: 0.7776\n",
      "Epoch 7/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.5169 - val_loss: 0.7816\n",
      "Epoch 8/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4858 - val_loss: 0.7811\n",
      "Epoch 9/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4585 - val_loss: 0.7743\n",
      "Epoch 10/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4347 - val_loss: 0.7818\n",
      "Epoch 11/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.4191 - val_loss: 0.7843\n",
      "Epoch 12/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.4049 - val_loss: 0.7833\n",
      "Epoch 13/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3856 - val_loss: 0.7920\n",
      "Epoch 14/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3650 - val_loss: 0.7901\n",
      "Epoch 15/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3546 - val_loss: 0.8024\n",
      "Epoch 16/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3476 - val_loss: 0.7972\n",
      "Epoch 17/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.3379 - val_loss: 0.7925\n",
      "Epoch 18/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3209 - val_loss: 0.7876\n",
      "Epoch 19/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3111 - val_loss: 0.7987\n",
      "Epoch 20/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.3022 - val_loss: 0.7900\n",
      "Epoch 21/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2944 - val_loss: 0.7840\n",
      "Epoch 22/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2867 - val_loss: 0.7889\n",
      "Epoch 23/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2750 - val_loss: 0.7863\n",
      "Epoch 24/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2703 - val_loss: 0.7913\n",
      "Epoch 25/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2644 - val_loss: 0.7906\n",
      "Epoch 26/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2647 - val_loss: 0.7922\n",
      "Epoch 27/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2554 - val_loss: 0.7829\n",
      "Epoch 28/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2558 - val_loss: 0.7879\n",
      "Epoch 29/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2482 - val_loss: 0.7929\n",
      "Epoch 30/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2461 - val_loss: 0.7900\n",
      "Epoch 31/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2454 - val_loss: 0.7881\n",
      "Epoch 32/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.2402 - val_loss: 0.7869\n",
      "Epoch 33/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.2368 - val_loss: 0.7801\n",
      "Epoch 34/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 0.2328 - val_loss: 0.7836\n",
      "'########################################################Model9\n",
      "Epoch 1/300\n",
      "35/35 [==============================] - 2s 14ms/step - loss: 1354.9238 - val_loss: 501.0595\n",
      "Epoch 2/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 9486.8916 - val_loss: 405.6971\n",
      "Epoch 3/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 1189.7098 - val_loss: 371.3688\n",
      "Epoch 4/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 2350.9475 - val_loss: 366.3348\n",
      "Epoch 5/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 8582.0615 - val_loss: 443.2498\n",
      "Epoch 6/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 5212.6860 - val_loss: 411.0025\n",
      "Epoch 7/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 6392.8096 - val_loss: 340.9230\n",
      "Epoch 8/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1529.4685 - val_loss: 277.3482\n",
      "Epoch 9/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 4532.6582 - val_loss: 471.9611\n",
      "Epoch 10/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 5895.2407 - val_loss: 313.4873\n",
      "Epoch 11/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 3011.0798 - val_loss: 284.8880\n",
      "Epoch 12/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 6747.3887 - val_loss: 258.5316\n",
      "Epoch 13/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 1756.4332 - val_loss: 226.7831\n",
      "Epoch 14/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1756.1418 - val_loss: 239.1453\n",
      "Epoch 15/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 2087.3765 - val_loss: 228.8551\n",
      "Epoch 16/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 3835.3130 - val_loss: 230.5035\n",
      "Epoch 17/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 2303.3271 - val_loss: 217.6686\n",
      "Epoch 18/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1503.5779 - val_loss: 234.6380\n",
      "Epoch 19/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1888.6357 - val_loss: 208.7947\n",
      "Epoch 20/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 912.2364 - val_loss: 193.2772\n",
      "Epoch 21/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 1443.6041 - val_loss: 184.5790\n",
      "Epoch 22/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 775.7171 - val_loss: 190.5367\n",
      "Epoch 23/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 939.0248 - val_loss: 186.5136\n",
      "Epoch 24/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 510.6158 - val_loss: 188.7735\n",
      "Epoch 25/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1473.2933 - val_loss: 182.7583\n",
      "Epoch 26/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 680.5107 - val_loss: 182.5519\n",
      "Epoch 27/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 1267.0238 - val_loss: 184.3799\n",
      "Epoch 28/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 294.3065 - val_loss: 187.1542\n",
      "Epoch 29/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 870.3361 - val_loss: 184.3760\n",
      "Epoch 30/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 499.8092 - val_loss: 176.2981\n",
      "Epoch 31/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 750.1385 - val_loss: 175.6790\n",
      "Epoch 32/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 362.2037 - val_loss: 176.6292\n",
      "Epoch 33/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 610.2758 - val_loss: 168.2552\n",
      "Epoch 34/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 518.5148 - val_loss: 168.7489\n",
      "Epoch 35/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 451.8930 - val_loss: 168.1276\n",
      "Epoch 36/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 350.0492 - val_loss: 164.2658\n",
      "Epoch 37/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2758.6313 - val_loss: 178.3671\n",
      "Epoch 38/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 522.8900 - val_loss: 188.0116\n",
      "Epoch 39/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 572.8384 - val_loss: 167.0500\n",
      "Epoch 40/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 576.2466 - val_loss: 160.2261\n",
      "Epoch 41/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 564.5345 - val_loss: 171.1655\n",
      "Epoch 42/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 466.3517 - val_loss: 174.6609\n",
      "Epoch 43/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 645.1896 - val_loss: 173.8876\n",
      "Epoch 44/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 693.0453 - val_loss: 165.3203\n",
      "Epoch 45/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 639.5757 - val_loss: 164.1251\n",
      "Epoch 46/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 327.9649 - val_loss: 160.0319\n",
      "Epoch 47/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 416.1401 - val_loss: 159.5350\n",
      "Epoch 48/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 318.6420 - val_loss: 159.1100\n",
      "Epoch 49/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 468.3333 - val_loss: 164.7161\n",
      "Epoch 50/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 371.2159 - val_loss: 162.1764\n",
      "Epoch 51/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 462.8929 - val_loss: 157.6855\n",
      "Epoch 52/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 484.8518 - val_loss: 157.4298\n",
      "Epoch 53/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 449.4176 - val_loss: 156.3550\n",
      "Epoch 54/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 261.3942 - val_loss: 155.7533\n",
      "Epoch 55/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 372.1439 - val_loss: 162.9010\n",
      "Epoch 56/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 510.4173 - val_loss: 158.4259\n",
      "Epoch 57/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 153.1650 - val_loss: 162.4964\n",
      "Epoch 58/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 614.9849 - val_loss: 157.3008\n",
      "Epoch 59/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 227.7072 - val_loss: 158.5683\n",
      "Epoch 60/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 509.1425 - val_loss: 154.7854\n",
      "Epoch 61/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 264.4197 - val_loss: 161.4086\n",
      "Epoch 62/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 580.3867 - val_loss: 154.9153\n",
      "Epoch 63/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 398.9913 - val_loss: 154.9765\n",
      "Epoch 64/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 222.3207 - val_loss: 158.2816\n",
      "Epoch 65/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 659.7175 - val_loss: 158.5304\n",
      "Epoch 66/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 337.6397 - val_loss: 164.1638\n",
      "Epoch 67/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 271.1347 - val_loss: 165.5881\n",
      "Epoch 68/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 342.0324 - val_loss: 160.8893\n",
      "Epoch 69/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 328.8105 - val_loss: 160.3907\n",
      "Epoch 70/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 343.1920 - val_loss: 157.8213\n",
      "Epoch 71/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 349.9853 - val_loss: 156.7639\n",
      "Epoch 72/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 304.8027 - val_loss: 152.7019\n",
      "Epoch 73/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 324.9990 - val_loss: 152.4114\n",
      "Epoch 74/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 272.5339 - val_loss: 152.9923\n",
      "Epoch 75/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 203.3935 - val_loss: 153.0140\n",
      "Epoch 76/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 240.9112 - val_loss: 149.9734\n",
      "Epoch 77/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 214.5502 - val_loss: 149.7775\n",
      "Epoch 78/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 278.4746 - val_loss: 150.8657\n",
      "Epoch 79/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 203.0202 - val_loss: 151.7686\n",
      "Epoch 80/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 226.6696 - val_loss: 148.9809\n",
      "Epoch 81/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 169.8959 - val_loss: 150.9139\n",
      "Epoch 82/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 269.1432 - val_loss: 149.4086\n",
      "Epoch 83/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 188.0859 - val_loss: 150.5518\n",
      "Epoch 84/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 257.5063 - val_loss: 147.4436\n",
      "Epoch 85/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 218.9628 - val_loss: 147.2437\n",
      "Epoch 86/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 281.8578 - val_loss: 147.8564\n",
      "Epoch 87/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 180.6290 - val_loss: 147.8527\n",
      "Epoch 88/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 224.7218 - val_loss: 149.5249\n",
      "Epoch 89/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 228.3457 - val_loss: 149.4381\n",
      "Epoch 90/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 232.7610 - val_loss: 149.1866\n",
      "Epoch 91/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 177.4651 - val_loss: 150.1334\n",
      "Epoch 92/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 275.8969 - val_loss: 148.1991\n",
      "Epoch 93/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 237.3690 - val_loss: 147.0957\n",
      "Epoch 94/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 315.5706 - val_loss: 146.7419\n",
      "Epoch 95/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 231.1476 - val_loss: 145.8086\n",
      "Epoch 96/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 208.1314 - val_loss: 144.8862\n",
      "Epoch 97/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 220.8148 - val_loss: 144.4159\n",
      "Epoch 98/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 348.4087 - val_loss: 149.6182\n",
      "Epoch 99/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 495.5007 - val_loss: 148.2640\n",
      "Epoch 100/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 302.6746 - val_loss: 144.5893\n",
      "Epoch 101/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 240.7411 - val_loss: 141.7389\n",
      "Epoch 102/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 415.4944 - val_loss: 142.8295\n",
      "Epoch 103/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 273.2668 - val_loss: 143.1812\n",
      "Epoch 104/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 213.1043 - val_loss: 142.3003\n",
      "Epoch 105/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 370.6917 - val_loss: 142.3679\n",
      "Epoch 106/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 264.9125 - val_loss: 145.0947\n",
      "Epoch 107/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 173.3798 - val_loss: 144.3975\n",
      "Epoch 108/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 193.4211 - val_loss: 145.1621\n",
      "Epoch 109/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 248.5479 - val_loss: 144.7400\n",
      "Epoch 110/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 192.4088 - val_loss: 146.5330\n",
      "Epoch 111/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 277.8773 - val_loss: 143.7131\n",
      "Epoch 112/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 182.4861 - val_loss: 142.3112\n",
      "Epoch 113/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 182.9933 - val_loss: 142.6646\n",
      "Epoch 114/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 197.8286 - val_loss: 143.4317\n",
      "Epoch 115/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 173.6271 - val_loss: 144.3545\n",
      "Epoch 116/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 229.3845 - val_loss: 146.1606\n",
      "Epoch 117/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 224.1714 - val_loss: 142.4638\n",
      "Epoch 118/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 336.2850 - val_loss: 142.8545\n",
      "Epoch 119/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 258.6494 - val_loss: 141.0655\n",
      "Epoch 120/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 196.4626 - val_loss: 143.0565\n",
      "Epoch 121/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 449.5971 - val_loss: 140.9232\n",
      "Epoch 122/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 356.6684 - val_loss: 141.7486\n",
      "Epoch 123/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 377.5540 - val_loss: 145.8456\n",
      "Epoch 124/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 645.0605 - val_loss: 144.5144\n",
      "Epoch 125/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 250.7310 - val_loss: 141.4010\n",
      "Epoch 126/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 304.6918 - val_loss: 142.2385\n",
      "Epoch 127/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 370.6695 - val_loss: 139.1222\n",
      "Epoch 128/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 240.5386 - val_loss: 141.7331\n",
      "Epoch 129/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 540.0975 - val_loss: 136.5974\n",
      "Epoch 130/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 192.6194 - val_loss: 139.2564\n",
      "Epoch 131/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 471.1755 - val_loss: 136.4269\n",
      "Epoch 132/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 202.4314 - val_loss: 136.8554\n",
      "Epoch 133/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 669.5536 - val_loss: 136.8873\n",
      "Epoch 134/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 175.4175 - val_loss: 137.4361\n",
      "Epoch 135/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 306.8350 - val_loss: 135.2346\n",
      "Epoch 136/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 300.3228 - val_loss: 136.4852\n",
      "Epoch 137/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 222.5575 - val_loss: 132.6512\n",
      "Epoch 138/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 247.8163 - val_loss: 138.2939\n",
      "Epoch 139/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 363.4160 - val_loss: 151.4207\n",
      "Epoch 140/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 2126.0833 - val_loss: 142.9646\n",
      "Epoch 141/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 2498.3284 - val_loss: 193.9724\n",
      "Epoch 142/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 313.9789 - val_loss: 169.8971\n",
      "Epoch 143/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 2238.1980 - val_loss: 144.2248\n",
      "Epoch 144/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 403.7248 - val_loss: 139.4316\n",
      "Epoch 145/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 286.8495 - val_loss: 133.0142\n",
      "Epoch 146/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 369.2616 - val_loss: 135.5281\n",
      "Epoch 147/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1120.0604 - val_loss: 140.4661\n",
      "Epoch 148/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 467.4875 - val_loss: 161.2402\n",
      "Epoch 149/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 835.8776 - val_loss: 123.8616\n",
      "Epoch 150/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 397.8539 - val_loss: 136.6336\n",
      "Epoch 151/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 638.9773 - val_loss: 120.9073\n",
      "Epoch 152/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 399.5615 - val_loss: 119.7985\n",
      "Epoch 153/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1362.4048 - val_loss: 123.8609\n",
      "Epoch 154/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 729.5901 - val_loss: 118.3625\n",
      "Epoch 155/300\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 254.4759 - val_loss: 121.4874\n",
      "Epoch 156/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 446.8082 - val_loss: 119.8214\n",
      "Epoch 157/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 593.3751 - val_loss: 126.3181\n",
      "Epoch 158/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 158.1498 - val_loss: 117.6211\n",
      "Epoch 159/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 232.9650 - val_loss: 118.3970\n",
      "Epoch 160/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1890.7770 - val_loss: 114.7542\n",
      "Epoch 161/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 151.2302 - val_loss: 117.6964\n",
      "Epoch 162/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 623.3434 - val_loss: 113.4442\n",
      "Epoch 163/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 170.0233 - val_loss: 113.4684\n",
      "Epoch 164/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 262.1447 - val_loss: 111.5137\n",
      "Epoch 165/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 180.2655 - val_loss: 113.2248\n",
      "Epoch 166/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 153.5230 - val_loss: 111.2015\n",
      "Epoch 167/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 156.7520 - val_loss: 113.2525\n",
      "Epoch 168/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 118.3008 - val_loss: 111.4275\n",
      "Epoch 169/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 152.7629 - val_loss: 112.6996\n",
      "Epoch 170/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 125.4242 - val_loss: 110.6097\n",
      "Epoch 171/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 138.7182 - val_loss: 113.6142\n",
      "Epoch 172/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 136.9997 - val_loss: 110.8322\n",
      "Epoch 173/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 131.5789 - val_loss: 112.2614\n",
      "Epoch 174/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 120.0484 - val_loss: 111.5053\n",
      "Epoch 175/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 133.5033 - val_loss: 112.3455\n",
      "Epoch 176/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 112.7674 - val_loss: 111.1254\n",
      "Epoch 177/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 137.3200 - val_loss: 112.3915\n",
      "Epoch 178/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 100.7140 - val_loss: 113.5959\n",
      "Epoch 179/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 138.8110 - val_loss: 111.5527\n",
      "Epoch 180/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 108.7579 - val_loss: 112.4225\n",
      "Epoch 181/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 123.7951 - val_loss: 111.3458\n",
      "Epoch 182/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 111.4802 - val_loss: 113.5814\n",
      "Epoch 183/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 131.4130 - val_loss: 111.4911\n",
      "Epoch 184/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 102.1735 - val_loss: 113.5699\n",
      "Epoch 185/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 124.4031 - val_loss: 111.6156\n",
      "Epoch 186/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 110.7174 - val_loss: 112.7610\n",
      "Epoch 187/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 117.4107 - val_loss: 112.1963\n",
      "Epoch 188/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 118.5664 - val_loss: 113.1547\n",
      "Epoch 189/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 122.5280 - val_loss: 111.3307\n",
      "Epoch 190/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 117.9362 - val_loss: 113.6553\n",
      "Epoch 191/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 117.8864 - val_loss: 110.6252\n",
      "Epoch 192/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 117.7480 - val_loss: 112.9881\n",
      "Epoch 193/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 108.8847 - val_loss: 111.2661\n",
      "Epoch 194/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 119.8287 - val_loss: 112.6944\n",
      "Epoch 195/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 101.1760 - val_loss: 112.2391\n",
      "Epoch 196/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 144.7208 - val_loss: 112.5514\n",
      "Epoch 197/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 106.9167 - val_loss: 110.3214\n",
      "Epoch 198/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 135.1204 - val_loss: 112.0108\n",
      "Epoch 199/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 112.5813 - val_loss: 111.4298\n",
      "Epoch 200/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 103.3584 - val_loss: 112.1561\n",
      "Epoch 201/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 100.7958 - val_loss: 111.5147\n",
      "Epoch 202/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 105.7121 - val_loss: 112.3087\n",
      "Epoch 203/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 101.9916 - val_loss: 111.3430\n",
      "Epoch 204/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 105.5960 - val_loss: 112.9963\n",
      "Epoch 205/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 103.2630 - val_loss: 111.3458\n",
      "Epoch 206/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 101.8868 - val_loss: 112.6419\n",
      "Epoch 207/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 98.8505 - val_loss: 110.8023\n",
      "Epoch 208/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 99.6092 - val_loss: 112.1579\n",
      "Epoch 209/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 99.1398 - val_loss: 110.8669\n",
      "Epoch 210/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 103.2561 - val_loss: 112.0880\n",
      "Epoch 211/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 99.4263 - val_loss: 110.6068\n",
      "Epoch 212/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 104.8114 - val_loss: 112.6397\n",
      "Epoch 213/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 103.2175 - val_loss: 110.6838\n",
      "Epoch 214/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 98.8469 - val_loss: 111.7963\n",
      "Epoch 215/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 101.5836 - val_loss: 111.0333\n",
      "Epoch 216/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 99.6176 - val_loss: 111.5556\n",
      "Epoch 217/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 100.1907 - val_loss: 112.6008\n",
      "Epoch 218/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 101.9191 - val_loss: 112.2596\n",
      "Epoch 219/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 117.4307 - val_loss: 110.4682\n",
      "Epoch 220/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 94.4598 - val_loss: 111.7356\n",
      "Epoch 221/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 116.6935 - val_loss: 110.3020\n",
      "Epoch 222/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 94.4673 - val_loss: 110.8100\n",
      "Epoch 223/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 111.4410 - val_loss: 111.7447\n",
      "Epoch 224/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 103.8451 - val_loss: 111.9446\n",
      "Epoch 225/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 111.9321 - val_loss: 110.7576\n",
      "Epoch 226/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 108.8341 - val_loss: 111.6058\n",
      "Epoch 227/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 106.4886 - val_loss: 110.6788\n",
      "Epoch 228/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 99.9881 - val_loss: 112.0755\n",
      "Epoch 229/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 120.3019 - val_loss: 110.6610\n",
      "Epoch 230/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 110.9459 - val_loss: 110.4120\n",
      "Epoch 231/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 103.8204 - val_loss: 109.9416\n",
      "Epoch 232/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 109.9269 - val_loss: 110.7509\n",
      "Epoch 233/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 109.9653 - val_loss: 111.9826\n",
      "Epoch 234/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 109.3305 - val_loss: 109.3321\n",
      "Epoch 235/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 96.8257 - val_loss: 111.0016\n",
      "Epoch 236/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 100.8327 - val_loss: 109.4443\n",
      "Epoch 237/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 111.0730 - val_loss: 111.0899\n",
      "Epoch 238/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 112.5362 - val_loss: 109.5249\n",
      "Epoch 239/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 89.3960 - val_loss: 111.1640\n",
      "Epoch 240/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 103.5474 - val_loss: 110.3305\n",
      "Epoch 241/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 101.0143 - val_loss: 111.8366\n",
      "Epoch 242/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 101.2739 - val_loss: 110.7086\n",
      "Epoch 243/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 98.1939 - val_loss: 110.9970\n",
      "Epoch 244/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 100.0343 - val_loss: 109.8722\n",
      "Epoch 245/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 103.1002 - val_loss: 111.1640\n",
      "Epoch 246/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 100.7548 - val_loss: 109.9101\n",
      "Epoch 247/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 95.3118 - val_loss: 109.9195\n",
      "Epoch 248/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 95.7945 - val_loss: 109.7708\n",
      "Epoch 249/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 92.7506 - val_loss: 110.4052\n",
      "Epoch 250/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 98.6126 - val_loss: 108.3125\n",
      "Epoch 251/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 104.4091 - val_loss: 110.0407\n",
      "Epoch 252/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 91.8193 - val_loss: 109.1028\n",
      "Epoch 253/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 93.6248 - val_loss: 108.4341\n",
      "Epoch 254/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 94.2432 - val_loss: 107.7061\n",
      "Epoch 255/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 82.8703 - val_loss: 109.0438\n",
      "Epoch 256/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 97.3142 - val_loss: 109.0014\n",
      "Epoch 257/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 89.3613 - val_loss: 109.4357\n",
      "Epoch 258/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 92.5783 - val_loss: 110.6698\n",
      "Epoch 259/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 125.6958 - val_loss: 112.4681\n",
      "Epoch 260/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 95.2972 - val_loss: 111.0221\n",
      "Epoch 261/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 104.9406 - val_loss: 111.3342\n",
      "Epoch 262/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 174.4665 - val_loss: 109.7522\n",
      "Epoch 263/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 98.3330 - val_loss: 109.7927\n",
      "Epoch 264/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 91.0639 - val_loss: 108.1914\n",
      "Epoch 265/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 86.0179 - val_loss: 110.6712\n",
      "Epoch 266/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 91.9857 - val_loss: 110.2007\n",
      "Epoch 267/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 184.2904 - val_loss: 111.6457\n",
      "Epoch 268/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 172.2086 - val_loss: 110.4371\n",
      "Epoch 269/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 128.2990 - val_loss: 113.5266\n",
      "Epoch 270/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 111.4355 - val_loss: 109.5604\n",
      "Epoch 271/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 90.3260 - val_loss: 112.4022\n",
      "Epoch 272/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 87.2836 - val_loss: 109.6808\n",
      "Epoch 273/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 82.9947 - val_loss: 111.7769\n",
      "Epoch 274/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 84.8838 - val_loss: 110.0236\n",
      "Epoch 275/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 84.5897 - val_loss: 110.9531\n",
      "Epoch 276/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 83.1786 - val_loss: 111.2021\n",
      "Epoch 277/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 83.6884 - val_loss: 111.2760\n",
      "Epoch 278/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 82.8550 - val_loss: 111.1656\n",
      "Epoch 279/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 85.0982 - val_loss: 111.6956\n",
      "Epoch 280/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 101.4566 - val_loss: 112.0145\n",
      "Epoch 281/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 87.6735 - val_loss: 111.2770\n",
      "Epoch 282/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 82.4023 - val_loss: 112.7356\n",
      "Epoch 283/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 83.2102 - val_loss: 111.0382\n",
      "Epoch 284/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 81.2395 - val_loss: 112.2196\n",
      "'########################################################Model0\n",
      "Epoch 1/300\n",
      "35/35 [==============================] - 1s 14ms/step - loss: 978.9057 - val_loss: 411.3004\n",
      "Epoch 2/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 8694.7324 - val_loss: 439.6427\n",
      "Epoch 3/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 960.9996 - val_loss: 353.7969\n",
      "Epoch 4/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2383.8552 - val_loss: 297.3085\n",
      "Epoch 5/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1725.7078 - val_loss: 342.3824\n",
      "Epoch 6/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 23768.3145 - val_loss: 432.1787\n",
      "Epoch 7/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 1326.1875 - val_loss: 498.5258\n",
      "Epoch 8/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 2172.8040 - val_loss: 410.4432\n",
      "Epoch 9/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 7280.4751 - val_loss: 389.6611\n",
      "Epoch 10/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 7400.2612 - val_loss: 265.9185\n",
      "Epoch 11/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 2714.5776 - val_loss: 277.7736\n",
      "Epoch 12/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 828.2999 - val_loss: 251.9616\n",
      "Epoch 13/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 2006.2936 - val_loss: 240.5545\n",
      "Epoch 14/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 329.3993 - val_loss: 259.7327\n",
      "Epoch 15/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 8158.8247 - val_loss: 372.8069\n",
      "Epoch 16/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1220.2500 - val_loss: 370.6649\n",
      "Epoch 17/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 1479.6119 - val_loss: 242.7935\n",
      "Epoch 18/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 687.0943 - val_loss: 211.1222\n",
      "Epoch 19/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 1326.1697 - val_loss: 200.5572\n",
      "Epoch 20/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 436.8116 - val_loss: 224.4671\n",
      "Epoch 21/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 369.5849 - val_loss: 283.5227\n",
      "Epoch 22/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 925.2822 - val_loss: 568.2820\n",
      "Epoch 23/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4281.2681 - val_loss: 238.3038\n",
      "Epoch 24/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 1185.3099 - val_loss: 583.5284\n",
      "Epoch 25/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3804.1511 - val_loss: 256.2551\n",
      "Epoch 26/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1717.8427 - val_loss: 219.9704\n",
      "Epoch 27/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4305.9951 - val_loss: 202.5904\n",
      "Epoch 28/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 1103.5406 - val_loss: 262.3526\n",
      "Epoch 29/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1484.2671 - val_loss: 241.4039\n",
      "Epoch 30/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3972.6160 - val_loss: 230.1566\n",
      "Epoch 31/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2645.5156 - val_loss: 211.9203\n",
      "Epoch 32/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 421.7154 - val_loss: 170.1643\n",
      "Epoch 33/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2263.6121 - val_loss: 185.8226\n",
      "Epoch 34/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 319.4380 - val_loss: 185.8483\n",
      "Epoch 35/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2217.1968 - val_loss: 181.4744\n",
      "Epoch 36/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 261.3992 - val_loss: 179.5976\n",
      "Epoch 37/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 560.8782 - val_loss: 175.6042\n",
      "Epoch 38/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 1341.3575 - val_loss: 193.0538\n",
      "Epoch 39/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 691.6226 - val_loss: 233.6887\n",
      "Epoch 40/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 12289.4424 - val_loss: 300.3346\n",
      "Epoch 41/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2522.4668 - val_loss: 183.5364\n",
      "Epoch 42/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 1311.2753 - val_loss: 166.4540\n",
      "Epoch 43/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4068.3140 - val_loss: 172.3451\n",
      "Epoch 44/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 713.0961 - val_loss: 159.8235\n",
      "Epoch 45/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 233.2346 - val_loss: 160.2720\n",
      "Epoch 46/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 707.8096 - val_loss: 156.7607\n",
      "Epoch 47/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 354.5519 - val_loss: 157.2257\n",
      "Epoch 48/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 849.8677 - val_loss: 162.1930\n",
      "Epoch 49/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 277.1089 - val_loss: 150.2228\n",
      "Epoch 50/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 591.9144 - val_loss: 148.9912\n",
      "Epoch 51/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 394.3074 - val_loss: 164.6793\n",
      "Epoch 52/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 671.7756 - val_loss: 149.2043\n",
      "Epoch 53/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 245.3312 - val_loss: 152.9295\n",
      "Epoch 54/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 662.7901 - val_loss: 158.3886\n",
      "Epoch 55/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1384.6931 - val_loss: 150.5292\n",
      "Epoch 56/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 348.6942 - val_loss: 149.9072\n",
      "Epoch 57/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 318.2559 - val_loss: 148.3934\n",
      "Epoch 58/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 289.2858 - val_loss: 152.7623\n",
      "Epoch 59/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 248.0967 - val_loss: 153.2896\n",
      "Epoch 60/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 310.3952 - val_loss: 148.6675\n",
      "Epoch 61/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 292.2042 - val_loss: 150.6809\n",
      "Epoch 62/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 255.7710 - val_loss: 148.7161\n",
      "Epoch 63/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 245.8822 - val_loss: 146.2132\n",
      "Epoch 64/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 229.5244 - val_loss: 146.9008\n",
      "Epoch 65/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 317.1273 - val_loss: 147.2057\n",
      "Epoch 66/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 179.9553 - val_loss: 151.0282\n",
      "Epoch 67/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 293.7050 - val_loss: 149.3562\n",
      "Epoch 68/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 375.3997 - val_loss: 149.7829\n",
      "Epoch 69/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 336.0934 - val_loss: 147.8689\n",
      "Epoch 70/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 156.7003 - val_loss: 148.9241\n",
      "Epoch 71/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 574.7851 - val_loss: 151.1068\n",
      "Epoch 72/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 543.7549 - val_loss: 150.9607\n",
      "Epoch 73/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 442.5115 - val_loss: 148.7634\n",
      "Epoch 74/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 222.4504 - val_loss: 148.4693\n",
      "Epoch 75/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 410.9633 - val_loss: 146.9029\n",
      "Epoch 76/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 139.9210 - val_loss: 150.4575\n",
      "Epoch 77/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 359.3268 - val_loss: 148.2278\n",
      "Epoch 78/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 143.8770 - val_loss: 149.0763\n",
      "Epoch 79/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 305.4310 - val_loss: 146.5047\n",
      "Epoch 80/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 139.5874 - val_loss: 150.0176\n",
      "Epoch 81/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 345.0297 - val_loss: 151.4062\n",
      "Epoch 82/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 314.1035 - val_loss: 151.4786\n",
      "Epoch 83/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 270.5703 - val_loss: 150.2461\n",
      "Epoch 84/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 175.2373 - val_loss: 149.7019\n",
      "Epoch 85/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 242.7941 - val_loss: 150.0861\n",
      "Epoch 86/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 197.2827 - val_loss: 150.5869\n",
      "Epoch 87/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 301.5865 - val_loss: 144.4575\n",
      "Epoch 88/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 136.8856 - val_loss: 145.5677\n",
      "Epoch 89/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 222.8639 - val_loss: 145.2458\n",
      "Epoch 90/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 219.5153 - val_loss: 146.5415\n",
      "Epoch 91/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 199.7597 - val_loss: 145.2893\n",
      "Epoch 92/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 190.6377 - val_loss: 147.2065\n",
      "Epoch 93/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 178.4831 - val_loss: 146.1604\n",
      "Epoch 94/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 195.2787 - val_loss: 146.6069\n",
      "Epoch 95/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 248.0434 - val_loss: 147.2865\n",
      "Epoch 96/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 242.1731 - val_loss: 147.0823\n",
      "Epoch 97/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 262.3915 - val_loss: 147.0153\n",
      "Epoch 98/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 258.9456 - val_loss: 149.3835\n",
      "Epoch 99/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 270.3553 - val_loss: 148.5123\n",
      "Epoch 100/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 319.9444 - val_loss: 147.2106\n",
      "Epoch 101/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 227.0230 - val_loss: 144.9147\n",
      "Epoch 102/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 198.0919 - val_loss: 144.7656\n",
      "Epoch 103/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 159.3686 - val_loss: 146.4659\n",
      "Epoch 104/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 299.0102 - val_loss: 144.5710\n",
      "Epoch 105/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 147.7847 - val_loss: 143.0561\n",
      "Epoch 106/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 282.1324 - val_loss: 148.9245\n",
      "Epoch 107/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 272.8995 - val_loss: 146.7703\n",
      "Epoch 108/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 235.6697 - val_loss: 146.3347\n",
      "Epoch 109/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 261.7508 - val_loss: 145.1912\n",
      "Epoch 110/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 166.1596 - val_loss: 147.5922\n",
      "Epoch 111/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 192.4565 - val_loss: 146.4642\n",
      "Epoch 112/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 246.4217 - val_loss: 145.8671\n",
      "Epoch 113/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 254.3560 - val_loss: 146.9556\n",
      "Epoch 114/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 218.5043 - val_loss: 151.7898\n",
      "Epoch 115/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 138.4839 - val_loss: 146.7205\n",
      "Epoch 116/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 726.8317 - val_loss: 146.0555\n",
      "Epoch 117/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 139.6772 - val_loss: 149.5111\n",
      "Epoch 118/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 527.3298 - val_loss: 147.9695\n",
      "Epoch 119/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 294.1834 - val_loss: 149.3465\n",
      "Epoch 120/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 244.7841 - val_loss: 158.1308\n",
      "Epoch 121/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 409.8924 - val_loss: 154.1661\n",
      "Epoch 122/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1769.6687 - val_loss: 171.9284\n",
      "Epoch 123/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 940.8562 - val_loss: 158.0233\n",
      "Epoch 124/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 511.7708 - val_loss: 167.3300\n",
      "Epoch 125/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 593.3513 - val_loss: 155.4191\n",
      "Epoch 126/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 940.7297 - val_loss: 170.1738\n",
      "Epoch 127/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 257.7554 - val_loss: 173.6859\n",
      "Epoch 128/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 1966.9316 - val_loss: 166.1669\n",
      "Epoch 129/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 784.2275 - val_loss: 144.1837\n",
      "Epoch 130/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 620.3334 - val_loss: 145.0216\n",
      "Epoch 131/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 417.7668 - val_loss: 168.1601\n",
      "Epoch 132/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 6457.4448 - val_loss: 144.1717\n",
      "Epoch 133/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1215.3849 - val_loss: 144.8747\n",
      "Epoch 134/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 167.8840 - val_loss: 155.0573\n",
      "Epoch 135/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 1199.2765 - val_loss: 131.2293\n",
      "Epoch 136/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 376.3528 - val_loss: 131.1598\n",
      "Epoch 137/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 399.3729 - val_loss: 130.6899\n",
      "Epoch 138/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 277.0807 - val_loss: 131.3573\n",
      "Epoch 139/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 266.0469 - val_loss: 129.2469\n",
      "Epoch 140/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 171.3808 - val_loss: 129.7294\n",
      "Epoch 141/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 228.8284 - val_loss: 131.5584\n",
      "Epoch 142/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 146.8962 - val_loss: 130.3986\n",
      "Epoch 143/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 317.9297 - val_loss: 129.9443\n",
      "Epoch 144/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 162.0205 - val_loss: 129.9060\n",
      "Epoch 145/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 211.6736 - val_loss: 131.0058\n",
      "Epoch 146/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 167.3133 - val_loss: 129.6345\n",
      "Epoch 147/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 199.7487 - val_loss: 129.1976\n",
      "Epoch 148/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 190.7177 - val_loss: 129.8830\n",
      "Epoch 149/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 202.2386 - val_loss: 128.5311\n",
      "Epoch 150/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 154.9421 - val_loss: 127.2355\n",
      "Epoch 151/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 193.7883 - val_loss: 127.5149\n",
      "Epoch 152/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 267.3265 - val_loss: 126.6303\n",
      "Epoch 153/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 231.0411 - val_loss: 129.2261\n",
      "Epoch 154/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 290.7581 - val_loss: 130.2383\n",
      "Epoch 155/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 173.2982 - val_loss: 127.0235\n",
      "Epoch 156/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 338.4483 - val_loss: 126.2173\n",
      "Epoch 157/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 129.1544 - val_loss: 124.0552\n",
      "Epoch 158/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 263.7758 - val_loss: 124.6693\n",
      "Epoch 159/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 128.5310 - val_loss: 125.2056\n",
      "Epoch 160/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 185.4974 - val_loss: 126.2147\n",
      "Epoch 161/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 393.7206 - val_loss: 126.2232\n",
      "Epoch 162/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 213.8271 - val_loss: 124.6812\n",
      "Epoch 163/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 230.3476 - val_loss: 125.8165\n",
      "Epoch 164/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 158.2393 - val_loss: 123.9728\n",
      "Epoch 165/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 220.8595 - val_loss: 123.3459\n",
      "Epoch 166/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 134.9129 - val_loss: 124.7458\n",
      "Epoch 167/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 225.8605 - val_loss: 125.0010\n",
      "Epoch 168/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 137.9718 - val_loss: 124.0338\n",
      "Epoch 169/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 167.6193 - val_loss: 124.1224\n",
      "Epoch 170/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 138.2512 - val_loss: 124.9986\n",
      "Epoch 171/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 147.0834 - val_loss: 125.8114\n",
      "Epoch 172/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 149.1196 - val_loss: 125.4506\n",
      "Epoch 173/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 235.1243 - val_loss: 123.5566\n",
      "Epoch 174/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 141.5354 - val_loss: 122.9662\n",
      "Epoch 175/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 142.7099 - val_loss: 123.3058\n",
      "Epoch 176/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 142.8332 - val_loss: 122.9220\n",
      "Epoch 177/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 160.6635 - val_loss: 122.8621\n",
      "Epoch 178/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 151.4085 - val_loss: 123.4141\n",
      "Epoch 179/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 137.0547 - val_loss: 123.2677\n",
      "Epoch 180/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 144.0821 - val_loss: 124.2012\n",
      "Epoch 181/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 121.1947 - val_loss: 124.1515\n",
      "Epoch 182/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 178.6980 - val_loss: 123.5288\n",
      "Epoch 183/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 119.0463 - val_loss: 123.4190\n",
      "Epoch 184/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 130.9916 - val_loss: 123.8729\n",
      "Epoch 185/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 123.8136 - val_loss: 125.1213\n",
      "Epoch 186/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 181.3076 - val_loss: 125.5324\n",
      "Epoch 187/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 129.6179 - val_loss: 125.0085\n",
      "Epoch 188/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 200.9703 - val_loss: 125.4820\n",
      "Epoch 189/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 134.2549 - val_loss: 125.3004\n",
      "Epoch 190/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 161.6571 - val_loss: 125.1961\n",
      "Epoch 191/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 144.8329 - val_loss: 125.9253\n",
      "Epoch 192/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 141.9541 - val_loss: 125.7565\n",
      "Epoch 193/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 146.8538 - val_loss: 124.4300\n",
      "Epoch 194/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 126.3285 - val_loss: 124.6733\n",
      "Epoch 195/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 133.4313 - val_loss: 124.7809\n",
      "Epoch 196/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 181.0532 - val_loss: 125.0725\n",
      "Epoch 197/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 131.1100 - val_loss: 124.7238\n",
      "Epoch 198/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 161.0374 - val_loss: 126.6338\n",
      "Epoch 199/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 120.2180 - val_loss: 126.1537\n",
      "Epoch 200/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 149.1134 - val_loss: 124.2271\n",
      "Epoch 201/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 149.4077 - val_loss: 124.7672\n",
      "Epoch 202/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 195.2896 - val_loss: 122.8829\n",
      "Epoch 203/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 246.4001 - val_loss: 123.7342\n",
      "Epoch 204/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 132.7456 - val_loss: 124.6405\n",
      "Epoch 205/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 154.3564 - val_loss: 124.6032\n",
      "Epoch 206/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 178.2802 - val_loss: 125.1018\n",
      "Epoch 207/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 123.1054 - val_loss: 125.0203\n",
      "'########################################################Model1\n",
      "Epoch 1/300\n",
      "35/35 [==============================] - 1s 11ms/step - loss: 897.5998 - val_loss: 377.0301\n",
      "Epoch 2/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3380.2217 - val_loss: 446.7579\n",
      "Epoch 3/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 6257.3394 - val_loss: 405.7938\n",
      "Epoch 4/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4869.6846 - val_loss: 323.4232\n",
      "Epoch 5/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4073.8691 - val_loss: 390.8727\n",
      "Epoch 6/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3568.3611 - val_loss: 357.4591\n",
      "Epoch 7/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 921.0130 - val_loss: 309.9593\n",
      "Epoch 8/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 6702.0552 - val_loss: 248.6387\n",
      "Epoch 9/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 1182.4669 - val_loss: 241.6864\n",
      "Epoch 10/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 1415.9148 - val_loss: 336.3853\n",
      "Epoch 11/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 18930.8691 - val_loss: 296.7688\n",
      "Epoch 12/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2316.6824 - val_loss: 222.3875\n",
      "Epoch 13/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 395.1862 - val_loss: 253.0911\n",
      "Epoch 14/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 1967.8990 - val_loss: 352.1703\n",
      "Epoch 15/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3277.8594 - val_loss: 308.3873\n",
      "Epoch 16/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 547.9269 - val_loss: 214.7426\n",
      "Epoch 17/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3452.2046 - val_loss: 189.5922\n",
      "Epoch 18/300\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 854.3259 - val_loss: 186.4528\n",
      "Epoch 19/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 1273.5807 - val_loss: 182.7372\n",
      "Epoch 20/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 423.5411 - val_loss: 179.7778\n",
      "Epoch 21/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 2173.3242 - val_loss: 175.1552\n",
      "Epoch 22/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 887.3793 - val_loss: 212.8720\n",
      "Epoch 23/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 1910.8190 - val_loss: 214.3898\n",
      "Epoch 24/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 1335.9324 - val_loss: 203.8372\n",
      "Epoch 25/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 762.0082 - val_loss: 175.9581\n",
      "Epoch 26/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 658.8287 - val_loss: 174.6220\n",
      "Epoch 27/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 682.0413 - val_loss: 226.3822\n",
      "Epoch 28/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2468.6477 - val_loss: 192.9144\n",
      "Epoch 29/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 832.4492 - val_loss: 179.5324\n",
      "Epoch 30/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 582.7452 - val_loss: 172.1108\n",
      "Epoch 31/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 664.7926 - val_loss: 181.0428\n",
      "Epoch 32/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 788.9011 - val_loss: 157.5822\n",
      "Epoch 33/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 321.0291 - val_loss: 164.7964\n",
      "Epoch 34/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 366.2021 - val_loss: 185.9123\n",
      "Epoch 35/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 352.3052 - val_loss: 195.5044\n",
      "Epoch 36/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 3394.8005 - val_loss: 150.6690\n",
      "Epoch 37/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 292.7783 - val_loss: 147.4973\n",
      "Epoch 38/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 403.2417 - val_loss: 145.8308\n",
      "Epoch 39/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 950.3751 - val_loss: 150.4520\n",
      "Epoch 40/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 385.4946 - val_loss: 150.7259\n",
      "Epoch 41/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 620.7848 - val_loss: 160.1042\n",
      "Epoch 42/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 421.1411 - val_loss: 152.0931\n",
      "Epoch 43/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2405.8198 - val_loss: 187.4959\n",
      "Epoch 44/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 241.1945 - val_loss: 183.0317\n",
      "Epoch 45/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 796.4006 - val_loss: 165.8795\n",
      "Epoch 46/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 297.5297 - val_loss: 167.6116\n",
      "Epoch 47/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 505.8307 - val_loss: 178.2637\n",
      "Epoch 48/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 972.3590 - val_loss: 165.3216\n",
      "Epoch 49/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 466.5559 - val_loss: 155.7505\n",
      "Epoch 50/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 334.4066 - val_loss: 159.6325\n",
      "Epoch 51/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 298.8468 - val_loss: 168.0925\n",
      "Epoch 52/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 563.8014 - val_loss: 168.0694\n",
      "Epoch 53/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 943.1559 - val_loss: 162.6062\n",
      "Epoch 54/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 235.6369 - val_loss: 161.5845\n",
      "Epoch 55/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 919.2554 - val_loss: 151.4006\n",
      "Epoch 56/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 362.9068 - val_loss: 149.9265\n",
      "Epoch 57/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 410.7601 - val_loss: 150.5685\n",
      "Epoch 58/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 341.5226 - val_loss: 151.6702\n",
      "Epoch 59/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 414.9234 - val_loss: 158.1624\n",
      "Epoch 60/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 279.4821 - val_loss: 150.0820\n",
      "Epoch 61/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 379.5624 - val_loss: 151.2750\n",
      "Epoch 62/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 258.8260 - val_loss: 149.1976\n",
      "Epoch 63/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 341.3833 - val_loss: 150.0909\n",
      "Epoch 64/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 387.4630 - val_loss: 151.0188\n",
      "Epoch 65/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 327.8741 - val_loss: 157.7211\n",
      "Epoch 66/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 238.3215 - val_loss: 149.3667\n",
      "Epoch 67/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 267.4088 - val_loss: 152.8804\n",
      "Epoch 68/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 180.6064 - val_loss: 147.9888\n",
      "'########################################################Model2\n",
      "Epoch 1/300\n",
      "35/35 [==============================] - 2s 13ms/step - loss: 1103.9875 - val_loss: 499.8797\n",
      "Epoch 2/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 9473.4297 - val_loss: 516.3246\n",
      "Epoch 3/300\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 1262.2371 - val_loss: 395.8008\n",
      "Epoch 4/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3296.2493 - val_loss: 549.8580\n",
      "Epoch 5/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 20001.8555 - val_loss: 374.4458\n",
      "Epoch 6/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 11362.1699 - val_loss: 587.3380\n",
      "Epoch 7/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 9074.9521 - val_loss: 394.7227\n",
      "Epoch 8/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 3151.6567 - val_loss: 326.6255\n",
      "Epoch 9/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 1666.5753 - val_loss: 301.7538\n",
      "Epoch 10/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 4821.6289 - val_loss: 318.9588\n",
      "Epoch 11/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1323.0763 - val_loss: 277.8730\n",
      "Epoch 12/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2693.4753 - val_loss: 328.7260\n",
      "Epoch 13/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 4281.0464 - val_loss: 243.1865\n",
      "Epoch 14/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 469.8922 - val_loss: 251.5865\n",
      "Epoch 15/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2461.7224 - val_loss: 267.3535\n",
      "Epoch 16/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 2523.6414 - val_loss: 279.6450\n",
      "Epoch 17/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 1044.4282 - val_loss: 255.8771\n",
      "Epoch 18/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 305.2682 - val_loss: 254.8638\n",
      "Epoch 19/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 545.3153 - val_loss: 267.4580\n",
      "Epoch 20/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 4089.4456 - val_loss: 228.8485\n",
      "Epoch 21/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 1551.4729 - val_loss: 215.0297\n",
      "Epoch 22/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1393.6898 - val_loss: 266.2773\n",
      "Epoch 23/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 643.4491 - val_loss: 231.2365\n",
      "Epoch 24/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 1668.5629 - val_loss: 205.2647\n",
      "Epoch 25/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 751.4012 - val_loss: 221.3050\n",
      "Epoch 26/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 955.6827 - val_loss: 237.7398\n",
      "Epoch 27/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1289.5052 - val_loss: 217.4039\n",
      "Epoch 28/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1044.4763 - val_loss: 206.2667\n",
      "Epoch 29/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 390.1839 - val_loss: 197.0565\n",
      "Epoch 30/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1472.9946 - val_loss: 228.7034\n",
      "Epoch 31/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 626.3938 - val_loss: 246.2011\n",
      "Epoch 32/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 669.5306 - val_loss: 270.4748\n",
      "Epoch 33/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 346.1403 - val_loss: 185.7227\n",
      "Epoch 34/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1410.4269 - val_loss: 174.5883\n",
      "Epoch 35/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 960.7704 - val_loss: 188.2977\n",
      "Epoch 36/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 515.5060 - val_loss: 183.0066\n",
      "Epoch 37/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 811.7188 - val_loss: 186.4911\n",
      "Epoch 38/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 215.2151 - val_loss: 179.1833\n",
      "Epoch 39/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 661.4440 - val_loss: 180.0688\n",
      "Epoch 40/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 269.9576 - val_loss: 182.1195\n",
      "Epoch 41/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 500.9796 - val_loss: 182.6047\n",
      "Epoch 42/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 762.4043 - val_loss: 180.9711\n",
      "Epoch 43/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 838.5996 - val_loss: 183.2932\n",
      "Epoch 44/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1045.6532 - val_loss: 186.3333\n",
      "Epoch 45/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 333.3402 - val_loss: 186.3478\n",
      "Epoch 46/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 307.2024 - val_loss: 181.9351\n",
      "Epoch 47/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 856.5220 - val_loss: 184.5725\n",
      "Epoch 48/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 440.9572 - val_loss: 180.6094\n",
      "Epoch 49/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 814.6801 - val_loss: 180.5406\n",
      "Epoch 50/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 211.8348 - val_loss: 178.5656\n",
      "Epoch 51/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 1013.4822 - val_loss: 179.9292\n",
      "Epoch 52/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 223.7728 - val_loss: 178.6992\n",
      "Epoch 53/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 1210.9431 - val_loss: 178.0925\n",
      "Epoch 54/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 238.7541 - val_loss: 179.4161\n",
      "Epoch 55/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 2247.3252 - val_loss: 176.6975\n",
      "Epoch 56/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 285.9882 - val_loss: 178.9746\n",
      "Epoch 57/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 424.1049 - val_loss: 169.2865\n",
      "Epoch 58/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 712.5778 - val_loss: 165.2715\n",
      "Epoch 59/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 280.3959 - val_loss: 168.7527\n",
      "Epoch 60/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 748.8441 - val_loss: 165.6091\n",
      "Epoch 61/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 156.2172 - val_loss: 169.6404\n",
      "Epoch 62/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1018.2720 - val_loss: 162.6722\n",
      "Epoch 63/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 371.5179 - val_loss: 165.6967\n",
      "Epoch 64/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 479.9159 - val_loss: 160.4848\n",
      "Epoch 65/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 474.4760 - val_loss: 158.4022\n",
      "Epoch 66/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 429.7803 - val_loss: 155.1716\n",
      "Epoch 67/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 385.0905 - val_loss: 161.5342\n",
      "Epoch 68/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 248.0710 - val_loss: 161.3141\n",
      "Epoch 69/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 303.1092 - val_loss: 166.6913\n",
      "Epoch 70/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 516.2958 - val_loss: 155.2846\n",
      "Epoch 71/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 370.8938 - val_loss: 166.5351\n",
      "Epoch 72/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 169.2053 - val_loss: 171.0664\n",
      "Epoch 73/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 564.4064 - val_loss: 170.6987\n",
      "Epoch 74/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 427.8686 - val_loss: 151.1810\n",
      "Epoch 75/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 366.6998 - val_loss: 150.5046\n",
      "Epoch 76/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 746.0470 - val_loss: 154.4999\n",
      "Epoch 77/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 520.7397 - val_loss: 158.0006\n",
      "Epoch 78/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 325.3787 - val_loss: 150.4176\n",
      "Epoch 79/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 412.6454 - val_loss: 152.0032\n",
      "Epoch 80/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 420.9686 - val_loss: 154.4183\n",
      "Epoch 81/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 366.1436 - val_loss: 158.7774\n",
      "Epoch 82/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 236.3105 - val_loss: 160.8535\n",
      "Epoch 83/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 280.6110 - val_loss: 161.2030\n",
      "Epoch 84/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 473.1950 - val_loss: 157.4978\n",
      "Epoch 85/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 413.9361 - val_loss: 158.6108\n",
      "Epoch 86/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 679.3493 - val_loss: 154.2983\n",
      "Epoch 87/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 375.5085 - val_loss: 148.2304\n",
      "Epoch 88/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 435.3977 - val_loss: 151.4318\n",
      "Epoch 89/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 695.7141 - val_loss: 144.7340\n",
      "Epoch 90/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 318.8268 - val_loss: 147.7371\n",
      "Epoch 91/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 266.0321 - val_loss: 150.8641\n",
      "Epoch 92/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 252.8712 - val_loss: 148.8859\n",
      "Epoch 93/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 253.6183 - val_loss: 144.9772\n",
      "Epoch 94/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 271.3134 - val_loss: 146.9710\n",
      "Epoch 95/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 328.9549 - val_loss: 146.8451\n",
      "Epoch 96/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 285.4709 - val_loss: 144.3835\n",
      "Epoch 97/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 242.5858 - val_loss: 143.6672\n",
      "Epoch 98/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 347.5646 - val_loss: 141.9991\n",
      "Epoch 99/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 172.5981 - val_loss: 145.8343\n",
      "Epoch 100/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 292.9113 - val_loss: 146.6212\n",
      "Epoch 101/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 207.7778 - val_loss: 145.9706\n",
      "Epoch 102/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 216.8713 - val_loss: 141.0761\n",
      "Epoch 103/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 233.2529 - val_loss: 140.7392\n",
      "Epoch 104/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 205.8417 - val_loss: 143.2501\n",
      "Epoch 105/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 307.6364 - val_loss: 140.1843\n",
      "Epoch 106/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 219.0374 - val_loss: 141.3871\n",
      "Epoch 107/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 295.7860 - val_loss: 140.4324\n",
      "Epoch 108/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 288.5559 - val_loss: 142.0221\n",
      "Epoch 109/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 150.2070 - val_loss: 142.2416\n",
      "Epoch 110/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 375.1670 - val_loss: 142.9666\n",
      "Epoch 111/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 224.6197 - val_loss: 145.0160\n",
      "Epoch 112/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 174.5145 - val_loss: 139.3429\n",
      "Epoch 113/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 275.4176 - val_loss: 141.3939\n",
      "Epoch 114/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 238.9435 - val_loss: 142.1654\n",
      "Epoch 115/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 239.5124 - val_loss: 145.5625\n",
      "Epoch 116/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 232.6150 - val_loss: 141.6735\n",
      "Epoch 117/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 291.2119 - val_loss: 155.5579\n",
      "Epoch 118/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 586.1666 - val_loss: 148.6586\n",
      "Epoch 119/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 549.2238 - val_loss: 146.1809\n",
      "Epoch 120/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 283.0855 - val_loss: 145.8840\n",
      "Epoch 121/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 845.9958 - val_loss: 156.4961\n",
      "Epoch 122/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 363.6347 - val_loss: 148.1335\n",
      "Epoch 123/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 410.6558 - val_loss: 151.0025\n",
      "Epoch 124/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 298.1182 - val_loss: 146.3565\n",
      "Epoch 125/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 534.8873 - val_loss: 147.7978\n",
      "Epoch 126/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 534.2493 - val_loss: 145.3936\n",
      "Epoch 127/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 740.9316 - val_loss: 143.8799\n",
      "Epoch 128/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 425.0026 - val_loss: 139.1478\n",
      "Epoch 129/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 379.4110 - val_loss: 149.7662\n",
      "Epoch 130/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 591.4138 - val_loss: 144.1318\n",
      "Epoch 131/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 186.3827 - val_loss: 144.9668\n",
      "Epoch 132/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 570.7946 - val_loss: 142.1484\n",
      "Epoch 133/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 450.9861 - val_loss: 142.6794\n",
      "Epoch 134/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 660.2325 - val_loss: 144.2793\n",
      "Epoch 135/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 292.0479 - val_loss: 143.6278\n",
      "Epoch 136/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 386.3232 - val_loss: 141.1318\n",
      "Epoch 137/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 196.3440 - val_loss: 142.8492\n",
      "Epoch 138/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 282.1393 - val_loss: 148.5968\n",
      "Epoch 139/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 502.6111 - val_loss: 138.7686\n",
      "Epoch 140/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 248.4003 - val_loss: 135.1681\n",
      "Epoch 141/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 162.8614 - val_loss: 133.8073\n",
      "Epoch 142/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 253.2541 - val_loss: 133.0103\n",
      "Epoch 143/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 159.8432 - val_loss: 134.8245\n",
      "Epoch 144/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 291.5943 - val_loss: 134.0704\n",
      "Epoch 145/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 434.4503 - val_loss: 134.5696\n",
      "Epoch 146/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 213.9730 - val_loss: 136.4966\n",
      "Epoch 147/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 255.6861 - val_loss: 136.0747\n",
      "Epoch 148/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 195.0609 - val_loss: 135.4644\n",
      "Epoch 149/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 200.1562 - val_loss: 133.9207\n",
      "Epoch 150/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 686.0976 - val_loss: 137.6781\n",
      "Epoch 151/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 239.2881 - val_loss: 139.2896\n",
      "Epoch 152/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 164.6460 - val_loss: 140.2023\n",
      "Epoch 153/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 158.3240 - val_loss: 146.5236\n",
      "Epoch 154/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1273.5391 - val_loss: 138.2770\n",
      "Epoch 155/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 214.8838 - val_loss: 142.5209\n",
      "Epoch 156/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 434.2101 - val_loss: 136.7117\n",
      "Epoch 157/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 297.4467 - val_loss: 127.8602\n",
      "Epoch 158/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 598.5447 - val_loss: 129.3745\n",
      "Epoch 159/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 606.5139 - val_loss: 133.8761\n",
      "Epoch 160/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 176.4257 - val_loss: 129.3988\n",
      "Epoch 161/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 584.4026 - val_loss: 125.1099\n",
      "Epoch 162/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 247.6319 - val_loss: 127.9478\n",
      "Epoch 163/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 340.2242 - val_loss: 123.9433\n",
      "Epoch 164/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 170.0058 - val_loss: 124.0136\n",
      "Epoch 165/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 212.2315 - val_loss: 122.5490\n",
      "Epoch 166/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 137.1072 - val_loss: 122.9640\n",
      "Epoch 167/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 160.8045 - val_loss: 122.4475\n",
      "Epoch 168/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 131.0882 - val_loss: 121.6879\n",
      "Epoch 169/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 175.5444 - val_loss: 120.7762\n",
      "Epoch 170/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 119.3599 - val_loss: 120.4305\n",
      "Epoch 171/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 150.5642 - val_loss: 119.7105\n",
      "Epoch 172/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 113.8492 - val_loss: 120.1924\n",
      "Epoch 173/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 125.4171 - val_loss: 119.4308\n",
      "Epoch 174/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 113.1531 - val_loss: 119.6518\n",
      "Epoch 175/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 140.5175 - val_loss: 120.5043\n",
      "Epoch 176/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 105.0506 - val_loss: 121.0683\n",
      "Epoch 177/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 153.5363 - val_loss: 120.5048\n",
      "Epoch 178/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 102.3476 - val_loss: 120.4550\n",
      "Epoch 179/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 141.1432 - val_loss: 119.5589\n",
      "Epoch 180/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 105.7505 - val_loss: 119.6028\n",
      "Epoch 181/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 139.7642 - val_loss: 118.2561\n",
      "Epoch 182/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 113.2603 - val_loss: 119.6405\n",
      "Epoch 183/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 107.7066 - val_loss: 119.6459\n",
      "Epoch 184/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 108.9142 - val_loss: 119.9789\n",
      "Epoch 185/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 123.0529 - val_loss: 119.4766\n",
      "Epoch 186/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 103.5967 - val_loss: 119.4550\n",
      "Epoch 187/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 130.9300 - val_loss: 120.1137\n",
      "Epoch 188/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 102.1928 - val_loss: 119.9772\n",
      "Epoch 189/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 129.7189 - val_loss: 120.1015\n",
      "Epoch 190/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 104.3521 - val_loss: 119.9308\n",
      "Epoch 191/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 146.0483 - val_loss: 119.2567\n",
      "Epoch 192/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 97.1825 - val_loss: 119.6888\n",
      "Epoch 193/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 144.7072 - val_loss: 120.3536\n",
      "Epoch 194/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 173.7698 - val_loss: 121.5138\n",
      "Epoch 195/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 133.7040 - val_loss: 120.6268\n",
      "Epoch 196/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 109.1214 - val_loss: 120.7164\n",
      "Epoch 197/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 139.7811 - val_loss: 122.0848\n",
      "Epoch 198/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 131.4342 - val_loss: 121.3620\n",
      "Epoch 199/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 113.9357 - val_loss: 121.8043\n",
      "Epoch 200/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 106.3776 - val_loss: 120.6425\n",
      "Epoch 201/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 102.5280 - val_loss: 122.5060\n",
      "Epoch 202/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 104.8291 - val_loss: 121.5821\n",
      "Epoch 203/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 109.3867 - val_loss: 121.4319\n",
      "Epoch 204/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 106.4050 - val_loss: 120.9171\n",
      "Epoch 205/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 97.1425 - val_loss: 121.4035\n",
      "Epoch 206/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 116.6012 - val_loss: 121.8192\n",
      "Epoch 207/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 95.9293 - val_loss: 122.1390\n",
      "Epoch 208/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 100.1302 - val_loss: 121.9424\n",
      "Epoch 209/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 106.0852 - val_loss: 123.3008\n",
      "Epoch 210/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 100.7626 - val_loss: 122.4650\n",
      "Epoch 211/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 150.4452 - val_loss: 122.5471\n",
      "'########################################################Model3\n",
      "Epoch 1/300\n",
      "35/35 [==============================] - 2s 15ms/step - loss: 901.8528 - val_loss: 474.3658\n",
      "Epoch 2/300\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 10934.5771 - val_loss: 421.2811\n",
      "Epoch 3/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 3655.6760 - val_loss: 356.5429\n",
      "Epoch 4/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4346.8481 - val_loss: 393.6740\n",
      "Epoch 5/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1259.9117 - val_loss: 369.3285\n",
      "Epoch 6/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 17054.5938 - val_loss: 277.3084\n",
      "Epoch 7/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 774.7481 - val_loss: 345.3036\n",
      "Epoch 8/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 5072.7256 - val_loss: 283.8023\n",
      "Epoch 9/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 2062.8853 - val_loss: 267.4038\n",
      "Epoch 10/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 1514.6333 - val_loss: 328.9886\n",
      "Epoch 11/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 2688.7004 - val_loss: 273.4351\n",
      "Epoch 12/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1891.6600 - val_loss: 276.6246\n",
      "Epoch 13/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 4878.4111 - val_loss: 287.9614\n",
      "Epoch 14/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 1253.1151 - val_loss: 247.3504\n",
      "Epoch 15/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 2127.4729 - val_loss: 254.5776\n",
      "Epoch 16/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 2035.5009 - val_loss: 253.9149\n",
      "Epoch 17/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1372.5990 - val_loss: 250.4871\n",
      "Epoch 18/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 9400.6113 - val_loss: 265.7787\n",
      "Epoch 19/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 644.4562 - val_loss: 247.4694\n",
      "Epoch 20/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 3379.0730 - val_loss: 204.4572\n",
      "Epoch 21/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 686.1537 - val_loss: 197.0113\n",
      "Epoch 22/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2177.3147 - val_loss: 215.8397\n",
      "Epoch 23/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 910.8182 - val_loss: 203.5829\n",
      "Epoch 24/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 1275.6166 - val_loss: 199.6075\n",
      "Epoch 25/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 993.9710 - val_loss: 220.5788\n",
      "Epoch 26/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1604.6321 - val_loss: 223.4943\n",
      "Epoch 27/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 461.5257 - val_loss: 205.8190\n",
      "Epoch 28/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 961.2828 - val_loss: 221.9429\n",
      "Epoch 29/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 2457.1255 - val_loss: 201.3990\n",
      "Epoch 30/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 587.5828 - val_loss: 202.7810\n",
      "Epoch 31/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 391.4474 - val_loss: 206.5306\n",
      "Epoch 32/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1050.4662 - val_loss: 190.8372\n",
      "Epoch 33/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 544.0023 - val_loss: 179.7010\n",
      "Epoch 34/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 849.9428 - val_loss: 187.9570\n",
      "Epoch 35/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 8098.3730 - val_loss: 191.3335\n",
      "Epoch 36/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 734.5055 - val_loss: 185.9218\n",
      "Epoch 37/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 509.9412 - val_loss: 179.1323\n",
      "Epoch 38/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 514.9807 - val_loss: 176.3870\n",
      "Epoch 39/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 594.5175 - val_loss: 178.2567\n",
      "Epoch 40/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 423.7462 - val_loss: 173.8526\n",
      "Epoch 41/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 306.7838 - val_loss: 174.1713\n",
      "Epoch 42/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 589.0756 - val_loss: 169.9516\n",
      "Epoch 43/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1643.1793 - val_loss: 184.1203\n",
      "Epoch 44/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 438.7376 - val_loss: 177.7942\n",
      "Epoch 45/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 200.6765 - val_loss: 174.1261\n",
      "Epoch 46/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1078.6549 - val_loss: 168.3305\n",
      "Epoch 47/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 263.3455 - val_loss: 173.6010\n",
      "Epoch 48/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 599.5543 - val_loss: 172.1182\n",
      "Epoch 49/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 881.7299 - val_loss: 168.3029\n",
      "Epoch 50/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 392.9660 - val_loss: 165.7180\n",
      "Epoch 51/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 921.9764 - val_loss: 174.9426\n",
      "Epoch 52/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 291.0154 - val_loss: 170.2652\n",
      "Epoch 53/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 537.9291 - val_loss: 169.0037\n",
      "Epoch 54/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 300.3161 - val_loss: 172.1453\n",
      "Epoch 55/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 437.1572 - val_loss: 169.6388\n",
      "Epoch 56/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 518.7675 - val_loss: 167.2953\n",
      "Epoch 57/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 361.0471 - val_loss: 165.6634\n",
      "Epoch 58/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 211.7762 - val_loss: 165.5824\n",
      "Epoch 59/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 432.9145 - val_loss: 159.9098\n",
      "Epoch 60/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 329.2070 - val_loss: 162.7069\n",
      "Epoch 61/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 737.5472 - val_loss: 161.7187\n",
      "Epoch 62/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 296.2473 - val_loss: 158.1613\n",
      "Epoch 63/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 389.0882 - val_loss: 163.4146\n",
      "Epoch 64/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 240.5187 - val_loss: 157.5405\n",
      "Epoch 65/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 340.8086 - val_loss: 155.5678\n",
      "Epoch 66/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 193.8475 - val_loss: 156.6841\n",
      "Epoch 67/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 495.7335 - val_loss: 155.1454\n",
      "Epoch 68/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 251.5642 - val_loss: 157.6664\n",
      "Epoch 69/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 282.0839 - val_loss: 154.2155\n",
      "Epoch 70/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1323.1392 - val_loss: 203.3065\n",
      "Epoch 71/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 290.1876 - val_loss: 163.8005\n",
      "Epoch 72/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 361.4337 - val_loss: 154.6480\n",
      "Epoch 73/300\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 409.1530 - val_loss: 151.5133\n",
      "Epoch 74/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 188.4882 - val_loss: 147.6775\n",
      "Epoch 75/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 463.6229 - val_loss: 150.2403\n",
      "Epoch 76/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 730.8973 - val_loss: 157.4412\n",
      "Epoch 77/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 868.8462 - val_loss: 164.8798\n",
      "Epoch 78/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 377.4360 - val_loss: 158.0264\n",
      "Epoch 79/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 239.8348 - val_loss: 152.7833\n",
      "Epoch 80/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 258.1227 - val_loss: 157.0228\n",
      "Epoch 81/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 203.7853 - val_loss: 155.7941\n",
      "Epoch 82/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 197.9621 - val_loss: 155.0391\n",
      "Epoch 83/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 349.1732 - val_loss: 156.4463\n",
      "Epoch 84/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 226.6462 - val_loss: 167.9449\n",
      "Epoch 85/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 917.4504 - val_loss: 145.9246\n",
      "Epoch 86/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 480.3571 - val_loss: 147.8066\n",
      "Epoch 87/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 246.1999 - val_loss: 157.6948\n",
      "Epoch 88/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 313.0560 - val_loss: 152.3791\n",
      "Epoch 89/300\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 440.0941 - val_loss: 141.5323\n",
      "Epoch 90/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 206.0876 - val_loss: 144.8493\n",
      "Epoch 91/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 241.3171 - val_loss: 146.9195\n",
      "Epoch 92/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 781.0340 - val_loss: 147.4086\n",
      "Epoch 93/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 445.0106 - val_loss: 152.3028\n",
      "Epoch 94/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 419.8589 - val_loss: 148.1949\n",
      "Epoch 95/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 497.8057 - val_loss: 146.0828\n",
      "Epoch 96/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2284.4353 - val_loss: 156.2777\n",
      "Epoch 97/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 660.0697 - val_loss: 151.8270\n",
      "Epoch 98/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 172.0691 - val_loss: 151.4826\n",
      "Epoch 99/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 631.8841 - val_loss: 156.4133\n",
      "Epoch 100/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 949.4222 - val_loss: 142.8895\n",
      "Epoch 101/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 524.8636 - val_loss: 144.2967\n",
      "Epoch 102/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 405.6234 - val_loss: 141.9347\n",
      "Epoch 103/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 254.5917 - val_loss: 154.1416\n",
      "Epoch 104/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 303.5526 - val_loss: 150.3168\n",
      "Epoch 105/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 239.3282 - val_loss: 152.2563\n",
      "Epoch 106/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 653.8176 - val_loss: 140.4120\n",
      "Epoch 107/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 285.3732 - val_loss: 143.4932\n",
      "Epoch 108/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 307.0422 - val_loss: 138.0712\n",
      "Epoch 109/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 304.5264 - val_loss: 136.4225\n",
      "Epoch 110/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 134.6883 - val_loss: 135.4352\n",
      "Epoch 111/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 402.4736 - val_loss: 135.2124\n",
      "Epoch 112/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 151.7870 - val_loss: 134.1962\n",
      "Epoch 113/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 324.7278 - val_loss: 137.1234\n",
      "Epoch 114/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 165.2087 - val_loss: 135.3772\n",
      "Epoch 115/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 251.0011 - val_loss: 137.5319\n",
      "Epoch 116/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 141.3542 - val_loss: 136.6358\n",
      "Epoch 117/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 232.9946 - val_loss: 136.5233\n",
      "Epoch 118/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 135.6218 - val_loss: 136.2148\n",
      "Epoch 119/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 210.8048 - val_loss: 138.1691\n",
      "Epoch 120/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 116.9010 - val_loss: 136.4448\n",
      "Epoch 121/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 213.3852 - val_loss: 138.1912\n",
      "Epoch 122/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 163.8077 - val_loss: 137.1123\n",
      "Epoch 123/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 214.1245 - val_loss: 136.7648\n",
      "Epoch 124/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 167.5403 - val_loss: 134.5131\n",
      "Epoch 125/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 236.1588 - val_loss: 132.2751\n",
      "Epoch 126/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 142.2137 - val_loss: 137.5784\n",
      "Epoch 127/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 348.8123 - val_loss: 136.3598\n",
      "Epoch 128/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 179.1770 - val_loss: 132.4096\n",
      "Epoch 129/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 129.0505 - val_loss: 135.1760\n",
      "Epoch 130/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 312.7870 - val_loss: 134.9968\n",
      "Epoch 131/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 580.4749 - val_loss: 132.4858\n",
      "Epoch 132/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 212.7523 - val_loss: 134.6648\n",
      "Epoch 133/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 314.4120 - val_loss: 134.8093\n",
      "Epoch 134/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 232.9976 - val_loss: 135.5400\n",
      "Epoch 135/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 396.0182 - val_loss: 137.7455\n",
      "Epoch 136/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 184.6639 - val_loss: 135.7269\n",
      "Epoch 137/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 354.9782 - val_loss: 136.0931\n",
      "Epoch 138/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 173.2848 - val_loss: 135.5230\n",
      "Epoch 139/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 183.0942 - val_loss: 135.3721\n",
      "Epoch 140/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 157.5747 - val_loss: 134.3440\n",
      "Epoch 141/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 170.1290 - val_loss: 135.4985\n",
      "Epoch 142/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 176.2677 - val_loss: 133.2397\n",
      "Epoch 143/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 140.8646 - val_loss: 134.6845\n",
      "Epoch 144/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 143.2056 - val_loss: 133.2432\n",
      "Epoch 145/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 150.2090 - val_loss: 133.3338\n",
      "Epoch 146/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 145.0674 - val_loss: 133.3061\n",
      "Epoch 147/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 162.4071 - val_loss: 134.0420\n",
      "Epoch 148/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 113.6056 - val_loss: 132.2964\n",
      "Epoch 149/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 177.7631 - val_loss: 132.0941\n",
      "Epoch 150/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 131.7120 - val_loss: 130.5383\n",
      "Epoch 151/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 153.8473 - val_loss: 130.7670\n",
      "Epoch 152/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 161.3948 - val_loss: 130.6555\n",
      "Epoch 153/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 142.5631 - val_loss: 131.4591\n",
      "Epoch 154/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 138.3598 - val_loss: 133.0108\n",
      "Epoch 155/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 146.7092 - val_loss: 131.9410\n",
      "Epoch 156/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 143.3877 - val_loss: 132.8371\n",
      "Epoch 157/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 167.1585 - val_loss: 132.7412\n",
      "Epoch 158/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 130.5585 - val_loss: 133.4449\n",
      "Epoch 159/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 165.4703 - val_loss: 131.7063\n",
      "Epoch 160/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 182.8339 - val_loss: 133.0773\n",
      "Epoch 161/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 139.6374 - val_loss: 130.6360\n",
      "Epoch 162/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 171.2189 - val_loss: 131.1206\n",
      "Epoch 163/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 183.4397 - val_loss: 131.5531\n",
      "Epoch 164/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 143.3410 - val_loss: 131.7243\n",
      "Epoch 165/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 189.5193 - val_loss: 130.4885\n",
      "Epoch 166/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 134.6447 - val_loss: 130.6699\n",
      "Epoch 167/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 157.2152 - val_loss: 131.3658\n",
      "Epoch 168/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 159.5065 - val_loss: 129.7427\n",
      "Epoch 169/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 234.5660 - val_loss: 130.7558\n",
      "Epoch 170/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 129.2556 - val_loss: 130.7033\n",
      "Epoch 171/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 206.3428 - val_loss: 130.7584\n",
      "Epoch 172/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 114.6976 - val_loss: 130.3840\n",
      "Epoch 173/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 185.3929 - val_loss: 129.4882\n",
      "Epoch 174/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 160.3714 - val_loss: 129.1639\n",
      "Epoch 175/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 198.6078 - val_loss: 129.9624\n",
      "Epoch 176/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 143.6631 - val_loss: 129.2248\n",
      "Epoch 177/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 204.4371 - val_loss: 129.8807\n",
      "Epoch 178/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 160.3517 - val_loss: 128.7269\n",
      "Epoch 179/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 189.9900 - val_loss: 130.4590\n",
      "Epoch 180/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 251.8615 - val_loss: 130.7805\n",
      "Epoch 181/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 135.4581 - val_loss: 129.2334\n",
      "Epoch 182/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 186.7950 - val_loss: 129.4561\n",
      "Epoch 183/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 131.9016 - val_loss: 127.8367\n",
      "Epoch 184/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 177.0753 - val_loss: 129.0327\n",
      "Epoch 185/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 193.2362 - val_loss: 128.7016\n",
      "Epoch 186/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 159.1381 - val_loss: 129.6830\n",
      "Epoch 187/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 210.7826 - val_loss: 129.6895\n",
      "Epoch 188/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 153.5125 - val_loss: 130.2078\n",
      "Epoch 189/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 155.9983 - val_loss: 129.9409\n",
      "Epoch 190/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 146.6302 - val_loss: 128.6046\n",
      "Epoch 191/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 183.1727 - val_loss: 128.0664\n",
      "Epoch 192/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 152.9572 - val_loss: 128.6704\n",
      "Epoch 193/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 136.1454 - val_loss: 128.1124\n",
      "Epoch 194/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 152.3499 - val_loss: 128.6112\n",
      "Epoch 195/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 111.8468 - val_loss: 127.7570\n",
      "Epoch 196/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 146.1649 - val_loss: 128.3161\n",
      "Epoch 197/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 159.9531 - val_loss: 128.9783\n",
      "Epoch 198/300\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 158.8973 - val_loss: 127.4720\n",
      "Epoch 199/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 133.4032 - val_loss: 128.5567\n",
      "Epoch 200/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 157.4981 - val_loss: 127.0565\n",
      "Epoch 201/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 370.0735 - val_loss: 126.6113\n",
      "Epoch 202/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 119.4557 - val_loss: 128.5678\n",
      "Epoch 203/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 276.1152 - val_loss: 128.4926\n",
      "Epoch 204/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 157.0173 - val_loss: 127.8906\n",
      "Epoch 205/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 95.9009 - val_loss: 127.5811\n",
      "Epoch 206/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 112.5286 - val_loss: 127.6167\n",
      "Epoch 207/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 108.2814 - val_loss: 127.8329\n",
      "Epoch 208/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 103.6752 - val_loss: 126.8556\n",
      "Epoch 209/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 107.6080 - val_loss: 127.4985\n",
      "Epoch 210/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 103.9190 - val_loss: 125.9306\n",
      "Epoch 211/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 105.2147 - val_loss: 126.0743\n",
      "Epoch 212/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 96.5933 - val_loss: 125.5751\n",
      "Epoch 213/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 116.0823 - val_loss: 125.9282\n",
      "Epoch 214/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 98.8748 - val_loss: 125.1680\n",
      "Epoch 215/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 99.6884 - val_loss: 125.2213\n",
      "Epoch 216/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 94.2908 - val_loss: 124.7403\n",
      "Epoch 217/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 97.2471 - val_loss: 125.1364\n",
      "Epoch 218/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 95.3004 - val_loss: 124.8590\n",
      "Epoch 219/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 99.5481 - val_loss: 125.6287\n",
      "Epoch 220/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 94.5426 - val_loss: 125.6556\n",
      "Epoch 221/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 97.0151 - val_loss: 125.8071\n",
      "Epoch 222/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 95.8594 - val_loss: 125.6938\n",
      "Epoch 223/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 100.2572 - val_loss: 124.3473\n",
      "Epoch 224/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 94.9852 - val_loss: 125.2437\n",
      "Epoch 225/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 90.1860 - val_loss: 124.4064\n",
      "Epoch 226/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 101.2206 - val_loss: 125.6058\n",
      "Epoch 227/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 93.2693 - val_loss: 125.2843\n",
      "Epoch 228/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 95.6455 - val_loss: 126.7941\n",
      "Epoch 229/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 96.7140 - val_loss: 125.0991\n",
      "Epoch 230/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 100.4750 - val_loss: 125.5490\n",
      "Epoch 231/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 88.7478 - val_loss: 126.2931\n",
      "Epoch 232/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 103.5522 - val_loss: 126.4532\n",
      "Epoch 233/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 97.3167 - val_loss: 124.5971\n",
      "Epoch 234/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 103.0233 - val_loss: 125.6915\n",
      "Epoch 235/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 98.0751 - val_loss: 125.5310\n",
      "Epoch 236/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 109.9506 - val_loss: 126.8752\n",
      "Epoch 237/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 92.8706 - val_loss: 126.6626\n",
      "Epoch 238/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 97.1200 - val_loss: 126.1003\n",
      "Epoch 239/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 95.1306 - val_loss: 126.9137\n",
      "Epoch 240/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 120.1516 - val_loss: 125.7036\n",
      "Epoch 241/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 93.8980 - val_loss: 125.9865\n",
      "Epoch 242/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 103.6271 - val_loss: 125.9079\n",
      "Epoch 243/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 96.6958 - val_loss: 125.9483\n",
      "Epoch 244/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 95.9877 - val_loss: 126.0932\n",
      "Epoch 245/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 99.0031 - val_loss: 126.0129\n",
      "Epoch 246/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 90.9560 - val_loss: 126.5292\n",
      "Epoch 247/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 96.1856 - val_loss: 125.6474\n",
      "Epoch 248/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 89.8471 - val_loss: 124.0901\n",
      "Epoch 249/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 127.1427 - val_loss: 124.3117\n",
      "Epoch 250/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 89.4155 - val_loss: 124.6251\n",
      "Epoch 251/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 104.7631 - val_loss: 124.5433\n",
      "Epoch 252/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 102.6688 - val_loss: 122.7366\n",
      "Epoch 253/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 104.6246 - val_loss: 124.3105\n",
      "Epoch 254/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 96.5376 - val_loss: 125.4583\n",
      "Epoch 255/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 101.1717 - val_loss: 123.9302\n",
      "Epoch 256/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 158.4307 - val_loss: 122.2127\n",
      "Epoch 257/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 97.5764 - val_loss: 123.2249\n",
      "Epoch 258/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 89.3061 - val_loss: 122.5943\n",
      "Epoch 259/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 102.2085 - val_loss: 121.6924\n",
      "Epoch 260/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 91.8801 - val_loss: 121.4714\n",
      "Epoch 261/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 98.7846 - val_loss: 120.9957\n",
      "Epoch 262/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 111.3574 - val_loss: 122.1547\n",
      "Epoch 263/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 122.1608 - val_loss: 122.6495\n",
      "Epoch 264/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 94.8968 - val_loss: 122.9920\n",
      "Epoch 265/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 99.3465 - val_loss: 121.3901\n",
      "Epoch 266/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 105.5758 - val_loss: 125.8261\n",
      "Epoch 267/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 96.5003 - val_loss: 124.9331\n",
      "Epoch 268/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 105.1083 - val_loss: 125.2325\n",
      "Epoch 269/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 100.5010 - val_loss: 126.0906\n",
      "Epoch 270/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 85.9325 - val_loss: 125.6179\n",
      "Epoch 271/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 98.9537 - val_loss: 124.3264\n",
      "Epoch 272/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 82.5239 - val_loss: 121.7618\n",
      "Epoch 273/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 89.2943 - val_loss: 122.9865\n",
      "Epoch 274/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 96.8605 - val_loss: 123.3878\n",
      "Epoch 275/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 86.0966 - val_loss: 125.5164\n",
      "Epoch 276/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 100.7660 - val_loss: 122.9738\n",
      "Epoch 277/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 137.8952 - val_loss: 121.5328\n",
      "Epoch 278/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 82.9824 - val_loss: 123.7585\n",
      "Epoch 279/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 127.7957 - val_loss: 122.2254\n",
      "Epoch 280/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 92.9788 - val_loss: 121.8109\n",
      "Epoch 281/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 97.3185 - val_loss: 121.3341\n",
      "Epoch 282/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 102.3422 - val_loss: 120.8888\n",
      "Epoch 283/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 103.9470 - val_loss: 120.3675\n",
      "Epoch 284/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 95.0448 - val_loss: 121.3476\n",
      "Epoch 285/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 97.9443 - val_loss: 120.6456\n",
      "Epoch 286/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 85.4029 - val_loss: 121.4793\n",
      "Epoch 287/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 82.4281 - val_loss: 121.5950\n",
      "Epoch 288/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 89.7025 - val_loss: 123.0480\n",
      "Epoch 289/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 103.7546 - val_loss: 121.3363\n",
      "Epoch 290/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 165.4344 - val_loss: 122.3053\n",
      "Epoch 291/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 81.1683 - val_loss: 121.4226\n",
      "Epoch 292/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 140.3499 - val_loss: 121.7094\n",
      "Epoch 293/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 106.1744 - val_loss: 121.1824\n",
      "Epoch 294/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 82.3420 - val_loss: 120.1469\n",
      "Epoch 295/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 79.4226 - val_loss: 120.3047\n",
      "Epoch 296/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 80.5096 - val_loss: 119.3442\n",
      "Epoch 297/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 79.2526 - val_loss: 120.6205\n",
      "Epoch 298/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 79.5228 - val_loss: 121.1633\n",
      "Epoch 299/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 76.5934 - val_loss: 120.0498\n",
      "Epoch 300/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 80.2212 - val_loss: 121.0423\n",
      "'########################################################Model4\n",
      "Epoch 1/300\n",
      "35/35 [==============================] - 2s 14ms/step - loss: 3143.9800 - val_loss: 567.8960\n",
      "Epoch 2/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 5759.4097 - val_loss: 464.4048\n",
      "Epoch 3/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 7427.1787 - val_loss: 437.5441\n",
      "Epoch 4/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 4363.2271 - val_loss: 483.6203\n",
      "Epoch 5/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 2913.6487 - val_loss: 578.0994\n",
      "Epoch 6/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 4971.6533 - val_loss: 424.8929\n",
      "Epoch 7/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 2671.8325 - val_loss: 399.4624\n",
      "Epoch 8/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 6763.9419 - val_loss: 689.8349\n",
      "Epoch 9/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 7985.1743 - val_loss: 349.5147\n",
      "Epoch 10/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1155.5004 - val_loss: 349.4482\n",
      "Epoch 11/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 3475.6809 - val_loss: 1228.6191\n",
      "Epoch 12/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 6395.3130 - val_loss: 276.5820\n",
      "Epoch 13/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 39689.2578 - val_loss: 320.9281\n",
      "Epoch 14/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3049.2004 - val_loss: 422.1129\n",
      "Epoch 15/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 2989.8613 - val_loss: 388.0974\n",
      "Epoch 16/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1750.8733 - val_loss: 328.0797\n",
      "Epoch 17/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 8854.2871 - val_loss: 258.2584\n",
      "Epoch 18/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 8953.0020 - val_loss: 282.3114\n",
      "Epoch 19/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 2349.8760 - val_loss: 225.0737\n",
      "Epoch 20/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 876.9378 - val_loss: 480.1165\n",
      "Epoch 21/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 4784.7925 - val_loss: 265.3700\n",
      "Epoch 22/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 760.6481 - val_loss: 260.6231\n",
      "Epoch 23/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 2485.5049 - val_loss: 331.0842\n",
      "Epoch 24/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1072.7788 - val_loss: 350.6977\n",
      "Epoch 25/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 12404.4277 - val_loss: 309.6692\n",
      "Epoch 26/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1104.2482 - val_loss: 264.8644\n",
      "Epoch 27/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 479.4639 - val_loss: 237.7930\n",
      "Epoch 28/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1384.5792 - val_loss: 227.0937\n",
      "Epoch 29/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 460.2495 - val_loss: 195.6046\n",
      "Epoch 30/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 718.3466 - val_loss: 246.2510\n",
      "Epoch 31/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 897.7485 - val_loss: 227.4874\n",
      "Epoch 32/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1370.4949 - val_loss: 213.7910\n",
      "Epoch 33/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1079.6780 - val_loss: 210.9287\n",
      "Epoch 34/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 636.5990 - val_loss: 201.8826\n",
      "Epoch 35/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 768.9174 - val_loss: 198.9793\n",
      "Epoch 36/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 1474.4052 - val_loss: 195.5050\n",
      "Epoch 37/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 548.2773 - val_loss: 190.4690\n",
      "Epoch 38/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 809.6624 - val_loss: 189.0908\n",
      "Epoch 39/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 450.5791 - val_loss: 187.1402\n",
      "Epoch 40/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 825.1922 - val_loss: 191.3466\n",
      "Epoch 41/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 527.2628 - val_loss: 197.6996\n",
      "Epoch 42/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1011.8176 - val_loss: 176.9583\n",
      "Epoch 43/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 395.0115 - val_loss: 179.2560\n",
      "Epoch 44/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 687.9206 - val_loss: 175.5313\n",
      "Epoch 45/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 266.3342 - val_loss: 174.4719\n",
      "Epoch 46/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 632.1976 - val_loss: 175.0160\n",
      "Epoch 47/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 335.8430 - val_loss: 185.5664\n",
      "Epoch 48/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 419.6341 - val_loss: 183.2907\n",
      "Epoch 49/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 190.3578 - val_loss: 177.0378\n",
      "Epoch 50/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 756.6124 - val_loss: 176.8211\n",
      "Epoch 51/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 199.7499 - val_loss: 175.7172\n",
      "Epoch 52/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 416.7807 - val_loss: 174.1579\n",
      "Epoch 53/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 210.2493 - val_loss: 171.5598\n",
      "Epoch 54/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 349.9197 - val_loss: 171.3966\n",
      "Epoch 55/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 429.8525 - val_loss: 175.1477\n",
      "Epoch 56/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 437.1408 - val_loss: 172.1535\n",
      "Epoch 57/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 876.7695 - val_loss: 168.3239\n",
      "Epoch 58/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 742.5817 - val_loss: 174.1253\n",
      "Epoch 59/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 823.2205 - val_loss: 180.7029\n",
      "Epoch 60/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 407.4408 - val_loss: 170.9333\n",
      "Epoch 61/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 195.5382 - val_loss: 171.8417\n",
      "Epoch 62/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 643.7011 - val_loss: 164.9821\n",
      "Epoch 63/300\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 815.1409 - val_loss: 161.7650\n",
      "Epoch 64/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 539.4487 - val_loss: 166.5613\n",
      "Epoch 65/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 948.3440 - val_loss: 161.4394\n",
      "Epoch 66/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 421.4315 - val_loss: 161.2289\n",
      "Epoch 67/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 308.7590 - val_loss: 173.8258\n",
      "Epoch 68/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 820.0804 - val_loss: 172.8011\n",
      "Epoch 69/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 271.1272 - val_loss: 170.9408\n",
      "Epoch 70/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 450.6539 - val_loss: 178.7792\n",
      "Epoch 71/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 792.0472 - val_loss: 177.6521\n",
      "Epoch 72/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 10206.7910 - val_loss: 187.2561\n",
      "Epoch 73/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 469.4605 - val_loss: 186.9797\n",
      "Epoch 74/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 210.9472 - val_loss: 211.7652\n",
      "Epoch 75/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 1874.1171 - val_loss: 170.5637\n",
      "Epoch 76/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 412.1530 - val_loss: 180.2450\n",
      "Epoch 77/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 733.7568 - val_loss: 187.8839\n",
      "Epoch 78/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 571.4155 - val_loss: 185.9678\n",
      "Epoch 79/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 439.8851 - val_loss: 197.2982\n",
      "Epoch 80/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1818.4817 - val_loss: 188.8575\n",
      "Epoch 81/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 499.2169 - val_loss: 311.8414\n",
      "Epoch 82/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 32722.1113 - val_loss: 199.5467\n",
      "Epoch 83/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 1226.1136 - val_loss: 246.4636\n",
      "Epoch 84/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 2695.0920 - val_loss: 199.5139\n",
      "Epoch 85/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 790.5701 - val_loss: 194.5199\n",
      "Epoch 86/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 334.0372 - val_loss: 189.9632\n",
      "Epoch 87/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 1387.7942 - val_loss: 182.5493\n",
      "Epoch 88/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 422.9321 - val_loss: 178.5460\n",
      "Epoch 89/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 794.0602 - val_loss: 196.8398\n",
      "Epoch 90/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 394.5879 - val_loss: 194.5523\n",
      "Epoch 91/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 241.2780 - val_loss: 176.8403\n",
      "Epoch 92/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1054.3961 - val_loss: 166.0145\n",
      "Epoch 93/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 337.5437 - val_loss: 161.9728\n",
      "Epoch 94/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 496.5943 - val_loss: 160.9766\n",
      "Epoch 95/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 181.2847 - val_loss: 163.0504\n",
      "Epoch 96/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 594.9503 - val_loss: 157.6349\n",
      "Epoch 97/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 230.1362 - val_loss: 156.9702\n",
      "Epoch 98/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 256.9629 - val_loss: 154.7732\n",
      "Epoch 99/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 456.0532 - val_loss: 152.8929\n",
      "Epoch 100/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 249.2652 - val_loss: 149.0289\n",
      "Epoch 101/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 559.3638 - val_loss: 150.5236\n",
      "Epoch 102/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 256.0432 - val_loss: 166.4892\n",
      "Epoch 103/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 532.3236 - val_loss: 161.0166\n",
      "Epoch 104/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 171.1576 - val_loss: 162.8064\n",
      "Epoch 105/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 490.9821 - val_loss: 166.7574\n",
      "Epoch 106/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 594.7891 - val_loss: 158.2247\n",
      "Epoch 107/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 709.2371 - val_loss: 158.3418\n",
      "Epoch 108/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 356.2260 - val_loss: 147.5085\n",
      "Epoch 109/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 181.2185 - val_loss: 146.4268\n",
      "Epoch 110/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 440.5855 - val_loss: 145.0846\n",
      "Epoch 111/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 162.9534 - val_loss: 142.0993\n",
      "Epoch 112/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 497.4767 - val_loss: 144.5748\n",
      "Epoch 113/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 302.1107 - val_loss: 144.7682\n",
      "Epoch 114/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 274.5464 - val_loss: 145.0038\n",
      "Epoch 115/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 254.0012 - val_loss: 145.1809\n",
      "Epoch 116/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 311.9108 - val_loss: 146.0864\n",
      "Epoch 117/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 252.8894 - val_loss: 142.6043\n",
      "Epoch 118/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 155.4365 - val_loss: 143.2251\n",
      "Epoch 119/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 301.3262 - val_loss: 144.2604\n",
      "Epoch 120/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 161.3186 - val_loss: 145.3482\n",
      "Epoch 121/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 388.8024 - val_loss: 149.7946\n",
      "Epoch 122/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 135.3784 - val_loss: 152.2498\n",
      "Epoch 123/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 424.0103 - val_loss: 149.1431\n",
      "Epoch 124/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 476.1046 - val_loss: 145.4511\n",
      "Epoch 125/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 219.9602 - val_loss: 143.5751\n",
      "Epoch 126/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 283.4757 - val_loss: 142.3195\n",
      "Epoch 127/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 184.8097 - val_loss: 144.0860\n",
      "Epoch 128/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 384.7564 - val_loss: 141.4316\n",
      "Epoch 129/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 180.3780 - val_loss: 142.9937\n",
      "Epoch 130/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 177.0601 - val_loss: 142.9457\n",
      "Epoch 131/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 205.8693 - val_loss: 143.2330\n",
      "Epoch 132/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 202.9498 - val_loss: 142.0945\n",
      "Epoch 133/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 149.1744 - val_loss: 142.8691\n",
      "Epoch 134/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 187.4486 - val_loss: 145.0989\n",
      "Epoch 135/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 161.9841 - val_loss: 146.5792\n",
      "Epoch 136/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 299.2998 - val_loss: 144.1481\n",
      "Epoch 137/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 246.6012 - val_loss: 144.5264\n",
      "Epoch 138/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 200.8104 - val_loss: 140.5961\n",
      "Epoch 139/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 322.9380 - val_loss: 141.3075\n",
      "Epoch 140/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 133.2250 - val_loss: 143.4164\n",
      "Epoch 141/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 326.2423 - val_loss: 143.4817\n",
      "Epoch 142/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 114.2751 - val_loss: 141.2939\n",
      "Epoch 143/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 254.0776 - val_loss: 139.7603\n",
      "Epoch 144/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 207.9782 - val_loss: 141.1402\n",
      "Epoch 145/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 288.9422 - val_loss: 138.3257\n",
      "Epoch 146/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 118.9178 - val_loss: 138.8974\n",
      "Epoch 147/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 245.3574 - val_loss: 138.4921\n",
      "Epoch 148/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 133.8240 - val_loss: 139.2538\n",
      "Epoch 149/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 205.1324 - val_loss: 137.1855\n",
      "Epoch 150/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 302.9463 - val_loss: 137.0907\n",
      "Epoch 151/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 128.5041 - val_loss: 136.7770\n",
      "Epoch 152/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 261.2536 - val_loss: 136.7243\n",
      "Epoch 153/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 137.8589 - val_loss: 137.3809\n",
      "Epoch 154/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 243.7464 - val_loss: 136.1839\n",
      "Epoch 155/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 134.4104 - val_loss: 136.9836\n",
      "Epoch 156/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 248.1383 - val_loss: 138.3781\n",
      "Epoch 157/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 234.7913 - val_loss: 136.2508\n",
      "Epoch 158/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 332.4353 - val_loss: 133.6043\n",
      "Epoch 159/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 140.4191 - val_loss: 133.5209\n",
      "Epoch 160/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 331.5896 - val_loss: 134.8630\n",
      "Epoch 161/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 186.1884 - val_loss: 134.5129\n",
      "Epoch 162/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 263.1820 - val_loss: 133.4506\n",
      "Epoch 163/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 167.7812 - val_loss: 141.7753\n",
      "Epoch 164/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 347.0254 - val_loss: 137.4206\n",
      "Epoch 165/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 151.1393 - val_loss: 136.8462\n",
      "Epoch 166/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 349.0300 - val_loss: 138.3339\n",
      "Epoch 167/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 221.0629 - val_loss: 141.6599\n",
      "Epoch 168/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 213.3978 - val_loss: 139.1135\n",
      "Epoch 169/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 211.5388 - val_loss: 137.5429\n",
      "Epoch 170/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 219.3335 - val_loss: 135.7346\n",
      "Epoch 171/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 173.0141 - val_loss: 136.0698\n",
      "Epoch 172/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 203.8296 - val_loss: 135.2855\n",
      "Epoch 173/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 186.9074 - val_loss: 134.5911\n",
      "Epoch 174/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 288.2615 - val_loss: 135.8844\n",
      "Epoch 175/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 130.9456 - val_loss: 137.2422\n",
      "Epoch 176/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 306.1435 - val_loss: 137.8737\n",
      "Epoch 177/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 439.9004 - val_loss: 136.5700\n",
      "Epoch 178/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 313.2632 - val_loss: 134.8961\n",
      "Epoch 179/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 170.8797 - val_loss: 133.2354\n",
      "Epoch 180/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 196.0647 - val_loss: 133.5756\n",
      "Epoch 181/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 127.9322 - val_loss: 133.3261\n",
      "Epoch 182/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 232.9856 - val_loss: 133.5952\n",
      "Epoch 183/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 196.0604 - val_loss: 133.8033\n",
      "Epoch 184/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 194.6699 - val_loss: 130.7672\n",
      "Epoch 185/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 186.9710 - val_loss: 130.9695\n",
      "Epoch 186/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 219.4814 - val_loss: 129.7942\n",
      "Epoch 187/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 163.8810 - val_loss: 129.1901\n",
      "Epoch 188/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 244.3866 - val_loss: 129.1095\n",
      "Epoch 189/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 186.0425 - val_loss: 131.5149\n",
      "Epoch 190/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 121.7620 - val_loss: 131.2493\n",
      "Epoch 191/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 147.8055 - val_loss: 136.9978\n",
      "Epoch 192/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 379.1483 - val_loss: 133.0133\n",
      "Epoch 193/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 197.4292 - val_loss: 130.2099\n",
      "Epoch 194/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 185.1149 - val_loss: 132.4160\n",
      "Epoch 195/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 239.7349 - val_loss: 160.1089\n",
      "Epoch 196/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 1975.5387 - val_loss: 130.4978\n",
      "Epoch 197/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 218.3641 - val_loss: 140.1189\n",
      "Epoch 198/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 333.4668 - val_loss: 159.4980\n",
      "Epoch 199/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 2433.0684 - val_loss: 132.9102\n",
      "Epoch 200/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 277.6497 - val_loss: 132.2681\n",
      "Epoch 201/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 249.0943 - val_loss: 134.5428\n",
      "Epoch 202/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 798.6265 - val_loss: 134.4089\n",
      "Epoch 203/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 454.4222 - val_loss: 138.6717\n",
      "Epoch 204/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 2087.1250 - val_loss: 150.9628\n",
      "Epoch 205/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 637.7779 - val_loss: 138.6407\n",
      "Epoch 206/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 828.4437 - val_loss: 137.9032\n",
      "Epoch 207/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 314.4032 - val_loss: 161.4072\n",
      "Epoch 208/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 235.9580 - val_loss: 139.7996\n",
      "Epoch 209/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 316.4391 - val_loss: 153.0390\n",
      "Epoch 210/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 298.0440 - val_loss: 139.5701\n",
      "Epoch 211/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 628.5347 - val_loss: 133.8660\n",
      "Epoch 212/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 203.3580 - val_loss: 145.7413\n",
      "Epoch 213/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 246.7171 - val_loss: 153.0035\n",
      "Epoch 214/300\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 277.4901 - val_loss: 124.4195\n",
      "Epoch 215/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 165.1985 - val_loss: 127.6594\n",
      "Epoch 216/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 575.4357 - val_loss: 131.8338\n",
      "Epoch 217/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1267.4568 - val_loss: 119.6716\n",
      "Epoch 218/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 247.3468 - val_loss: 144.7725\n",
      "Epoch 219/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 624.0538 - val_loss: 120.8351\n",
      "Epoch 220/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 152.5140 - val_loss: 131.7812\n",
      "Epoch 221/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 465.3992 - val_loss: 122.1780\n",
      "Epoch 222/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 134.4050 - val_loss: 123.7481\n",
      "Epoch 223/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 377.3786 - val_loss: 124.8239\n",
      "Epoch 224/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 226.4500 - val_loss: 119.6171\n",
      "Epoch 225/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 181.9453 - val_loss: 119.9492\n",
      "Epoch 226/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 314.3411 - val_loss: 121.9773\n",
      "Epoch 227/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 170.7261 - val_loss: 122.7164\n",
      "Epoch 228/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 216.3337 - val_loss: 122.9903\n",
      "Epoch 229/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 208.4006 - val_loss: 121.0615\n",
      "Epoch 230/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 306.7927 - val_loss: 121.7051\n",
      "Epoch 231/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 177.6272 - val_loss: 119.9854\n",
      "Epoch 232/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 167.4501 - val_loss: 121.9343\n",
      "Epoch 233/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 185.7800 - val_loss: 121.9899\n",
      "Epoch 234/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 168.2875 - val_loss: 121.8538\n",
      "Epoch 235/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 146.1911 - val_loss: 121.6241\n",
      "Epoch 236/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 157.3931 - val_loss: 121.7014\n",
      "Epoch 237/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 153.8940 - val_loss: 121.1567\n",
      "Epoch 238/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 157.5370 - val_loss: 121.3701\n",
      "Epoch 239/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 144.6348 - val_loss: 121.1505\n",
      "Epoch 240/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 153.6503 - val_loss: 120.2263\n",
      "Epoch 241/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 160.3374 - val_loss: 120.5959\n",
      "Epoch 242/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 151.8349 - val_loss: 121.4422\n",
      "Epoch 243/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 132.5030 - val_loss: 121.2075\n",
      "Epoch 244/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 163.5156 - val_loss: 121.6424\n",
      "Epoch 245/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 146.2361 - val_loss: 121.9747\n",
      "Epoch 246/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 134.9094 - val_loss: 122.3879\n",
      "Epoch 247/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 139.3993 - val_loss: 122.1580\n",
      "Epoch 248/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 147.5284 - val_loss: 121.9981\n",
      "Epoch 249/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 147.7057 - val_loss: 122.0318\n",
      "Epoch 250/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 116.5414 - val_loss: 122.0027\n",
      "Epoch 251/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 141.1330 - val_loss: 121.6418\n",
      "Epoch 252/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 110.8942 - val_loss: 122.7569\n",
      "Epoch 253/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 150.6396 - val_loss: 121.1527\n",
      "Epoch 254/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 118.8868 - val_loss: 121.9389\n",
      "'########################################################Model5\n",
      "Epoch 1/300\n",
      "35/35 [==============================] - 2s 15ms/step - loss: 1744.0718 - val_loss: 448.7365\n",
      "Epoch 2/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 2451.2668 - val_loss: 461.2183\n",
      "Epoch 3/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 5779.8730 - val_loss: 369.9817\n",
      "Epoch 4/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 4479.7236 - val_loss: 331.0872\n",
      "Epoch 5/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 2571.0608 - val_loss: 389.6449\n",
      "Epoch 6/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 3322.0752 - val_loss: 343.9550\n",
      "Epoch 7/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 614.4857 - val_loss: 327.8704\n",
      "Epoch 8/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1824.1659 - val_loss: 354.2259\n",
      "Epoch 9/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 1622.1217 - val_loss: 331.3889\n",
      "Epoch 10/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 5299.6621 - val_loss: 359.7105\n",
      "Epoch 11/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 988.5373 - val_loss: 670.9285\n",
      "Epoch 12/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 7636.9390 - val_loss: 305.0862\n",
      "Epoch 13/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1623.1022 - val_loss: 249.1542\n",
      "Epoch 14/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1921.7505 - val_loss: 268.9908\n",
      "Epoch 15/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 14289.6816 - val_loss: 270.7293\n",
      "Epoch 16/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1151.2279 - val_loss: 254.1446\n",
      "Epoch 17/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1576.3842 - val_loss: 246.4847\n",
      "Epoch 18/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 1267.7649 - val_loss: 274.4492\n",
      "Epoch 19/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 615.4047 - val_loss: 345.4742\n",
      "Epoch 20/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 5410.4575 - val_loss: 454.8419\n",
      "Epoch 21/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1060.8245 - val_loss: 265.1297\n",
      "Epoch 22/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 631.4559 - val_loss: 237.0458\n",
      "Epoch 23/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 2587.2822 - val_loss: 231.3847\n",
      "Epoch 24/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 795.4025 - val_loss: 406.8190\n",
      "Epoch 25/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 1711.9232 - val_loss: 196.1795\n",
      "Epoch 26/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 796.2183 - val_loss: 186.9117\n",
      "Epoch 27/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 2109.6895 - val_loss: 225.8157\n",
      "Epoch 28/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 9751.0742 - val_loss: 207.6149\n",
      "Epoch 29/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 593.3099 - val_loss: 194.6465\n",
      "Epoch 30/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1123.6028 - val_loss: 244.6911\n",
      "Epoch 31/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 3022.0698 - val_loss: 187.0285\n",
      "Epoch 32/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 545.0129 - val_loss: 177.9178\n",
      "Epoch 33/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 471.9840 - val_loss: 185.5448\n",
      "Epoch 34/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 942.1217 - val_loss: 162.2039\n",
      "Epoch 35/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 621.2695 - val_loss: 155.1418\n",
      "Epoch 36/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 346.5768 - val_loss: 160.6967\n",
      "Epoch 37/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 679.0578 - val_loss: 154.7374\n",
      "Epoch 38/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 397.2220 - val_loss: 159.2619\n",
      "Epoch 39/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 516.7474 - val_loss: 155.7451\n",
      "Epoch 40/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 273.8555 - val_loss: 153.3879\n",
      "Epoch 41/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 440.9569 - val_loss: 151.9411\n",
      "Epoch 42/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 286.8462 - val_loss: 149.9276\n",
      "Epoch 43/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 473.9151 - val_loss: 150.6265\n",
      "Epoch 44/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 303.7646 - val_loss: 147.8028\n",
      "Epoch 45/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 364.3544 - val_loss: 148.8343\n",
      "Epoch 46/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 204.1328 - val_loss: 147.8451\n",
      "Epoch 47/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 359.7711 - val_loss: 151.4807\n",
      "Epoch 48/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 183.8503 - val_loss: 150.9773\n",
      "Epoch 49/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 415.0615 - val_loss: 149.6553\n",
      "Epoch 50/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 186.7256 - val_loss: 149.8935\n",
      "Epoch 51/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 332.8542 - val_loss: 149.2795\n",
      "Epoch 52/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 219.1809 - val_loss: 146.9058\n",
      "Epoch 53/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 275.2440 - val_loss: 150.2241\n",
      "Epoch 54/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 237.6057 - val_loss: 152.4859\n",
      "Epoch 55/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 429.7595 - val_loss: 149.6846\n",
      "Epoch 56/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 259.3309 - val_loss: 146.9480\n",
      "Epoch 57/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 220.4726 - val_loss: 145.8783\n",
      "Epoch 58/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 352.8765 - val_loss: 148.9676\n",
      "Epoch 59/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 186.1941 - val_loss: 149.8036\n",
      "Epoch 60/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 272.8018 - val_loss: 149.6053\n",
      "Epoch 61/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 209.4434 - val_loss: 150.9321\n",
      "Epoch 62/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 231.5144 - val_loss: 151.4922\n",
      "Epoch 63/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 210.5445 - val_loss: 146.6416\n",
      "Epoch 64/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 285.2655 - val_loss: 147.2429\n",
      "Epoch 65/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 194.7044 - val_loss: 143.5474\n",
      "Epoch 66/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 325.9065 - val_loss: 144.6040\n",
      "Epoch 67/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 179.4401 - val_loss: 143.7904\n",
      "Epoch 68/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 378.9046 - val_loss: 146.3435\n",
      "Epoch 69/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 211.6219 - val_loss: 148.5660\n",
      "Epoch 70/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 310.3545 - val_loss: 148.0679\n",
      "Epoch 71/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 210.1677 - val_loss: 146.2457\n",
      "Epoch 72/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 260.8425 - val_loss: 151.2130\n",
      "Epoch 73/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 242.1027 - val_loss: 147.4080\n",
      "Epoch 74/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 298.9742 - val_loss: 148.6453\n",
      "Epoch 75/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 295.6199 - val_loss: 147.0075\n",
      "Epoch 76/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 257.4273 - val_loss: 150.1248\n",
      "Epoch 77/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 288.1353 - val_loss: 149.5644\n",
      "Epoch 78/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 211.4948 - val_loss: 147.9783\n",
      "Epoch 79/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 210.1449 - val_loss: 147.8442\n",
      "Epoch 80/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 251.2160 - val_loss: 150.8544\n",
      "Epoch 81/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 165.4626 - val_loss: 150.1907\n",
      "Epoch 82/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 207.2206 - val_loss: 149.6815\n",
      "Epoch 83/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 253.1551 - val_loss: 147.2729\n",
      "Epoch 84/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 196.9098 - val_loss: 147.6001\n",
      "Epoch 85/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 191.5676 - val_loss: 148.7837\n",
      "Epoch 86/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 330.0914 - val_loss: 152.2832\n",
      "Epoch 87/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 140.8268 - val_loss: 148.7157\n",
      "Epoch 88/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 370.4633 - val_loss: 141.9312\n",
      "Epoch 89/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 190.6721 - val_loss: 152.2017\n",
      "Epoch 90/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 436.4977 - val_loss: 146.3562\n",
      "Epoch 91/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 160.8979 - val_loss: 148.2707\n",
      "Epoch 92/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 410.1305 - val_loss: 156.3184\n",
      "Epoch 93/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 348.0300 - val_loss: 152.9578\n",
      "Epoch 94/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 270.9877 - val_loss: 150.5677\n",
      "Epoch 95/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 350.2752 - val_loss: 151.1863\n",
      "Epoch 96/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 152.1741 - val_loss: 152.7448\n",
      "Epoch 97/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 636.3034 - val_loss: 149.8913\n",
      "Epoch 98/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 266.4567 - val_loss: 162.7442\n",
      "Epoch 99/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 1171.4594 - val_loss: 149.5956\n",
      "Epoch 100/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 418.4959 - val_loss: 150.5654\n",
      "Epoch 101/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 286.0909 - val_loss: 151.6517\n",
      "Epoch 102/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 590.9648 - val_loss: 151.2000\n",
      "Epoch 103/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 719.4370 - val_loss: 152.6935\n",
      "Epoch 104/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 202.1355 - val_loss: 142.1330\n",
      "Epoch 105/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 274.6241 - val_loss: 146.9824\n",
      "Epoch 106/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 244.6219 - val_loss: 140.8565\n",
      "Epoch 107/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 3805.4995 - val_loss: 139.2932\n",
      "Epoch 108/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 226.6906 - val_loss: 154.9255\n",
      "Epoch 109/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 223.3909 - val_loss: 192.4412\n",
      "Epoch 110/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 591.1409 - val_loss: 181.1728\n",
      "Epoch 111/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 373.1058 - val_loss: 243.7906\n",
      "Epoch 112/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 4125.0537 - val_loss: 147.9362\n",
      "Epoch 113/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 243.8187 - val_loss: 170.7211\n",
      "Epoch 114/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1976.1846 - val_loss: 158.8420\n",
      "Epoch 115/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 260.0759 - val_loss: 150.0208\n",
      "Epoch 116/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 309.8762 - val_loss: 150.4876\n",
      "Epoch 117/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 996.6172 - val_loss: 142.3396\n",
      "Epoch 118/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 295.0995 - val_loss: 138.5632\n",
      "Epoch 119/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 452.7450 - val_loss: 136.9625\n",
      "Epoch 120/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 858.7927 - val_loss: 130.0678\n",
      "Epoch 121/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 174.7396 - val_loss: 129.1803\n",
      "Epoch 122/300\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 327.3734 - val_loss: 123.1654\n",
      "Epoch 123/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 172.2297 - val_loss: 129.5017\n",
      "Epoch 124/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 343.2035 - val_loss: 131.5429\n",
      "Epoch 125/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 333.9628 - val_loss: 132.5020\n",
      "Epoch 126/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 204.2219 - val_loss: 132.0560\n",
      "Epoch 127/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 296.1839 - val_loss: 127.8580\n",
      "Epoch 128/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 227.2686 - val_loss: 125.1585\n",
      "Epoch 129/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 269.8001 - val_loss: 132.5347\n",
      "Epoch 130/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 311.3633 - val_loss: 128.7860\n",
      "Epoch 131/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 311.0874 - val_loss: 130.1868\n",
      "Epoch 132/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 312.9599 - val_loss: 127.7668\n",
      "Epoch 133/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 296.5283 - val_loss: 125.5717\n",
      "Epoch 134/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 147.1725 - val_loss: 124.9253\n",
      "Epoch 135/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 259.9842 - val_loss: 123.9638\n",
      "Epoch 136/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 224.3957 - val_loss: 121.7448\n",
      "Epoch 137/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 244.8770 - val_loss: 125.1566\n",
      "Epoch 138/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 181.6669 - val_loss: 121.9628\n",
      "Epoch 139/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 205.3219 - val_loss: 122.3983\n",
      "Epoch 140/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 137.6839 - val_loss: 125.3387\n",
      "Epoch 141/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 196.4933 - val_loss: 122.3817\n",
      "Epoch 142/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 261.7397 - val_loss: 120.1855\n",
      "Epoch 143/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 196.3461 - val_loss: 119.4274\n",
      "Epoch 144/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 167.1619 - val_loss: 121.2583\n",
      "Epoch 145/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 331.8623 - val_loss: 121.1974\n",
      "Epoch 146/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 258.0096 - val_loss: 119.7217\n",
      "Epoch 147/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 169.7420 - val_loss: 122.1275\n",
      "Epoch 148/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 184.6606 - val_loss: 119.9011\n",
      "Epoch 149/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 207.8126 - val_loss: 121.4774\n",
      "Epoch 150/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 177.6854 - val_loss: 120.5200\n",
      "Epoch 151/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 158.0245 - val_loss: 122.0295\n",
      "Epoch 152/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 145.2621 - val_loss: 119.9973\n",
      "Epoch 153/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 128.6020 - val_loss: 120.9563\n",
      "Epoch 154/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 151.9457 - val_loss: 119.5050\n",
      "Epoch 155/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 149.8181 - val_loss: 121.2159\n",
      "Epoch 156/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 139.7115 - val_loss: 120.1159\n",
      "Epoch 157/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 149.9973 - val_loss: 122.1744\n",
      "Epoch 158/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 141.2274 - val_loss: 120.8717\n",
      "Epoch 159/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 141.3242 - val_loss: 121.3730\n",
      "Epoch 160/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 152.5319 - val_loss: 122.6432\n",
      "Epoch 161/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 192.0993 - val_loss: 123.9700\n",
      "Epoch 162/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 232.1740 - val_loss: 125.9991\n",
      "Epoch 163/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 179.9869 - val_loss: 125.8473\n",
      "Epoch 164/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 213.5271 - val_loss: 118.7627\n",
      "Epoch 165/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 142.0389 - val_loss: 123.7256\n",
      "Epoch 166/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 160.8355 - val_loss: 125.2702\n",
      "Epoch 167/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 198.5895 - val_loss: 127.3205\n",
      "Epoch 168/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 187.9330 - val_loss: 126.2537\n",
      "Epoch 169/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 473.2972 - val_loss: 121.5741\n",
      "Epoch 170/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 125.5454 - val_loss: 124.4872\n",
      "Epoch 171/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 251.3934 - val_loss: 120.0757\n",
      "Epoch 172/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 137.4275 - val_loss: 121.8649\n",
      "Epoch 173/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 172.2777 - val_loss: 123.9080\n",
      "Epoch 174/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 220.1506 - val_loss: 122.8604\n",
      "Epoch 175/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 180.3311 - val_loss: 121.1911\n",
      "Epoch 176/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 144.8212 - val_loss: 122.1780\n",
      "Epoch 177/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 276.9771 - val_loss: 123.9703\n",
      "Epoch 178/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 221.0852 - val_loss: 122.9473\n",
      "Epoch 179/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 163.9825 - val_loss: 123.5576\n",
      "Epoch 180/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 129.2384 - val_loss: 127.5451\n",
      "Epoch 181/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 150.3721 - val_loss: 123.8940\n",
      "Epoch 182/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 144.5197 - val_loss: 124.0599\n",
      "Epoch 183/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 150.4915 - val_loss: 123.5003\n",
      "Epoch 184/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 121.4933 - val_loss: 125.0993\n",
      "Epoch 185/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 148.7881 - val_loss: 123.2197\n",
      "Epoch 186/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 130.1251 - val_loss: 126.5607\n",
      "Epoch 187/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 156.1059 - val_loss: 121.4294\n",
      "Epoch 188/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 147.6840 - val_loss: 121.8505\n",
      "Epoch 189/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 118.2536 - val_loss: 124.8207\n",
      "Epoch 190/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 159.4770 - val_loss: 123.7285\n",
      "Epoch 191/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 142.4147 - val_loss: 124.1074\n",
      "Epoch 192/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 169.5908 - val_loss: 124.9248\n",
      "Epoch 193/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 153.8974 - val_loss: 123.0792\n",
      "Epoch 194/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 178.8062 - val_loss: 124.6493\n",
      "'########################################################Model6\n",
      "Epoch 1/300\n",
      "35/35 [==============================] - 2s 16ms/step - loss: 2424.1255 - val_loss: 412.9061\n",
      "Epoch 2/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 2538.0334 - val_loss: 386.5117\n",
      "Epoch 3/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 4637.1260 - val_loss: 338.1272\n",
      "Epoch 4/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 2485.8904 - val_loss: 677.2827\n",
      "Epoch 5/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 6231.6602 - val_loss: 383.8757\n",
      "Epoch 6/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 1205.6714 - val_loss: 396.0360\n",
      "Epoch 7/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 5799.5674 - val_loss: 646.5388\n",
      "Epoch 8/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 2935.4856 - val_loss: 625.3215\n",
      "Epoch 9/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 3336.4673 - val_loss: 1248.0276\n",
      "Epoch 10/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 3063.5542 - val_loss: 1331.9835\n",
      "Epoch 11/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 13326.3926 - val_loss: 521.7571\n",
      "Epoch 12/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 3951.9429 - val_loss: 4928.1743\n",
      "Epoch 13/300\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 408923.0938 - val_loss: 1004.2393\n",
      "Epoch 14/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 13657.8574 - val_loss: 580.1993\n",
      "Epoch 15/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 7172.5659 - val_loss: 228.3732\n",
      "Epoch 16/300\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 1095.8787 - val_loss: 273.9918\n",
      "Epoch 17/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 1615.2402 - val_loss: 353.5042\n",
      "Epoch 18/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1409.6063 - val_loss: 246.3565\n",
      "Epoch 19/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 1573.4645 - val_loss: 300.9067\n",
      "Epoch 20/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1553.7610 - val_loss: 206.0605\n",
      "Epoch 21/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 1740.1718 - val_loss: 419.2532\n",
      "Epoch 22/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 3535.5342 - val_loss: 322.8572\n",
      "Epoch 23/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 2522.4180 - val_loss: 214.1766\n",
      "Epoch 24/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1530.3099 - val_loss: 210.1696\n",
      "Epoch 25/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 922.5714 - val_loss: 192.4724\n",
      "Epoch 26/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 791.4890 - val_loss: 189.3844\n",
      "Epoch 27/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 821.9622 - val_loss: 184.7340\n",
      "Epoch 28/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 545.4616 - val_loss: 188.1015\n",
      "Epoch 29/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 496.5690 - val_loss: 192.8866\n",
      "Epoch 30/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 966.6330 - val_loss: 192.3765\n",
      "Epoch 31/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 608.0411 - val_loss: 207.2406\n",
      "Epoch 32/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 518.9022 - val_loss: 255.8699\n",
      "Epoch 33/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 2058.5833 - val_loss: 178.0269\n",
      "Epoch 34/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 228.7684 - val_loss: 191.9345\n",
      "Epoch 35/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 864.3703 - val_loss: 175.0221\n",
      "Epoch 36/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 738.6381 - val_loss: 177.9370\n",
      "Epoch 37/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 957.2447 - val_loss: 175.7994\n",
      "Epoch 38/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 536.2086 - val_loss: 182.4847\n",
      "Epoch 39/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 538.8896 - val_loss: 190.7643\n",
      "Epoch 40/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 816.0177 - val_loss: 184.4046\n",
      "Epoch 41/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 516.9655 - val_loss: 185.5783\n",
      "Epoch 42/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1681.3033 - val_loss: 178.7643\n",
      "Epoch 43/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 471.0346 - val_loss: 177.2022\n",
      "Epoch 44/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 674.1133 - val_loss: 174.1055\n",
      "Epoch 45/300\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 513.3955 - val_loss: 174.8824\n",
      "Epoch 46/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 432.0162 - val_loss: 173.5290\n",
      "Epoch 47/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 445.0735 - val_loss: 173.1676\n",
      "Epoch 48/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 572.3689 - val_loss: 169.8704\n",
      "Epoch 49/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 417.4282 - val_loss: 169.8048\n",
      "Epoch 50/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 482.6697 - val_loss: 171.4481\n",
      "Epoch 51/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 389.9573 - val_loss: 168.0232\n",
      "Epoch 52/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 891.7535 - val_loss: 165.7383\n",
      "Epoch 53/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 279.5729 - val_loss: 164.6710\n",
      "Epoch 54/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 645.8098 - val_loss: 163.4586\n",
      "Epoch 55/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 255.2373 - val_loss: 160.5762\n",
      "Epoch 56/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 547.2585 - val_loss: 165.5655\n",
      "Epoch 57/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 249.9911 - val_loss: 175.0970\n",
      "Epoch 58/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 848.7682 - val_loss: 166.1835\n",
      "Epoch 59/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 340.1255 - val_loss: 165.5270\n",
      "Epoch 60/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 334.9876 - val_loss: 168.2531\n",
      "Epoch 61/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 550.0687 - val_loss: 163.1572\n",
      "Epoch 62/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 333.9840 - val_loss: 162.7240\n",
      "Epoch 63/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 526.4484 - val_loss: 160.1210\n",
      "Epoch 64/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 276.3115 - val_loss: 161.8505\n",
      "Epoch 65/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 300.8983 - val_loss: 160.7774\n",
      "Epoch 66/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 400.0701 - val_loss: 158.3053\n",
      "Epoch 67/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 692.5259 - val_loss: 197.3845\n",
      "Epoch 68/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 620.2141 - val_loss: 192.9004\n",
      "Epoch 69/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 6577.0220 - val_loss: 651.2320\n",
      "Epoch 70/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 796.4852 - val_loss: 256.7104\n",
      "Epoch 71/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 13978.3779 - val_loss: 276.7457\n",
      "Epoch 72/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 622.3113 - val_loss: 459.1498\n",
      "Epoch 73/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 2838.8945 - val_loss: 202.8738\n",
      "Epoch 74/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 533.1380 - val_loss: 192.3754\n",
      "Epoch 75/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1146.8688 - val_loss: 228.7732\n",
      "Epoch 76/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 700.9094 - val_loss: 220.7088\n",
      "Epoch 77/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 650.9030 - val_loss: 244.5974\n",
      "Epoch 78/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 2478.6201 - val_loss: 224.3104\n",
      "Epoch 79/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1001.9359 - val_loss: 225.6777\n",
      "Epoch 80/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 915.4292 - val_loss: 312.1544\n",
      "Epoch 81/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 1651.5576 - val_loss: 999.0967\n",
      "Epoch 82/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 6763.3999 - val_loss: 226.5636\n",
      "Epoch 83/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 4173.9268 - val_loss: 271.3406\n",
      "Epoch 84/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 463.5897 - val_loss: 161.4992\n",
      "Epoch 85/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 625.8489 - val_loss: 176.1895\n",
      "Epoch 86/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 481.5002 - val_loss: 158.7213\n",
      "Epoch 87/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 650.3210 - val_loss: 371.3557\n",
      "Epoch 88/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 7610.3921 - val_loss: 185.9866\n",
      "Epoch 89/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 605.4453 - val_loss: 179.6845\n",
      "Epoch 90/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 398.6197 - val_loss: 168.2888\n",
      "Epoch 91/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 552.6200 - val_loss: 169.8889\n",
      "Epoch 92/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 537.5714 - val_loss: 278.7904\n",
      "Epoch 93/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 345.0643 - val_loss: 201.9900\n",
      "Epoch 94/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 2196.5042 - val_loss: 178.4749\n",
      "Epoch 95/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 659.8386 - val_loss: 191.1667\n",
      "Epoch 96/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 720.5129 - val_loss: 181.0334\n",
      "'########################################################Model7\n",
      "Epoch 1/300\n",
      "35/35 [==============================] - 2s 16ms/step - loss: 1639.9061 - val_loss: 443.0792\n",
      "Epoch 2/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 14828.0322 - val_loss: 430.6230\n",
      "Epoch 3/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 5049.3628 - val_loss: 348.6845\n",
      "Epoch 4/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 3495.6729 - val_loss: 303.0762\n",
      "Epoch 5/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 2508.6943 - val_loss: 357.4321\n",
      "Epoch 6/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 4192.9663 - val_loss: 361.2704\n",
      "Epoch 7/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 10027.2471 - val_loss: 273.3003\n",
      "Epoch 8/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 3148.5459 - val_loss: 246.3933\n",
      "Epoch 9/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 2362.0483 - val_loss: 231.6054\n",
      "Epoch 10/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 580.7283 - val_loss: 278.8712\n",
      "Epoch 11/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 2012.9877 - val_loss: 303.2202\n",
      "Epoch 12/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 4402.7129 - val_loss: 264.4724\n",
      "Epoch 13/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 3697.3892 - val_loss: 302.8576\n",
      "Epoch 14/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1755.4182 - val_loss: 234.3141\n",
      "Epoch 15/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1486.5930 - val_loss: 222.8648\n",
      "Epoch 16/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 3358.7959 - val_loss: 263.1837\n",
      "Epoch 17/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 2314.1670 - val_loss: 221.6396\n",
      "Epoch 18/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 618.4714 - val_loss: 239.7157\n",
      "Epoch 19/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 4536.4507 - val_loss: 232.8736\n",
      "Epoch 20/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 1194.5707 - val_loss: 308.1170\n",
      "Epoch 21/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3071.6643 - val_loss: 268.0365\n",
      "Epoch 22/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 723.1556 - val_loss: 255.5356\n",
      "Epoch 23/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 3423.0903 - val_loss: 199.9554\n",
      "Epoch 24/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 521.9442 - val_loss: 197.4066\n",
      "Epoch 25/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 699.4860 - val_loss: 224.7586\n",
      "Epoch 26/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 3483.0603 - val_loss: 192.9761\n",
      "Epoch 27/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 830.0637 - val_loss: 189.0588\n",
      "Epoch 28/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 559.9398 - val_loss: 181.5695\n",
      "Epoch 29/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 954.1553 - val_loss: 178.0076\n",
      "Epoch 30/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 661.7528 - val_loss: 180.3039\n",
      "Epoch 31/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 1025.3956 - val_loss: 161.9546\n",
      "Epoch 32/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 654.7500 - val_loss: 171.2028\n",
      "Epoch 33/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 296.3811 - val_loss: 177.3853\n",
      "Epoch 34/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 599.7729 - val_loss: 186.9934\n",
      "Epoch 35/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 1248.7817 - val_loss: 178.5741\n",
      "Epoch 36/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 220.0373 - val_loss: 173.2795\n",
      "Epoch 37/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 785.8496 - val_loss: 173.4410\n",
      "Epoch 38/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 539.5089 - val_loss: 172.7290\n",
      "Epoch 39/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 615.5956 - val_loss: 172.5979\n",
      "Epoch 40/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 560.4062 - val_loss: 170.6302\n",
      "Epoch 41/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 725.0486 - val_loss: 169.1399\n",
      "Epoch 42/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 596.6387 - val_loss: 167.4612\n",
      "Epoch 43/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 477.2125 - val_loss: 164.2309\n",
      "Epoch 44/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 400.1913 - val_loss: 157.0094\n",
      "Epoch 45/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 276.9697 - val_loss: 163.5407\n",
      "Epoch 46/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 726.1385 - val_loss: 162.8985\n",
      "Epoch 47/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 435.1377 - val_loss: 160.4028\n",
      "Epoch 48/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 452.1174 - val_loss: 155.5429\n",
      "Epoch 49/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 184.2356 - val_loss: 154.5216\n",
      "Epoch 50/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 616.7514 - val_loss: 155.4344\n",
      "Epoch 51/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 207.5905 - val_loss: 156.9934\n",
      "Epoch 52/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 507.5934 - val_loss: 165.1866\n",
      "Epoch 53/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 353.4308 - val_loss: 157.3852\n",
      "Epoch 54/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 823.4209 - val_loss: 150.8792\n",
      "Epoch 55/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 289.3986 - val_loss: 153.0712\n",
      "Epoch 56/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 457.4411 - val_loss: 152.5182\n",
      "Epoch 57/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 1041.6648 - val_loss: 151.3479\n",
      "Epoch 58/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 375.5847 - val_loss: 156.0765\n",
      "Epoch 59/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 267.1628 - val_loss: 159.3970\n",
      "Epoch 60/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 710.2797 - val_loss: 163.1927\n",
      "Epoch 61/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 279.3128 - val_loss: 163.7841\n",
      "Epoch 62/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 753.6537 - val_loss: 160.0930\n",
      "Epoch 63/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 297.3037 - val_loss: 157.7572\n",
      "Epoch 64/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 257.2914 - val_loss: 159.5334\n",
      "Epoch 65/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 492.1860 - val_loss: 150.8481\n",
      "Epoch 66/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 237.4816 - val_loss: 158.0482\n",
      "Epoch 67/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 426.9585 - val_loss: 154.7359\n",
      "Epoch 68/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 159.2045 - val_loss: 154.0056\n",
      "Epoch 69/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 387.7882 - val_loss: 151.9632\n",
      "Epoch 70/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 186.0951 - val_loss: 153.9581\n",
      "Epoch 71/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 370.0579 - val_loss: 151.7291\n",
      "Epoch 72/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 240.5652 - val_loss: 150.5616\n",
      "Epoch 73/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 292.3893 - val_loss: 148.6293\n",
      "Epoch 74/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 219.6022 - val_loss: 150.4591\n",
      "Epoch 75/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 212.3900 - val_loss: 148.3720\n",
      "Epoch 76/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 241.8707 - val_loss: 153.7644\n",
      "Epoch 77/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 257.1463 - val_loss: 151.3211\n",
      "Epoch 78/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 256.9544 - val_loss: 150.5914\n",
      "Epoch 79/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 273.0203 - val_loss: 150.8203\n",
      "Epoch 80/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 198.2435 - val_loss: 149.4452\n",
      "Epoch 81/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 345.2029 - val_loss: 151.6743\n",
      "Epoch 82/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 253.4779 - val_loss: 148.8538\n",
      "Epoch 83/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 452.1325 - val_loss: 150.0142\n",
      "Epoch 84/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 151.5376 - val_loss: 149.7150\n",
      "Epoch 85/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 399.5067 - val_loss: 157.3779\n",
      "Epoch 86/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 142.3475 - val_loss: 153.9173\n",
      "Epoch 87/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 732.3508 - val_loss: 144.5356\n",
      "Epoch 88/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 421.7618 - val_loss: 146.3405\n",
      "Epoch 89/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 523.9780 - val_loss: 148.4353\n",
      "Epoch 90/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 657.8025 - val_loss: 152.2659\n",
      "Epoch 91/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 426.4381 - val_loss: 168.8075\n",
      "Epoch 92/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1274.7950 - val_loss: 157.0343\n",
      "Epoch 93/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 1115.2990 - val_loss: 173.3102\n",
      "Epoch 94/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 343.3154 - val_loss: 154.7222\n",
      "Epoch 95/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 817.8184 - val_loss: 151.0732\n",
      "Epoch 96/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 326.1389 - val_loss: 146.9919\n",
      "Epoch 97/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 975.3101 - val_loss: 145.8668\n",
      "Epoch 98/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 185.6265 - val_loss: 150.2041\n",
      "Epoch 99/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 428.6371 - val_loss: 143.7991\n",
      "Epoch 100/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 1702.7036 - val_loss: 146.3584\n",
      "Epoch 101/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 343.6492 - val_loss: 139.4561\n",
      "Epoch 102/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 618.6782 - val_loss: 135.5109\n",
      "Epoch 103/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 431.4889 - val_loss: 130.3701\n",
      "Epoch 104/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 2053.6499 - val_loss: 138.2344\n",
      "Epoch 105/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 435.7574 - val_loss: 134.2995\n",
      "Epoch 106/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 326.3174 - val_loss: 131.1171\n",
      "Epoch 107/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 287.9103 - val_loss: 125.6080\n",
      "Epoch 108/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 832.2705 - val_loss: 130.9741\n",
      "Epoch 109/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 276.9516 - val_loss: 130.5694\n",
      "Epoch 110/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 320.2784 - val_loss: 133.9476\n",
      "Epoch 111/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 280.5471 - val_loss: 129.2834\n",
      "Epoch 112/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 254.6784 - val_loss: 126.3996\n",
      "Epoch 113/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 198.0895 - val_loss: 128.0750\n",
      "Epoch 114/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 307.1326 - val_loss: 128.2954\n",
      "Epoch 115/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 320.2672 - val_loss: 127.9507\n",
      "Epoch 116/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 228.4796 - val_loss: 128.3102\n",
      "Epoch 117/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 188.2380 - val_loss: 125.0623\n",
      "Epoch 118/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 232.8981 - val_loss: 124.9815\n",
      "Epoch 119/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 273.3337 - val_loss: 125.9530\n",
      "Epoch 120/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 190.0224 - val_loss: 126.5002\n",
      "Epoch 121/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 212.7814 - val_loss: 127.2378\n",
      "Epoch 122/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 153.2847 - val_loss: 127.9550\n",
      "Epoch 123/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 188.5214 - val_loss: 129.3493\n",
      "Epoch 124/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 198.9068 - val_loss: 128.8728\n",
      "Epoch 125/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 118.5302 - val_loss: 127.3343\n",
      "Epoch 126/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 292.4471 - val_loss: 126.9740\n",
      "Epoch 127/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 120.4554 - val_loss: 125.0917\n",
      "Epoch 128/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 207.0266 - val_loss: 126.5643\n",
      "Epoch 129/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 135.8286 - val_loss: 126.8737\n",
      "Epoch 130/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 202.9521 - val_loss: 129.3855\n",
      "Epoch 131/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 281.3393 - val_loss: 130.9373\n",
      "Epoch 132/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 164.7070 - val_loss: 130.2980\n",
      "Epoch 133/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 130.7172 - val_loss: 130.3066\n",
      "Epoch 134/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 165.6218 - val_loss: 129.9406\n",
      "Epoch 135/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 160.1370 - val_loss: 129.8658\n",
      "Epoch 136/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 166.4786 - val_loss: 128.9571\n",
      "Epoch 137/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 115.5414 - val_loss: 127.4626\n",
      "Epoch 138/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 153.1549 - val_loss: 128.6302\n",
      "Epoch 139/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 153.6087 - val_loss: 129.4512\n",
      "Epoch 140/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 179.9706 - val_loss: 129.3872\n",
      "Epoch 141/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 154.5314 - val_loss: 126.6020\n",
      "Epoch 142/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 144.0311 - val_loss: 125.7686\n",
      "Epoch 143/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 128.8655 - val_loss: 123.7096\n",
      "Epoch 144/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 139.0371 - val_loss: 123.7512\n",
      "Epoch 145/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 115.5260 - val_loss: 125.1650\n",
      "Epoch 146/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 148.3286 - val_loss: 124.0927\n",
      "Epoch 147/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 150.0875 - val_loss: 128.2138\n",
      "Epoch 148/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 112.9512 - val_loss: 127.5237\n",
      "Epoch 149/300\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 178.4130 - val_loss: 126.8198\n",
      "Epoch 150/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 123.2819 - val_loss: 126.0984\n",
      "Epoch 151/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 143.4428 - val_loss: 127.0860\n",
      "Epoch 152/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 141.2256 - val_loss: 128.8139\n",
      "Epoch 153/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 121.5551 - val_loss: 128.2317\n",
      "Epoch 154/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 109.2310 - val_loss: 129.2833\n",
      "Epoch 155/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 113.6741 - val_loss: 129.1366\n",
      "Epoch 156/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 121.7944 - val_loss: 129.2346\n",
      "Epoch 157/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 126.6021 - val_loss: 128.1786\n",
      "Epoch 158/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 119.7020 - val_loss: 128.6509\n",
      "Epoch 159/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 103.4581 - val_loss: 127.9620\n",
      "Epoch 160/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 132.5221 - val_loss: 128.2639\n",
      "Epoch 161/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 125.4171 - val_loss: 128.5801\n",
      "Epoch 162/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 133.1117 - val_loss: 127.3962\n",
      "Epoch 163/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 159.3513 - val_loss: 129.3994\n",
      "Epoch 164/300\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 132.8755 - val_loss: 131.1944\n",
      "Epoch 165/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 147.3429 - val_loss: 127.1959\n",
      "Epoch 166/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 141.0189 - val_loss: 127.1359\n",
      "Epoch 167/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 109.1888 - val_loss: 130.0057\n",
      "Epoch 168/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 205.4595 - val_loss: 129.5039\n",
      "Epoch 169/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 166.3052 - val_loss: 130.5440\n",
      "Epoch 170/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 150.2769 - val_loss: 128.4969\n",
      "Epoch 171/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 149.9187 - val_loss: 127.2698\n",
      "Epoch 172/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 203.6617 - val_loss: 124.9620\n",
      "Epoch 173/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 175.7729 - val_loss: 125.6211\n",
      "'########################################################Model8\n",
      "Epoch 1/300\n",
      "35/35 [==============================] - 2s 15ms/step - loss: 1244.4645 - val_loss: 481.9056\n",
      "Epoch 2/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 10504.1797 - val_loss: 299.9846\n",
      "Epoch 3/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 3976.3569 - val_loss: 343.8418\n",
      "Epoch 4/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 3720.3320 - val_loss: 354.4857\n",
      "Epoch 5/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 2885.4807 - val_loss: 351.7032\n",
      "Epoch 6/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 4219.8755 - val_loss: 338.1200\n",
      "Epoch 7/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 3824.5769 - val_loss: 626.3061\n",
      "Epoch 8/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 2800.7146 - val_loss: 405.6412\n",
      "Epoch 9/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 10463.9453 - val_loss: 279.8892\n",
      "Epoch 10/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 2821.3638 - val_loss: 298.4545\n",
      "Epoch 11/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 11142.6514 - val_loss: 282.0949\n",
      "Epoch 12/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 905.9866 - val_loss: 246.2330\n",
      "Epoch 13/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 2047.5497 - val_loss: 270.7531\n",
      "Epoch 14/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 2032.8555 - val_loss: 232.8224\n",
      "Epoch 15/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 2636.6702 - val_loss: 214.6966\n",
      "Epoch 16/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1663.7292 - val_loss: 212.7345\n",
      "Epoch 17/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 1225.0612 - val_loss: 210.9841\n",
      "Epoch 18/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1805.7616 - val_loss: 272.1531\n",
      "Epoch 19/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 1572.1050 - val_loss: 237.5331\n",
      "Epoch 20/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 12308.9590 - val_loss: 339.9612\n",
      "Epoch 21/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1249.8690 - val_loss: 220.9954\n",
      "Epoch 22/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 2125.0269 - val_loss: 205.4770\n",
      "Epoch 23/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 396.3392 - val_loss: 200.1968\n",
      "Epoch 24/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1597.2410 - val_loss: 192.8484\n",
      "Epoch 25/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 517.5396 - val_loss: 184.1897\n",
      "Epoch 26/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1117.8959 - val_loss: 186.6842\n",
      "Epoch 27/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 609.2103 - val_loss: 187.1098\n",
      "Epoch 28/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1054.6215 - val_loss: 183.9716\n",
      "Epoch 29/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 209.6436 - val_loss: 182.0603\n",
      "Epoch 30/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1189.1699 - val_loss: 177.2594\n",
      "Epoch 31/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 444.1990 - val_loss: 182.3268\n",
      "Epoch 32/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 857.4613 - val_loss: 179.6207\n",
      "Epoch 33/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 358.6004 - val_loss: 179.3471\n",
      "Epoch 34/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1080.5251 - val_loss: 163.0950\n",
      "Epoch 35/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 419.3136 - val_loss: 166.7384\n",
      "Epoch 36/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 945.9128 - val_loss: 162.7933\n",
      "Epoch 37/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 231.1426 - val_loss: 153.9579\n",
      "Epoch 38/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 761.9800 - val_loss: 151.0319\n",
      "Epoch 39/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 334.7735 - val_loss: 160.3860\n",
      "Epoch 40/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 690.3434 - val_loss: 153.5676\n",
      "Epoch 41/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 299.7716 - val_loss: 158.4856\n",
      "Epoch 42/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 701.7219 - val_loss: 154.4742\n",
      "Epoch 43/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 273.7529 - val_loss: 156.5277\n",
      "Epoch 44/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 603.2761 - val_loss: 151.9135\n",
      "Epoch 45/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 224.9458 - val_loss: 155.5367\n",
      "Epoch 46/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 466.6819 - val_loss: 151.0372\n",
      "Epoch 47/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 163.2618 - val_loss: 148.9118\n",
      "Epoch 48/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 428.8828 - val_loss: 151.7384\n",
      "Epoch 49/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 263.5814 - val_loss: 150.9911\n",
      "Epoch 50/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 615.2795 - val_loss: 152.9354\n",
      "Epoch 51/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 252.0133 - val_loss: 149.9015\n",
      "Epoch 52/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 431.2060 - val_loss: 151.8824\n",
      "Epoch 53/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 262.8862 - val_loss: 152.2691\n",
      "Epoch 54/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 376.8870 - val_loss: 158.6493\n",
      "Epoch 55/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 210.1280 - val_loss: 149.3940\n",
      "Epoch 56/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 187.6141 - val_loss: 167.7640\n",
      "Epoch 57/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 611.0432 - val_loss: 157.4534\n",
      "Epoch 58/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 472.2207 - val_loss: 157.5515\n",
      "Epoch 59/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 529.2274 - val_loss: 154.8655\n",
      "Epoch 60/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 310.5880 - val_loss: 154.4245\n",
      "Epoch 61/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 497.6607 - val_loss: 150.8540\n",
      "Epoch 62/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 252.4984 - val_loss: 154.7859\n",
      "Epoch 63/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 293.8571 - val_loss: 152.2896\n",
      "Epoch 64/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 149.7075 - val_loss: 155.1294\n",
      "Epoch 65/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 484.1584 - val_loss: 156.5343\n",
      "Epoch 66/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 150.4454 - val_loss: 150.7777\n",
      "Epoch 67/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 371.4515 - val_loss: 146.5582\n",
      "Epoch 68/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 288.0538 - val_loss: 147.0711\n",
      "Epoch 69/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 279.7026 - val_loss: 149.3599\n",
      "Epoch 70/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 200.6035 - val_loss: 148.1034\n",
      "Epoch 71/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 361.6033 - val_loss: 149.7268\n",
      "Epoch 72/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 218.8674 - val_loss: 141.9835\n",
      "Epoch 73/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 321.6165 - val_loss: 142.1050\n",
      "Epoch 74/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 245.5413 - val_loss: 141.9396\n",
      "Epoch 75/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 365.6579 - val_loss: 143.1458\n",
      "Epoch 76/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 282.4621 - val_loss: 144.1407\n",
      "Epoch 77/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 151.5837 - val_loss: 146.4816\n",
      "Epoch 78/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 437.3938 - val_loss: 142.5696\n",
      "Epoch 79/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 292.4344 - val_loss: 151.6676\n",
      "Epoch 80/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 453.2052 - val_loss: 137.4716\n",
      "Epoch 81/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 318.0414 - val_loss: 141.1537\n",
      "Epoch 82/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 459.3752 - val_loss: 144.1689\n",
      "Epoch 83/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 248.2924 - val_loss: 142.9450\n",
      "Epoch 84/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 592.7917 - val_loss: 138.6992\n",
      "Epoch 85/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 267.7129 - val_loss: 138.5880\n",
      "Epoch 86/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 262.2085 - val_loss: 132.6341\n",
      "Epoch 87/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 410.1326 - val_loss: 145.8860\n",
      "Epoch 88/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 353.9508 - val_loss: 141.7160\n",
      "Epoch 89/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 389.8512 - val_loss: 144.0735\n",
      "Epoch 90/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 256.5143 - val_loss: 137.4854\n",
      "Epoch 91/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 302.5585 - val_loss: 137.6504\n",
      "Epoch 92/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 421.9339 - val_loss: 138.1046\n",
      "Epoch 93/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 237.0525 - val_loss: 135.9784\n",
      "Epoch 94/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 306.9761 - val_loss: 132.9152\n",
      "Epoch 95/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 194.8635 - val_loss: 132.5671\n",
      "Epoch 96/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 291.0779 - val_loss: 133.8503\n",
      "Epoch 97/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 248.4361 - val_loss: 136.9285\n",
      "Epoch 98/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 329.7013 - val_loss: 132.2113\n",
      "Epoch 99/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 223.2671 - val_loss: 139.2262\n",
      "Epoch 100/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 241.2319 - val_loss: 133.1147\n",
      "Epoch 101/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 204.1037 - val_loss: 137.0181\n",
      "Epoch 102/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 288.9737 - val_loss: 132.7134\n",
      "Epoch 103/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 213.8256 - val_loss: 131.6065\n",
      "Epoch 104/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 190.6225 - val_loss: 131.4653\n",
      "Epoch 105/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 418.7647 - val_loss: 136.5273\n",
      "Epoch 106/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 220.7137 - val_loss: 131.8180\n",
      "Epoch 107/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 366.6892 - val_loss: 140.1209\n",
      "Epoch 108/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 327.9464 - val_loss: 139.2426\n",
      "Epoch 109/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1840.8757 - val_loss: 143.7361\n",
      "Epoch 110/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 282.6974 - val_loss: 135.8581\n",
      "Epoch 111/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 183.6396 - val_loss: 141.8318\n",
      "Epoch 112/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 533.1490 - val_loss: 129.0791\n",
      "Epoch 113/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 206.1013 - val_loss: 153.9664\n",
      "Epoch 114/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 523.1410 - val_loss: 152.2729\n",
      "Epoch 115/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 849.6418 - val_loss: 162.3708\n",
      "Epoch 116/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 232.5599 - val_loss: 154.5604\n",
      "Epoch 117/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 520.1060 - val_loss: 161.1178\n",
      "Epoch 118/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 10156.8369 - val_loss: 207.5004\n",
      "Epoch 119/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 1353.7001 - val_loss: 164.1990\n",
      "Epoch 120/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 2673.4414 - val_loss: 258.6510\n",
      "Epoch 121/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 955.1605 - val_loss: 166.4494\n",
      "Epoch 122/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 384.8596 - val_loss: 153.0660\n",
      "Epoch 123/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 560.3292 - val_loss: 154.6770\n",
      "Epoch 124/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 11077.3223 - val_loss: 178.7459\n",
      "Epoch 125/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 910.8307 - val_loss: 183.9530\n",
      "Epoch 126/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 651.3872 - val_loss: 325.5992\n",
      "Epoch 127/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 6289.8125 - val_loss: 195.0676\n",
      "Epoch 128/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 1324.2623 - val_loss: 169.1758\n",
      "Epoch 129/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 565.7661 - val_loss: 246.6939\n",
      "Epoch 130/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 658.5569 - val_loss: 133.6027\n",
      "Epoch 131/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 365.4683 - val_loss: 138.7271\n",
      "Epoch 132/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 490.9906 - val_loss: 158.1444\n",
      "Epoch 133/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 452.9648 - val_loss: 156.0758\n",
      "Epoch 134/300\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 14742.1338 - val_loss: 137.7166\n",
      "Epoch 135/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 675.1885 - val_loss: 129.2762\n",
      "Epoch 136/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 460.5208 - val_loss: 126.7257\n",
      "Epoch 137/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 311.9052 - val_loss: 132.6034\n",
      "Epoch 138/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 185.8734 - val_loss: 141.6388\n",
      "Epoch 139/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 397.6571 - val_loss: 123.8216\n",
      "Epoch 140/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 203.4181 - val_loss: 124.2079\n",
      "Epoch 141/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 301.4790 - val_loss: 123.2833\n",
      "Epoch 142/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 141.8945 - val_loss: 124.7325\n",
      "Epoch 143/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 396.1965 - val_loss: 119.9863\n",
      "Epoch 144/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 225.3598 - val_loss: 116.9004\n",
      "Epoch 145/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 161.2614 - val_loss: 117.7428\n",
      "Epoch 146/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 315.5229 - val_loss: 119.8547\n",
      "Epoch 147/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 139.7099 - val_loss: 119.4144\n",
      "Epoch 148/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 209.1777 - val_loss: 121.7926\n",
      "Epoch 149/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 139.4982 - val_loss: 119.5912\n",
      "Epoch 150/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 238.4572 - val_loss: 118.9515\n",
      "Epoch 151/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 148.4857 - val_loss: 120.7102\n",
      "Epoch 152/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 196.5775 - val_loss: 125.6806\n",
      "Epoch 153/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 171.8205 - val_loss: 119.5964\n",
      "Epoch 154/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 199.1591 - val_loss: 119.4088\n",
      "Epoch 155/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 183.6242 - val_loss: 119.0866\n",
      "Epoch 156/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 161.8427 - val_loss: 119.5836\n",
      "Epoch 157/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 181.3110 - val_loss: 117.6204\n",
      "Epoch 158/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 152.7802 - val_loss: 120.5182\n",
      "Epoch 159/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 176.5489 - val_loss: 115.7452\n",
      "Epoch 160/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 154.8463 - val_loss: 118.0008\n",
      "Epoch 161/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 141.5116 - val_loss: 116.0920\n",
      "Epoch 162/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 144.5029 - val_loss: 118.6315\n",
      "Epoch 163/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 172.3016 - val_loss: 119.2259\n",
      "Epoch 164/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 142.7780 - val_loss: 118.0086\n",
      "Epoch 165/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 162.9655 - val_loss: 117.4299\n",
      "Epoch 166/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 141.7636 - val_loss: 116.7137\n",
      "Epoch 167/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 160.6335 - val_loss: 118.2179\n",
      "Epoch 168/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 137.3016 - val_loss: 118.6440\n",
      "Epoch 169/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 166.6398 - val_loss: 116.1810\n",
      "Epoch 170/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 122.9288 - val_loss: 116.7654\n",
      "Epoch 171/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 182.8708 - val_loss: 116.6645\n",
      "Epoch 172/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 138.9796 - val_loss: 117.3209\n",
      "Epoch 173/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 170.8858 - val_loss: 116.0488\n",
      "Epoch 174/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 129.8885 - val_loss: 119.0699\n",
      "Epoch 175/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 162.6405 - val_loss: 115.8554\n",
      "Epoch 176/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 115.4038 - val_loss: 118.4396\n",
      "Epoch 177/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 169.5515 - val_loss: 116.0839\n",
      "Epoch 178/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 110.6572 - val_loss: 117.1733\n",
      "Epoch 179/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 187.1441 - val_loss: 117.5121\n",
      "Epoch 180/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 111.4332 - val_loss: 115.7818\n",
      "Epoch 181/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 155.0505 - val_loss: 117.1294\n",
      "Epoch 182/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 122.5125 - val_loss: 117.4870\n",
      "Epoch 183/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 186.4455 - val_loss: 117.5042\n",
      "Epoch 184/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 119.0848 - val_loss: 118.3590\n",
      "Epoch 185/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 202.6096 - val_loss: 119.7708\n",
      "Epoch 186/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 153.2371 - val_loss: 116.3651\n",
      "Epoch 187/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 219.7346 - val_loss: 125.0244\n",
      "Epoch 188/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 118.3139 - val_loss: 119.7966\n",
      "Epoch 189/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 152.9138 - val_loss: 131.7610\n",
      "'########################################################Model9\n",
      "Epoch 1/300\n",
      "35/35 [==============================] - 1s 12ms/step - loss: 142.9043 - val_loss: 138.2565\n",
      "Epoch 2/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 135.7465 - val_loss: 132.3795\n",
      "Epoch 3/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 130.8034 - val_loss: 125.8227\n",
      "Epoch 4/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 127.2883 - val_loss: 123.2729\n",
      "Epoch 5/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 123.1848 - val_loss: 122.0902\n",
      "Epoch 6/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 121.9795 - val_loss: 121.0814\n",
      "Epoch 7/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 119.5379 - val_loss: 122.7622\n",
      "Epoch 8/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 115.8936 - val_loss: 119.1835\n",
      "Epoch 9/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 114.9710 - val_loss: 120.9681\n",
      "Epoch 10/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 115.6325 - val_loss: 120.1824\n",
      "Epoch 11/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 114.2573 - val_loss: 119.8514\n",
      "Epoch 12/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 112.9990 - val_loss: 116.6367\n",
      "Epoch 13/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 111.8227 - val_loss: 118.1053\n",
      "Epoch 14/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 112.6453 - val_loss: 118.3877\n",
      "Epoch 15/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 110.0646 - val_loss: 117.2758\n",
      "Epoch 16/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 108.0150 - val_loss: 116.7948\n",
      "Epoch 17/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 107.4052 - val_loss: 114.6411\n",
      "Epoch 18/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 104.7826 - val_loss: 116.7825\n",
      "Epoch 19/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 103.8211 - val_loss: 114.1877\n",
      "Epoch 20/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 101.4930 - val_loss: 116.8476\n",
      "Epoch 21/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 100.3903 - val_loss: 115.7987\n",
      "Epoch 22/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 105.2141 - val_loss: 119.3451\n",
      "Epoch 23/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 102.8389 - val_loss: 119.2996\n",
      "Epoch 24/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 100.1141 - val_loss: 117.5794\n",
      "Epoch 25/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 98.5832 - val_loss: 119.5555\n",
      "Epoch 26/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 96.6626 - val_loss: 117.8116\n",
      "Epoch 27/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 94.1845 - val_loss: 118.8135\n",
      "Epoch 28/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 93.4022 - val_loss: 119.3052\n",
      "Epoch 29/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 94.1766 - val_loss: 118.7885\n",
      "Epoch 30/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 91.8635 - val_loss: 119.7498\n",
      "Epoch 31/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 96.4712 - val_loss: 120.1371\n",
      "Epoch 32/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 96.0046 - val_loss: 119.2370\n",
      "Epoch 33/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 92.9737 - val_loss: 117.2442\n",
      "Epoch 34/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 90.7386 - val_loss: 118.0260\n",
      "Epoch 35/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 88.2001 - val_loss: 119.5022\n",
      "Epoch 36/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 87.8782 - val_loss: 119.8713\n",
      "Epoch 37/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 87.3375 - val_loss: 118.3338\n",
      "Epoch 38/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 85.0261 - val_loss: 119.8225\n",
      "Epoch 39/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 106.9423 - val_loss: 121.4930\n",
      "Epoch 40/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 102.5357 - val_loss: 121.4094\n",
      "Epoch 41/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 98.8855 - val_loss: 122.6484\n",
      "Epoch 42/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 94.8233 - val_loss: 122.3596\n",
      "Epoch 43/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 92.6850 - val_loss: 119.8973\n",
      "Epoch 44/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 90.3062 - val_loss: 121.5854\n",
      "Epoch 45/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 87.8531 - val_loss: 121.7505\n",
      "Epoch 46/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 87.0723 - val_loss: 120.9000\n",
      "Epoch 47/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 86.3758 - val_loss: 119.5659\n",
      "Epoch 48/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 86.0661 - val_loss: 119.3315\n",
      "Epoch 49/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 87.3841 - val_loss: 119.6683\n",
      "'########################################################Model0\n",
      "Epoch 1/300\n",
      "35/35 [==============================] - 2s 14ms/step - loss: 139.8302 - val_loss: 134.2962\n",
      "Epoch 2/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 132.9222 - val_loss: 129.1829\n",
      "Epoch 3/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 132.2015 - val_loss: 125.8690\n",
      "Epoch 4/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 128.2228 - val_loss: 129.7009\n",
      "Epoch 5/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 127.6476 - val_loss: 121.5330\n",
      "Epoch 6/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 124.5705 - val_loss: 120.8073\n",
      "Epoch 7/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 122.5806 - val_loss: 120.6442\n",
      "Epoch 8/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 119.1676 - val_loss: 118.7174\n",
      "Epoch 9/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 116.9293 - val_loss: 118.2740\n",
      "Epoch 10/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 114.3396 - val_loss: 119.5502\n",
      "Epoch 11/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 114.3124 - val_loss: 119.4537\n",
      "Epoch 12/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 113.2269 - val_loss: 118.8902\n",
      "Epoch 13/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 112.1733 - val_loss: 117.5428\n",
      "Epoch 14/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 109.3103 - val_loss: 120.0075\n",
      "Epoch 15/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 106.4875 - val_loss: 118.6372\n",
      "Epoch 16/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 104.6382 - val_loss: 118.7129\n",
      "Epoch 17/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 104.5192 - val_loss: 118.1719\n",
      "Epoch 18/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 102.3006 - val_loss: 118.1501\n",
      "Epoch 19/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 101.8042 - val_loss: 117.9347\n",
      "Epoch 20/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 101.4397 - val_loss: 117.9923\n",
      "Epoch 21/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 99.5965 - val_loss: 117.2935\n",
      "Epoch 22/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 99.4275 - val_loss: 117.5905\n",
      "Epoch 23/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 98.0816 - val_loss: 116.5295\n",
      "Epoch 24/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 96.3223 - val_loss: 116.3995\n",
      "Epoch 25/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 95.9108 - val_loss: 116.0660\n",
      "Epoch 26/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 94.2834 - val_loss: 116.1053\n",
      "Epoch 27/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 97.6853 - val_loss: 118.8852\n",
      "Epoch 28/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 97.3462 - val_loss: 117.2259\n",
      "Epoch 29/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 95.8117 - val_loss: 118.3340\n",
      "Epoch 30/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 97.4478 - val_loss: 116.9801\n",
      "Epoch 31/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 95.6811 - val_loss: 118.4785\n",
      "Epoch 32/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 92.3312 - val_loss: 118.1713\n",
      "Epoch 33/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 90.3965 - val_loss: 119.7017\n",
      "Epoch 34/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 89.7081 - val_loss: 118.0952\n",
      "Epoch 35/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 89.0983 - val_loss: 120.2576\n",
      "Epoch 36/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 88.4929 - val_loss: 118.3524\n",
      "Epoch 37/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 88.7696 - val_loss: 119.8157\n",
      "Epoch 38/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 88.7983 - val_loss: 119.3921\n",
      "Epoch 39/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 87.4095 - val_loss: 118.9125\n",
      "Epoch 40/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 87.4291 - val_loss: 119.6441\n",
      "Epoch 41/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 86.4701 - val_loss: 117.6109\n",
      "Epoch 42/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 84.3375 - val_loss: 119.2796\n",
      "Epoch 43/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 84.0965 - val_loss: 118.2751\n",
      "Epoch 44/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 83.2333 - val_loss: 119.0677\n",
      "Epoch 45/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 82.7070 - val_loss: 118.0317\n",
      "Epoch 46/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 84.2924 - val_loss: 117.9944\n",
      "Epoch 47/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 83.8714 - val_loss: 117.8644\n",
      "Epoch 48/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 82.2803 - val_loss: 118.7665\n",
      "Epoch 49/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 81.6048 - val_loss: 118.0087\n",
      "Epoch 50/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 85.5967 - val_loss: 119.2520\n",
      "Epoch 51/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 86.6817 - val_loss: 118.3915\n",
      "Epoch 52/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 83.8283 - val_loss: 119.9104\n",
      "Epoch 53/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 83.6114 - val_loss: 119.7277\n",
      "Epoch 54/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 82.0106 - val_loss: 118.3779\n",
      "Epoch 55/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 81.9670 - val_loss: 118.7878\n",
      "'########################################################Model1\n",
      "Epoch 1/300\n",
      "35/35 [==============================] - 2s 14ms/step - loss: 147.5113 - val_loss: 143.9258\n",
      "Epoch 2/300\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 142.1961 - val_loss: 132.1145\n",
      "Epoch 3/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 134.9119 - val_loss: 131.3620\n",
      "Epoch 4/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 130.5494 - val_loss: 124.6683\n",
      "Epoch 5/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 124.0133 - val_loss: 119.2953\n",
      "Epoch 6/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 119.7824 - val_loss: 118.4701\n",
      "Epoch 7/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 118.3676 - val_loss: 118.9523\n",
      "Epoch 8/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 116.7821 - val_loss: 118.8744\n",
      "Epoch 9/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 114.0827 - val_loss: 116.0718\n",
      "Epoch 10/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 113.0194 - val_loss: 123.7148\n",
      "Epoch 11/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 115.0891 - val_loss: 118.2335\n",
      "Epoch 12/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 110.9998 - val_loss: 117.2899\n",
      "Epoch 13/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 110.0950 - val_loss: 114.6056\n",
      "Epoch 14/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 108.3213 - val_loss: 115.6184\n",
      "Epoch 15/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 106.7930 - val_loss: 115.0995\n",
      "Epoch 16/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 104.5678 - val_loss: 115.3542\n",
      "Epoch 17/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 103.1295 - val_loss: 117.1947\n",
      "Epoch 18/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 103.5949 - val_loss: 114.0353\n",
      "Epoch 19/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 102.4512 - val_loss: 114.4390\n",
      "Epoch 20/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 101.2794 - val_loss: 115.9456\n",
      "Epoch 21/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 99.3709 - val_loss: 115.0484\n",
      "Epoch 22/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 99.8715 - val_loss: 115.6626\n",
      "Epoch 23/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 98.5256 - val_loss: 117.2576\n",
      "Epoch 24/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 98.0405 - val_loss: 116.7252\n",
      "Epoch 25/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 97.6043 - val_loss: 115.6224\n",
      "Epoch 26/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 95.6123 - val_loss: 115.1904\n",
      "Epoch 27/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 93.6599 - val_loss: 114.1182\n",
      "Epoch 28/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 94.9621 - val_loss: 115.1982\n",
      "Epoch 29/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 95.7071 - val_loss: 116.6109\n",
      "Epoch 30/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 91.9767 - val_loss: 116.6380\n",
      "Epoch 31/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 91.4453 - val_loss: 116.2990\n",
      "Epoch 32/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 90.4702 - val_loss: 115.9807\n",
      "Epoch 33/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 91.7565 - val_loss: 118.0064\n",
      "Epoch 34/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 91.3771 - val_loss: 115.7485\n",
      "Epoch 35/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 89.1658 - val_loss: 116.7462\n",
      "Epoch 36/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 88.0991 - val_loss: 115.8542\n",
      "Epoch 37/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 87.5433 - val_loss: 114.6650\n",
      "Epoch 38/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 87.8445 - val_loss: 117.3160\n",
      "Epoch 39/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 86.8350 - val_loss: 116.8500\n",
      "Epoch 40/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 87.0711 - val_loss: 117.2143\n",
      "Epoch 41/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 86.7426 - val_loss: 117.0941\n",
      "Epoch 42/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 85.3166 - val_loss: 116.9339\n",
      "Epoch 43/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 84.4411 - val_loss: 116.4072\n",
      "Epoch 44/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 83.2912 - val_loss: 116.6595\n",
      "Epoch 45/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 82.5861 - val_loss: 116.6636\n",
      "Epoch 46/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 82.6513 - val_loss: 116.7855\n",
      "Epoch 47/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 86.2423 - val_loss: 115.5486\n",
      "Epoch 48/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 84.1556 - val_loss: 117.0186\n",
      "'########################################################Model2\n",
      "Epoch 1/300\n",
      "35/35 [==============================] - 2s 15ms/step - loss: 139.3465 - val_loss: 130.2144\n",
      "Epoch 2/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 132.9164 - val_loss: 125.9310\n",
      "Epoch 3/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 128.1241 - val_loss: 124.8933\n",
      "Epoch 4/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 126.7605 - val_loss: 123.1897\n",
      "Epoch 5/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 122.4811 - val_loss: 119.2696\n",
      "Epoch 6/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 119.4996 - val_loss: 118.7539\n",
      "Epoch 7/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 117.4276 - val_loss: 118.9523\n",
      "Epoch 8/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 118.7144 - val_loss: 115.8310\n",
      "Epoch 9/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 113.7890 - val_loss: 115.4049\n",
      "Epoch 10/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 111.2777 - val_loss: 114.9810\n",
      "Epoch 11/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 113.9007 - val_loss: 116.7781\n",
      "Epoch 12/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 112.1982 - val_loss: 115.2427\n",
      "Epoch 13/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 109.9232 - val_loss: 115.7710\n",
      "Epoch 14/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 108.5548 - val_loss: 114.6266\n",
      "Epoch 15/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 107.4021 - val_loss: 115.0342\n",
      "Epoch 16/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 104.9608 - val_loss: 114.8752\n",
      "Epoch 17/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 103.6286 - val_loss: 115.2086\n",
      "Epoch 18/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 112.4454 - val_loss: 118.8847\n",
      "Epoch 19/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 112.6560 - val_loss: 120.6016\n",
      "Epoch 20/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 110.3516 - val_loss: 118.4337\n",
      "Epoch 21/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 107.9499 - val_loss: 121.3451\n",
      "Epoch 22/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 106.1413 - val_loss: 118.1488\n",
      "Epoch 23/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 104.5312 - val_loss: 119.0696\n",
      "Epoch 24/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 103.8034 - val_loss: 116.9241\n",
      "Epoch 25/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 102.3150 - val_loss: 119.1625\n",
      "Epoch 26/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 100.6913 - val_loss: 117.5542\n",
      "Epoch 27/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 99.1227 - val_loss: 117.4008\n",
      "Epoch 28/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 97.5221 - val_loss: 117.2846\n",
      "Epoch 29/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 96.3054 - val_loss: 116.0392\n",
      "Epoch 30/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 95.3276 - val_loss: 117.5042\n",
      "Epoch 31/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 94.0712 - val_loss: 117.8676\n",
      "Epoch 32/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 93.3812 - val_loss: 117.1830\n",
      "Epoch 33/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 92.9647 - val_loss: 116.8704\n",
      "Epoch 34/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 93.5612 - val_loss: 116.6564\n",
      "Epoch 35/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 92.6450 - val_loss: 116.5672\n",
      "Epoch 36/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 90.5283 - val_loss: 116.4480\n",
      "Epoch 37/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 90.4990 - val_loss: 117.5299\n",
      "Epoch 38/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 89.2073 - val_loss: 116.2080\n",
      "Epoch 39/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 89.3967 - val_loss: 116.0390\n",
      "Epoch 40/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 90.2163 - val_loss: 116.8404\n",
      "Epoch 41/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 88.7924 - val_loss: 115.9329\n",
      "Epoch 42/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 90.5382 - val_loss: 116.8577\n",
      "Epoch 43/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 88.9422 - val_loss: 118.4218\n",
      "Epoch 44/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 88.1896 - val_loss: 118.6784\n",
      "'########################################################Model3\n",
      "Epoch 1/300\n",
      "35/35 [==============================] - 2s 16ms/step - loss: 142.9980 - val_loss: 139.6195\n",
      "Epoch 2/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 133.8075 - val_loss: 128.5083\n",
      "Epoch 3/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 129.6406 - val_loss: 126.6691\n",
      "Epoch 4/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 128.4956 - val_loss: 126.3789\n",
      "Epoch 5/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 126.0296 - val_loss: 122.7884\n",
      "Epoch 6/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 122.8820 - val_loss: 118.7908\n",
      "Epoch 7/300\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 119.3602 - val_loss: 120.8155\n",
      "Epoch 8/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 117.0111 - val_loss: 116.8138\n",
      "Epoch 9/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 114.3351 - val_loss: 115.8522\n",
      "Epoch 10/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 112.3992 - val_loss: 114.4304\n",
      "Epoch 11/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 110.7964 - val_loss: 115.3759\n",
      "Epoch 12/300\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 110.1817 - val_loss: 117.7235\n",
      "Epoch 13/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 110.3909 - val_loss: 115.6749\n",
      "Epoch 14/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 108.5303 - val_loss: 113.8370\n",
      "Epoch 15/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 105.7069 - val_loss: 114.0448\n",
      "Epoch 16/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 104.0949 - val_loss: 113.5517\n",
      "Epoch 17/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 101.2584 - val_loss: 115.5450\n",
      "Epoch 18/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 101.9148 - val_loss: 114.0159\n",
      "Epoch 19/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 101.7708 - val_loss: 117.4940\n",
      "Epoch 20/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 103.2717 - val_loss: 114.0323\n",
      "Epoch 21/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 100.9349 - val_loss: 113.4532\n",
      "Epoch 22/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 102.4956 - val_loss: 114.6415\n",
      "Epoch 23/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 100.6730 - val_loss: 115.0611\n",
      "Epoch 24/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 97.1477 - val_loss: 112.9673\n",
      "Epoch 25/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 96.9954 - val_loss: 112.2816\n",
      "Epoch 26/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 99.6213 - val_loss: 113.8445\n",
      "Epoch 27/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 96.4423 - val_loss: 115.1880\n",
      "Epoch 28/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 94.4128 - val_loss: 114.1912\n",
      "Epoch 29/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 93.2254 - val_loss: 114.3009\n",
      "Epoch 30/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 92.8889 - val_loss: 114.3860\n",
      "Epoch 31/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 91.3505 - val_loss: 114.1265\n",
      "Epoch 32/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 90.9252 - val_loss: 114.5943\n",
      "Epoch 33/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 90.1116 - val_loss: 115.5276\n",
      "Epoch 34/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 88.5712 - val_loss: 113.5423\n",
      "Epoch 35/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 88.2142 - val_loss: 115.5632\n",
      "Epoch 36/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 88.0215 - val_loss: 115.7123\n",
      "Epoch 37/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 87.7184 - val_loss: 115.0847\n",
      "Epoch 38/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 86.0683 - val_loss: 114.4997\n",
      "Epoch 39/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 86.7413 - val_loss: 112.7108\n",
      "Epoch 40/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 89.5801 - val_loss: 114.3772\n",
      "Epoch 41/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 87.7188 - val_loss: 115.3681\n",
      "Epoch 42/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 86.1903 - val_loss: 114.3232\n",
      "Epoch 43/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 86.5152 - val_loss: 113.4716\n",
      "Epoch 44/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 86.6542 - val_loss: 114.4625\n",
      "Epoch 45/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 86.9440 - val_loss: 114.7947\n",
      "Epoch 46/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 85.0078 - val_loss: 114.9131\n",
      "Epoch 47/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 84.0299 - val_loss: 115.1321\n",
      "Epoch 48/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 84.0419 - val_loss: 115.8674\n",
      "Epoch 49/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 82.4944 - val_loss: 116.0722\n",
      "Epoch 50/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 82.6896 - val_loss: 115.3563\n",
      "Epoch 51/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 82.4141 - val_loss: 115.4390\n",
      "Epoch 52/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 81.8280 - val_loss: 116.0315\n",
      "Epoch 53/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 82.8189 - val_loss: 114.2473\n",
      "Epoch 54/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 85.2394 - val_loss: 115.8724\n",
      "Epoch 55/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 83.9394 - val_loss: 114.6359\n",
      "'########################################################Model4\n",
      "Epoch 1/300\n",
      "35/35 [==============================] - 2s 15ms/step - loss: 143.4054 - val_loss: 138.9541\n",
      "Epoch 2/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 133.5162 - val_loss: 130.1887\n",
      "Epoch 3/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 128.4647 - val_loss: 129.2776\n",
      "Epoch 4/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 131.6687 - val_loss: 154.2772\n",
      "Epoch 5/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 127.2287 - val_loss: 122.8724\n",
      "Epoch 6/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 121.6483 - val_loss: 120.1873\n",
      "Epoch 7/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 118.5751 - val_loss: 119.4482\n",
      "Epoch 8/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 118.0499 - val_loss: 120.8084\n",
      "Epoch 9/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 117.1742 - val_loss: 117.7729\n",
      "Epoch 10/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 113.8268 - val_loss: 117.5319\n",
      "Epoch 11/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 111.0503 - val_loss: 116.9095\n",
      "Epoch 12/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 110.0655 - val_loss: 118.0057\n",
      "Epoch 13/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 108.5778 - val_loss: 117.1282\n",
      "Epoch 14/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 109.2359 - val_loss: 118.2928\n",
      "Epoch 15/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 109.1772 - val_loss: 117.3684\n",
      "Epoch 16/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 107.5829 - val_loss: 116.3245\n",
      "Epoch 17/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 106.6793 - val_loss: 116.2815\n",
      "Epoch 18/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 105.0191 - val_loss: 115.9678\n",
      "Epoch 19/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 104.1224 - val_loss: 115.0578\n",
      "Epoch 20/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 102.0042 - val_loss: 115.1435\n",
      "Epoch 21/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 99.9191 - val_loss: 115.4403\n",
      "Epoch 22/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 98.7976 - val_loss: 115.6513\n",
      "Epoch 23/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 98.3667 - val_loss: 116.3851\n",
      "Epoch 24/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 95.3641 - val_loss: 116.9852\n",
      "Epoch 25/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 97.1513 - val_loss: 117.4150\n",
      "Epoch 26/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 98.5767 - val_loss: 117.6228\n",
      "Epoch 27/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 96.7733 - val_loss: 116.2361\n",
      "Epoch 28/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 99.5178 - val_loss: 118.2331\n",
      "Epoch 29/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 101.9117 - val_loss: 116.6942\n",
      "Epoch 30/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 97.6578 - val_loss: 117.5232\n",
      "Epoch 31/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 95.8004 - val_loss: 116.8200\n",
      "Epoch 32/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 97.1871 - val_loss: 118.1598\n",
      "Epoch 33/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 95.3486 - val_loss: 118.1723\n",
      "Epoch 34/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 94.2742 - val_loss: 116.7489\n",
      "Epoch 35/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 92.1477 - val_loss: 117.7785\n",
      "Epoch 36/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 90.9280 - val_loss: 117.4308\n",
      "Epoch 37/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 89.0687 - val_loss: 117.5808\n",
      "Epoch 38/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 87.6536 - val_loss: 118.6782\n",
      "Epoch 39/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 86.8891 - val_loss: 119.3128\n",
      "Epoch 40/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 87.8210 - val_loss: 117.9236\n",
      "Epoch 41/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 87.7661 - val_loss: 119.0211\n",
      "Epoch 42/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 85.3872 - val_loss: 119.2461\n",
      "Epoch 43/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 85.1549 - val_loss: 118.9383\n",
      "Epoch 44/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 87.1686 - val_loss: 120.2631\n",
      "Epoch 45/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 86.2561 - val_loss: 120.4946\n",
      "Epoch 46/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 83.9166 - val_loss: 120.1435\n",
      "Epoch 47/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 83.1973 - val_loss: 119.5042\n",
      "Epoch 48/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 82.3349 - val_loss: 118.6057\n",
      "Epoch 49/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 82.4579 - val_loss: 118.6455\n",
      "'########################################################Model5\n",
      "Epoch 1/300\n",
      "35/35 [==============================] - 2s 14ms/step - loss: 145.2139 - val_loss: 139.9181\n",
      "Epoch 2/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 136.3921 - val_loss: 130.3725\n",
      "Epoch 3/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 128.3878 - val_loss: 127.4549\n",
      "Epoch 4/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 127.6735 - val_loss: 123.4981\n",
      "Epoch 5/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 124.4428 - val_loss: 127.2132\n",
      "Epoch 6/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 123.7515 - val_loss: 121.9519\n",
      "Epoch 7/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 120.9364 - val_loss: 121.3678\n",
      "Epoch 8/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 123.3590 - val_loss: 133.1369\n",
      "Epoch 9/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 123.8623 - val_loss: 117.6723\n",
      "Epoch 10/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 118.5248 - val_loss: 114.2753\n",
      "Epoch 11/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 114.2958 - val_loss: 115.4247\n",
      "Epoch 12/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 110.2703 - val_loss: 114.7931\n",
      "Epoch 13/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 109.4741 - val_loss: 113.0485\n",
      "Epoch 14/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 108.6162 - val_loss: 114.0612\n",
      "Epoch 15/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 107.0424 - val_loss: 113.7237\n",
      "Epoch 16/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 104.2069 - val_loss: 113.9894\n",
      "Epoch 17/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 103.1378 - val_loss: 115.4890\n",
      "Epoch 18/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 101.1806 - val_loss: 114.2153\n",
      "Epoch 19/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 101.0249 - val_loss: 115.4571\n",
      "Epoch 20/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 105.7283 - val_loss: 115.4864\n",
      "Epoch 21/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 103.4295 - val_loss: 115.7618\n",
      "Epoch 22/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 102.5197 - val_loss: 115.4732\n",
      "Epoch 23/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 99.9345 - val_loss: 113.6138\n",
      "Epoch 24/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 97.8846 - val_loss: 113.7932\n",
      "Epoch 25/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 97.1276 - val_loss: 113.0064\n",
      "Epoch 26/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 96.4522 - val_loss: 114.2111\n",
      "Epoch 27/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 94.8597 - val_loss: 114.1472\n",
      "Epoch 28/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 93.4168 - val_loss: 113.7259\n",
      "Epoch 29/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 93.1183 - val_loss: 114.9264\n",
      "Epoch 30/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 92.0791 - val_loss: 114.5418\n",
      "Epoch 31/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 90.2601 - val_loss: 114.7859\n",
      "Epoch 32/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 90.1939 - val_loss: 113.6831\n",
      "Epoch 33/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 90.5026 - val_loss: 114.4762\n",
      "Epoch 34/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 90.7229 - val_loss: 115.3930\n",
      "Epoch 35/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 89.4772 - val_loss: 114.0875\n",
      "Epoch 36/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 89.0406 - val_loss: 114.1076\n",
      "Epoch 37/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 89.4941 - val_loss: 114.9276\n",
      "Epoch 38/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 87.4803 - val_loss: 112.8798\n",
      "Epoch 39/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 88.6545 - val_loss: 114.1765\n",
      "Epoch 40/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 88.9830 - val_loss: 114.5242\n",
      "Epoch 41/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 88.1017 - val_loss: 114.6972\n",
      "Epoch 42/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 89.8112 - val_loss: 114.9896\n",
      "Epoch 43/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 88.8277 - val_loss: 114.4612\n",
      "Epoch 44/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 88.0159 - val_loss: 115.2998\n",
      "Epoch 45/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 86.9607 - val_loss: 115.9331\n",
      "Epoch 46/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 85.4804 - val_loss: 116.6065\n",
      "Epoch 47/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 84.1796 - val_loss: 117.7419\n",
      "Epoch 48/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 84.7355 - val_loss: 116.8291\n",
      "Epoch 49/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 86.0811 - val_loss: 117.6110\n",
      "Epoch 50/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 84.7921 - val_loss: 116.4428\n",
      "Epoch 51/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 83.6901 - val_loss: 117.2217\n",
      "Epoch 52/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 82.8879 - val_loss: 116.8279\n",
      "Epoch 53/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 85.4692 - val_loss: 116.1472\n",
      "Epoch 54/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 83.7089 - val_loss: 117.4741\n",
      "Epoch 55/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 84.2727 - val_loss: 115.8387\n",
      "Epoch 56/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 83.5437 - val_loss: 117.0447\n",
      "Epoch 57/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 80.4903 - val_loss: 117.0714\n",
      "Epoch 58/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 80.9938 - val_loss: 115.8292\n",
      "Epoch 59/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 82.6021 - val_loss: 117.1243\n",
      "Epoch 60/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 81.9185 - val_loss: 116.9347\n",
      "Epoch 61/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 85.0973 - val_loss: 116.7296\n",
      "Epoch 62/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 81.2167 - val_loss: 117.3951\n",
      "Epoch 63/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 80.2340 - val_loss: 116.4649\n",
      "Epoch 64/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 79.4016 - val_loss: 116.9115\n",
      "Epoch 65/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 79.7270 - val_loss: 116.9778\n",
      "Epoch 66/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 79.3453 - val_loss: 117.6297\n",
      "Epoch 67/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 78.7585 - val_loss: 117.9628\n",
      "Epoch 68/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 78.3201 - val_loss: 117.6256\n",
      "'########################################################Model6\n",
      "Epoch 1/300\n",
      "35/35 [==============================] - 1s 11ms/step - loss: 146.7947 - val_loss: 134.5851\n",
      "Epoch 2/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 138.9648 - val_loss: 137.8126\n",
      "Epoch 3/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 133.9249 - val_loss: 126.9367\n",
      "Epoch 4/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 131.4381 - val_loss: 130.5408\n",
      "Epoch 5/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 131.6161 - val_loss: 132.3471\n",
      "Epoch 6/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 129.9383 - val_loss: 130.2737\n",
      "Epoch 7/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 124.5853 - val_loss: 124.1898\n",
      "Epoch 8/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 121.8165 - val_loss: 121.8685\n",
      "Epoch 9/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 120.0035 - val_loss: 118.2748\n",
      "Epoch 10/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 116.1808 - val_loss: 120.4294\n",
      "Epoch 11/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 113.6829 - val_loss: 116.5728\n",
      "Epoch 12/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 114.7930 - val_loss: 118.0443\n",
      "Epoch 13/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 112.4822 - val_loss: 117.5649\n",
      "Epoch 14/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 112.3592 - val_loss: 115.0476\n",
      "Epoch 15/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 109.8777 - val_loss: 115.8484\n",
      "Epoch 16/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 107.3667 - val_loss: 117.2242\n",
      "Epoch 17/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 106.6422 - val_loss: 115.8112\n",
      "Epoch 18/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 104.1729 - val_loss: 115.6721\n",
      "Epoch 19/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 105.9304 - val_loss: 115.7642\n",
      "Epoch 20/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 103.2971 - val_loss: 115.5625\n",
      "Epoch 21/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 100.5801 - val_loss: 117.8733\n",
      "Epoch 22/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 99.7320 - val_loss: 116.5968\n",
      "Epoch 23/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 98.9043 - val_loss: 115.4964\n",
      "Epoch 24/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 97.7284 - val_loss: 120.3678\n",
      "Epoch 25/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 103.3068 - val_loss: 117.0964\n",
      "Epoch 26/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 101.0471 - val_loss: 116.8543\n",
      "Epoch 27/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 98.0906 - val_loss: 116.2540\n",
      "Epoch 28/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 97.5501 - val_loss: 117.7020\n",
      "Epoch 29/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 96.7341 - val_loss: 117.1386\n",
      "Epoch 30/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 94.8710 - val_loss: 116.1624\n",
      "Epoch 31/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 94.1189 - val_loss: 118.7995\n",
      "Epoch 32/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 92.4018 - val_loss: 117.7208\n",
      "Epoch 33/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 91.9069 - val_loss: 117.2504\n",
      "Epoch 34/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 91.1053 - val_loss: 117.2489\n",
      "Epoch 35/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 90.1884 - val_loss: 117.3991\n",
      "Epoch 36/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 88.2790 - val_loss: 118.0761\n",
      "Epoch 37/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 89.2282 - val_loss: 117.6931\n",
      "Epoch 38/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 92.4276 - val_loss: 117.6424\n",
      "Epoch 39/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 92.6969 - val_loss: 115.8191\n",
      "Epoch 40/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 90.2934 - val_loss: 116.7568\n",
      "Epoch 41/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 89.0288 - val_loss: 117.0082\n",
      "Epoch 42/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 87.4614 - val_loss: 116.1983\n",
      "Epoch 43/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 86.3375 - val_loss: 116.9946\n",
      "Epoch 44/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 85.5938 - val_loss: 117.3758\n",
      "'########################################################Model7\n",
      "Epoch 1/300\n",
      "35/35 [==============================] - 1s 14ms/step - loss: 145.8263 - val_loss: 138.2937\n",
      "Epoch 2/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 136.8481 - val_loss: 134.4695\n",
      "Epoch 3/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 136.6112 - val_loss: 138.5823\n",
      "Epoch 4/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 132.5440 - val_loss: 128.7399\n",
      "Epoch 5/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 130.1210 - val_loss: 126.9805\n",
      "Epoch 6/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 127.1385 - val_loss: 126.5895\n",
      "Epoch 7/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 128.2362 - val_loss: 127.9684\n",
      "Epoch 8/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 122.4096 - val_loss: 123.9519\n",
      "Epoch 9/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 119.7250 - val_loss: 120.9443\n",
      "Epoch 10/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 119.4746 - val_loss: 123.4055\n",
      "Epoch 11/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 116.6498 - val_loss: 119.1912\n",
      "Epoch 12/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 115.0525 - val_loss: 120.6534\n",
      "Epoch 13/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 117.8277 - val_loss: 117.5153\n",
      "Epoch 14/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 115.0542 - val_loss: 118.7870\n",
      "Epoch 15/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 114.9420 - val_loss: 120.1010\n",
      "Epoch 16/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 111.8959 - val_loss: 115.2692\n",
      "Epoch 17/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 111.9635 - val_loss: 116.5619\n",
      "Epoch 18/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 110.3287 - val_loss: 119.6964\n",
      "Epoch 19/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 109.0482 - val_loss: 118.0323\n",
      "Epoch 20/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 106.8343 - val_loss: 120.0232\n",
      "Epoch 21/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 104.3965 - val_loss: 116.5027\n",
      "Epoch 22/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 104.3843 - val_loss: 118.3158\n",
      "Epoch 23/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 104.8671 - val_loss: 118.8127\n",
      "Epoch 24/300\n",
      "35/35 [==============================] - 0s 6ms/step - loss: 103.0923 - val_loss: 116.3136\n",
      "Epoch 25/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 101.0106 - val_loss: 116.6021\n",
      "Epoch 26/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 99.2166 - val_loss: 118.5887\n",
      "Epoch 27/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 97.9787 - val_loss: 118.5938\n",
      "Epoch 28/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 96.7430 - val_loss: 118.4430\n",
      "Epoch 29/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 95.6365 - val_loss: 118.3144\n",
      "Epoch 30/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 94.4979 - val_loss: 118.5119\n",
      "Epoch 31/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 93.9060 - val_loss: 118.8114\n",
      "Epoch 32/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 93.6856 - val_loss: 119.0982\n",
      "Epoch 33/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 92.7146 - val_loss: 121.0628\n",
      "Epoch 34/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 93.2417 - val_loss: 120.0180\n",
      "Epoch 35/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 91.8979 - val_loss: 117.3056\n",
      "Epoch 36/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 90.4855 - val_loss: 119.3808\n",
      "Epoch 37/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 88.8359 - val_loss: 118.6000\n",
      "Epoch 38/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 89.8654 - val_loss: 117.7184\n",
      "Epoch 39/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 92.8718 - val_loss: 118.1047\n",
      "Epoch 40/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 92.5982 - val_loss: 118.4977\n",
      "Epoch 41/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 90.6019 - val_loss: 119.2165\n",
      "Epoch 42/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 89.0136 - val_loss: 118.4671\n",
      "Epoch 43/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 89.1687 - val_loss: 116.9775\n",
      "Epoch 44/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 87.2975 - val_loss: 117.7478\n",
      "Epoch 45/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 86.7957 - val_loss: 117.1923\n",
      "Epoch 46/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 86.1654 - val_loss: 118.2948\n",
      "'########################################################Model8\n",
      "Epoch 1/300\n",
      "35/35 [==============================] - 2s 16ms/step - loss: 143.6586 - val_loss: 133.9326\n",
      "Epoch 2/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 131.8070 - val_loss: 131.3822\n",
      "Epoch 3/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 130.5630 - val_loss: 127.2432\n",
      "Epoch 4/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 125.2900 - val_loss: 122.6068\n",
      "Epoch 5/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 124.3977 - val_loss: 123.5282\n",
      "Epoch 6/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 120.2922 - val_loss: 118.8491\n",
      "Epoch 7/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 117.8803 - val_loss: 120.3019\n",
      "Epoch 8/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 115.5509 - val_loss: 118.5053\n",
      "Epoch 9/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 112.6067 - val_loss: 118.2623\n",
      "Epoch 10/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 117.0124 - val_loss: 124.6634\n",
      "Epoch 11/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 118.1751 - val_loss: 120.0588\n",
      "Epoch 12/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 114.5375 - val_loss: 121.7316\n",
      "Epoch 13/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 113.8030 - val_loss: 119.6753\n",
      "Epoch 14/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 113.8188 - val_loss: 120.0066\n",
      "Epoch 15/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 115.8693 - val_loss: 117.4471\n",
      "Epoch 16/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 111.1921 - val_loss: 114.8452\n",
      "Epoch 17/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 108.4929 - val_loss: 115.7590\n",
      "Epoch 18/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 106.9827 - val_loss: 116.2505\n",
      "Epoch 19/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 104.7932 - val_loss: 114.6597\n",
      "Epoch 20/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 107.4122 - val_loss: 116.1086\n",
      "Epoch 21/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 107.9041 - val_loss: 116.5506\n",
      "Epoch 22/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 105.3268 - val_loss: 116.1553\n",
      "Epoch 23/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 103.4892 - val_loss: 116.2379\n",
      "Epoch 24/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 101.7069 - val_loss: 115.3036\n",
      "Epoch 25/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 99.4049 - val_loss: 116.7061\n",
      "Epoch 26/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 99.3188 - val_loss: 116.1894\n",
      "Epoch 27/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 98.8734 - val_loss: 116.8940\n",
      "Epoch 28/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 97.1093 - val_loss: 117.2618\n",
      "Epoch 29/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 96.1049 - val_loss: 116.3361\n",
      "Epoch 30/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 94.0217 - val_loss: 117.4823\n",
      "Epoch 31/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 93.2073 - val_loss: 118.2172\n",
      "Epoch 32/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 91.6648 - val_loss: 116.9056\n",
      "Epoch 33/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 91.1334 - val_loss: 116.9852\n",
      "Epoch 34/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 93.9344 - val_loss: 117.0896\n",
      "Epoch 35/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 92.1391 - val_loss: 117.4363\n",
      "Epoch 36/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 90.9480 - val_loss: 117.3150\n",
      "Epoch 37/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 91.1436 - val_loss: 116.7092\n",
      "Epoch 38/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 90.7955 - val_loss: 117.2123\n",
      "Epoch 39/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 88.6778 - val_loss: 116.2961\n",
      "Epoch 40/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 87.4014 - val_loss: 116.9834\n",
      "Epoch 41/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 86.8035 - val_loss: 117.0200\n",
      "Epoch 42/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 85.4725 - val_loss: 116.7449\n",
      "Epoch 43/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 85.9902 - val_loss: 116.0915\n",
      "Epoch 44/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 85.0425 - val_loss: 118.2230\n",
      "Epoch 45/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 83.6226 - val_loss: 118.2221\n",
      "Epoch 46/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 83.3586 - val_loss: 117.9841\n",
      "Epoch 47/300\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 83.0060 - val_loss: 118.7126\n",
      "Epoch 48/300\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 83.3953 - val_loss: 119.0163\n",
      "Epoch 49/300\n",
      "35/35 [==============================] - 0s 5ms/step - loss: 82.9454 - val_loss: 117.4351\n",
      "'########################################################Model9\n"
     ]
    }
   ],
   "source": [
    "model_num = 10\n",
    "\n",
    "mase_models = train_bagging_models(model_num, MASE(y_train,24),300,30,8,0.0005)\n",
    "mape_models = train_bagging_models(model_num,'mape',300,30,8,0.0005)\n",
    "smape_models = train_bagging_models(model_num, SMAPE(),300,30,8,0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c961ec8-129c-4f36-a2dc-04b0b9661a19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 1s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(16.25598940938081, 3.2194907959716272)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred1,_=smape_models\n",
    "pred2,_=mase_models\n",
    "pred3,_=mape_models\n",
    "\n",
    "smape_predictions = bagging_predict2(pred1, test_X)\n",
    "mase_predictions = bagging_predict2(pred2, test_X)\n",
    "mape_predictions = bagging_predict2(pred3, test_X)\n",
    "concat_I = np.concatenate([smape_predictions, mase_predictions,mape_predictions],axis=0)\n",
    "fin_pred_I = np.median(concat_I,axis=0)\n",
    "#pd.DataFrame(fin_pred).to_csv(\"freezing_I.csv\")\n",
    "mean_squared_error(test_y.flatten(),fin_pred_I.flatten()),mean_absolute_error(test_y.flatten(),fin_pred_I.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02005ee4-9b13-4a5a-a2c3-d25441395630",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(fin_pred_I.reshape(-1,24)).to_csv(\"../result7_new/NBEATs_B/pred_mid_I.csv\")\n",
    "for i in range(10):\n",
    "    pd.DataFrame(concat_I[i].reshape(-1,24)).to_csv(f\"../result7_new/NBEATs_B/pred_I{i}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a104b3-22fb-46e4-855e-ca5e5202a204",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 일반블락"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df7fa618-a25e-48c5-9544-ca3e091f28ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 16:52:57.625926: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-09-23 16:52:57.625971: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ymlee2-desktop): /proc/driver/nvidia/version does not exist\n",
      "2024-09-23 16:52:57.626474: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'########################################################Model0\n",
      "'########################################################Model1\n",
      "'########################################################Model2\n",
      "'########################################################Model3\n",
      "'########################################################Model4\n",
      "'########################################################Model5\n",
      "'########################################################Model6\n",
      "'########################################################Model7\n",
      "'########################################################Model8\n",
      "'########################################################Model9\n",
      "'########################################################Model0\n",
      "'########################################################Model1\n",
      "'########################################################Model2\n",
      "'########################################################Model3\n",
      "'########################################################Model4\n",
      "'########################################################Model5\n",
      "'########################################################Model6\n",
      "'########################################################Model7\n",
      "'########################################################Model8\n",
      "'########################################################Model9\n",
      "'########################################################Model0\n",
      "'########################################################Model1\n",
      "'########################################################Model2\n",
      "'########################################################Model3\n",
      "'########################################################Model4\n",
      "'########################################################Model5\n",
      "'########################################################Model6\n",
      "'########################################################Model7\n",
      "'########################################################Model8\n",
      "'########################################################Model9\n",
      "'########################################################Model0\n",
      "'########################################################Model1\n",
      "'########################################################Model2\n",
      "'########################################################Model3\n",
      "'########################################################Model4\n",
      "'########################################################Model5\n",
      "'########################################################Model6\n",
      "'########################################################Model7\n",
      "'########################################################Model8\n",
      "'########################################################Model9\n",
      "'########################################################Model0\n",
      "'########################################################Model1\n",
      "'########################################################Model2\n",
      "'########################################################Model3\n",
      "'########################################################Model4\n",
      "'########################################################Model5\n",
      "'########################################################Model6\n",
      "'########################################################Model7\n",
      "'########################################################Model8\n",
      "'########################################################Model9\n"
     ]
    }
   ],
   "source": [
    "model_num = 10\n",
    "\n",
    "mase_models_G = train_bagging_models_G(model_num, MASE(y_train,24),300,30,8,0.0005)\n",
    "mape_models_G = train_bagging_models_G(model_num,'mape',300,30,8,0.0005)\n",
    "smape_models_G = train_bagging_models_G(model_num, SMAPE(),300,30,8,0.0005)\n",
    "mae_models_G = train_bagging_models_G(model_num,'mae',300,30,8,0.0005)\n",
    "mse_models_G = train_bagging_models_G(model_num,'mse',300,30,8,0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e75f04ad-3c0b-4c36-89ae-d856c3069a0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 2s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "pred1,_=smape_models_G\n",
    "pred2,_=mase_models_G\n",
    "pred3,_=mape_models_G\n",
    "pred4,_=mae_models_G\n",
    "pred5,_=mse_models_G\n",
    "smape_predictions_G = bagging_predict2(pred1, test_X)\n",
    "mase_predictions_G = bagging_predict2(pred2, test_X)\n",
    "mape_predictions_G = bagging_predict2(pred3, test_X)\n",
    "mae_predictions_G = bagging_predict2(pred4, test_X)\n",
    "mse_predictions_G = bagging_predict2(pred5, test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82b79ab4-6819-462b-a1e5-570dff369346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0157199503342074, 0.6563157007116968)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_G = np.concatenate([smape_predictions_G,mase_predictions_G,mape_predictions_G,mae_predictions_G,mse_predictions_G])\n",
    "fin_pred_G = np.mean(concat_G,axis=0)\n",
    "#pd.DataFrame(fin_pred).to_csv(\"freezing_I.csv\")\n",
    "np.sqrt(mean_squared_error(test_y.flatten(),fin_pred_G.flatten())),r2_score(test_y.flatten(),fin_pred_G.flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "123429bf-d328-490e-a747-4c9b5e253ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0009997822975467, 0.6662051029663056)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_G = np.concatenate([mase_predictions_G,mae_predictions_G,mse_predictions_G])\n",
    "fin_pred_G = np.mean(concat_G,axis=0)\n",
    "#pd.DataFrame(fin_pred).to_csv(\"freezing_I.csv\")\n",
    "np.sqrt(mean_squared_error(test_y.flatten(),fin_pred_G.flatten())),r2_score(test_y.flatten(),fin_pred_G.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d0ecdff-b2d2-44f1-8288-7469c7517106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0797487869773528, 0.6116197145442674)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_G = np.concatenate([smape_predictions_G],axis=0)\n",
    "fin_pred_G = np.median(concat_G,axis=0)\n",
    "np.sqrt(mean_squared_error(test_y.flatten(),fin_pred_G.flatten())),r2_score(test_y.flatten(),fin_pred_G.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9104f360-66c8-4cd9-9164-4ac0deb495a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.3428339603283617, 0.3993017606281618)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_G = np.concatenate([mape_predictions_G],axis=0)\n",
    "fin_pred_G = np.median(concat_G,axis=0)\n",
    "np.sqrt(mean_squared_error(test_y.flatten(),fin_pred_G.flatten())),r2_score(test_y.flatten(),fin_pred_G.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1384c3bc-9226-4cf5-9ac9-834eda2e51d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.006234880693363, 0.6627045655504646)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_G = np.concatenate([mase_predictions_G],axis=0)\n",
    "fin_pred_G = np.median(concat_G,axis=0)\n",
    "np.sqrt(mean_squared_error(test_y.flatten(),fin_pred_G.flatten())),r2_score(test_y.flatten(),fin_pred_G.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0dc3d80a-02a0-44d2-a9f0-251daaeeebe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.015525205022743, 0.6564474781558897)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_G = np.concatenate([mae_predictions_G],axis=0)\n",
    "fin_pred_G = np.median(concat_G,axis=0)\n",
    "np.sqrt(mean_squared_error(test_y.flatten(),fin_pred_G.flatten())),r2_score(test_y.flatten(),fin_pred_G.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af6f962f-49f4-4a9d-878b-71bcd3f148ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0051053811282102, 0.6634613694168919)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_G = np.concatenate([mse_predictions_G],axis=0)\n",
    "fin_pred_G = np.median(concat_G,axis=0)\n",
    "np.sqrt(mean_squared_error(test_y.flatten(),fin_pred_G.flatten())),r2_score(test_y.flatten(),fin_pred_G.flatten())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
